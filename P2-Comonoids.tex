% !TeX root = P2-Comonoids.tex
\documentclass[Book-Poly]{subfiles}

\begin{document}
%

\setcounter{chapter}{4}%Just finished 4.

\part{A different category of categories}\label{part.comon}

\Opensolutionfile{solutions}[solution-file5]

%------------ Chapter ------------%
\chapter{The composition product}\label{ch.comon.comp}


% In this chapter we will discuss a monoidal structure on $\poly$ that is quite easy from the mathematical point of view---it is simply composition---but which is again remarkable both in terms of its semantics and the phenomena that emerge mathematically, as we will see in later chapters. 

% In particular, we will see that the comonoids for the composition monoidal structure on $\poly$ are precisely categories. However, the morphisms are different---they are often called \emph{cofunctors}---and so we get a second category $\smcat^\sharp$ of categories and cofunctors. But the core groupoids of each---the groupoid of small categories and all functor isomorphisms between them, as well as the groupoid of small categories and all cofunctor isomorphisms between them---are isomorphic as groupoids. In other words, the following slogan is justified:
% \slogan{Polynomial comonads are precisely categories.}

% Cofunctors are not too familiar, but we will explain how to think of them in a variety of ways. We will see that whereas a functor $\cat{C}\to\cat{D}$ gives a kind of ``picture'' of $\cat{C}$ inside $\cat{D}$, a cofunctor $\cat{C}\cof\cat{D}$ gives a kind of $\cat{D}$-shaped ``crystallization'' of $\cat{C}$, one that is intuitively more geometric, more like creating neighborhoods. We will see in \cref{chapter.bimod} that there is another kind of morphism between comonoids, namely the bimodules, that are perhaps more familiar: they are the so-called \emph{parametric right adjoints}, or in perhaps more friendly terms, \emph{data migration functors} between copresheaf categories.

% The plan for this part is to first introduce what is perhaps the most interesting monoidal structure on $\poly$, namely the composition product; we do so in this chapter. We'll give a bunch of examples and ways to think about it in terms that relate to dynamical systems and our work so far. Then in \cref{sec.comonoids_in_poly} we'll discuss comonoids in $\poly$ and explain why they are categories in down-to-earth, set-theoretic terms. We will also discuss the morphisms between them.

% Finally in \cref{sec.cofree} we will discuss the cofree comonoid construction that takes any polynomial and returns a category. We will show how it relates to decision trees, as one may see in combinatorial game theory.

%%%%% ** old preamble above




We have seen that the category $\poly$ of polynomial functors has quite a bit of well-interoperating mathematical structure. Further, it is an expressive way to talk about dynamical systems that can change their interfaces and wiring patterns based on their internal states.

But we touched upon one thing---what in some sense is the most interesting part of the story---only briefly. That thing is quite simple to state, and yet has profound consequences. Namely, polynomials can be composed:
\[
\yon^\2\circ(\yon+\1)=(\yon+\1)^\2\iso\yon^\2+\2\yon+\1.
\]
What could be simpler?

It turns out that this operation, which we'll see soon is a monoidal product, has a lot to do with time.
There is a strong sense---made precise in \cref{prop.poly_closed_comp}---in which the polynomial $p\circ q$ represents ``starting at a position $i$ in $p$, choosing a direction in $p[i]$, landing at a position $j$ in $q$, choosing a direction in $q[j]$, and then landing... somewhere.''
This is exactly what we need to run through multiple steps of a dynamical system, the very thing we didn't know how to do in \cref{ex.do_nothing}.
We'll continue that story in \cref{subsec.comon.comp.def.dyn_sys}.

The composition product has many surprises up its sleeve, as we'll see in the following chapters.
We've given you a glimpse of some of them already in \cref{sec.poly.intro.math_theory}.
We won't amass all the rest here; instead, we'll take you through the story step by step.
But as a preview, $\circ$ will get us into decision trees, databases, and more dynamics, as well as the interactions between these.

%-------- Section --------%
\section{Defining the composition product}\label{sec.comon.comp.def}
We begin with the definition of the composition product in terms of polynomials as functors.

\subsection{Composite functors}\label{subsec.comon.comp.def.functor}

\begin{definition}[Composition product] \label{def.comp}
Given polynomial functors $p, q$, we let $p \circ q$ denote their \emph{composition product}, or their composite as functors.
That is, $p \circ q \colon \smset \to \smset$ sends each set $X$ to the set $p(q(X))$.
\end{definition}

Functor composition gives a monoidal structure on the category $\smset^\smset$ of functors $\smset\to\smset$, but to check that the full subcategory $\poly$ of $\smset^\smset$ inherits this monoidal structure, we need to verify that the composite of two functors in $\poly$ is still a functor in $\poly$.

\begin{proposition}\label{prop.poly_closed_comp}
Suppose $p,q\in\poly$ are polynomial functors $p,q\colon\smset\to\smset$. Then their composite $p\circ q$ is again a polynomial functor, and we have the following isomorphism:
\begin{equation} \label{eqn.composite_formula_circ}
p\circ q\iso\sum_{i\in p(\1)}\prod_{a\in p[i]}\sum_{j\in q(\1)}\prod_{b\in q[j]}\yon.
\end{equation}
\end{proposition}
\begin{proof}
We can rewrite $p$ and $q$ as
\[
p\iso\sum_{i\in p(\1)}\yon^{p[i]}\iso\sum_{i\in p(\1)}\prod_{a\in p[i]}\yon
\qqand
q\iso\sum_{j\in q(\1)}\yon^{q[j]}\iso\sum_{j\in q(\1)}\prod_{b\in q[j]}\yon.
\]
For any set $X$ we have $(p\circ q)(X)=p(q(X))=p(\sum_j\prod_b X)=\sum_i\prod_a\sum_j\prod_bX$, so \eqref{eqn.composite_formula_circ} is indeed the formula for the composite $p \circ q$.
To see this is a polynomial, we use \eqref{eqn.push_prod_sum_set_indep}, which says we can rewrite the $\prod\sum$ in \eqref{eqn.composite_formula_circ} as a $\sum\prod$ to obtain
\begin{align}\label{eqn.composite_formula_sums_first_circ}
  p\circ q\iso
  \scalebox{1.3}{$\displaystyle
  \sum_{i\in p(\1)} \; \sum_{\bar{j_i}\colon p[i]\to q(\1)}\yon^{\sum_{a\in p[i]}q[\bar{j_i}(a)]}$}
\end{align}
(written slightly bigger for clarity), which is clearly a polynomial.
\end{proof}

\begin{corollary} \label{cor.comp_monoidal}
The category $\poly$ has a monoidal structure $(\yon,\circ)$, where $\yon$ is the identity functor and $\circ$ is given by composition.
\end{corollary}

Because we may wish to use $\circ$ to denote composition in arbitrary categories, we use a special symbol for polynomial composition, namely
\[
p\tri q\coloneqq p\circ q.
\]
The symbol $\tri$ looks a bit like the composition symbol in that it is an open shape, and when writing quickly by hand, it's okay if it morphs into a $\circ$.
But $\tri$ highlights the asymmetry of composition, in contrast with the other monoidal structures on $\poly$ we've encountered.
Moreover, we'll soon see that $\tri$ is quite evocative in terms of trees.
For each $n\in\nn$, we'll also use $p\tripow{n}$ to denote the $n$-fold composite of $p$, i.e.\ $n$ copies of $p$ all composed with each other.\footnote{When we say ``the $n$-fold composition product of $p$,'' we mean $n$ copies of $p$ all composed with each other; but when we discuss an ``$n$-fold composition product'' in general, we refer to an arbitrary composition product of $n$ polynomials that may or may not all be equal to each other. This will apply to composition products of lenses as well, once we define those.}
In particular, $p\tripow0=\yon$ and $p\tripow1=p$.

We repeat the important formulas from \cref{prop.poly_closed_comp} and its proof in the new notation:
\begin{equation}\label{eqn.composite_formula}
p\tri q\iso\sum_{i\in p(\1)}\prod_{a\in p[i]}\sum_{j\in q(\1)}\prod_{b\in q[j]}\yon.
\end{equation}

\begin{align}\label{eqn.composite_formula_sums_first}
  p\tri q\iso
  \scalebox{1.3}{$\displaystyle
  \sum_{i\in p(\1)} \; \sum_{\bar{j_i}\colon p[i]\to q(\1)}\yon^{\sum_{a\in p[i]}q[\bar{j_i}(a)]}$}
\end{align}

% \[
% \begin{tikzpicture}[polybox, baseline=(helper)]
% 	\node[poly] (p) {$a:p[i]$\at$i:p(\1)$};
% 	\node[poly, above=of p] (q) {$b:q[j]$\at$j:q(\1)$};
% 	\coordinate (helper) at ($(p.north)!.5!(q.south)$);
% \end{tikzpicture}
% \quad\cong\quad
% \begin{tikzpicture}[polybox, baseline=(p.east)]
% 	\node[poly] (p) {$(a:p[i], b:q[j(a)]$)\at$(i:p(1), j: p[i]\to q(\1))$};
% \end{tikzpicture}
% \]

\begin{exercise}
Let's consider \eqref{eqn.composite_formula_sums_first} piece by piece, with concrete polynomials $p\coloneqq\yon^\2+\yon^\1$ and $q\coloneqq \yon^\3+\1$.
\begin{enumerate}
	\item What is $\yon^\2\tri q$? 
	\item What is $\yon^\1\tri q$?
	\item What is $(\yon^\2+\yon^\1)\tri q$? This is what $p\tri q$ ``should be.''
	\item How many functions $\bar{j_1}\colon p[1]\to q(\1)$ are there?
	\item For each function $\bar{j_1}$ as above, what is $\sum_{a\in p[1]} q[\bar{j_1}(a)]$?
	\item How many functions $\bar{j_2}\colon p[2]\to q(\1)$ are there?
	\item For each function $\bar{j_2}$ as above, what is $\sum_{a\in p[2]} q[\bar{j_2}(a)]$?
	\item Write out \[\sum_{i\in p(\1)}\;\sum_{\bar{j_i}\colon p[i]\to q(\1)}\yon^{\sum_{a\in p[i]}q[\bar{j_i}(a)]}.\]
	Does the result agree with what $p\tri q$ should be?
\qedhere
\end{enumerate}
\begin{solution}
We are given $p\coloneqq\yon^\2+\yon^\1$ and $q\coloneqq \yon^\3+\1$.
\begin{enumerate}
    \item By standard polynomial multiplication, we have that $\yon^\2 \tri q \iso q \times q \iso \yon^\6 + \2\yon^\3 + \1$.
    \item We have that $\yon^\1 \tri q \iso q \iso \yon^\3 + \1$.
    \item Combining the previous parts, we have that $(\yon^\2 + \yon^\1) \tri q \iso q \times q + q \iso \yon^\6 + \3\yon^\3 + \2$.
    \item Since $p[1] \iso \2$ and $q(\1) \iso \2$, there are $2^2 = 4$ functions $p[1] \to q(\1)$.
    \item When $\bar{j_1} \colon p[1] \to q(\1)$ is one of the two possible bijections, we have that
    \[
        \sum_{a \in p[1]} q[\bar{j_1}(a)] \iso q[1] + q[2] \iso \3 + \0 \iso \3.
    \]
    When $\bar{j_1} \colon p[1] \to q(\1)$ sends everything to $1 \in q(\1)$, we have that
    \[
        \sum_{a \in p[1]} q[\bar{j_1}(a)] \iso q[1] + q[1] \iso \3 + \3 \iso \6.
    \]
    Finally, when $\bar{j_1} \colon p[1] \to q(\1)$ sends everything to $2 \in q(\1)$, we have that
    \[
        \sum_{a \in p[1]} q[\bar{j_1}(a)] \iso q[2] + q[2] \iso \0 + \0 \iso \0.
    \]
    \item Since $p[2] \iso \1$ and $q(\1) \iso \2$, there are $2^1 = 2$ functions $p[2] \to q(\1)$.
    \item When $j_2 \colon p[2] \to q(\1)$ maps to $1 \in q(\1)$, we have that $\sum_{a \in p[2]} q[\bar{j_2}(a)] \iso q[1] \iso \3$, and when $\bar{j_2} \colon p[2] \to q(\1)$ maps to $2 \in q(\1)$, we have that $\sum_{a \in p[2]} q[\bar{j_2}(a)] \iso q[2] \iso \0$.
    \item From the previous parts, we have that
    \[
        \sum_{i\in p(\1)}\;\sum_{\bar{j_i}\colon p[i]\to q(\1)}\yon^{\sum_{a\in p[i]}q[j_i(a)]} \iso (\2\yon^\3 + \yon^\6 + \yon^\0) + (\yon^\3 + \yon^\0) \iso \yon^\6 + \3\yon^\3 + \2,
    \]
    which agrees with what $p \tri q$ should be.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}\label{exc.composites_of_specials}
\begin{enumerate}
	\item If $p$ and $q$ are representable, show that $p\tri q$ is too. Give a formula for it.
	\item If $p$ and $q$ are linear, show that $p\tri q$ is too. Give a formula for it.
	\item If $p$ and $q$ are constant, show that $p\tri q$ is too. Give a formula for it.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
	\item Given representable polynomials $p \coloneqq \yon^A$ and $q \coloneqq \yon^B$, we have that $p \tri q \iso \left(\yon^B\right)^A \iso \yon^{AB}$, which is also representable.
	\item Given linear polynomials $p \coloneqq A\yon$ and $q \coloneqq B\yon$, we have that $p \tri q \iso A(B\yon) \iso AB\yon$, which is also linear.
	\item Given constant polynomials $p \coloneqq A$ and $q \coloneqq B$, we have that $p \tri q \iso A$, which is also constant (see also \cref{exc.composing_with_constants}).
\end{enumerate}
\end{solution}
\end{exercise}

We know how $\tri$ acts on the objects in $\poly$, but what does it do to the morphisms between them?
For any pair of natural transformations $f\colon p\to p'$ and $g\colon q\to q'$ between polynomial functors, their composition product $f\tri g\colon p\tri q\to p'\tri q'$ is given by \emph{horizontal composition}.

\begin{definition}[Horizontal composition of natural transformations]\label{def.horiz_comp_nat_trans}
Let $f\colon p\to p'$ and $g\colon q\to q'$ be two natural transformations between (polynomial) functors $p,p',q,q'\colon\smset\to\smset$.
Then the \emph{horizontal composite} of $f$ and $g$, denoted $f\tri g$, is the natural transformation $p\tri q\to p'\tri q'$ whose $X$-component for each $X\in\smset$ is the function
\begin{equation} \label{eqn.horiz_comp_nat_trans_comp}
    p(q(X)) \To{f_{q(X)}} p'(q(X)) \To{p'(g_X)} p'(q'(X))
\end{equation}
obtained by composing the $q(X)$-component of $f$ with the functor $p'$ applied to the $X$-component of $g$.
\end{definition}

\begin{exercise}
Show that we could have replaced the composite function \eqref{eqn.horiz_comp_nat_trans_comp} in \cref{def.horiz_comp_nat_trans} with the function
\begin{equation} \label{eqn.horiz_comp_nat_trans_comp2}
    p(q(X)) \To{p(g_X)} p(q'(X)) \To{f_{q'(X)}} p'(q'(X))
\end{equation}
obtained by composing $p$ applied to the $X$-component of $g$ with the $q'(X)$-component of $f$, without altering the definition.
\begin{solution}
We wish to show that \eqref{eqn.horiz_comp_nat_trans_comp2} could replace \eqref{eqn.horiz_comp_nat_trans_comp} in \cref{def.horiz_comp_nat_trans}.
We claim that \eqref{eqn.horiz_comp_nat_trans_comp} and \eqref{eqn.horiz_comp_nat_trans_comp2} are in fact the same function; that is, that the following square commutes:
\[
\begin{tikzcd}
    p(q(X)) \ar[r, "f_{q(X)}"]\ar[d, "p(g_X)"'] & p'(q(X)) \ar[d, "p'(g_X)"] \\
    p(q'(X)) \ar[r, "f_{q'(X)}"'] & p'(q'(X))
\end{tikzcd}
\]
Indeed it does, by the naturality of $f$.
\end{solution}
\end{exercise}

\begin{remark}
There are two very different notions of lens composition floating around, so we'll try to mitigate confusion by standardizing terminology here.
We'll reserve the term \emph{composite lens} for lenses $h\then j\colon r\to t$ obtained by composing a lens $h\colon r\to s$ with a lens $j\colon s\to t$, according to the composition rule of the category $\poly$.
This corresponds to \emph{vertical composition} of natural transformations.
This is also the kind of composition we will mean whenever we use the verb ``\emph{compose},'' if the objects of that verb are lenses.

Meanwhile, we'll use the term \emph{composition product (of lenses)} for lenses $f\tri g\colon p\tri q\to p'\tri q'$ obtained by applying the monoidal product functor $\tri\colon\poly\times\poly\to\poly$ on the lenses $f\colon p\to p'$ and $g\colon q\to q'$.
This corresponds to \emph{horizontal composition} of natural transformations.
In this case, we'll use the verb phrase ``\emph{taking the monoidal product}.''

On the other hand, we'll use the terms ``composite'' and ``composition product'' interchangeably to refer to polynomials $p\tri q$, obtained by composing $p,q\in\poly$ as functors or, equivalently, applying the monoidal product functor $\tri$ on them---as there is no risk of confusion here.

This is another reason we tend to avoid the symbol $\circ$, preferring to use $\then$ for vertical composition and $\tri$ for horizontal composition.
Of course, if you're ever confused, you can always check whether the codomain of the first lens matches up with the domain of the second.
If they don't, we must be taking their monoidal product.
\end{remark}

The composition product of polynomials and lenses will be extremely important in the story that follows.
However, we only sometimes think of it as the composition of functors and the horizontal composition of natural transformations; more often we think of it as certain operations on arenas or corolla forests.

\subsection{Composite arenas}\label{subsec.comon.comp.def.arena}

Let us interpret our formula \eqref{eqn.composite_formula_sums_first} for the composite of two polynomials in terms of what it says about the positions and directions of the corresponding arenas.
The position-set of $p \tri q$ is
\begin{equation} \label{eqn.comp_pos}
    (p \tri q)(\1) \iso \sum_{i \in p(\1)} \; \sum_{\bar{j_i} \colon p[i] \to q(1)} \1 \iso \sum_{i \in p(\1)} \smset(p[i], q(\1)).
\end{equation}
In other words, specifying a position of $p \tri q$ amounts to first specifying a $p$-position $i$, then specifying a function $\bar{j_i} \colon p[i] \to q(\1)$, i.e.\ a $q$-position $\bar{j_i}(a)$ for each $p[i]$-direction $a$.

Given such a position $(i, \bar{j_i})$ of $p \tri q$, the direction-set of $p \tri q$ at $(i, \bar{j_i})$ is
\begin{equation} \label{eqn.comp_dir}
    (p \tri q)[(i, \bar{j_i})] \iso \sum_{a \in p[i]} q[\bar{j_i}(a)].
\end{equation}
So a direction of $p \tri q$ at $(i, \bar{j_i})$ consists of a $p[i]$-direction $a$ and a $q[\bar{j_i}(a)]$-direction.

While this description completely characterizes $p \tri q$ as an arena, it may be a bit tricky to wrap your head around.
Here is an alternative perspective that can help us get a better intuition for what's going on with composite arenas.

Back in \cref{subsec.poly.func_nat.repr_sum.dep_sum_prod_set}, we saw how to write the instructions for choosing an element of a dependent sum or product of sets.
For instance, given a polynomial $p$ and a set $X$, the instructions for choosing an element of
\[
    p\tri X=p(X)\iso\sum_{i\in p(\1)}\prod_{a\in p[i]}X
\]
would be written as follows.
\begin{quote}
To choose an element of $p(X)$: 
\begin{enumerate}
    \item choose an element $i\in p(\1)$;
    \item for each element $a\in p[i]$:
    \begin{enumerate}[label*=\arabic*.]
        \item choose an element of $X$.
    \end{enumerate}
\end{enumerate}
\end{quote}
But say we hadn't picked a set $X$ yet; in fact, say we might replace $X$ with a general polynomial instead.
We'll replace ``an element of $X$'' with a placeholder---the words ``a future''---that indicates that we don't yet know what will go there.
Furthermore, to highlight that these instructions are associated with some polynomial $p$, we will use our familiar arena terminology of positions and directions.
\begin{quote}
The instructions associated with a polynomial $p$ are:
\begin{enumerate}
    \item choose a $p$-position $i$;
    \item for each $p[i]$-direction $a$:
    \begin{enumerate}[label*=\arabic*.]
        \item choose a future.
    \end{enumerate}
\end{enumerate}
\end{quote}

If we think of polynomials in terms of their instructions, then \eqref{eqn.composite_formula} tells us that the composition product simply nests one set of instructions within another, as follows.
\begin{quote}
The instructions associated with a polynomial $p\tri q$ are:
\begin{enumerate}
    \item choose a $p$-position $i$;
    \item for each $p[i]$-direction $a$:
    \begin{enumerate}[label*=\arabic*.]
        \item choose a $q$-position $j$;
        \item for each $q[j]$-direction $b$:
        \begin{enumerate}[label*=\arabic*.]
            \item choose a future.
        \end{enumerate}
    \end{enumerate}
\end{enumerate}
\end{quote}
Similarly, we could write down the instructions associated with any $n$-fold composite by nesting even further.
We might think of such instructions as specifying some sort of length-$n$ \emph{strategy}, in the sense of game theory, for picking positions given any directions---except that the opponent is somehow abstract, having no positions of its own.

When we rewrite \eqref{eqn.composite_formula} \eqref{eqn.composite_formula_sums_first}, we are collapsing the instructions down into the following, highlighting the positions and directions of $p\tri q$.
\begin{quote}
The instructions associated with a polynomial $p\tri q$ are:
\begin{enumerate}
    \item choose a $p$-position $i$ and, for each $p[i]$-direction $a$, a $q$-position $\bar{j}_i(a)$;
    \item for each $p[i]$-direction $a$ and each $q[\bar{j}_i(a)]$-direction $b$:
    \begin{enumerate}[label*=\arabic*.]
        \item choose a future.
    \end{enumerate}
\end{enumerate}
\end{quote}
We will see in \cref{subsec.comon.comp.def.corolla} that these instructions have a very natural interpretation when we translate from arenas to corolla forests.

\begin{exercise}
\begin{enumerate}
	\item Let $p$ be an arbitrary polynomial. Write out the (uncollapsed) instructions associated with $p\tripow3=p\tri p\tri p$.
	\item Write out the (uncollapsed) instructions for choosing an element of $p\tri p\tri\1$, but where you would normally write ``choose an element of $\1$,'' just write ``done.'' \qedhere
\end{enumerate}
\begin{solution}
\begin{longenum}
    \item The instructions associated with a polynomial $p\tri p\tri p$ are:
    \begin{enumerate}
        \item choose a $p$-position $i$;
        \item for each $p[i]$-direction $a$:
        \begin{enumerate}[label*=\arabic*.]
            \item choose a $p$-position $i'$;
            \item for each $p[i']$-direction $a'$:
            \begin{enumerate}[label*=\arabic*.]
                \item choose a $p$-position $i''$;
                \item for each $p[i'']$-direction $a''$:
                \begin{enumerate}[label*=\arabic*.]
                    \item choose a future.
                \end{enumerate}
            \end{enumerate}
        \end{enumerate}
    \end{enumerate}
    \item To choose an element of $p\tri p\tri\1$:
    \begin{enumerate}
        \item choose a $p$-position $i$;
        \item for each $p[i]$-direction $a$:
        \begin{enumerate}[label*=\arabic*.]
            \item choose a $p$-position $i'$;
            \item for each $p[i']$-direction $a'$:
            \begin{enumerate}[label*=\arabic*.]
                \item done.
            \end{enumerate}
        \end{enumerate}
    \end{enumerate}
\end{longenum}

\end{solution}
\end{exercise}

But how does the composition product act on lenses between arenas?
Given lenses $f\colon p\to p'$ and $g\colon q\to q'$, we can translate them to natural transformations, take their horizontal composite, then translate this back to a lens.
The following exercise guides us through this process.

\begin{exercise}[The composition product of lenses] \label{exc.comp_prod_lens}
Fix lenses $f\colon p\to p'$ and $g\colon q\to q'$.
We seek to characterize their composition product $f\tri g\colon p\tri q\to p'\tri q'$.
\begin{enumerate}
    \item\label{exc.comp_prod_lens.1} Use \cref{prop.morph_arena_to_func} to compute the $q(X)$-component of $f$ as a natural transformation.
    \item\label{exc.comp_prod_lens.2} Use \cref{prop.poly_on_functions,prop.morph_arena_to_func} to compute $p'$ applied to the $X$-component of $g$ as a natural transformation.
    \item\label{exc.comp_prod_lens.3} Combine \cref{exc.comp_prod_lens.1} and \cref{exc.comp_prod_lens.2} using \cref{def.horiz_comp_nat_trans} to compute the horizontal composite $f\tri g$ of $f$ and $g$ as natural transformations.
    \item Use \cref{cor.morph_func_to_arena} to translate the natural transformation $f\tri g$ obtained in \cref{exc.comp_prod_lens.3} to a lens between arenas $p\tri q\to p'\tri q'$.
    Verify that for each $(i,\bar{j}_i)$ in $(p\tri q)(\1)$ (see \eqref{eqn.comp_pos}), its on-positions function sends
    \begin{equation} \label{eqn.comp_lens_pos}
        (i,\bar{j}_i)\Mapsto{(f\:\tri\:g)_\1}\left(f_\1(i), f^\sharp_i\then\bar{j}_i\then g_\1\right);
    \end{equation}
    while for each $(a',b')$ in $(p'\tri q')[(f_\1(i), f^\sharp_i\then\bar{j}_i\then g_\1)]$ (see \eqref{eqn.comp_dir}), its on-directions function sends
    \begin{equation} \label{eqn.comp_lens_dir}
        (a',b')\Mapsto{(f\:\tri\:g)^\sharp_{(i,\bar{j}_i)}}\left(f^\sharp_i(a'), g^\sharp_{\bar{j}_i(f^\sharp_i(a'))}(b')\right).
    \end{equation}
    \qedhere
\end{enumerate}
\begin{solution}
We have lenses $f\colon p\to p'$ and $g\colon q\to q'$.
\begin{enumerate}
    \item By \cref{prop.morph_arena_to_func}, the $q(X)$-component of $f$ is a function $f_{q(X)}\colon p(q(X))\to p'(q(X))$ that sends every $(i,h)$ with $i\in p(\1)$ and $h\colon p[i]\to q(X)$ to $(f_\1(i),f^\sharp_i\then h)$.
    We can think of the function $h\colon p[i]\to q(X)$ equivalently as a function $\bar{j}_i\colon p[i]\to q(\1)$ and, for each $a\in p[i]$, a function $h_a\colon q[\bar{j}_i(a)]\to X$.
    So $f_{q(X)}\colon (p\tri q)(X)\to (p'\tri q)(X)$ sends \[(i,\bar{j}_i,(h_a)_{a\in p[i]})\mapsto\left(f_\1(i),f^\sharp_i\then\bar{j}_i,\left(h_{f^\sharp_i(a')}\right)_{a'\in p'[f_\1(i)]}\right).\]
    
    \item By \cref{prop.morph_arena_to_func}, the $X$-component of $g$ is a function $g_X\colon q(X)\to q'(X)$ that sends every $(j,k)$ with $j\in q(\1)$ and $k\colon q[j]\to X$ to $(g_\1(j),g^\sharp_j\then k)$ in $q'(X)$.
    Then by \cref{prop.poly_on_functions}, applying $p'$ to this $X$-component yields a function $p'(q(X))\to p'(q'(X))$ that sends every $(i',\bar{j'}_{i'},(h'_{a'})_{a'\in p'[i']})$ with $i'\in p'(\1)$ as well as $\bar{j'}_{i'}\colon p'[i']\to q(\1)$ and $h'_{a'}\colon q[\bar{j'}_{i'}(a')]\to X$ to \[\left(i',\bar{j'}_{i'}\then g_\1,\left(g^\sharp_{\bar{j'}_{i'}(a')}\then h'_{a'}\right)_{a'\in p'[i']}\right).\]
    
    \item By \cref{def.horiz_comp_nat_trans}, the horizontal composite of $f$ and $g$ is the natural transformation $f\tri g\colon p\tri p'\to q\tri q'$ whose $X$-component is the composite of the answers to \cref{exc.comp_prod_lens.1} and \cref{exc.comp_prod_lens.2}, sending
    \begin{align*}
        (i,\bar{j}_i,(h_a)_{a\in p[i]})&\mapsto\left(f_\1(i),f^\sharp_i\then\bar{j}_i,\left(h_{f^\sharp_i(a')}\right)_{a'\in p'[f_\1(i)]}\right)\\
        &\mapsto\left(f_\1(i),f^\sharp_i\then\bar{j}_i\then g_\1, \left(g^\sharp_{\bar{j}_{i}(f^\sharp_i(a'))}\then h_{f^\sharp_i(a')}\right)_{a'\in p'[f_\1(i)]}\right).
    \end{align*}
    
    \item We use \cref{cor.morph_func_to_arena} to translate the answer to \cref{exc.comp_prod_lens.3} into a lens $f\tri g\colon p\tri q\to p'\tri q'$, as follows.
    Its on-positions function is the $\1$-component $(f\tri g)_\1$, which sends every $(i,\bar{j}_i)$ with $i\in p(\1)$ and $\bar{j}_i\colon p[i]\to q(\1)$ to
    \[
        (f_\1(i),f^\sharp_i\then\bar{j}_i\then g_\1).
    \]
    Then for each such $(i,\bar{j}_i)$, if we apply the $(p\tri q)[(i,\bar{j}_i)]$-component of $f\tri g$ to the element $(i,\bar{j}_i,(\iota_d)_{a\in p[i]})$, where $\iota_d\colon q[\bar{j}_i(a)]\to(p\tri q)[(i,\bar{j}_i)]\iso\sum_{a\in p[i]}q[\bar{j}_i(a)]$ is the canonical inclusion, then take the last coordinate of the result, we obtain for each $a'\in p'[f_\1(i)]$ the function
    \[
        q'[g_\1(\bar{j}_i(f^\sharp_i(a')))] \To{g^\sharp_{\bar{j}_{i}(f^\sharp_i(a'))}} q[\bar{j}_i(f^\sharp_i(a'))] \To{\iota_{f^\sharp_i(a')}} \sum_{a\in p[i]}q[\bar{j}_i(a)] \iso (p\tri q)[(i,\bar{j}_i)].
    \]
    These can equivalently be thought of as a single function from
    \[
        \sum_{a'\in p'[f_\1(i)]} q'[g_\1(\bar{j}_i(f^\sharp_i(a')))] \iso (p'\tri q')[(f\tri g)_\1(i,\bar{j}_i)]
    \]
    which \cref{cor.morph_func_to_arena} tells us is the on-directions function of $f\tri g$ at $(i,\bar{j}_i)$, that sends every $(a',b')$ with $a'\in p'[f_\1(i)]$ and $b'\in q'[g_\1(\bar{j}_i(f^\sharp_i(a')))]$ to
    \[
        \left(f^\sharp_i(a'), g^\sharp_{\bar{j}_i(f^\sharp_i(a'))}(b')\right).
    \]
\end{enumerate}
\end{solution}
\end{exercise}

So what does \cref{exc.comp_prod_lens} tell us about the behavior of $f\tri g\colon p\tri q\to p'\tri q'$?
By \eqref{eqn.comp_lens_pos}, on positions, $f\tri g$ takes a $p$-position $i$ and sends it to the $p'$-position $f_\1(i)$; then for each direction $a'$ at this position, the associated $q'$-position is obtained by sending $a'$ back to a $p[i]$-direction via $f^\sharp_i$, checking what $q$-position is associated to that $p[i]$-direction via some $\bar{j}_i$, then sending that $q$-position forward again to a $q'$-position via $g_\1$.

Then by \eqref{eqn.comp_lens_pos}, on directions, $f\tri g$ sends a direction of $p'$ back to a direction of $p$ via an on-directions function of $f$, then sends a direction of $q'$ back to a direction of $q$ via an on-directions funtion of $g$.
We'll get a better sense of what's happening when we see this drawn out as corolla forests in \cref{ex.comp_prod_trees}.

\subsection{Composite corolla forests} \label{subsec.comon.comp.def.corolla}

It turns out that the forest of $p\tri q$ is given by gluing $q$-corollas onto the leaves of $p$-corollas in every possible way.
We will demonstrate this using an example.

Let's say $p\coloneqq\yon^\2+\yon$ and $q\coloneqq\yon^\3+\1$, whose corolla forests we draw as follows:
\begin{equation}\label{eqn.pq_misc39}
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, blue!50!black, "\color{blue!50!black} $p$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
      child {};
  \end{tikzpicture}
  };
%
	\node (p2) [draw, red!75!black, right=2 of p1, "\color{red!75!black} $q$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (4) {$\bullet$}
    ;
  \end{tikzpicture}
  };
\end{tikzpicture}
\end{equation}
By \eqref{eqn.comp_pos}, choosing a position of $p \tri q$ amounts to first choosing a $p$-root $i$, then choosing a $q$-root for every $p[i]$-leaf.
So we may depict $(p \tri q)(\1)$ by gluing roots from the corolla forest of $q$ to leaves in the corolla forest of $p$ in every possible way, as follows:
\begin{equation}\label{eqn.comp_pos_forest}
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "``$(${\color{blue!50!black} $p$}$\:\tri\:${\color{red!75!black}$q$}$)(\1)$''" above] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=8mm},
	  blue!50!black]
    \node[blue!50!black, "\tiny 1" below] (1) {$\bullet$} 
      child[blue!50!black] {node[red!75!black, "\color{red!75!black} \tiny 1" above] {$\bullet$}}
      child[blue!50!black] {node[red!75!black, "\color{red!75!black} \tiny 1" above] {$\bullet$}};
%
    \node[blue!50!black, right=1.5 of 1, "\tiny 1" below] (2) {$\bullet$} 
      child[blue!50!black] {node[red!75!black, "\color{red!75!black} \tiny 1" above] {$\bullet$}}
      child[blue!50!black] {node[red!75!black, "\color{red!75!black} \tiny 2" above] {$\bullet$}};
%
    \node[blue!50!black, right=1.5 of 2, "\tiny 1" below] (3) {$\bullet$} 
      child[blue!50!black] {node[red!75!black, "\color{red!75!black} \tiny 2" above] {$\bullet$}}
      child[blue!50!black] {node[red!75!black, "\color{red!75!black} \tiny 1" above] {$\bullet$}};
%
    \node[blue!50!black, right=1.5 of 3, "\tiny 1" below] (4) {$\bullet$} 
      child[blue!50!black] {node[red!75!black, "\color{red!75!black} \tiny 2" above] {$\bullet$}}
      child[blue!50!black] {node[red!75!black, "\color{red!75!black} \tiny 2" above] {$\bullet$}};
%
    \node[blue!50!black, right=1.2 of 4, "\tiny 2" below] (5) {$\bullet$} 
      child[blue!50!black] {node[red!75!black, "\color{red!75!black} \tiny 1" above] {$\bullet$}};
%
    \node[blue!50!black, right=1 of 5, "\tiny 2" below] (6) {$\bullet$} 
      child[blue!50!black] {node[red!75!black, "\color{red!75!black} \tiny 2" above] {$\bullet$}};
  \end{tikzpicture}
  };
\end{tikzpicture}
\end{equation}
Now fix one of the positions of $p \tri q$ drawn above: a $p$-root $i$ and a $q$-root glued to every $p[i]$-leaf.
By \eqref{eqn.comp_dir}, a direction of $p \tri q$ at that position consists of a $p[i]$-leaf $a$ and a second leaf emanating from the $q$-root that has been glued to $a$.
In other words, in the following picture, where we have glued not just $q$-roots but entire $q$-corollas to leaves in $p$, the directions of $p \tri q$ at the position corresponding to each tree are the rooted paths\footnote{A \emph{rooted path} of a rooted tree is a path up the tree that starts from the root.} of that tree of length $2$ (we omit the labels):
\begin{equation}\label{eqn.prefered_composite}
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "``{\color{blue!50!black} $p$}$\:\tri\:${\color{red!75!black}$q$}''" above] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=8mm},
	  level 2/.style={sibling distance=2.5mm},
	  blue!50!black]
    \node[blue!50!black] (1) {$\bullet$} 
      child {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
				child[red!75!black]
			}
      child {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
				child[red!75!black]
			};
%
    \node[blue!50!black, right=1.7 of 1] (2) {$\bullet$} 
      child {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
				child[red!75!black]
			}
      child {node[red!75!black] {$\bullet$} 
			};
%
    \node[blue!50!black, right=1.5 of 2] (3) {$\bullet$} 
      child {node[red!75!black] {$\bullet$} 
			}
      child {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
				child[red!75!black]
			};
%
    \node[blue!50!black, right=1.5 of 3] (4) {$\bullet$} 
      child {node[red!75!black] {$\bullet$}
			}
      child {node[red!75!black] {$\bullet$} 
			};
%
    \node[blue!50!black, right=1.2 of 4] (5) {$\bullet$} 
      child {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
				child[red!75!black]
			};
%
    \node[blue!50!black, right=1 of 5] (6) {$\bullet$} 
      child {node[red!75!black] {$\bullet$} 
			};
  \end{tikzpicture}
  };
\end{tikzpicture}
\end{equation}
Equivalently, we can think of the directions in the picture above as the leaves at the second level of each tree.
So $p \tri q$ has six positions; the first has six directions, the second, third, and fifth have three directions, and the fourth and sixth have no directions.
In total, we can read off that $p\tri q$ is isomorphic to $\yon^\6+\3\yon^\3+\2$.

We put the $p\tri q$ in scare quotes above \eqref{eqn.prefered_composite} because, to be pedantic, the corolla forest of $p \tri q$ has the two levels smashed together as follows:
\begin{equation}\label{eqn.actual_composite}
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "$p\tri q$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node (1) {$\bullet$} 
      child {}
      child {}
      child {}
      child {}
      child {}
      child {};
    \node[right=1 of 1] (2) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=1 of 2] (3) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=1 of 3] (4) {$\bullet$};
    \node[right=1 of 4] (5) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=1 of 5] (6) {$\bullet$};
  \end{tikzpicture}
  };
\end{tikzpicture}
\end{equation}
Usually, we will prefer the style of \eqref{eqn.prefered_composite} rather than the more pedantic style of \eqref{eqn.actual_composite}.

We have now seen how to draw a single polynomial as a corolla forest, with level-$1$ leaves as directions; as well as how to draw a two-fold composite of polynomials as a forest of trees, with level-$2$ leaves as directions.
Note that drawing a corolla of $p$ or a tree of $p\tri q$ is just a graphical way of following the instructions associated with the polynomial $p$ or $p\tri q$ that we saw in \cref{subsec.comon.comp.def.arena}, where the arrows---the top-level leaves---are where the ``futures'' would go.
Similarly, we could depict any $n$-fold composite as a forest with level-$n$ leaves as directions.
You'll have an opportunity to try this in the following exercise.

\begin{exercise}
Use $p,q$ as in \eqref{eqn.pq_misc39} and $r\coloneqq \2\yon+\1$ in the following.
\begin{enumerate}
	\item Draw $q\tri p$.
	\item Draw $p\tri p$.
	\item Draw $p\tri p\tri \1$.
	\item Draw $r\tri r$.
	\item Draw $r\tri r\tri r$.
\qedhere
\end{enumerate}
\begin{solution}
We have $p \coloneqq \yon^\2 + \yon$ and $q \coloneqq \yon^\3 + \1$ as in \eqref{eqn.pq_misc39}.
\begin{enumerate}
    \item Here is a picture of $q\tri p$, where each tree is obtained by taking a $q$-corolla and gluing $p$-corollas to every leaf:
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=4mm},
	  level 2/.style={sibling distance=2.5mm},
	  red!75!black]
    \node (1) {$\bullet$} 
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			};
%
    \node[right=1.2 of 1] (2) {$\bullet$} 
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			};
%
    \node[right=1.2 of 2] (3) {$\bullet$} 
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			};
%
    \node[right=1.2 of 3] (4) {$\bullet$} 
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			};

    \node[right=1.2 of 4] (5) {$\bullet$} 
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			};

    \node[right=1.2 of 5] (6) {$\bullet$} 
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			};

    \node[right=1.2 of 6] (7) {$\bullet$} 
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
				child[blue!50!black]
			};
%
    \node[right=1.2 of 7] (8) {$\bullet$} 
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			}
      child {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black]
			};
%
    \node[right=1 of 8] (9) {$\bullet$};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
    
    \item Here is a picture of $p\tri p$:
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=8mm},
	  level 2/.style={sibling distance=3mm},
	  blue!50!black]
    \node[blue!50!black] (1) {$\bullet$} 
      child {node {$\bullet$} 
      	child
				child
			}
      child {node {$\bullet$} 
      	child
				child
			};
%
    \node[blue!50!black, right=1.5 of 1] (2) {$\bullet$} 
      child {node {$\bullet$} 
      	child
				child
			}
      child {node {$\bullet$} 
        child
			};
%
    \node[blue!50!black, right=1.5 of 2] (3) {$\bullet$} 
      child {node {$\bullet$} 
        child
			}
      child {node {$\bullet$} 
      	child
				child
			};
%
    \node[blue!50!black, right=1.5 of 3] (4) {$\bullet$} 
      child {node {$\bullet$}
        child
			}
      child {node {$\bullet$}
        child
			};
%
    \node[blue!50!black, right=1.2 of 4] (5) {$\bullet$} 
      child {node {$\bullet$} 
      	child
				child
			};
%
    \node[blue!50!black, right=1 of 5] (6) {$\bullet$} 
      child {node {$\bullet$} 
        child
			};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]

    \item To obtain a picture of $p\tri p\tri\1$, we take our picture of $p\tri p$ and glue the single, leafless $\1$-root to every (level-$2$) leaf:
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=8mm},
	  level 2/.style={sibling distance=3mm},
	  blue!50!black]
    \node[blue!50!black] (1) {$\bullet$} 
      child {node {$\bullet$} 
      	child {node[black] {$\bullet$}}
				child {node[black] {$\bullet$}}
			}
      child {node {$\bullet$} 
      	child {node[black] {$\bullet$}}
				child {node[black] {$\bullet$}}
			};
%
    \node[blue!50!black, right=1.5 of 1] (2) {$\bullet$} 
      child {node {$\bullet$} 
      	child {node[black] {$\bullet$}}
				child {node[black] {$\bullet$}}
			}
      child {node {$\bullet$} 
        child {node[black] {$\bullet$}}
			};
%
    \node[blue!50!black, right=1.5 of 2] (3) {$\bullet$} 
      child {node {$\bullet$} 
        child {node[black] {$\bullet$}}
			}
      child {node {$\bullet$} 
      	child {node[black] {$\bullet$}}
				child {node[black] {$\bullet$}}
			};
%
    \node[blue!50!black, right=1.5 of 3] (4) {$\bullet$} 
      child {node {$\bullet$}
        child {node[black] {$\bullet$}}
			}
      child {node {$\bullet$}
        child {node[black] {$\bullet$}}
			};
%
    \node[blue!50!black, right=1.2 of 4] (5) {$\bullet$} 
      child {node {$\bullet$} 
      	child {node[black] {$\bullet$}}
				child {node[black] {$\bullet$}}
			};
%
    \node[blue!50!black, right=1 of 5] (6) {$\bullet$} 
      child {node {$\bullet$} 
        child {node[black] {$\bullet$}}
			};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
\end{enumerate}

Now $r\coloneqq \2\yon+\1$. Before we draw the composites, here's a picture of $r$ itself, with different colors to distinguish the different positions:

\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node[blue!50!black] (1) {$\bullet$} 
      child[blue!50!black];
%  
    \node[right=.5 of 1, red!75!black] (2) {$\bullet$} 
      child[red!75!black];
%
    \node[right=.5 of 2] (3) {$\bullet$};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]

\begin{enumerate}[resume]
    \item Here is a picture of $r\tri r$:
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=8mm},
	  level 2/.style={sibling distance=2.5mm},
	  blue!50!black]
    \node (1) {$\bullet$} 
      child {node {$\bullet$} 
      	child
			};
%
    \node[right=.5 of 1] (2) {$\bullet$} 
      child {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
			};
%
    \node[right=.5 of 2] (3) {$\bullet$} 
      child {node[black] {$\bullet$}};
%
    \node[right=.5 of 3, red!75!black] (4) {$\bullet$} 
      child[red!75!black] {node {$\bullet$}
        child};
%
    \node[right=.5 of 4, red!75!black] (5) {$\bullet$} 
      child[red!75!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
			};
%
    \node[right=.5 of 5, red!75!black] (6) {$\bullet$} 
      child[red!75!black] {node[black] {$\bullet$}};
%
    \node[right=.5 of 6, black] (7) {$\bullet$};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
    
    \item Here is a picture of $r\tri r\tri r$:
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=8mm},
	  level 2/.style={sibling distance=2.5mm},
	  blue!50!black]
    \node (1) {$\bullet$} 
      child {node {$\bullet$} 
      	child {node {$\bullet$}
      	  child
      	      }
			};
%
    \node[right=.5 of 1] (2) {$\bullet$} 
      child {node {$\bullet$} 
      	child {node[red!75!black] {$\bullet$}
      	  child[red!75!black]
      	      }
			};
%
    \node[right=.5 of 2] (3) {$\bullet$} 
      child {node {$\bullet$} 
      	child {node[black] {$\bullet$}}
			};
%
    \node[right=.5 of 3] (4) {$\bullet$} 
      child {node[red!75!black] {$\bullet$} 
      	child[red!75!black] {node[blue!50!black] {$\bullet$}
      	  child[blue!50!black]
      	      }
			};
%
    \node[right=.5 of 4] (5) {$\bullet$} 
      child {node[red!75!black] {$\bullet$} 
      	child[red!75!black] {node[red!75!black] {$\bullet$}
      	  child[red!75!black]
      	      }
			};
%
    \node[right=.5 of 5] (6) {$\bullet$} 
      child {node[red!75!black] {$\bullet$} 
      	child[red!75!black] {node[black] {$\bullet$}}
			};
%
    \node[right=.5 of 6] (7) {$\bullet$} 
      child {node[black] {$\bullet$}};
%
    \node[right=.5 of 7, red!75!black] (8) {$\bullet$} 
      child[red!75!black] {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black] {node[blue!50!black] {$\bullet$}
      	  child[blue!50!black]
      	      }
			};
%
    \node[right=.5 of 8, red!75!black] (9) {$\bullet$} 
      child[red!75!black] {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black] {node[red!75!black] {$\bullet$}
      	  child[red!75!black]
      	      }
			};
%
    \node[right=.5 of 9, red!75!black] (10) {$\bullet$} 
      child[red!75!black] {node[blue!50!black] {$\bullet$} 
      	child[blue!50!black] {node[black] {$\bullet$}}
			};
%
    \node[right=.5 of 10, red!75!black] (11) {$\bullet$} 
      child[red!75!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black] {node[blue!50!black] {$\bullet$}
      	  child[blue!50!black]
      	      }
			};
%
    \node[right=.5 of 11, red!75!black] (12) {$\bullet$} 
      child[red!75!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black] {node[red!75!black] {$\bullet$}
      	  child[red!75!black]
      	      }
			};
%
    \node[right=.5 of 12, red!75!black] (13) {$\bullet$} 
      child[red!75!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black] {node[black] {$\bullet$}}
			};
%
    \node[right=.5 of 13, red!75!black] (14) {$\bullet$} 
      child[red!75!black] {node[black] {$\bullet$}};
%
    \node[right=.5 of 14, black] (15) {$\bullet$};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
\end{enumerate}
\end{solution}
\end{exercise}


% ** Find a home for this
% Here is a curious fact relating composition and the closure operation adjoint to $\otimes$. Recall that for any two polynomials $p,q$, there is a polynomial $[p,q]\in\poly$.
 
% \begin{proposition}
% For any set $A\in\smset$ and any polynomial $p\in\poly$, there is an isomorphism
% \[
% \yon^A\tri p\cong[A\yon,p].
% \]
% \end{proposition}
% \begin{proof}
% \begin{align*}
% 	\yon^A\tri p&\cong
% 	\prod_{a\in A}\sum_{i\in p(\1)}\yon^{p[i]}\\&\cong
% 	\sum_{i\colon A\to p(\1)}\prod_{a\in A}\yon^{p[i(a)]}\\&\cong
% 	\sum_{i\colon A\to p(\1)}\yon^{\sum_{a\in A}p[i(a)]}\\&\cong
% 	\sum_{\varphi\colon A\yon\to p}\yon^{\sum_{a\in A\yon(\1)}
% 	p[\varphi_\1(a)]}\\&\cong
% 	[A\yon,p]
% \end{align*}
% \end{proof}

\begin{example}[Composing polynomials with constants] \label{ex.apply_2}
For any set $X$ and polynomial $p$, we can take $p(X)\in\smset$; indeed $p\colon\smset\to\smset$ is a functor! In particular, by this point you've seen us write $p(\1)$ hundreds of times. But we've also seen that $X$ is itself a polynomial, namely a constant one.

It's not hard to see that $p(X)\iso p\tri X$. Here's a picture, where $p\coloneqq\yon^\3+\yon+\1$ and $X\coloneqq\2$.
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, blue!50!black, "\color{blue!50!black} $p$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
      child {};
      ;
    \node[right=.5 of 2,"\tiny 3" below] (3) {$\bullet$} 
      ;
  \end{tikzpicture}
  };
%
	\node (p2) [draw, red!75!black, right=2 of p1, "\color{red!75!black}$X$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$};
    \node[right=.5 of 1,"\tiny 2" below] (4) {$\diamond$};
    \node[above=10pt of 4] {};
    ;
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Let's see how $(\yon^\3+\yon+\1)\tri\2$ looks.
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "{\color{blue!50!black} $p$}$\:\tri\:${\color{red!75!black}$X$}" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm, blue!50!black]
    \node[blue!50!black] (1) {$\bullet$} 
      child {node[red!75!black] {$\bullet$}}
      child {node[red!75!black] {$\bullet$}}
      child {node[red!75!black] {$\bullet$}};
    \node[blue!50!black, right=of 1] (2) {$\bullet$} 
      child {node[red!75!black] {$\bullet$}}
      child {node[red!75!black] {$\bullet$}}
      child {node[red!75!black] {$\diamond$}};
    \node[blue!50!black, right=of 2] (3) {$\bullet$} 
      child {node[red!75!black] {$\bullet$}}
      child {node[red!75!black] {$\diamond$}}
      child {node[red!75!black] {$\bullet$}};
    \node[blue!50!black, right=of 3] (4) {$\bullet$} 
      child {node[red!75!black] {$\bullet$}}
      child {node[red!75!black] {$\diamond$}}
      child {node[red!75!black] {$\diamond$}};
    \node[blue!50!black, right=of 4] (5) {$\bullet$} 
      child {node[red!75!black] {$\diamond$}}
      child {node[red!75!black] {$\bullet$}}
      child {node[red!75!black] {$\bullet$}};
    \node[blue!50!black, right=of 5] (6) {$\bullet$} 
      child {node[red!75!black] {$\diamond$}}
      child {node[red!75!black] {$\bullet$}}
      child {node[red!75!black] {$\diamond$}};
    \node[blue!50!black, right=of 6] (7) {$\bullet$} 
      child {node[red!75!black] {$\diamond$}}
      child {node[red!75!black] {$\diamond$}}
      child {node[red!75!black] {$\bullet$}};
    \node[blue!50!black, right=of 7] (8) {$\bullet$} 
      child {node[red!75!black] {$\diamond$}}
      child {node[red!75!black] {$\diamond$}}
      child {node[red!75!black] {$\diamond$}};
    \node[blue!50!black, right=.8 of 8] (9) {$\bullet$} 
      child {node[red!75!black] {$\bullet$}};
    \node[blue!50!black, right=.6 of 9] (10) {$\bullet$} 
      child {node[red!75!black] {$\diamond$}};
    \node[blue!50!black, right=.6 of 10] (11) {$\bullet$};
	\end{tikzpicture}
	};
\end{tikzpicture}
\]
It has $11$ positions and no level-$2$ leaves, which means it's a set (constant polynomial, with no directions), namely $p\tri X\iso \1\1$.

We could also draw $X\tri p$, since both are perfectly valid polynomials. Here it is:
\[
\begin{tikzpicture}[rounded corners]
	\node (p2) [draw, "{\color{red!75!black}$X$}$\:\tri\:${\color{blue!50!black} $p$}" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm, red!75!black]
    \node["\tiny 1" below] (1) {$\bullet$};
    \node[right=.5 of 1,"\tiny 2" below] (4) {$\diamond$};
    \node[above=10pt of 4] {};
    ;
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Each of the leaves in $X$---of which there are none---is given a $p$-corolla.
\end{example}

\begin{exercise}\label{exc.composing_with_constants}
\begin{enumerate}
	\item Choose a polynomial $p$ and draw $p\tri\1$ in the style of \cref{ex.apply_2}.
	\item Show that if $X$ is a set (considered as a constant polynomial) and $p$ is any polynomial, then $X\tri p\iso X$.
	\item \label{exc.composing_with_constants.appl} Show that if $X$ is a set and $p$ is a polynomial, then $p\tri X\iso p(X)$, where $p(X)$ is the set given by applying $p$ as a functor to $X$.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item We pick the list polynomial, $p\coloneqq\1+\yon+\yon^\2+\yon^\3+\cdots$, drawn as follows:
\[
\begin{tikzpicture}[rounded corners]
\node (p1) [draw] {
  \begin{tikzpicture}[trees, sibling distance=3mm]
    \node (1) {$\bullet$};
    \node[right=.3 of 1] (2) {$\bullet$}
      child {};
    \node[right=.4 of 2] (3) {$\bullet$} 
      child {}
      child {};
    \node[right=.6 of 3] (4) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=.6 of 4] {$\cdots$};
  \end{tikzpicture}
};
\end{tikzpicture}
\]
Then here is a picture of $p\tri\1$:
\[
\begin{tikzpicture}[rounded corners]
\node (p1) [draw] {
  \begin{tikzpicture}[trees, sibling distance=3mm]
    \node (1) {$\bullet$};
    \node[right=.3 of 1] (2) {$\bullet$}
      child {node {$\bullet$}};
    \node[right=.4 of 2] (3) {$\bullet$} 
      child {node {$\bullet$}}
      child {node {$\bullet$}};
    \node[right=.6 of 3] (4) {$\bullet$} 
      child {node {$\bullet$}}
      child {node {$\bullet$}}
      child {node {$\bullet$}};
    \node[right=.6 of 4] {$\cdots$};
  \end{tikzpicture}
};
\end{tikzpicture}
\]
\end{enumerate}
Below, $X$ is a set and $p$ is a polynomial.
\begin{enumerate}[resume]
    \item A constant functor composed with any functor is still the same constant functor, so $X \tri p \iso X$.
    We can also verify this using \eqref{eqn.composite_formula}:
    \[
        X \tri p \iso \sum_{i \in X} \prod_{a \in \varnothing} \sum_{j \in p(\1)} \prod_{b \in p[j]} \yon \iso \sum_{i \in X} \1 \iso X.
    \]
    \item When viewed as functors, it is easy to see that $p \tri X \iso p(X)$.
    We can also verify this using \eqref{eqn.composite_formula}:
    \[
        p \tri X \iso \sum_{i \in p(\1)} \prod_{a \in p[i]} \sum_{j \in X} \prod_{b \in \varnothing} \yon \iso \sum_{i \in p(\1)} \prod_{a \in p[i]} \sum_{j \in X} \1 \iso \sum_{i \in p(\1)} \prod_{a \in p[i]} X \iso \sum_{i \in p(\1)} X^{p[i]} \iso p(X).
    \]
\end{enumerate}
\end{solution}
\end{exercise}

In particular, this means we could write the position-set of a polynomial $p$ interchangeably as $p(\1)$ or as $p\tri\1$.
We'll generally write $p(\1)$ when we want to emphasize the position-set as a set, and $p\tri\1$ when we want to emphasize the position-set as a polynomial (albeit a constant one, with no directions).

\begin{exercise}\label{ex.compose_yon}
For any $p\in\poly$ there are natural isomorphisms $p\iso p\tri \yon$ and $p\iso\yon\tri p$.
\begin{enumerate}
	\item Thinking of polynomials as functors $\smset\to\smset$, what functor does $\yon$ represent?
	\item Why are $p\tri\yon$ and $\yon\tri p$ isomorphic to $p$?
	\item Let $p\coloneqq\yon^\3+\yon+\1$.
	In terms of tree pictures, draw $p\tri\yon$ and $\yon\tri p$, and explain pictorially how to see the isomorphisms $p\tri\yon \iso p \iso \yon\tri p$.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item The polynomial $\yon$ is the identity functor on $\smset$.
    \item Composing any functor with the identity functor yields the original functor, so $p\tri\yon \iso p \iso \yon\tri p$.
    \item Before we draw $\yon\tri p$ and $p\tri\yon$, here are pictures of $p$ and $\yon$ individually as corolla forests:
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, blue!50!black, "\color{blue!50!black} $p$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node (1) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=.5 of 1] (2) {$\bullet$} 
      child {};
    \node[right=.5 of 2] (3) {$\bullet$};
  \end{tikzpicture}
  };
%
	\node (p2) [draw, right=2 of p1, "$\yon$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node (1) {$\bullet$}
      child {};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Now here is a picture of $p\tri\yon$, obtained by gluing the one-leaf $\yon$-corolla to all the leaves of each $p$-corolla in turn:
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, blue!50!black, "{\color{blue!50!black}$p$}$\:\tri\:\yon$" above] {
	\begin{tikzpicture}[trees, sibling distance=5mm]
    \node (1) {$\bullet$} 
      child {node[black] {$\bullet$} child[black]}
      child {node[black] {$\bullet$} child[black]}
      child {node[black] {$\bullet$} child[black]};
    \node[right=1 of 1] (2) {$\bullet$} 
      child {node[black] {$\bullet$} child[black]};
    \node[right=.5 of 2] (3) {$\bullet$};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
This is just $p$ with every direction extended up one level, so it is still a picture of $p$.

And here is a picture of $\yon\tri p$, obtained by gluing each $p$-corolla to the single leaf of $\yon$:
\[
\begin{tikzpicture}[rounded corners]
	\node (p2) [draw, "$\yon\:\tri\:${\color{blue!50!black}$p$}" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node (1) {$\bullet$}
      child {
        node[blue!50!black] {$\bullet$}
            child[blue!50!black]
            child[blue!50!black]
            child[blue!50!black]
      };
    \node[right=.5 of 1] (2) {$\bullet$} 
      child {
        node[blue!50!black] {$\bullet$}
            child[blue!50!black]
      };
    \node[right=.5 of 2] (3) {$\bullet$}
      child {
        node[blue!50!black] {$\bullet$}
      };
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
\end{enumerate}
\end{solution}
This is just $p$ with every position propped up one level, so it is also still a picture of $p$.
\end{exercise}

How shall we think about taking the composition product of lenses in terms of our tree pictures?
We can interpret the results of \cref{exc.comp_prod_lens} as follows.

\begin{example}\label{ex.comp_prod_trees}
Let's take $p\coloneqq \yon^\2+\yon$, $q\coloneqq\yon^\2+\yon$, $p'\coloneqq\yon^\3+\yon$, and $q'\coloneqq\yon+\1$.
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, blue!50!black, "$p=$" left] {
	\begin{tikzpicture}[trees, sibling distance=5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
      child {};
  \end{tikzpicture}
  };
%
	\node (q) [draw, red!75!black, above=1 of p, "$q=$" left] {
	\begin{tikzpicture}[trees, sibling distance=5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
      child {};
  \end{tikzpicture}
  };
	\node (p') [draw, blue, right=3 of p, "$p'=$" left] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$}
      child {};
  \end{tikzpicture}
  };
	\node (q') [draw, red, above=1 of p', "$q'=$" left] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$}
    ;
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
For any pair of lenses $p\to p'$ and $q\to q'$, we have a lens $p\tri q\to p'\tri q'$. Let's draw $p\tri q$ and $p'\tri q'$.
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "$p\tri q$" above] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=8mm},
	  level 2/.style={sibling distance=2.5mm}]
    \node[blue!50!black] (1) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			};
%
    \node[blue!50!black, right=1.7 of 1] (2) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
			};
%
    \node[blue!50!black, right=1.5 of 2] (3) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			};
%
    \node[blue!50!black, right=1.5 of 3] (4) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
			};
%
    \node[blue!50!black, right=1.2 of 4] (5) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
      	child[red!75!black]
			};
%
    \node[blue!50!black, right=.8 of 5] (6) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
			};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "$p'\tri q'$" above] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=4mm},
	  level 2/.style={sibling distance=2.5mm}]
    \node[blue] (1) {$\bullet$} 
      child[blue] {node[red] {$\bullet$} 
      	child[red]
			}
      child[blue] {node[red] {$\bullet$} 
      	child[red]
			}
      child[blue] {node[red] {$\bullet$} 
				child[red]
			};
%
    \node[blue, right=1.4 of 1] (2) {$\bullet$} 
      child[blue] {node[red] {$\bullet$} 
      	child[red]
			}
      child[blue] {node[red] {$\bullet$} 
      	child[red]
			}
      child[blue] {node[red] {$\bullet$} 
			};
%
    \node[blue, right=1.4 of 2] (3) {$\bullet$} 
      child[blue] {node[red] {$\bullet$} 
      	child[red]
			}
      child[blue] {node[red] {$\bullet$} 
			}
      child[blue] {node[red] {$\bullet$} 
				child[red]
			};
%
    \node[blue, right=1.4 of 3] (4) {$\bullet$} 
      child[blue] {node[red] {$\bullet$} 
      	child[red]
			}
      child[blue] {node[red] {$\bullet$} 
			}
      child[blue] {node[red] {$\bullet$} 
			};
%
    \node[blue, right=1.4 of 4] (5) {$\bullet$} 
      child[blue] {node[red] {$\bullet$} 
			}
      child[blue] {node[red] {$\bullet$} 
      	child[red]
			}
      child[blue] {node[red] {$\bullet$} 
				child[red]
			};
%
    \node[blue, right=1.4 of 5] (6) {$\bullet$} 
      child[blue] {node[red] {$\bullet$} 
			}
      child[blue] {node[red] {$\bullet$} 
      	child[red]
			}
      child[blue] {node[red] {$\bullet$} 
			};
%
    \node[blue, right=1.4 of 6] (7) {$\bullet$} 
      child[blue] {node[red] {$\bullet$} 
			}
      child[blue] {node[red] {$\bullet$} 
			}
      child[blue] {node[red] {$\bullet$} 
      	child[red]
			};
%
    \node[blue, right=1.4 of 7] (8) {$\bullet$} 
      child[blue] {node[red] {$\bullet$} 
			}
      child[blue] {node[red] {$\bullet$} 
			}
      child[blue] {node[red] {$\bullet$} 
			};
%
    \node[blue, right=1 of 8] (9) {$\bullet$} 
      child[blue] {node[red] {$\bullet$} 
      	child[red]
			};
%
    \node[blue, right=.8 of 9] (10) {$\bullet$} 
      child[blue] {node[red] {$\bullet$} 
			};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]

Let's also pick a pair of lenses, $f\colon p\to p'$ and $g\colon q\to q'$.
\[
\begin{tikzpicture}
	\node (p1) {\raisebox{.3cm}{$f\colon p\to p'$}\qquad
	\begin{tikzpicture}[trees, sibling distance=5mm]
    \node[blue!50!black, "\color{blue!50!black} \tiny 1" below] (1) {$\bullet$} 
      child[blue!50!black] {coordinate (11)}
      child[blue!50!black] {coordinate (12)};
    \node[right=1.5 of 1, blue, "\color{blue} \tiny 1" below] (2) {$\bullet$} 
      child[blue] {coordinate (21)}
      child[blue] {coordinate (22)}
      child[blue] {coordinate (23)};
    \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
    \begin{scope}[densely dotted, bend right]
      \draw[postaction={decorate}] (21) to (12);
      \draw[postaction={decorate}] (22) to (12);
      \draw[postaction={decorate}] (23) to (11);
    \end{scope}
  \end{tikzpicture}	
	};	
%
	\node (p2) [below right=-1.3 and 1 of p1] {
	\begin{tikzpicture}[trees, sibling distance=5mm]
    \node[blue!50!black, "\color{blue!50!black} \tiny 2" below] (1) {$\bullet$} 
      child[blue!50!black] {coordinate (11)};
    \node[right=of 1, blue, "\color{blue} \tiny 2" below] (2) {$\bullet$}
      child[blue] {coordinate (21)};
    \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
    \begin{scope}[densely dotted, bend right]
      \draw[postaction={decorate}] (21) to (11);
		\end{scope}
  \end{tikzpicture}	
	};	
	\node [below=.5 of p1] (p3) {\raisebox{.3cm}{$g\colon q\to q'$}\qquad
	\begin{tikzpicture}[trees, sibling distance=5mm]
    \node[red!75!black, "\color{red!75!black} \tiny 1" below] (1) {$\bullet$} 
      child[red!75!black] {coordinate (11)}
      child[red!75!black] {coordinate (12)};
    \node[right=1.5 of 1, red, "\color{red} \tiny 1" below] (2) {$\bullet$} 
      child[red] {coordinate (21)};
    \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
    \begin{scope}[densely dotted, bend right]
      \draw[postaction={decorate}] (21) to (12);
    \end{scope}
  \end{tikzpicture}	
	};	
%
	\node (p4) [below right=-1.05 and 1 of p3] {
	\begin{tikzpicture}[trees, sibling distance=5mm]
    \node[red!75!black, "\color{red!75!black} \tiny 2" below] (1) {$\bullet$} 
      child[red!75!black] {coordinate (11)};
    \node[right=of 1, red, "\color{red} \tiny 2" below] (2) {$\bullet$};
    \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
  \end{tikzpicture}	
	};	
\end{tikzpicture}
\]
Then by \cref{exc.comp_prod_lens}, we can form the lens $f\tri g\colon p\tri q\to p'\tri q'$ as follows.
On positions, we follow \eqref{eqn.comp_lens_pos}: for each tree $t$ in the picture of $p\tri q$, we begin by using $f_\1$ to send the $p$-corolla $i$ that forms the bottom level of $t$ to a $p'$-corolla $i'$.
Then for each $p'[i']$-leaf $a'$ of $i'$, to choose which $q'$-corolla gets glued to $a'$, we use $f^\sharp_i$ to send $a'$ back to a $p[i]$-leaf $a$.
Since $t$ has the corolla $i$ as its bottom level, $a$ is just a level-$1$ vertex of the tree $t$.
So we can take the $q$-corolla $j$ that is glued to $a$ in $t$, then use $g_\1$ to send $j$ forward to a $q'$-corolla $j'$.
This is the corolla we glue to the $p'[i']$-leaf $a'$.
All this specifies a tree $t'$ in $p'\tri q'$ that $t$ gets sent to via $(f\tri g)_\1$.

On directions, we follow \eqref{eqn.comp_lens_dir}: picking a direction of $t'$ consists of picking a level-$1$ vertex $a'$ and a level-$2$ leaf $b'$ emanating from $a'$.
The on-directions function $f^\sharp_i$ sends $a'$ back to a level-$1$ vertex $a$ of $t$, and as we saw, the on-positions function $g_\1$ sends the $q$-corolla $j$ glued to $a$ in $t$ forward to the $q'$-corolla glued to $a'$.
Then $b'$ is a leaf of that $q'$-corolla, and $g^\sharp_j$ sends $b'$ back to a leaf $b$ emanating from $a$.
So the on-directions function $(f\tri g)^\sharp_t$ sends the level-$2$ leaf $b'$ to the level-$2$ leaf $b$.

We draw the lens $f\tri g\to p\tri q\to p'\tri q'$ below.
To avoid clutter, we leave out the arrows for $g_\1$ that show how the red corollas on the right are selected; we hope the reader can put it together for themselves.
\[
	\begin{tikzpicture}[trees]
	\begin{scope}[
		level 1/.style={sibling distance=8mm},
	  level 2/.style={sibling distance=5mm}]
    \node[blue!50!black] (1) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] (11') {$\bullet$} 
      	child[red!75!black] {coordinate (11)}
				child[red!75!black] {coordinate (12)}
			}
      child[blue!50!black] {node[red!75!black] (12') {$\bullet$} 
      	child[red!75!black] {coordinate (13)}
				child[red!75!black] {coordinate (14)}
			};
%
    \node[blue!50!black, right=5 of 1] (2) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] (21') {$\bullet$} 
      	child[red!75!black] {coordinate (21)}
				child[red!75!black] {coordinate (22)}
			}
      child[blue!50!black] {node[red!75!black] (22') {$\bullet$} 
      	child[red!75!black] {coordinate (23)}
			};
%
    \node[blue!50!black, below=1.3 of 1] (3) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] (31') {$\bullet$} 
      	child[red!75!black] {coordinate (31)}
			}
      child[blue!50!black] {node[red!75!black] (32') {$\bullet$} 
      	child[red!75!black] {coordinate (32)}
				child[red!75!black] {coordinate (33)}
			};
%
    \node[blue!50!black] at (2|-3) (4) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] (41') {$\bullet$} 
      	child[red!75!black] {coordinate (41)}
			}
      child[blue!50!black] {node[red!75!black] (42') {$\bullet$} 
      	child[red!75!black] {coordinate (42)}
			};
%
    \node[blue!50!black, below=1.3 of 3] (5) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] (51') {$\bullet$} 
      	child[red!75!black] {coordinate (51)}
				child[red!75!black] {coordinate (52)}
			};
%
    \node[blue!50!black] at (4|-5) (6) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] (61') {$\bullet$} 
      	child[red!75!black] {coordinate (61)}
			};
		\end{scope}
%%
	\begin{scope}[		
		level 1/.style={sibling distance=4mm},
	  level 2/.style={sibling distance=5mm}]
	    \node[blue, right=2 of 1] (1') {$\bullet$} 
      child[blue] {node[red] (1'1') {$\bullet$} 
      	child[red] {coordinate (1'1)}
			}
      child[blue] {node[red] (1'2') {$\bullet$} 
      	child[red] {coordinate (1'2)}
			}
      child[blue] {node[red] (1'3') {$\bullet$} 
      	child[red] {coordinate (1'3)}
			};
%
    \node[blue, right=2 of 2] (2') {$\bullet$} 
      child[blue] {node[red] (2'1') {$\bullet$} 
			}
      child[blue] {node[red] (2'2') {$\bullet$} 
			}
      child[blue] {node[red] (2'3') {$\bullet$} 
      	child[red] {coordinate (2'1)}
			};
%
    \node[blue, right=2 of 3] (3') {$\bullet$} 
      child[blue] {node[red] (3'1') {$\bullet$} 
      	child[red] {coordinate (3'1)}
			}
      child[blue] {node[red] (3'2') {$\bullet$} 
      	child[red] {coordinate (3'2)}
			}
      child[blue] {node[red] (3'3') {$\bullet$} 
			};
%
    \node[blue, right=2 of 4] (4') {$\bullet$} 
      child[blue] {node[red] (4'1') {$\bullet$} 
			}
      child[blue] {node[red] (4'2') {$\bullet$} 
			}
      child[blue] {node[red] (4'3') {$\bullet$} 
			};
%
    \node[blue, right=2 of 5] (5') {$\bullet$} 
      child[blue] {node[red] (5'1') {$\bullet$} 
      	child[red] {coordinate (5'1)}
			};
%
    \node[blue, right=2 of 6] (6') {$\bullet$} 
      child[blue] {node[red] (6'1') {$\bullet$} 
			};
%
\draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (1');
\draw[|->, shorten <= 3pt, shorten >= 3pt] (2) -- (2');
\draw[|->, shorten <= 3pt, shorten >= 3pt] (3) -- (3');
\draw[|->, shorten <= 3pt, shorten >= 3pt] (4) -- (4');
\draw[|->, shorten <= 3pt, shorten >= 3pt] (5) -- (5');
\draw[|->, shorten <= 3pt, shorten >= 3pt] (6) -- (6');
    \begin{scope}[densely dotted, bend right=15pt]
      \draw[postaction={decorate}] (1'1') to (12');
      \draw[postaction={decorate}] (1'2') to (12');
      \draw[postaction={decorate}] (1'3') to (11');
      \draw[postaction={decorate}] (1'1) to (14);
      \draw[postaction={decorate}] (1'2) to (14);
      \draw[postaction={decorate}] (1'3) to (12);
%
      \draw[postaction={decorate}] (2'1') to (22');
      \draw[postaction={decorate}] (2'2') to (22');
      \draw[postaction={decorate}] (2'3') to (21');
      \draw[postaction={decorate}] (2'1) to (23);
%
      \draw[postaction={decorate}] (3'1') to (32');
      \draw[postaction={decorate}] (3'2') to (32');
      \draw[postaction={decorate}] (3'3') to (31');
      \draw[postaction={decorate}] (3'1) to (33);
      \draw[postaction={decorate}] (3'2) to (33);
%
      \draw[postaction={decorate}] (4'1') to (42');
      \draw[postaction={decorate}] (4'2') to (42');
      \draw[postaction={decorate}] (4'3') to (41');
%
      \draw[postaction={decorate}] (5'1') to (51');
      \draw[postaction={decorate}] (5'1) to (52);
%
      \draw[postaction={decorate}] (6'1') to (61');
    \end{scope}

	\end{scope}
  \end{tikzpicture}
\]
\end{example}

\begin{exercise}
With $p,q,p',q'$ and $f,g$ as in \cref{ex.comp_prod_trees}, draw the lens $g\tri f\colon q\tri p\to q'\tri p'$ in terms of trees as in the example.
\begin{solution}
Using the definitions, instructions, and style from \cref{ex.comp_prod_trees}, we draw $g\tri f\colon q\tri p\to q'\tri p'$:
\[
	\begin{tikzpicture}[trees]
	\begin{scope}[
		level 1/.style={sibling distance=8mm},
	  level 2/.style={sibling distance=5mm}]
    \node[red!75!black] (1) {$\bullet$} 
      child[red!75!black] {node[blue!50!black] (11') {$\bullet$} 
      	child[blue!50!black] {coordinate (11)}
				child[blue!50!black] {coordinate (12)}
			}
      child[red!75!black] {node[blue!50!black] (12') {$\bullet$} 
      	child[blue!50!black] {coordinate (13)}
				child[blue!50!black] {coordinate (14)}
			};
%
    \node[red!75!black, right=5 of 1] (2) {$\bullet$} 
      child[red!75!black] {node[blue!50!black] (21') {$\bullet$} 
      	child[blue!50!black] {coordinate (21)}
				child[blue!50!black] {coordinate (22)}
			}
      child[red!75!black] {node[blue!50!black] (22') {$\bullet$} 
      	child[blue!50!black] {coordinate (23)}
			};
%
    \node[red!75!black, below=1.3 of 1] (3) {$\bullet$} 
      child[red!75!black] {node[blue!50!black] (31') {$\bullet$} 
      	child[blue!50!black] {coordinate (31)}
			}
      child[red!75!black] {node[blue!50!black] (32') {$\bullet$} 
      	child[blue!50!black] {coordinate (32)}
				child[blue!50!black] {coordinate (33)}
			};
%
    \node[red!75!black] at (2|-3) (4) {$\bullet$} 
      child[red!75!black] {node[blue!50!black] (41') {$\bullet$} 
      	child[blue!50!black] {coordinate (41)}
			}
      child[red!75!black] {node[blue!50!black] (42') {$\bullet$} 
      	child[blue!50!black] {coordinate (42)}
			};
%
    \node[red!75!black, below=1.3 of 3] (5) {$\bullet$} 
      child[red!75!black] {node[blue!50!black] (51') {$\bullet$} 
      	child[blue!50!black] {coordinate (51)}
				child[blue!50!black] {coordinate (52)}
			};
%
    \node[red!75!black] at (4|-5) (6) {$\bullet$} 
      child[red!75!black] {node[blue!50!black] (61') {$\bullet$} 
      	child[blue!50!black] {coordinate (61)}
			};
		\end{scope}
%%
	\begin{scope}[		
		level 1/.style={sibling distance=4mm},
	  level 2/.style={sibling distance=2.5mm}]
	    \node[red, right=2 of 1] (1') {$\bullet$} 
      child[red] {node[blue] (1'1') {$\bullet$} 
      	child[blue] {coordinate (1'1)}
      	child[blue] {coordinate (1'2)}
      	child[blue] {coordinate (1'3)}
			};
%
    \node[red, right=2 of 2] (2') {$\bullet$} 
      child[red] {node[blue] (2'1') {$\bullet$} 
        child[blue] {coordinate (2'1)}
			};
%
    \node[red, right=2 of 3] (3') {$\bullet$} 
      child[red] {node[blue] (3'1') {$\bullet$} 
      	child[blue] {coordinate (3'1)} 
      	child[blue] {coordinate (3'2)} 
      	child[blue] {coordinate (3'3)}
			};
%
    \node[red, right=2 of 4] (4') {$\bullet$} 
      child[red] {node[blue] (4'1') {$\bullet$}  
      	child[blue] {coordinate (4'1)}
			};
%
    \node[red, right=2 of 5] (5') {$\bullet$};
%
    \node[red, right=2 of 6] (6') {$\bullet$};
%
\draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (1');
\draw[|->, shorten <= 3pt, shorten >= 3pt] (2) -- (2');
\draw[|->, shorten <= 3pt, shorten >= 3pt] (3) -- (3');
\draw[|->, shorten <= 3pt, shorten >= 3pt] (4) -- (4');
\draw[|->, shorten <= 3pt, shorten >= 3pt] (5) -- (5');
\draw[|->, shorten <= 3pt, shorten >= 3pt] (6) -- (6');
    \begin{scope}[densely dotted, bend right=15pt]
      \draw[postaction={decorate}] (1'1') to (12');
      \draw[postaction={decorate}] (1'1) to (14);
      \draw[postaction={decorate}] (1'2) to (14);
      \draw[postaction={decorate}] (1'3) to (13);
%
      \draw[postaction={decorate}] (2'1') to (22');
      \draw[postaction={decorate}] (2'1) to (23);
%
      \draw[postaction={decorate}] (3'1') to (32');
      \draw[postaction={decorate}] (3'1) to (33);
      \draw[postaction={decorate}] (3'2) to (33);
      \draw[postaction={decorate}] (3'3) to (32);
%
      \draw[postaction={decorate}] (4'1') to (42');
      \draw[postaction={decorate}] (4'1) to (42);
    \end{scope}

	\end{scope}
  \end{tikzpicture}
\]
\end{solution}
\end{exercise}

\begin{exercise}
Suppose $p$, $q$, and $r$ are polynomials and you're given arbitrary lenses $f\colon q\to p\tri q$ and $g\colon q\to q\tri r$. Does the following diagram necessarily commute?\footnote{When the name of an object is used in place of a morphism, we refer to the identity morphism on that object.
So for instance, $f\tri r$ is the composition product of $f$ with the identity lens on $r$.}
\[
\begin{tikzcd}
	q\ar[r, "g"]\ar[d, "f"']&
	q\tri r\ar[d, "f\:\tri\:r"]\\
	p\tri q\ar[r, "p\:\tri\:g"']&
	p\tri q\tri r\ar[ul, phantom, "?"]
\end{tikzcd}
\]
That is, do we have $f\then (p\tri g)=^?g\then (f\tri r)$?
\begin{solution}
Given arbitrary polynomials $p,q,r$ and lenses $f\colon q\to p\tri q$ and $g\colon q\to q\tri r$, it is \emph{not} necessarily the case that $f\then (p\tri g)=g\then (f\tri r)$!
After all, we can let $p\coloneqq\yon$ and $q\coloneqq\2$ so that $f$ is a lens $\2\to\yon\tri\2\iso\2$ (see \cref{ex.compose_yon}) and $g$ is a lens $\2\to\2\tri r\iso\2$ (see \cref{exc.composing_with_constants}).
Then by following the instructions for interpreting a composition product of lenses from either \cref{exc.comp_prod_lens} or \cref{ex.comp_prod_trees}, we can verify that $p\tri g=\yon\tri g$ is a lens $\2\iso\yon\tri\2\to\yon\tri\2\tri r\iso\2$ equivalent to the lens $g$, while $f\tri r$ is a lens $\2\iso\2\tri r\to\yon\tri\2\tri r\iso\2$ equivalent to the lens $f$.
If, say, we let $f\colon\2\to\2$ be the function sending everything to $1\in\2$ and $g\colon\2\to\2$ be the function sending everything to $2\in\2$, then in this case $f\then (p\tri g)=f\then g\neq g\then f=g\then (f\tri r)$.
\end{solution}
\end{exercise}

\subsection{Dynamical systems and the composition product} \label{subsec.comon.comp.def.dyn_sys}

Back in \cref{ex.do_nothing}, we posed the question of how to model running multiple steps of dynamical system in $\poly$.
The answer lies with the composition product.

Recall that a dependent dynamical system is a lens $\phi\colon S\yon^S\to p$, where $S$ is a set of states and $p$ is a polynomial interface.
We call $S\yon^S$ the state system, each $p$-position $i$ an output, each $p[i]$-direction an input at $i$, and the on-position and on-direction functions of $\phi$ the return and update functions, respectively.
More generally, we saw in \cref{ex.do_nothing} that we could replace the state system with a monomial $q\coloneqq S\yon^{S'}$, where $S'$ is another set, as long as there is a function $e\colon S\to S'$ (or equivalently a situation $\epsilon\colon S\yon^{S'}\to\yon$) that is bijective.

The lens models a dynamical system as follows.
Every state $s\in q(\1)=S$ returns an output $o\coloneqq\phi_\1(s)\in p(\1)$, and every input $i\in p[o]$ yields an updated direction $s'\coloneqq\phi^\sharp_s(a)\in q[s]=S'$.
Then to model a second step through the system, we identify the $q[s]$-direction $s'$ with a $q$-position $e^{-1}(s')$, plug this position back into $\phi_\1$, and repeat the process all over again.

% Equivalently, we could think of running through two steps of the system as picking an initial state $s\in q(\1)$ and using a bijection $\ol{t}\colon q[s]\to q(\1)$ to assign each direction at $s$ to a state in $q(\1)$.
% Then we apply $\phi$ in two rounds.
% First, we use the return function to compute an output $i\coloneqq\phi_\1(s)$ and the update function $\phi^\sharp_s\colon p[i]\to q[s]$ to compute a direction at $s$ for each input.
% Before the next round, we use $\ol{t}$ to compute the state assigned to that direction.
% Second, we use the return function to compute an output for that state 

But this is exactly what the composition product $\phi\tri\phi\colon q\tri q\to p\tri p$ does: by \eqref{eqn.comp_lens_pos}, its on-positions function sends the pair $(s_0,e^{-1})\in(q\tri q)(\1)$, comprised of an initial state $s_0\in q(\1)$ and the function $e^{-1}\colon q[s_0]=S'\to S=q(\1)$, to the pair
\begin{equation} \label{eqn.interface_position_pair}
    \left(\phi_\1(s_0),\phi^\sharp_{s_0}\then e^{-1}\then\phi_\1\right)\in(p\tri p)(\1),
\end{equation}
comprised of the initial output $o_0\coloneqq\phi_\1(s)\in p(\1)$ and a composite function
\begin{equation} \label{eqn.interface_position_fn1}
    p[o_0]\To{\phi^\sharp_{s_0}}q[s_0]=S'\To{e^{-1}}S=q(\1)\To{\phi_\1}p(\1),
\end{equation}
which uses the update function at $s_0$ and the return function to tell us what the next output $o_1$ will be for every possible input $i_1$ we could select.
Then by \eqref{eqn.comp_lens_dir}, the on-directions function of $\phi\tri\phi$ sends each direction $(i_1,i_2)$ at the position \eqref{eqn.interface_position_pair}, comprised of a first input $i_1\in p[o_0]$ and (setting $o_1$ to be the function \eqref{eqn.interface_position_fn1} applied to $i_1$) a second input $i_2\in p[o_1]$, to the pair
\[
    \left(\phi^\sharp_{s_0}(i_1), \phi^\sharp_{e^{-1}(\phi^\sharp_{s_0}(i_1))}(i_2)\right),
\]
comprised of directions in $S'$ that (under $e^{-1}$) correspond to the next state $s_1$ upon selecting input $i_1$ at state $s_0$ and the successive state $s_2$ upon selecting input $i_2$ at $s_1$.
In summary, at certain positions, $\phi\tri\phi$ tells us how the dynamical system will behave when we step through it twice: starting from state $s_0$, returning output $o_0$, receiving input $i_1$, updating its state to $s_1$, returning output $o_1$, receiving input $i_2$, and preparing to update its state to $s_2$.
Adding another layer, $\phi\tri\phi\tri\phi\colon q\tri q\tri q\to p\tri p\tri p$ will tell us how the system behaves when we step through it three times; and in general, $\phi\tripow{n}\colon q\tripow{n}\to p\tripow{n}$ will tell us how the system behaves when we step through it $n$ times.

This is what we meant in the introduction when we said that the composition product has to do with time.
It takes a specification $\phi$ for how a state system and an interface can interact back-and-forth---or, indeed, any interaction pattern between wrapper interfaces---and extends it to a multistep model $\phi\tripow{n}$ that simulates $n$ successive interaction cycles over time, accounting for all possible external input that the interface could encounter.
Alternatively, we can think of $\phi\tripow{n}$ as ``speeding up'' the original dynamical system $\phi$ by a factor of $n$, as it runs $n$ steps in one---as long as whatever's connected to its new interface $p\tripow{n}$ can keep up with its pace and feed it $n$ inputs of $p$ at a time!
The lens $\phi$ tells us how the machine can run, but it is $\tri$ that makes the clock tick.

\subsubsection{Why this is not enough}\label{subsubsec.comon.comp.def.dyn_sys.issues}
There are several pressing issues we must address, however, before we can even begin to provide a satisfying answer to everything we asked for in \cref{ex.do_nothing}.
The first is a communication issue: as you probably sensed, our set-theoretic notation for $\phi\tripow{n}$ is rather cumbersome, and that was just for $n=2$.
We could depict the behavior of our composition products of dynamical systems more clearly using tree pictures (see \cref{exc.comp_dyn_sys_tree}), but even that becomes infeasible in greater generality.
A concise visual representation of the back-and-forth interaction of lenses would help us reason about composition products more effectively.

The second issue is more technical: to ensure that $\phi\tri\phi$ behaves the way we want, when we specify a position of its domain $q\tri q$, we have to provide not only an initial state $s_0$ but also the isomorphism $e^{-1}\colon S'\to S$ to let the lens know which state in $S$ each $q[s_0]$-direction in $S'$ should lead to.
But there are many other positions $(s_0,f)$ of $q\tri q$ that we could have specified, and each $f\colon S'\to S$ associates $q[s_0]$-directions to $q$-positions in a different way.
So $\phi\tri\phi$ is carrying around a lot of extraneous---even misleading!---data about how our dynamical system behaves when the state system moves in the right direction but to the wrong state.
Our isomorphism $e^{-1}$ is a temporary fix, but as we pointed out in \cref{ex.do_nothing}, it relies on the set-theoretic equality of the direction-sets of $q$---there's nothing inherent to the categorical structure of $q$ in $\poly$ that encodes how directions map to states, at least not yet.
What are we missing?

The key to resolving both these issues lies in the next section, where we will introduce a graphical notation to help us study lenses whose codomains are composite polynomials.

\begin{exercise} \label{exc.comp_dyn_sys_tree}
** % draw a sample dynamical system using corollas
\begin{solution}
**
\end{solution}
\end{exercise}


\begin{exercise} \label{exc.comp_interface}
** % composite interfaces...how to interpret them
\begin{solution}
**
\end{solution}
\end{exercise}

%-------- Section --------%
\section{Lenses to composites}\label{sec.comon.comp.to_comp}

Lenses to composites---that is, lenses of the form $f\colon p\to q_1\tri\cdots\tri q_n$ for some $n\in\nn$ with composites as their codomains---will be ubiquitous in the remainder of our story.
Fortunately, they have some very nice properties that make them convenient to work with.
Before we explore these properties, we'll introduce a new way of visualizing lenses that is well-suited to capturing the behavior of lenses to composites.

\subsection{Lenses as polyboxes}
First, let us consider what goes into specifying a lens $f\colon p\to q$.
To visualize this, we will introduce a new form of notation, which we will call \emph{polyboxes}, that will generalize well to lenses to composites:
\begin{equation} \label{eqn.polybox_lens}
\begin{tikzpicture}
  \node (f) ["$f\colon p\to q$" above] {
    \begin{tikzpicture}[polybox, tos]
  	  \node[poly, dom, "$p$" below] (p) {};
  	  \node[left=0pt of p_pos] {$p(\1)$};
  	  \node[left=0pt of p_dir] {$p[-]$};

  	  \node[poly, cod, right=of p, "$q$" below] (q) {};
  	  \node[right=0pt of q_pos] {$q(\1)$};
	  \node[right=0pt of q_dir] {$q[-]$};
	  
  	  \draw (p_pos) -- node[below] {} (q_pos);
  	  \draw (q_dir) -- node[above] {} (p_dir);
    \end{tikzpicture}
  };
\end{tikzpicture}
\end{equation}
In our polyboxes, each pair of boxes stacked on top of each other represents a single polynomial.
The lower box in a pair can be filled with any position of the polynomial, while the upper box must be filled with a direction of the polynomial at the position in the lower box.

We think of \eqref{eqn.polybox_lens} as depicting the lens $f$ as a sort of gadget that acts like an automated spreadsheet: the blue boxes accept user input, while the white boxes are computed based on what is entered into the blue boxes according to the spreadsheet's preprogrammed rules.
The arrows track the flow of information, starting from the lower left.

When the user fills the lower left blue box with a $p$-position $i$, the arrow to the right tells us that the gadget should automatically fill the lower right white box with some $q$-position $j$, based on the value $i$ that has already been entered.
This process yields a map $i\mapsto j$ that corresponds to the on-position function $f_\1$ of the lens.

Then when the user fills the upper right blue box with a $q[j]$-direction $b$, the arrow to the left tells us that the gadget should automatically fill the upper left white box with some $p[i]$-position $a$, based on the values $i$ and $b$ that have already been entered.
Fixing $i\in p(\1)$, this process yields a map $b\mapsto a$ that corresponds to the on-directions function $f^\sharp_i$ of the lens.

So when both the user and the automation have finished filling all the boxes, we'll end up with something that looks like this:
\[ \label{eqn.polybox_lens_filled}
\begin{tikzpicture}[polybox, mapstos]
    \node[poly, dom, "$p$" left] (p) {$a$\at$i$};
    \node[poly, cod, "$q$" right, right=of p] (q) {$b$\at$j$};
    \draw (p_pos) -- node[below] {$f_\1$} (q_pos);
    \draw (q_dir) -- node[above] {$f^\sharp$} (p_dir);
\end{tikzpicture}
\]
Here, of course, $j\coloneqq f_\1(i)$ and $a\coloneqq f^\sharp_i(b)$.
So a lens is any protocol that will fill in the white boxes once the user fills in the blue boxes, following the directions of the arrows drawn.
Be careful: although the arrow $f^\sharp$ is drawn from the upper right box, it also takes into account what is entered into the lower left box previously.
After all, the on-directions function of a lens is dependent on both a position of the domain and a direction of the codomain.

If we have two composable lenses $f\colon p\to q$ and $g\colon q\to r$, then we can piece their polyboxes together to form polyboxes for their composite, $f\then g\colon p\to r$:
\[
\begin{tikzpicture}[polybox, tos]
    \node[poly, dom, "$p$" below] (p) {};

    \node[poly, right=of p, "$q$" below] (q) {};

    \node[poly, cod, right=of q, "$r$" below] (r) {};
  
    \draw (p_pos) -- node[below] {$f_\1$} (q_pos);
    \draw (q_dir) -- node[above] {$f^\sharp$} (p_dir);
  
    \draw (q_pos) -- node[below] {$g_\1$} (r_pos);
    \draw (r_dir) -- node[above] {$g^\sharp$} (q_dir);
\end{tikzpicture}
\]
The lower (position) box for $q$, which would normally be blue as part of the polyboxes for $g\colon q\to r$, is instead filled in via $f_\1$; similarly, the upper (direction box) for $q$, which would normally be blue as part of the polyboxes for $f\colon p\to q$, is filled in via $g^\sharp$.
This forms a gadget that is equivalent to what the polyboxes would be for $f\then g$.

Again, as we follow the arrows from left to right and up and left again, take care to note that the arrow $g^\sharp$ depends not only on the upper box for $r$, but also the lower box for $q$ that came before it.
Similarly, the arrow $f^\sharp$ depends on both the lower box for $p$ and the upper box for $q$.

On the other hand, the arrow $g_\1$ depends only on the lower box for $q$, and not the lower box for $p$ that came before it: $g_\1$ is the on-positions function for a lens $q\to r$ and therefore depends only on its domain. (Of course, changing the contents of the lower box for $p$ may change the lower box for $q$, thus indirectly affecting what $g_\1$ enters in the lower box for $r$; what we mean is that if the lower box for $p$ changes but the lower box for $q$ does not, $g_\1$ will not change the lower box for $r$.)
For the same reason, the arrow $g^\sharp$ does not depend on the lower box for $p$, and the arrow $f^\sharp$ does not depend on either box for $r$.
The key is to let each arrow depend on exactly the boxes that come before it in either the domain or the codomain of the lens that the arrow is a part of.
Or just remember that these arrows are all on-positions and on-directions functions of lenses!

\begin{remark}
At this point in our introduction to polyboxes, the reader may be concerned that we are referring to things like ``gadgets,'' ``spreadsheets,'' ``users,'' ``automation,'' etc.\ without being entirely precise or rigorous about what we mean by them, or what it means to say that they are ``equivalent.''
We choose to elide this issue to highlight the pictorial intuition of our work, rather than grinding through the nitty-gritty details.
This is not to say our work with polyboxes will lack rigor moving forward---if you're particularly worried, you should think of polyboxes simply as an alternate way to present information about dependent sets, functions, sums, and products that can be systematically translated---via elementary steps, though perhaps with some laborious bookkeeping---into the more standard $\in$ and $\sum$ and $\prod$ notation we have been using thus far.

For example, given lenses $f\colon p\to q$ and $g\colon q\to r$, the polyboxes above really do just represent the element of the set
\[
    \prod_{i\in p(\1)}\sum_{k\in r(\1)}p[i]^{r[k]}\iso\poly(p,r)
\]
corresponding to the lens $p\to r$ whose on-positions function $p(\1)\to r(\1)$ is equal to the composite of the on-positions functions $f_\1$ and $g_\1$, and whose on-directions function $r[g_\1(f_\1(i))]\to p[i]$ for each $i\in p(\1)$ is equal to the composite of the on-directions functions $g^\sharp_{f_\1(i)}$ and $f^\sharp_i$.
In other words, it represents the composite lens $f\then g$.
But it displays the way lenses pass positions and directions back and forth far more legibly than all the words in this paragraph can.
Throughout the rest of this book, we'll see how this polybox notation provides immediate, reader-friendly computations and justifications; but all these results can be translated back into more grounded mathematical language as desired.
\end{remark}

\begin{example}[Dynamical systems as polyboxes]
Polyboxes provide a natural way to model our dependent dynamical systems.
We can express such a system $\phi\colon S\yon^S\to p$ in polyboxes as
\begin{equation*}
\begin{tikzpicture}[polybox, mapstos]
    \node[poly, dom, "$S\yon^S$" left] (S) {$t$\at$s$};

    \node[poly, cod, right=of S, "$p$" right] (p) {$i$\at$o$};
  
    \draw (S_pos) -- node[below] {return} (p_pos);
    \draw (p_dir) -- node[above] {update} (S_dir);
\end{tikzpicture}
\end{equation*}
Then the polybox acts as a channel between the internal state system on the left and the external interface on the right.
The state system enters its current state $s\in S$ into the lower left blue box, and the return function converts this state to the output $o\in p(\1)$, which is exposed by the interface in the lower right white box.
Associated with this output is a set of inputs $p[o]$; an interacting agent selects one of these inputs $i\in p[o]$ to enter into the upper right blue box.
Finally, the update function takes in the current state $s$ and the input $i$ and fills in the upper left white box accordingly with the next state $t\in S$ (or, more precisely, a direction at the current state $s$ that should point to the next state $t$).

We then compose $\phi$ with a wrapper $f\colon p\to q$ like so:
\begin{equation*}
\begin{tikzpicture}[polybox, mapstos]
    \node[poly, dom, "$S\yon^S$" left] (S) {$t$\at$s$};

    \node[poly, right=of S, "$p$" below] (p) {$i$\at$o$};

    \node[poly, cod, right=of p, "$q$" right] (q) {$i'$\at$o'$};
  
    \draw (S_pos) -- node[below] {return} (p_pos);
    \draw (p_dir) -- node[above] {update} (S_dir);
    \draw (p_pos) -- node[below] {$f_\1$} (q_pos);
    \draw (q_dir) -- node[above] {$f^\sharp$} (p_dir);
\end{tikzpicture}
\end{equation*}
The output $o$ displayed by the intermediary interface $p$ is instead exposed as an output $f_\1(o)=o'$ of the wrapper interface $q$ in the lower box on the far right.
Moreover, the upper box of $p$ is no longer blue: an agent who wishes to interact with the middle interface $p$ can only do so via the rightmost interface $q$.
The on-directions function of the wrapper at $o$ converts input $i'\in q[o']$ from the upper right blue box into input $i\in p[o]$.

Picture the agent standing to the right of all the polyboxes (i.e.\ ``outside'' of the system) with their attention directed leftward (i.e.\ ``inward''), receiving output from the white box below and feeding input into the blue box above.
To an agent who is unaware of its inner workings, the composite dynamical system $\phi\then f$ might as well look like this:
\begin{equation*}
\begin{tikzpicture}[polybox, mapstos]
    \node[poly, dom, "$S\yon^S$" left] (S) {$t$\at$s$};

    \node[poly, cod, right=of p, "$q$" right] (q) {$i'$\at$o'$};
  
    \draw (S_pos) -- node[below] {return$'$} (q_pos);
    \draw (q_dir) -- node[above] {update$'$} (S_dir);
\end{tikzpicture}
\end{equation*}
\end{example}

\subsection{Situations as polyboxes}
When a polynomial has only $1$ position (i.e.\ it is representable), we shade its lower (position) polybox gray to indicate that there is no choice to be made there, either by the user or by the automation; similarly, if a polynomial has only $1$ direction at every position (i.e.\ it is linear), we shade its upper (direction) polybox gray.
So both polyboxes for $\yon$ are shaded gray.

In \cref{subsec.poly.dyn_sys.new.sit_encl}, we discussed situations, which are lenses with codomain $\yon$.
A situation $\gamma\colon p\to\yon$, then, can be depicted as follows, where $!$ is the unique function into $\1$:
\[
 \begin{tikzpicture}[polybox, tos]
  	\node[poly, dom, "$p$" left] (p) {};
  	\node[poly, identity, right=of p, "$\yon$" right] (yon) {};
  	\draw (p_pos) -- node[below] {$!$} (yon_pos);
  	\draw (yon_dir) -- node[above] {$\gamma^\sharp$} (p_dir);
	\end{tikzpicture}
\]
But this is equivalent to a gadget where, when the user fills in the lower left blue box with a $p$-position $i$, the upper left white box is automatically filled with a $p[i]$-direction $a$.
(Remember that the arrow $\gamma^\sharp$ depends not only on the box to its right, but also on the lower left box of $p$.)
So we can redraw the gadget like so, combining the arrows $!$ and $\gamma^\sharp$ into one arrow $\gamma$:
\begin{equation}\label{eqn.map_to_0ary_composite}
\begin{tikzpicture}[polybox, tos]
    \node[poly, dom, "$p$" left] (p) {};
    \draw (p_pos) to[climb'] node[right] {$\gamma$} (p_dir);
\end{tikzpicture}
\end{equation}
This lines up with what we already know: that a situation $\gamma\colon p\to\yon$ is just a dependent function $\gamma\colon(i\in p(\1))\to p[i]$.

\begin{example}[Enclosures as polyboxes]
Recall that in the language of dynamical systems, situations for interfaces are thought of as enclosures: a fixed selection of input at every output that closes off the interface from external observation or interference.
In polyboxes, composing a system $S\yon^S\to p$ with an enclosure $\gamma$ for $p$ can be depicted as
\begin{equation*}
\begin{tikzpicture}[polybox, tos]
    \node[poly, dom, "$S\yon^S$" left] (S) {};

    \node[poly, right=of S, "$p$" below] (p) {};
    
  	\node[poly, identity, right=of p, "$\yon$" right] (yon) {};
  
    \draw (S_pos) -- node[below] {return} (p_pos);
    \draw (p_dir) -- node[above] {update} (S_dir);
    \draw (p_pos) -- node[below] {$!$} (yon_pos);
    \draw (yon_dir) -- node[above] {$\gamma^\sharp$} (p_dir);
\end{tikzpicture}
\end{equation*}
or, equivalently, as
\begin{equation*}
\begin{tikzpicture}[polybox, tos]
    \node[poly, dom, "$S\yon^S$" left] (S) {};

    \node[poly, right=of S, "$p$" below] (p) {};
  
    \draw (S_pos) -- node[below] {return} (p_pos);
    \draw (p_dir) -- node[above] {update} (S_dir);
    \draw (p_pos) to[climb'] node[right] {$\gamma$} (p_dir);
\end{tikzpicture}
\end{equation*}
Remember: in a polybox depiction of a dynamical system, the world outside the system exists to the right of all the boxes.
So the first picture represents $\yon$ as a gray wall, cutting off any interaction between the system to its left and the world to its right.
Meanwhile, the second picture illustrates how an enclosed system independently selects inputs to the intermediary interface $p$ via $\gamma$, according to the outputs of $p$ that the inner (leftward) system $S\yon^S\to p$ returns.
While the second picture shows us why the closed system neither seeks nor requires external input, the first picture helps remind us that the output of $p$ never reaches the outside world either.
The composite system is therefore equivalent to the enclosure drawn as follows:
\begin{equation*}
\begin{tikzpicture}[polybox, tos]
    \node[poly, dom, "$S\yon^S$" left] (S) {};

    \draw (S_pos) to[climb'] node[right] {$\gamma'$} (S_dir);
\end{tikzpicture}
\end{equation*}
In polynomial morphism parlance, $\gamma'\colon S\yon^S\to\yon$ is the original system $S\yon^S\to p$ composed with $\gamma\colon p\to\yon$; in the language of dependent functions, $\gamma'\colon S\to S$ is given by
\[
    \gamma'(s)=\text{update}(s,\gamma(\text{return}(s))) \qquad \text{for all }s\in S,
\]
where we interpret $\gamma$ as a dependent function $(i\in p(\1))\to p[i]$.
We can deduce this equation by matching up the previous two different polybox pictures, knowing that they represent the same lens.
Placing the boxes side by side and filling them in with dummy variables makes the equation easier to read off the picture:
\[
\begin{tikzpicture}
	\node (1) {
    \begin{tikzpicture}[polybox, mapstos]
        \node[poly, dom, "$S\yon^S$" left] (S) {$t$\at$s$};
    
        \node[poly, right=of S, "$p$" below] (p) {$o$\at$i$};
      
        \draw (S_pos) -- node[below] {return} (p_pos);
        \draw (p_dir) -- node[above] {update} (S_dir);
        \draw (p_pos) to[climb'] node[right] {$\gamma$} (p_dir);
    \end{tikzpicture}
	};
	\node[right=1.8 of 1] (2) {
    \begin{tikzpicture}[polybox, mapstos]
        \node[poly, dom, "$S\yon^S$" left] (S) {$t'$\at$s$};

        \draw (S_pos) to[climb'] node[right] {$\gamma'$} (S_dir);
    \end{tikzpicture}
	};
	\node at ($(1.east)!.5!(2.west)$) {=};
\end{tikzpicture}
\]
Notice that we filled the blue boxes on either side with the same entry.
Matching up the upper boxes of the domain in both pictures, we have that $t=t'$, so
\[
    \gamma'(s)=t'=t=\text{update}(s,o)=\text{update}(s,\gamma(i))=\text{update}(s,\gamma(\text{return}(s))).
\]
Later on, we will read more intricate equations off of polyboxes in this manner, although we won't spell it out in so much detail.
We encourage you to trace through the arrows on your own.
\end{example}

\begin{example}[The do-nothing enclosure in polyboxes]  \label{ex.do_nothing_polybox}
In \cref{ex.do_nothing}, we saw that every state system $S\yon^S$ can be equipped with an enclosure $\epsilon\colon S\yon^S\to\yon$ called the do-nothing enclosure, which assigns each state-position to its corresponding state-direction, thus leaving the state unchanged.
That is, it is the enclosure whose polyboxes can be drawn as follows:
\begin{equation*}
\begin{tikzpicture}[polybox, mapstos]
    \node[poly, dom, "$S\yon^S$" left] (S) {$s$\at$s$};

    \draw (S_pos) to[climb'] node[right] {$\epsilon$} (S_dir);
\end{tikzpicture}
\end{equation*}

This simple example illustrates how we can use polyboxes to specify a particular lens---or, equivalently, how we can use polyboxes to \emph{define} a lens, the same way we might define a function by writing it as a formula in a dummy variable.
\end{example}


\subsection{Lenses to composites as polyboxes}
A lens $p\to q_1\tri q_2$ is an element of the set
\begin{align*}
    \poly(p, q_1\tri q_2) &\iso \poly\left(p, \sum_{j_1\in q_1(\1)}\;\prod_{b_1\in q_1[j_1]}\;\sum_{j_2\in q_2(\1)}\;\prod_{b_2\in q_2[j_2]}\yon\right) \tag*{\eqref{eqn.composite_formula}} \\
    &\iso \prod_{i\in p(\1)}\;\sum_{j_1\in q_1(\1)}\;\prod_{b_1\in q_1[j_1]}\;\sum_{j_2\in q_2(\1)}\;\prod_{b_2\in q_2[j_2]}p[i]. \tag*{\eqref{eqn.main_formula}}
\end{align*}
So we can write down the instructions for picking a lens $p\to q_1\tri q_2$ as follows.
\begin{quote}
To choose a lens $p\to q_1\tri q_2$:
\begin{enumerate}
    \item for each $p$-position $i$:
    \begin{enumerate}[label*=\arabic*.]
        \item choose a $q_1$-position $j_1$;
        \item for each $q_1[j_1]$-direction $b_1$:
        \begin{enumerate}[label*=\arabic*.]
            \item choose a $q_2$-position $j_2$;
            \item for each $q_2[j_2]$-direction $b_2$:
            \begin{enumerate}[label*=\arabic*.]
                \item choose a $p[i]$-direction $a$.
            \end{enumerate}
        \end{enumerate}
    \end{enumerate}
\end{enumerate}
\end{quote}
We could try to write out the dependent functions that these instructions correspond to.
Alternatively, we could simply draw this protocol out using polyboxes, with every ``for each'' step corresponding to a user-maintained blue box and every ``choose'' step corresponding to an automated white box:
\begin{equation}\label{eqn.map_to_2ary_composite}
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$p$" left] (p) {$a$\at$i$};
	\node[poly, cod, right=1.5cm of p.south, yshift=-1ex, "$q_1$" right] (q1) {$b_1$\at$j_1$};
	\node[poly, cod, above=of q1, "$q_2$" right] (q2) {$b_2$\at$j_2$};
  	\draw (p_pos) to[first] (q1_pos);
  	\draw (q1_dir) to[climb] (q2_pos);
  	\draw (q2_dir) to[last] (p_dir);
\end{tikzpicture}
\end{equation}
Whenever we draw two pairs of polyboxes on top of each other, as we do with the polyboxes for $q_1$ and $q_2$ above on the right, we are indicating that the entire column of polyboxes depicts the composite of the polynomials depicted by each individual pair.
So the column of polyboxes on the right represents the composite $q_1\tri q_2$.
In particular, the position in the lower box of the top pair is the position associated with the direction in the upper box of the bottom pair, for the depicted position of the composite.

So a lens $p\to q_1\tri q_2$ is any protocol that will fill in the white boxes above as the user fills in the blue boxes in the direction of the arrows.
We'll see this in action in \cref{ex.map_to_comp}.

In fact, \eqref{eqn.map_to_0ary_composite}, \eqref{eqn.polybox_lens}, and \eqref{eqn.map_to_2ary_composite} are the respective polybox depictions of the $n=0, n=1,$ and $n=2$ cases of lenses $p\to q_1\tri\cdots\tri q_n$ to $n$-fold composites (we consider the monoidal unit $\yon$ of $\tri$ to be the $0$-fold composite, and a $1$-fold composite is just a polynomial on its own).
In general, for any $n\in\nn$, we can apply 
\begin{align} \label{eqn.lens_to_comp}
    \poly(p, q_1\tri\cdots\tri q_n) &\iso\poly\left(p, \sum_{j_1\in q_1(\1)}\;\prod_{b_1\in q_1[j_1]}\cdots\sum_{j_n\in q_n(\1)}\;\prod_{b_n\in q_n[j_n]}\yon\right) \tag*{\eqref{eqn.composite_formula}} \\
    &\iso \prod_{i\in p(\1)}\;\sum_{j_1\in q_1(\1)}\;\prod_{b_1\in q_1[j_1]}\cdots\sum_{j_n\in q_n(\1)}\;\prod_{b_n\in q_n[j_n]}p[i], \tag*{\eqref{eqn.main_formula}}
\end{align}
so the polybox depiction of $p\to q_1\tri\cdots\tri q_n$ generalizes analogously.
For example, here are the polyboxes corresponding to a lens to a $4$-fold composite:
\[
\begin{tikzpicture}[polybox, tos]
	\node[poly, dom, "$p$" left] (p) {};
	\foreach \i in {1,...,4}
	{
  	\node[poly, cod, "$q_\i$" right] (q\i) at (3,1.3*\i-3.25) {};
	};
	\draw (p_pos) to[first] node[below] {} (q1_pos.west);
	\foreach \i/\j in {1/2,2/3,3/4}
	{
		\draw 
			(q\i_dir.west) 
			to[climb] 
			node[left] {}
			(q\j_pos.west);
	};
	\draw (q4_dir) to[last] node[above left] {} (p_dir);
\end{tikzpicture}
\]

% We can use this to generalize our notation in the case $k=1$, i.e.\ for lenses $p\to q$. That is we denoted such a morphism by $\lens{f^\sharp}{f_\1}$, where $f_\1\colon p(\1)\to q(\1)$ and $f^\sharp_i\colon q[f_\1(i)]\to p[i]$. We generalize this to the $k$-ary composite case as
% \begin{equation}\label{eqn.notation_f1f2fk}
% (f_1,f_2,\ldots,f_k,f^\sharp)\colon p\too q_1\tri q_2\tri\cdots\tri q_k,
% \end{equation}
% where
% \begin{equation}\label{eqn.maps_to_comp}
% \begin{aligned}
% f_1&:p(\1)\to q_1(\1),\\
% f_2&:(i\in p(\1))\to (b_1\in q_1[f_1(i)])\to q_2(\1),\\
% f_3&:(i\in p(\1))\to (b_1\in q_1[f_1(i)])\to (b_2\in q_2[f_2(i,b_1)])\to q_3(\1),\\
% f_k&:(i\in p(\1))\to (b_1\in q_1[f_1(i)])\to  \cdots\to(b_{k-1}\in q_{k-1}[f_{k-1}(i,b_1,\ldots,b_{k-2})])\to q_k(\1),\\
% f^\sharp&:(i\in p(\1))\to (b_1\in q_1[f_1(i)])\to \cdots\to(b_{k}\in q_k[f_{k}(i,b_1,\ldots,b_{k-1})])\to p[i]
% \end{aligned}
% \end{equation}

These lenses to $n$-fold composites lend themselves to a very natural interpretation in terms of our decision-making language.
Each of $p$'s menus is passed forward to a menu for $q_1$ to choose from.
For every option that $q_1$ may choose, there is then also a menu for $q_2$ to choose from.
Then for every option that $q_2$ may choose, there is a menu for $q_3$ to choose from, and so on, all the way until $q_n$ has chosen an option.
Together, all the options that $q_1,\ldots,q_n$ chose then inform the option that $p$ should select from its original menu.

\slogan{A lens $p\to q_1\tri\cdots\tri q_n$ is a multi-step policy for $p$ to make decisions by asking for decisions from $q_1$, then $q_2$, etc., all the way to $q_n$, then interpreting the results.}

\begin{example}[Lenses $p\to q\tri r$]\label{ex.map_to_comp}
Consider a lens $f\colon p\to q\tri r$.
Let's label the three arrows in the lens's polybox depiction:
\[
\begin{tikzpicture}[polybox, tos]
	\node[poly, dom, "$p$" left] (p) {};
	\node[poly, cod, right=1.5cm of p.south, yshift=-1ex, "$q$" right] (q) {};
	\node[poly, cod, above=of q, "$r$" right] (r) {};
  	\draw (p_pos) to[first] node[below] {$f^q$} (q_pos);
  	\draw (q_dir) to[climb] node[right] {$f^r$} (r_pos);
  	\draw (r_dir) to[last] node[above] {$f^\sharp$} (p_dir);
\end{tikzpicture}
\]
So the on-position function of $f$ can be split into two parts: a function $f^q\colon p(\1)\to q(\1)$ and, for each $i\in p(\1)$, a function $f^r_i\colon q[f^q(i)]\to r(\1)$.
Then the on-directions function $f^\sharp_i\colon (q\tri r)[f_\1(i)]\to p[i]$ takes the direction of $q$ and the direction of $r$ in the two blue boxes on the right and sends them to a direction of $p$ at $i$ to fill the white box on the left.

For example, let $p\coloneqq\{A\}\yon^{\{R,S\}}+{B}\yon^{\{T\}}$, $q\coloneqq\{C\}\yon^{\{U,V,W\}}+\{D\}\yon^{\{X\}}$, and $r\coloneqq\{E\}\yon^{\{Y,Z\}}+\{F\}$.
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, "$p=$" left] {
	\begin{tikzpicture}[trees, sibling distance=4mm]
    \node["\tiny $A$" below] (1) {$\bullet$} 
      child {node[above, font=\tiny] {$R$}}
      child {node[above, font=\tiny] {$S$}};
    \node[right=.5 of 1,"\tiny $B$" below] (2) {$\bullet$} 
      child {node[above, font=\tiny] {$T$}};
  \end{tikzpicture}
  };
%
	\node (q) [draw, blue, right=2 of p, "$q=$" left] {
	\begin{tikzpicture}[trees, sibling distance=4mm]
    \node["\tiny $C$" below] (1) {$\bullet$} 
      child {node[above, font=\tiny] {$U$}}
      child {node[above, font=\tiny] {$V$}}
      child {node[above, font=\tiny] {$W$}};
    \node[right=.75 of 1,"\tiny $D$" below] (2) {$\bullet$} 
      child {node[above, font=\tiny] {$X$}};
  \end{tikzpicture}
  };
	\node (r) [draw, red, right=2 of q, "$r=$" left] {
	\begin{tikzpicture}[trees, sibling distance=4mm]
    \node["\tiny $E$" below] (1) {$\bullet$} 
      child {node[above, font=\tiny] {$Y$}}
      child {node[above, font=\tiny] {$Z$}};
    \node[right=.5 of 1,"\tiny $F$" below] (2) {$\bullet$};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Here is a tree picture of a lens $f\colon p\to q\tri r$:
\[
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=5mm},
	  level 2/.style={sibling distance=5mm}]
    \node["\tiny $A$" below] (1) {$\bullet$} 
      child {coordinate (11')}
      child {coordinate (12')};
    \node[right=2 of 1, blue, "\color{blue} \tiny $C$" below] (1') {$\bullet$}
    	child[blue] {node[red] {$\bullet$}
				child[red] {coordinate (1'1)}
				child[red] {coordinate (1'2)}
			}
		child[blue] {node[red] {$\bullet$}
			}
		child[blue] {node[red] {$\bullet$}
				child[red] {coordinate (1'3)}
				child[red] {coordinate (1'4)}
			}
			;
%
    \node (2) [right=3 of 1',"\tiny $B$" below] {$\bullet$} 
      child {coordinate (21')};
    \node[right=2 of 2, blue,"\color{blue} \tiny $D$" below] (2') {$\bullet$}
			child[blue] {node[red] {$\bullet$}
				child[red] {coordinate (2'1)}
				child[red] {coordinate (2'2)}
			}
			;
%
  \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (1');
  \draw[|->, shorten <= 3pt, shorten >= 3pt] (2) -- (2');
  \begin{scope}[densely dotted, bend right=60pt]
  	\draw[postaction={decorate}] (1'1) to (12');
  	\draw[postaction={decorate}] (1'2) to (11');
  	\draw[postaction={decorate}] (1'3) to (11');
  	\draw[postaction={decorate}] (1'4) to (11');
  	\draw[postaction={decorate}] (2'1) to (21');
  	\draw[postaction={decorate}] (2'2) to (21');
  \end{scope}
\end{tikzpicture}
\]
If we write $f$ as the corresponding triple $(f^q, f^r, f^\sharp)$, then we have
\begin{gather*}
f^q(A)=C,\quad f^q(B)=D;\\
f^r_A(U)=E,\quad f^r_A(V)=F,\quad f^r_A(W)=E;\\
f^r_B(X)=E;\\
f^\sharp_A(U,Y)=S,\quad f^\sharp_A(U,Z)=R,\quad f^\sharp_A(W,Y)=R,\quad f^\sharp_A(W,Z)=R;\\
f^\sharp_B(X,Y)=T,\quad f^\sharp_B(X,Z)=T.
\end{gather*}
Polyboxes display the same data in a different format:
\[
\begin{tikzpicture}[polybox, mapstos, node distance=2ex and 1.4cm]
  \node (a) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$S$\at$A$};
  	\node[poly, cod, right= of p.south, yshift=-1ex] (q) {$U$\at$C$};
  	\node[poly, cod, above=of q] (r) {$Y$\at$E$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
  };
  \node[right=.6 of a] (b) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$R$\at$A$};
  	\node[poly, cod, right= of p.south, yshift=-1ex] (q) {$U$\at$C$};
  	\node[poly, cod, above=of q] (r) {$Z$\at$E$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
  };
  \node[right=.6of b] (c) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {\at$A$};
  	\node[poly, cod, right= of p.south, yshift=-1ex] (q) {$V$\at$C$};
  	\node[poly, constant, above=of q] (r) {\at$F$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
		\draw[densely dotted] (r_dir) to[last] (p_dir);
  \end{tikzpicture}
  };
  \node[right=.6 of c] (d) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$R$\at$A$};
  	\node[poly, cod, right= of p.south, yshift=-1ex] (q) {$W$\at$C$};
  	\node[poly, cod, above=of q] (r) {$Y$\at$E$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
	};
  \node[right=.6 of d] (e) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$R$\at$A$};
  	\node[poly, cod, right= of p.south, yshift=-1ex] (q) {$W$\at$C$};
  	\node[poly, cod, above=of q] (r) {$Z$\at$E$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
	};
  \node[below=.6 of a] (f) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$T$\at$B$};
  	\node[poly, cod, right= of p.south, yshift=-1ex] (q) {$X$\at$D$};
  	\node[poly, cod, above=of q] (r) {$Y$\at$E$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
	};
  \node[below=.6 of b] (g) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$T$\at$B$};
  	\node[poly, cod, right= of p.south, yshift=-1ex] (q) {$X$\at$D$};
  	\node[poly, cod, above=of q] (r) {$Z$\at$E$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
	};
\end{tikzpicture}
\]
As before, keep in mind that each arrow of a lens depends not only on the box it emerges from, but also on every box that came before it in our usual reading order (lower left to lower right to upper right to upper left).

The third set of polyboxes, where the left blue box has been filled with an $A$ and the lower right blue box has been filled with a $V$, is worth highlighting: as $f^r_A(V)=F$, but $r[F]=\varnothing$, it is impossible to write a direction of $r$ at $F$ to go in the upper right box.
To indicate this, we color the upper right box red and leave the arrow emerging from it dashsed.
\end{example}

% \begin{example}[Using \eqref{eqn.notation_f1f2fk} to denote positions and directions in a composite]\label{ex.pos_in_composite}
% Given polynomials $p_1,\ldots,p_n$, recall from \cref{exc.positions_maps_yon} that the position-set of their composite is isomorphic to the hom-set
% \[
%     \poly(\yon, p_1\tri\cdots\tri p_n),
% \]
% which by \eqref{eqn.lens_to_comp} is in turn isomorphic to
% \[
%     \sum_{i_1\in p_1(\1)}\;\prod_{d_1\in p_1[i_1]}\cdots\sum_{i_n\in p_n(\1)}\;\prod_{d_n\in p_n[i_n]}\1.
% \]

% We can denote $i$ in the notation \eqref{eqn.notation_f1f2fk} as $i=(i_1,\ldots,i_n)$, forgoing the input to $i_1$ because it is always $1\in\1$ and also forgoing $f^\sharp$ because it is always the unique map to $\1$. Then in this notation 
% \begin{gather*}
% i_1\in p_1(\1),\quad
% i_2\colon p_1[i_1]\to p_2(\1),\quad
% i_3\colon (d_1\in p_1[i_1])\to(d_2\in p_2[i_2(d_1)])\to p_3(\1),\\
% i_k\colon(d_1\in p_1[i_1])\to(d_2\in p_2[i_2(d_1)])\to\cdots(d_{k-1}\in p_{k-1}[i_{k-1}(d_1,\ldots,d_{k-2})])\to p_k(\1)
% \end{gather*}

% So for example to give a position in $p\tri q\tri r$ we need 
% \[
% i\in p(\1),\quad
% j\colon p[i]\to q(\1),\quad
% k:(a\in p[i])\to(b\in q[j(a)])\to r(\1).
% \]

% The direction-set of $p_1\tri\cdots\tri p_k$ at position $(i_1,\ldots,i_k)$ is 
% \[
% (p_1\tri\cdots\tri p_k)[(i_1,\ldots,i_k)]\cong\sum_{d_1\in p_1[i_1]}\sum_{d_2\in p_2[i_2(d_1)]}\cdots\sum_{d_k\in p_k[i_k(d_1,\ldots,d_{k-1})]}\1
% \]
% So for example given a position $(i,j,k)\in p\tri q\tri r$, a direction there consists of a tuple $(a,b,c)$ where $a\in p[i]$, $b\in q[j(a)]$ and $f\in r[k(a,b)]$.
% \end{example}

% \begin{exercise}
% Suppose $A_1,\ldots,A_k$ are sets and $p_i\coloneqq A_i\yon$ for each $i$. Use the notation of \cref{ex.pos_in_composite} to give the position-set $p\coloneqq p_1\tri\cdots\tri p_k$.
% \end{exercise}

\begin{example}[Dynamical systems with composite interfaces]
We explored dynamical systems with product interfaces in \cref{subsec.poly.dyn_sys.new.prod} and parallel product interfaces in \cref{subsec.poly.dyn_sys.new.par}.
How about dynamical systems with composite interfaces?
We now have all the tools we need to characterize them.

By the previous example, a dynamical system $\phi\colon S\yon^S\to q\tri r$ can be drawn as
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$S\yon^S$" left] (p) {$t$\at$s$};
	\node[poly, cod, right=1.5cm of p.south, yshift=-1ex, "$q$" right] (q) {$b$\at$j$};
	\node[poly, cod, above=of q, "$r$" right] (r) {$c$\at$k$};
  	\draw (p_pos) to[first] node[below] {$\phi^q$} (q_pos);
  	\draw (q_dir) to[climb] node[right] {$\phi^r$} (r_pos);
  	\draw (r_dir) to[last] node[above] {$\phi^\sharp$} (p_dir);
\end{tikzpicture}
\]
We can interpret the behavior of this system as follows.
Rather than a single interface $q\tri r$, we view $\phi$ as having two interfaces that must be interacted with in succession, $q$ followed by $r$.

Given the current state $s\in S$, the system feeds it into $\phi^q$ to return an output $j$ of the first interface $q$.
Upon receiving an input $b\in q[j]$, it then uses $\phi^r$ to return another output $k$ (dependent on the state $s$ and the input $b$), this time belonging to the second interface $r$.
Once a second input $c$ is received, this time from $r[k]$, the system updates its state by feeding the current state $s$ and the pair of inputs $(b,c)$ it received into $\phi^\sharp$, yielding a new state $t\in S$.

That's a lot of words, which is why the polybox picture is so helpful: by following the arrows, we can see that a dynamical system with a composite interface actually captures a very natural type of interaction!
Mixing our metaphors a little, $\phi$ could model a system that displays cascading menus, where selecting an option $b$ on the first menu $j$ opens up a second menu $k$.
It is only when the interacting agent selects an option $c$ from this second menu that both choices are sent back to the state system, which updates its state accordingly.

All this generalizes to $n$-fold composite interfaces exactly how you'd expect: a dynamical system with interface $q_1\tri\cdots\tri q_n$ produces output and receives input through interface $q_1$, then accordingly produces output and receives input through interface $q_2$, and so on, until it produces output (according to the current state and all previous inputs) and receives input through $q_n$, whereupon it updates its state according to the $n$ inputs it received along with the current state.
\end{example}


\subsection{The composition product of lenses as polyboxes}

A special case of a lens whose codomain is a composite is a lens that is itself the composition product of lenses.
If we draw such a lens using polyboxes by following the instructions from \eqref{eqn.comp_lens_pos} and \eqref{eqn.comp_lens_dir}, we would really just be stacking the polyboxes for the constituent lenses on top of each other.
For example, given lenses $f\colon p\to q$ and $f'\colon p'\to q'$, here is $f\tri f'$ drawn as polyboxes:
\begin{equation} \label{eqn.comp_lens_polybox}
\begin{tikzpicture}[polybox, tos]
	\node[poly, dom, "$p$" left] (p) {};
	\node[poly, dom, above=.8 of p, "$p'$" left] (p') {};
	\node[poly, cod, right=of p, "$q$" right] (q) {};
	\node[poly, cod, above=.8 of q, "$q'$" right] (q') {};
	\draw (p_pos) -- node[below] {$f_\1$} (q_pos);
	\draw (q_dir) -- node[above] {$f^\sharp$} (p_dir);
	\draw (p'_pos) -- node[below] {$f'_\1$} (q'_pos);
	\draw (q'_dir) -- node[above] {$(f')^\sharp$} (p'_dir);	
\end{tikzpicture}
\end{equation}
What differentiates this from simply writing down the polyboxes for $f$ and the polyboxes for $f'$ is that we are explictly associating the position that will fill the lower box of $p'$ with the direction that will fill the upper box of $p$, and likewise the position that will fill the lower box of $q'$ with the direction that will fill the upper box of $q$.
Moreover, we have the user fill out the lower set of boxes first and work their way up, so that, in particular, they can use the information they obtained from the behavior of $f_\1$ and $f^\sharp$ to decide what to put in the lower box of $p'$.
So this really does depict a lens $p\tri p'\to q\tri q'$.

How does \eqref{eqn.comp_lens_polybox} relate to our usual polybox depiction of a lens to a composite, as in \eqref{eqn.map_to_2ary_composite}, but with the domain also replaced with a composite?
A user who interacts with \eqref{eqn.comp_lens_polybox} can fill the lower set of polyboxes (the ones for $f$) first, ignoring the upper set of polyboxes (the ones for $f'$) until the entire lower half is filled.
Alternatively, after they fill in the lower box of $p$, but before they fill in anything else, they can already decide what position to put in the lower box of $p'$ for every possible direction that could end up in the upper box of $p$.
By \eqref{eqn.comp_pos}, such a choice is equivalent to picking a position of the composite $p\tri p'$.
Then by \eqref{eqn.comp_lens_pos}, following just the bottom arrow $f_\1$ leads to the corresponding position of $q$ given by $f\tri f'$, while filling in the upper box of $q$ and following $f^\sharp$, then $f'_\1$ leads to the position of $q'$ that goes in the bottom box of $q'$.
Finally, once the user fills in the upper box of $q'$, following the top arrow $(f')^\sharp$ completes the specification of a direction of $p\tri p'$.
In this way, \eqref{eqn.comp_lens_polybox} can be thought of as a special case of \eqref{eqn.map_to_2ary_composite}.

\begin{example}[Dynamical systems and the composition product, revisited] \label{ex.dyn_sys_comp_polyboxes}
In \cref{subsec.comon.comp.def.dyn_sys}, we explained how the $n$-fold composition product $\phi\tripow{n}$ of a dynamical system $\phi\colon S\yon^S\to p$ models the behavior of running through the system $n$ times, provided we choose the positions of $(S\yon^S)\tripow{n}$ appropriately.
We can visualize this behavior using polyboxes---for example, here's what the $n=3$ case looks like:
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$S\yon^S$" left] (s) {$s_1$\at$s_0$};
	\node[poly, dom, above=.8 of s, "$S\yon^S$" left] (s') {$s_2$\at$s_1$};
	\node[poly, dom, above=.8 of s', "$S\yon^S$" left] (s'') {$s_3$\at$s_2$};
	
	\node[poly, cod, right=of s, "$p$" right] (p) {$i_1$\at$o_0$};
	\node[poly, cod, above=.75 of p, "$p$" right] (p') {$i_2$\at$o_1$};
	\node[poly, cod, above=.7 of p', "$p$" right] (p'') {$i_3$\at$o_2$};
	
	\draw (s_pos) -- node[below] {return} (p_pos);
	\draw (p_dir) -- node[above] {update} (s_dir);
	
	\draw (s'_pos) -- node[below] {return} (p'_pos);
	\draw (p'_dir) -- node[above] {update} (s'_dir);
	
	\draw (s''_pos) -- node[below] {return} (p''_pos);
	\draw (p''_dir) -- node[above] {update} (s''_dir);
\end{tikzpicture}
\]
It is now patently obvious what $\phi\tripow3$ does from this picture, as long as we know how to read polyboxes (and we could probably make a pretty good guess even if we didn't!).
This resolves the first issue we raised in \cref{subsec.comon.comp.def.dyn_sys}, page~\pageref{subsubsec.comon.comp.def.dyn_sys.issues}: we now have a concise way of depicting the $n$-fold composite of a dynamical system.
The second issue becomes clear when we look at which boxes are blue along the left: we would really like the position $s_1$ to be entered above the direction $s_1$ automatically, the $s_2$ entered above $s_2$ automatically, etc.\ rather than having to specify the contents of those blue boxes manually.
We shouldn't even having the option to fill those blue boxes in with anything else.
We'll see how to address this issue shortly in \cref{ex.dyn_sys_trans_polyboxes}.
\end{example}

We make a big deal out of it, but \eqref{eqn.comp_lens_polybox} really is just the polyboxes of two separate lenses drawn together.
Where such polyboxes truly get interesting is when we compose them with polyboxes that look like \eqref{eqn.map_to_2ary_composite}.
That is, given a lens $g\colon r\to p\tri p'$, consider the polyboxes for $g\then(f\tri f')$:
\[
\begin{tikzpicture}[polybox, tos]
	\node[poly, dom, "$r$" left] (r) {};
	\node[poly, right=1.8 of r.south, yshift=-2.5ex, "$p$" below] (p) {};
	\node[poly, above=.8 of p, "$p'$" above] (p') {};
	\node[poly, cod, right=of p, "$q$" right] (q) {};
	\node[poly, cod, above=.8 of q, "$q'$" right] (q') {};
	\draw (p_pos) -- node[below] {$f_\1$} (q_pos);
	\draw (q_dir) -- node[above] {$f^\sharp$} (p_dir);
	\draw (p'_pos) -- node[below] {$f'_\1$} (q'_pos);
	\draw (q'_dir) -- node[above] {$(f')^\sharp$} (p'_dir);	
	\draw (r_pos) to[first] node[below] {$g^{p}$} (p_pos);
	\draw (p_dir) to[climb] node[right] {$g^{p'}$} (p'_pos);
	\draw (p'_dir) to[last] node[above] {$g^\sharp$} (r_dir);
\end{tikzpicture}
\]
There's a lot going on with this lens! To fill out these polyboxes, we start from the lower box of $r$, go all the way right to the lower box of $q$, loop back left, up, and right again to the lower box of $q'$, then travel left all the way back to the upper box of $r$.

Say we knew that $g\then(f\tri f')$ were equal to some other lens $h\colon r\to q\tri q'$:
\[
\begin{tikzpicture}
	\node (1) {
  \begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$r$" left] (r) {\at$k$};
	\node[poly, right=1.8 of r.south, yshift=-2.5ex, "$p$" below] (p) {};
	\node[poly, above=.8 of p, "$p'$" above] (p') {};
	\node[poly, cod, right=of p, "$q$" right] (q) {$b$};
	\node[poly, cod, above=.8 of q, "$q'$" right] (q') {$b'$};
	\draw (p_pos) -- node[below] {$f_\1$} (q_pos);
	\draw (q_dir) -- node[above] {$f^\sharp$} (p_dir);
	\draw (p'_pos) -- node[below] {$f'_\1$} (q'_pos);
	\draw (q'_dir) -- node[above] {$(f')^\sharp$} (p'_dir);	
	\draw (r_pos) to[first] node[below] {$g^{p}$} (p_pos);
	\draw (p_dir) to[climb] node[right] {$g^{p'}$} (p'_pos);
	\draw (p'_dir) to[last] node[above] {$g^\sharp$} (r_dir);
  \end{tikzpicture}
	};
	\node[right=1.8 of 1] (2) {
  \begin{tikzpicture}[polybox, mapstos]
  	\node[poly, dom, "$r$" left] (r) {\at$k$};
  	\node[poly, cod, right=1.8 of r.south, yshift=-1ex, "$q$" right] (q) {$b$};
  	\node[poly, cod, above=of q, "$q'$" right] (q') {$b'$};
  	\draw (r_pos) to[first] node[below] {$h^q$} (q_pos);
  	\draw (q_dir) to[climb] node[right] {$h^{q'}$} (q'_pos);
  	\draw (q'_dir) to[last] node[above] {$h^\sharp$} (r_dir);
  \end{tikzpicture}
	};
	\node at ($(1.east)!.5!(2.west)$) {=};
\end{tikzpicture}
\]

We've filled in the corresponding blue boxes on either side of the equation with the same entries.
So if these two sets of polyboxes really do depict the same lens, each of the three white boxes in the domain and codomain on the left should end up with the same entry as the corresponding white box on the right (although the intermediary mechanics may differ).
Then if we follow the arrows in order on either side, matching up the white boxes in the domain and codomain along the way, we can read off three equations:
\[
    g^p\then f_\1 = h^q, \qquad f^\sharp_{g^p(k)}\then g^{p'}_k\then f'_\1 = h^{q'}_k, \qqand (f')^\sharp_{g^{p'}\left(f^\sharp_{g^p(k)}(b)\right)}\then g^\sharp_k = h^\sharp_k.
\]
The converse holds as well: if the three equations above all hold, then $g\then(f\tri f')=h$.
We will read equations off of polyboxes like this repeatedly in the rest of the book.%, including in the following example.

\begin{example}[Transition lenses for state systems] \label{ex.dyn_sys_trans_polyboxes}

In \cref{ex.dyn_sys_comp_polyboxes}, we saw that the $2$-fold composition product $\phi\tripow2$ of a dynamical system $\phi\colon S\yon^S\to p$ can be drawn as follows:
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$S\yon^S$" left] (s) {$s_1$\at$s_0$};
	\node[poly, dom, above=.8 of s, "$S\yon^S$" left] (s') {$s_2$\at$s_1$};

	\node[poly, cod, right=of s, "$p$" right] (p) {$i_1$\at$o_0$};
	\node[poly, cod, above=.75 of p, "$p$" right] (p') {$i_2$\at$o_1$};

	\draw (s_pos) -- node[below] {return} (p_pos);
	\draw (p_dir) -- node[above] {update} (s_dir);
	
	\draw (s'_pos) -- node[below] {return} (p'_pos);
	\draw (p'_dir) -- node[above] {update} (s'_dir);
\end{tikzpicture}
\]
This \emph{almost} models the behavior of running through the system twice, except that we should really only have one blue box on the domain side---the one we fill with the initial state $s_0$.
The second blue box on the domain side, the one we fill with $s_1$, should instead be filled automatically with the same state as the direction $s_1$ in the white box below it.

In fact, it would be nice if the domain were still just $S\yon^S$.
Then we would have a lens $S\yon^S\to p\tri p$ that takes an initial state $s_0\in S$ and runs the original system $\phi$ twice, returning two outputs and receiving two inputs before stopping at the new state $s_2$.
But we just learned how to take a composition product of lenses such as $\phi\tripow2\colon S\yon^S\tri S\yon^S\to p\tri p$ and convert its domain to a new polynomial, say $S\yon^S$, with only one blue box on the domain side---just compose it with another lens $S\yon^S\to S\yon^S\tri S\yon^S$ like so:
\[
\begin{tikzpicture}
	\node (1) {
  \begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$S\yon^S$" left] (r) {$s_2$\at$s_0$};
	\node[poly, right=1.8 of r.south, yshift=-2.5ex, "$S\yon^S$" below] (p) {$s_1$\at$s_0$};
	\node[poly, above=.8 of p, "$S\yon^S$" above] (p') {$s_2$\at$s_1$};
	\node[poly, cod, right=of p, "$p$" right] (q) {$i_1$\at$o_0$};
	\node[poly, cod, above=.75 of q, "$p$" right] (q') {$i_2$\at$o_1$};
	\draw (p_pos) -- node[below] {return} (q_pos);
	\draw (q_dir) -- node[above] {update} (p_dir);
	\draw (p'_pos) -- node[below] {return} (q'_pos);
	\draw (q'_dir) -- node[above] {update} (p'_dir);	
	\draw (r_pos) to[first] node[below] {} (p_pos);
	\draw (p_dir) to[climb] node[right] {} (p'_pos);
	\draw (p'_dir) to[last] node[above] {} (r_dir);
  \end{tikzpicture}
	};
	\node[right=1.8 of 1] (2) {
  \begin{tikzpicture}[polybox, mapstos]
  	\node[poly, dom, "$S\yon^S$" left] (r) {$s_2$\at$s_0$};
  	\node[poly, cod, right=1.8 of r.south, yshift=-1ex, "$p$" right] (q) {$i_1$\at$o_0$};
  	\node[poly, cod, above=of q, "$p$" right] (q') {$i_2$\at$o_1$};
  	\draw (r_pos) to[first] node[below] {} (q_pos);
  	\draw (q_dir) to[climb] node[right] {} (q'_pos);
  	\draw (q'_dir) to[last] node[above] {} (r_dir);
  \end{tikzpicture}
	};
	\node at ($(1.east)!.5!(2.west)$) {=};
\end{tikzpicture}
\]
We'll denote our new lens $S\yon^S\to S\yon^S\tri S\yon^S$ on the far left by $\delta$.
Let's take a closer look at how $\delta$ behaves on its own, labeling its arrows for ease of reference:
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$S\yon^S$" left] (r) {$s_2$\at$s_0$};
	\node[poly, cod, right=1.8 of r.south, yshift=-2.5ex, "$S\yon^S$" below] (p) {$s_1$\at$s_0$};
	\node[poly, cod, above=.8 of p, "$S\yon^S$" above] (p') {$s_2$\at$s_1$};

	\draw[double] (r_pos) to[first] node[below] {$\delta_0$} (p_pos);
	\draw (p_dir) to[climb] node[right] {$\delta_1$} (p'_pos);
	\draw (p'_dir) to[last] node[above] {$\delta_2$} (r_dir);
  \end{tikzpicture}
\]
We can see from this picture that $\delta$ arises very naturally from the structure of $S\yon^S$; indeed, every state system can be equipped with such a lens, just as every state system can be equipped with a do-nothing enclosure from \cref{ex.do_nothing}.
The bottom arrow $\delta_0\colon S\to S$ sending $s_0\mapsto s_0$ is the identity on the position-set $S$: it sends each state to itself.
We use a double arrow to denote this equality.
While the middle arrow $\delta_1$ also looks like an identity arrow, remember that we should think of it as depending on the left blue box as well; so it is really a function $\delta_1\colon S\times S\to S$ sending $(s_0,s_1)$, a position-state $s_0$ and a direction at $s_0$ corresponding to state $s_1$, to the new position-state $s_1$.
Similarly, $\delta_2\colon S\times S\times S\to S$ sends $(s_0,s_1,s_2)$, where the last coordinate is the direction at position-state $s_1$ corresponding to state $s_2$, to the direction at position-state $s_0$ that also corresponds to state $s_2$.

Notice the crucial role that $\delta_1$ plays here: it matches up every direction at a given state to the new state that the direction in question should point to, encoding how the state system transitions from one state to the next.
We have been labeling each direction by the state that it points to, but we should really think of all the directions of $S\yon^S$ as pairs of position-states $(s,t)\in S\times S$, where $(s,t)$ is a direction at $s$ that represents the transition from state $s$ to state $t$.
The structure of the polynomial $S\yon^S$ tells us the state that each direction transitions from, but it is $\delta_1$ that tells us the new state $\delta_1(s,t)=t$ that $(s,t)$ transitions to.
For that reason, we call $\delta$ the \emph{transition lens} of the state system $S\yon^S$, and we call $\delta_1\colon S\times S\to S$ the \emph{target function}, relabeling it tgt for short, indicating where each direction leads.

This is exactly what we wanted back in \cref{ex.do_nothing}: a way to encode which directions of a state system point to which positions in the language of $\poly$. Expressions in that language are lenses such as $\delta$, and polyboxes like the ones above are the way we write them down.

We highlighted $\delta_1$ above, but the arrows $\delta_0$ and $\delta_2$ are no less important.
As an identity function, $\delta_0=\id_S$ remembers the initial state $s_0$ as we shift from its original setting $S\yon^S$, where we can only move one state away from $s_0$, to a new setting $S\yon^S\tri S\yon^S$, where we can think about all the ways to move two states away from $s_0$.
Meanwhile, $\delta_2$ shifts us from the two-state setting back to the one-state setting while ensuring a sort of transitive coherence condition: the state where we end up after moving from $s_0$ through $s_1$ to $s_2$ is the same state we would end up at if we had moved from $s_0$ directly to $s_2$.
We will call it the \emph{run function}, because it runs a sequence of two transitions together, and because it is what keeps the system running as it tells the original state system to actually move along one of its directions.

Here is another picture of the transition lens $\delta$ of $S\yon^S$ with our new arrow names:
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$S\yon^S$" left] (r) {$s_2$\at$s_0$};
	\node[poly, cod, right=1.8 of r.south, yshift=-2.5ex, "$S\yon^S$" below] (p) {$s_1$\at$s_0$};
	\node[poly, cod, above=.8 of p, "$S\yon^S$" above] (p') {$s_2$\at$s_1$};

	\draw[double] (r_pos) to[first] node[below=.3] {$\id_S$} (p_pos);
	\draw (p_dir) to[climb] node[right] {tgt} (p'_pos);
	\draw (p'_dir) to[last] node[above=.4] {run} (r_dir);
  \end{tikzpicture}
\]
This resolves the second issue we raised in \cref{subsec.comon.comp.def.dyn_sys}, page~\pageref{subsubsec.comon.comp.def.dyn_sys.issues} for the case of $n=2$, giving us a dynamical system $\delta\then(\phi\tri\phi)\colon S\yon^S\to p\tri p$ that simulates stepping through the system $\phi$ twice.
But what about more general values of $n$?

We already have a way of talking about the $n=0$ case: that is what the do-nothing enclosure $\epsilon\colon S\yon^S\to\yon$ models.
But there is some overlap in how $\epsilon$ matches up state-positions with directions and how $\delta$ does.
Put another way, if $\epsilon$ tells us how to do nothing, and $\delta$ tells us how to do two things, then we had better check that if one of the two things we do is nothing, then that's the same as doing just one thing.
Can we ensure that $\epsilon$ and $\delta$ agree on what they are saying about our state system?

Then for $n=3$, we would like a dynamical system $S\yon^S\to p\tri p\tri p$ that simulates stepping through $\phi$ three times.
One way to do this would be to compose $\phi\tripow3$ with a lens of the form $S\yon^S\to\left(S\yon^S\right)\tripow3$ that we obtain by extending $\delta$ from modeling two-step transitions to three-step transitions.
But there are two ways to derive a lens with codomain $\left(S\yon^S\right)\tripow3$ from $\delta$: we could either take $\delta\then\left(\delta\tri\id_{S\yon^S}\right)$, or we could take $\delta\then\left(\id_{S\yon^S}\tri\delta\right)$
For larger values of $n$, there are even more possibilities for what we could do.
But there should really only be one dynamical system that models stepping through $\phi$ a fixed number of times.
How do we guarantee that all these different ways of extending $\delta$ to $n$-step transitions end up telling us the same thing?

In summary, we need some kind of compatibility condition between $\epsilon$ and $\delta$, as well as some kind of associativity condition on $\delta$ to guarantee that it can be extended coherently.
In fact, we already have all the tools we need to characterize these conditions: we'll see exactly how to state the properties we want in the next chapter.
And if this is all starting to sound suspiciously familiar, youre not wrongbut well save that surprise for the next chapter as well.
\end{example}

\begin{exercise}
Let $S\coloneqq\nn$ and $p\coloneqq\rr\yon^\1$, and define $\phi\colon S\yon^S\to p$ to be the dynamical system with return function $\phi_\1(k)\coloneqq k$ and update function $\phi^\sharp_k(1)\coloneqq k+1$.
\begin{enumerate}
    \item Draw the polyboxes for $\phi$ and describe its dynamics: what does $1$ run through the system look like?
    \item Let $\delta\colon S\yon^S\to S\yon^S\tri S\yon^S$ be the transition lens of $S\yon^S$, and draw the polyboxes for the new system $\delta\then(\phi\tri\phi)\colon S\yon^S\to p\tri p$.
    Describe its dynamics: how does it model $2$ runs through the system?
\end{enumerate}

What is the induced lens $\text{Run}_n(\phi)$?
First of all, it is a dynamical system
\[\text{Run}_n(\phi)\colon S\yon^S\to\rr^n\yon,\]
meaning that it has the same set of states as before, but it outputs $n$-many reals in every moment. 

For $n=3$, here is one moment of output:
\[
\begin{tikzpicture}[polybox, mapstos]
		\node[poly, dom, "$S\yon^S$" left] (S) {$k+3$\vphantom{!}\at$k$\vphantom{!}};
		\node[poly, right=of S] (S2) {$k+2$\vphantom{!}\at$k+1\vphantom{!}$};
		\node[poly, below=of S2] (S1) {$k+1$\vphantom{!}\at$k\vphantom{!}$};
		\node[poly, above=of S2] (S3) {$k+3$\vphantom{!}\at$k+2\vphantom{!}$};
		\node[poly, linear cod, right=of S1, "$\rr\yon$" right] (p1) {$!$\at$\hphantom{+}k\hphantom{+}$\vphantom{!}};
		\node[poly, linear cod, right=of S2, "$\rr\yon$" right] (p2) {$!$\at$k+1$\vphantom{!}};
		\node[poly, linear cod, right=of S3, "$\rr\yon$" right] (p3) {$!$\at$k+2$\vphantom{!}};
%
		\draw (S1_pos) to[first] (p1_pos);
		\draw (p1_dir) to[last] (S1_dir);		
		\draw (S2_pos) to[first] (p2_pos);
		\draw (p2_dir) to[last]  (S2_dir);		
		\draw (S3_pos) to[first] (p3_pos);
		\draw (p3_dir) to[last]  (S3_dir);
		\draw (S_pos) to[first] (S1_pos);
		\draw (S1_dir) to[climb] (S2_pos);
		\draw (S2_dir) to[climb] (S3_pos);
		\draw (S3_dir) to[last] (S_dir);
\end{tikzpicture}
\]
So for example, starting at initial state $k=0$, we get the following output stream, e.g.\ for 4 steps:
\[(0,1,2),(3,4,5),(6,7,8),(9,10,11).\]
\end{exercise}


% ** stringing two dynamical systems together (maybe also an exercise?)

\begin{exercise}
As a lens whose domain is a state system, the transition lens $\delta\colon S\yon^S\to S\yon^S\tri S\yon^S$ of a state system $S\yon^S$ can be interpreted as a standalone dynamical system. Describe the dynamics of this system.
\begin{solution}
We can interpret the transition lens $\delta\colon S\yon^S\to S\yon^S\tri S\yon^S$ as a dynamical system as follows.
**
\end{solution}
\end{exercise}

%-------- Section --------%
\section{Categorical properties of the composition product} \label{sec.comon.comp.prop}

We conclude this chapter by discussing several interesting properties of the composition product, many of which will come in handy in the following chapters.
We'll focus on how $\tri$ interacts with other constructions on $\poly$ that we introduced in previous chapters.

\subsection{Interaction with products and coproducts} \label{subsec.comon.comp.prop.prod}

It turns out that the composition product behaves well---albeit asymmetrically---with products and coproducts.

\begin{proposition}[Left distributivity of $\tri$ over $+$ and $\times$]\label{prop.left_dist_prod}
Given a polynomial $r$, the functor $(-\tri r)\colon\poly\to\poly$ that sends each $p\in\poly$ to $p\tri r$ commutes with coproducts and products (up to natural isomorphism).
That is, for any $p,q\in\poly$, we have the following natural isomorphisms:
\begin{equation}\label{eqn.comp_left_pres_plus}
    (p+q)\tri r\iso (p\tri r)+(q\tri r)
\end{equation}
and
\begin{equation}\label{eqn.comp_left_pres_times}
    pq\tri r\iso (p\tri r)(q\tri r).
\end{equation}
More generally, given a set $A$ and polynomials $(q_a)_{a\in A}$, we have the following natural isomorphisms:
\begin{equation}\label{eqn.comp_left_pres_sum}
    \left(\sum_{a\in A}q_a\right)\tri r\iso \sum_{a\in A} (q_a\tri r)
\end{equation}
and
\begin{equation}\label{eqn.comp_left_pres_prod}
    \left(\prod_{a\in A}q_a\right)\tri r\iso \prod_{a\in A} (q_a\tri r)
\end{equation}
\end{proposition} 
\begin{proof}
Formally, this comes down to the fact that (co)products of functors $\smset\to\smset$ are computed pointwise (\cref{prop.presheaf_lim_ptwise}) and that (co)products in $\poly$ coincide with (co)products in $[\smset,\smset]$ (\cref{prop.poly_coprods,prop.poly_prods}).
One could instead give an explicit proof using \eqref{eqn.composite_formula}; this is done in \cref{exc.left_dist}.
In fact, we will see yet another proof of \eqref{eqn.comp_left_pres_prod} (and thus \eqref{eqn.comp_left_pres_times}) in \cref{exc.comp_left_pres_lim} \cref{exc.comp_left_pres_lim.prod}.
\end{proof}

\begin{exercise}\label{exc.left_dist}
Prove \cref{prop.left_dist_prod} using the explicit formula for $\tri$ given in \eqref{eqn.composite_formula} by manipulating sums and products.
\begin{solution}
To prove \cref{prop.left_dist_prod}, it suffices to verify \eqref{eqn.comp_left_pres_sum} and \eqref{eqn.comp_left_pres_prod}, as \eqref{eqn.comp_left_pres_plus} and \eqref{eqn.comp_left_pres_times} follow directly when $A\coloneqq\2$.

Given polynomials $(q_a)_{a\in A}$, recall that the position-set of the sum $\sum_{a\in A}q_a$ is $\sum_{a\in A}q_a(\1)$, while the direction-set at each position $(a,j)$ with $a\in A$ and $j\in q_a(\1)$ is $q_a[j]$.
So by \eqref{eqn.composite_formula}, we have that
\begin{align*}
    \left(\sum_{a\in A}q_a\right)\tri r &\iso \sum_{\substack{a\in A, \\ j\in q_a(\1)}}\;\prod_{b \in q_a[j]}\;\sum_{k \in r(\1)}\;\prod_{c \in r[k]}\yon \\
    &\iso \sum_{a\in A}\;\sum_{j\in q_a(\1)}\;\prod_{b \in q_a[j]}\;\sum_{k \in r(\1)}\;\prod_{c \in r[k]}\yon \\
    &\iso\sum_{a\in A}(q_a\tri r).
\end{align*}
We can also recall that the position-set of the product $\prod_{a\in A}q_a$ is $\prod_{a\in A}q_a(\1)$, while the direction-set at each position $\bar{j}\colon(a\in A)\to q_a(\1)$ is $\sum_{a\in A}q_a[\bar{j}(a)]$.
So by \eqref{eqn.composite_formula}, we have that
\begin{align*}
    \left(\prod_{a\in A}q_a\right)\tri r &\iso \sum_{\bar{j}\in\prod_{a\in A}q_a(\1)} \; \prod_{\substack{a\in A, \\ b\in q_a[\bar{j}(a)]}} \; \sum_{k \in r(\1)} \; \prod_{c \in r[j]} \yon \\
    &\iso \prod_{a\in A} \; \sum_{j\in q_a(\1)} \; \prod_{b\in q_a[j]} \; \sum_{k \in r(\1)} \; \prod_{c \in r[k]} \yon \tag*{\eqref{eqn.cat_completely_distributive}} \\
    &\iso\prod_{a\in A}(q_a\tri r).
\end{align*}
\end{solution}
\end{exercise}

\begin{example}[Picturing the left distributivity of $\tri$ over $\times$]\label{ex.picturing_dist}
We want an intuitive understanding of the left distributivity given by \eqref{eqn.comp_left_pres_times}.
Let $p\coloneqq\yon$, $q\coloneqq\yon+\1$, and $r\coloneqq\yon^\2+\1$, as shown here:
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, blue!50!black, "$p$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node (p1) {$\bullet$} 
      child {};
  \end{tikzpicture}
  };
	\node (q) [draw, blue!50!black, right=1 of p, "$q$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node (q1) {$\bullet$} 
      child {};
    \node[right=.5 of q1] (q2) {$\bullet$};
  \end{tikzpicture}
  };
	\node (r) [draw, red!75!black, right=1 of q, "$r$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node (r1) {$\bullet$} 
      child {}
      child {};
    \node[right=.5 of r1] (r2) {$\bullet$};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Then $pq\cong\yon^\2+\yon$ can be drawn as follows, with each corolla comprised of a $p$-corolla and a $q$-corolla with their roots glued together:
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, blue!50!black, "$pq\cong$" left] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
        \node (q1) {$\bullet$}
          child {}
          child {};
        \node[right=.5 of q1] (q2) {$\bullet$}
          child {};
    \end{tikzpicture}
	};
\end{tikzpicture}
\]
We can therefore draw $pq\tri r$ by gluing $r$-corollas to leaves of $pq$ in every way, as follows:
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, "$pq\tri r\cong$" left] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=5mm},
	  level 2/.style={sibling distance=2.5mm}]
    \node[blue!50!black] (1) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			};
%
    \node[blue!50!black, right=1.3 of 1] (2) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
			};
%
    \node[blue!50!black, right=1.3 of 2] (3) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			};
%
    \node[blue!50!black, right=1.3 of 3] (4) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
			};
%
    \node[blue!50!black, right=1 of 4] (5) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
      	child[red!75!black]
			};
%
    \node[blue!50!black, right=.8 of 5] (6) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$}
      };
  \end{tikzpicture}
	};
\end{tikzpicture}
\]
So each tree in $pq\tri r$ is obtained by gluing together the roots of a $p$-corolla and a $q$-corolla, then attaching $r$-corollas to each leaf.

Alternatively, we can compute $p\tri r$ and $q\tri r$ seperately, gluing $r$-corollas to leaves of $p$ in every way, then to leaves of $q$ in every way:
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, "$p\tri r\cong$" left] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=5mm},
	  level 2/.style={sibling distance=2.5mm}]
    \node[blue!50!black] (p1) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			};
    \node[blue!50!black, right=.5 of p1] (p2) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
			};
  \end{tikzpicture}
  };
%
	\node (q) [draw, "$q\tri r\cong$" left] at (4,0) {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=5mm},
	  level 2/.style={sibling distance=2.5mm}]
    \node[blue!50!black] (q1) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			};
    \node[blue!50!black, right=.5 of q1] (q2) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
			};
    \node[blue!50!black, right=.5 of q2] (q3) {$\bullet$};		
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Their product is then obtained by taking each tree from $p\tri r$ and pairing it with each tree from $q\tri r$ by gluing their roots together:
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, "$(p\tri q)(p\tri r)\cong$" left] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=5mm},
	  level 2/.style={sibling distance=2.5mm}]
    \node[blue!50!black] (1) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			};
%
    \node[blue!50!black, right=1.3 of 1] (2) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
			};
%
    \node[blue!50!black, right=1 of 2] (3) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
      	child[red!75!black]
			};
%
    \node[blue!50!black, right=1 of 3] (4) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			};
%
    \node[blue!50!black, right=1.3 of 4] (5) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
			}
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
			};
%
    \node[blue!50!black, right=.8 of 5] (6) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$}
      };	  	
	\end{tikzpicture}
	};
\end{tikzpicture}
\]
So each tree in $(p\tri r)(q\tri r)$ is obtained by attaching $r$-corollas to each leaf of a $p$-corolla and a $q$-corolla before gluing their roots together.

But it doesn't matter if we glue $r$-corollas to leaves first, or if we glue the roots of $p$- and $q$-corollas together first--the processes are equivalent.
Hence the isomorphism $pq\tri r\iso(p\tri r)(q\tri r)$ holds.
\end{example}

\begin{exercise}\label{exc.picturing_dist}
Follow \cref{ex.picturing_dist} with coproducts $(+)$ in place of products $(\times)$: use pictures to give an intuitive understanding of the left distributivity given by \eqref{eqn.comp_left_pres_plus}.
\begin{solution}
We want an intuitive understanding of the left distributivity of $\tri$ over $+$.
Let $p\coloneqq\yon^\2$, $q\coloneqq\yon+\1$, and $r\coloneqq\yon^\2+\1$, as shown here:
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, green!50!black, "$p$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node (p1) {$\bullet$} 
      child {}
      child {};
  \end{tikzpicture}
  };
	\node (q) [draw, blue!50!black, right=1 of p, "$q$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node (q1) {$\bullet$} 
      child {};
    \node[right=.5 of q1] (q2) {$\bullet$};
  \end{tikzpicture}
  };
	\node (r) [draw, red!75!black, right=1 of q, "$r$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node (r1) {$\bullet$} 
      child {}
      child {};
    \node[right=.5 of r1] (r2) {$\bullet$};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Then $p+q\iso\yon^\2+\yon+\1$ can be drawn as follows, consisting of every $p$-corolla and every $q$-corolla:
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, "$p+q\iso$" left] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
        \node[green!50!black] (q1) {$\bullet$}
          child[green!50!black] {}
          child[green!50!black] {};
        \node[blue!50!black, right=.5 of q1] (q2) {$\bullet$}
          child[blue!50!black] {};
        \node[blue!50!black, right=.5 of q2] (q3) {$\bullet$};
    \end{tikzpicture}
	};
\end{tikzpicture}
\]
We can therefore draw $(p+q)\tri r$ by gluing $r$-corollas to leaves of $p+q$ in every way, as follows:
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, "$(p+q)\tri r\cong$" left] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=5mm},
	  level 2/.style={sibling distance=2.5mm}]
    \node[green!50!black] (1) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			};
%
    \node[green!50!black, right=1.3 of 1] (2) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			};
%
    \node[green!50!black, right=1.3 of 2] (3) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			};
%
    \node[green!50!black, right=1.3 of 3] (4) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			};
%
    \node[blue!50!black, right=1 of 4] (5) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
      	child[red!75!black]
			};
%
    \node[blue!50!black, right=.8 of 5] (6) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$}
      };
      
    \node[blue!50!black, right=.8 of 6] (7) {$\bullet$};
  \end{tikzpicture}
	};
\end{tikzpicture}
\]
So each tree in $(p+q)\tri r$ is obtained by taking either a $p$-corolla or a $q$-corolla, then attaching an $r$-corolla to each leaf.

Alternatively, we can compute $p\tri r$ and $q\tri r$ seperately, gluing $r$-corollas to leaves of $p$ in every way, then to leaves of $q$ in every way:
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, "$p\tri r\cong$" left] at (-2,0) {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=5mm},
	  level 2/.style={sibling distance=2.5mm}]
    \node[green!50!black] (1) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			};
%
    \node[green!50!black, right=1.3 of 1] (2) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			};
%
    \node[green!50!black, right=1.3 of 2] (3) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			};
%
    \node[green!50!black, right=1.3 of 3] (4) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			};
  \end{tikzpicture}
  };
%
	\node (q) [draw, "$q\tri r\cong$" left] at (4,0) {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=5mm},
	  level 2/.style={sibling distance=2.5mm}]
    \node[blue!50!black] (q1) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			};
    \node[blue!50!black, right=.5 of q1] (q2) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
			};
    \node[blue!50!black, right=.5 of q2] (q3) {$\bullet$};		
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Their coproduct then consists of all the trees from $p\tri r$ and all the trees from $q\tri r$:
\[
\begin{tikzpicture}[rounded corners]
	\node (p) [draw, "$p\tri r+q\tri r\cong$" left] {
	\begin{tikzpicture}[trees,
		level 1/.style={sibling distance=5mm},
	  level 2/.style={sibling distance=2.5mm}]
    \node[green!50!black] (1) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
				child[red!75!black]
			};
%
    \node[green!50!black, right=1.3 of 1] (2) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			};
%
    \node[green!50!black, right=1.3 of 2] (3) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
				child[red!75!black]
				child[red!75!black]
			};
%
    \node[green!50!black, right=1.3 of 3] (4) {$\bullet$} 
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			}
      child[green!50!black] {node[red!75!black] {$\bullet$} 
			};
%
    \node[blue!50!black, right=1 of 4] (5) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$} 
      	child[red!75!black]
      	child[red!75!black]
			};
%
    \node[blue!50!black, right=.8 of 5] (6) {$\bullet$} 
      child[blue!50!black] {node[red!75!black] {$\bullet$}
      };
      
    \node[blue!50!black, right=.8 of 6] (7) {$\bullet$};
  \end{tikzpicture}
	};
\end{tikzpicture}
\]
So each tree in $p\tri r+q\tri r$ is either a $p$-corolla with an $r$-corolla attached to each leaf, or a $q$-corolla with an $r$-corolla attached to each leaf.

But it doesn't matter whether we glue $r$-corollas to leaves first, or if we pool together corollas from $p$ and $q$ first--the processes are equivalent.
Hence the isomorphism $(p+q)\tri r\iso p\tri r+q\tri r$ holds.
\end{solution}
\end{exercise}

\begin{exercise}
Show that for any set $A$ and polynomials $p,q$, we have an isomorphism $A(p\tri q)\iso (Ap)\tri q$.
\begin{solution}
Given a set $A$ and polynomials $p,q$, the left distributivity of $\tri$ over products from \eqref{eqn.comp_left_pres_prod} implies that $(Ap)\tri q\iso(A\tri q)(p\tri q)$, while \cref{exc.composing_with_constants} \cref{exc.composing_with_constants.appl} implies that $A\tri q\iso A$.
So $(Ap)\tri q\iso A(p\tri q)$.
\end{solution}
\end{exercise}

In \cref{subsec.comon.comp.prop.lim_left}, we will see how to generalize the left distributivity of $\tri$ over products to arbitrary limits.
But first, we observe that right distributivity does not hold.

\begin{exercise} \label{exc.right_not_dist_prod}
Show that the distributivities of \cref{prop.left_dist_prod} do not hold on the other side:
\begin{enumerate}
	\item \label{exc.right_not_dist_prod.prod} Find polynomials $p,q,r$ such that $p\tri (qr)\not\iso(p\tri q)(p\tri r)$.
	\item Find polynomials $p,q,r$ such that $p\tri (q+r)\not\iso(p\tri q)+(p\tri r)$.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item Let $p \coloneqq \yon + \1, q \coloneqq \1,$ and $r \coloneqq \0$.
    Then $p \tri (qr) \iso (\yon + \1) \tri \0 \iso \1$, while $(p \tri q)(p \tri r) \iso ((\yon + \1) \tri \1)((\yon + \1) \tri \0) \iso \2 \times \1 \iso \2$.
    \item Again let $p \coloneqq \yon + \1, q \coloneqq \1,$ and $r \coloneqq \0$.
    Then $p \tri (q+r) \iso (\yon + \1) \tri \1 \iso \2$, while $(p \tri q)+(p \tri r) \iso ((\yon + \1) \tri \1)+((\yon + \1) \tri \0) \iso \2 + \1 \iso \3$.
\end{enumerate}
\end{solution}
\end{exercise}

Nevertheless, there is something to be said about the relationship between $p\tri q, p\tri r,$ and $p\tri(qr)$.
We'll see this in action after we discuss how $\tri$ preserves limits on the left.

\subsection{Interaction with limits on the left} \label{subsec.comon.comp.prop.lim_left}

We saw in \cref{thm.poly_limits} that $\poly$ has all limits, and we saw in \cref{exc.refl_limits} that these limits coincide with limits in $[\smset,\smset]$.
Hence the argument in the proof of \cref{prop.left_dist_prod} by appealing to \cref{prop.presheaf_lim_ptwise} can be generalized to arbitrary limits.
It follows that $\tri$ preserves all limits on the left.
But we will present a proof of this fact from an alternative perspective: by appealing to the left coclosure of $\tri$.

\begin{proposition}[Meyers] \label{prop.comp_left_coclosed}
The composition product is left coclosed.
That is, there exists a left coclosure operation, which we denote $\lchom{-}{-}\colon\poly\op\times\poly\to\poly$,
such that there is a natural isomorphism
\begin{equation} \label{eqn.lchom_adj_iso}
    \poly(p, r\tri q)\iso\poly\left(\lchom{q}{p}, r\right).
\end{equation}
In particular, the left coclosure operation sends $q,p\in\poly$ to
\begin{equation} \label{eqn.lchom_def}
    \lchom{q}{p}\coloneqq\sum_{i\in p(\1)}\yon^{q(p[i])}.
\end{equation}
\end{proposition}
\begin{proof} % ** exercise to show that coclosure operation is actually functorial?
We present an argument using polyboxes; we leave it to the reader to write this proof in more standard mathematical notation in \cref{exc.comp_left_coclosed_calc}.

As in \cref{ex.map_to_comp}, a lens $f\colon p\to r\tri q$ can be written as follows:
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$p$" left] (p) {$a$\at$i$};
	\node[poly, cod, right=1.5cm of p.south, yshift=-1ex, "$r$" right] (r) {$c$\at$k$};
	\node[poly, cod, above=of r, "$q$" right] (q) {$b$\at$j$};
  	\draw (p_pos) to[first] node[below] {$f^r$} (r_pos);
  	\draw (r_dir) to[climb] node[right] {$f^q$} (q_pos);
  	\draw (q_dir) to[last] node[above] {$f^\sharp$} (p_dir);
\end{tikzpicture}
\]
But this is equivalent to the following gadget (to visualize this equivalence, imagine leaving the positions box for $p$, the arrow $f^r$, and the polyboxes for $r$ untouched, while dragging the polyboxes for $q$ leftward to the directions box for $p$, merging all the data from $q$ and the arrows $f^q$ and $f^\sharp$ into a single on-directions arrow and directions box):
\[
\begin{tikzpicture}[polybox, mapstos]
    \node[poly, dom, "$\lchom{q}{p}$" left] (l) {$(j,f^\sharp)$\at$i$};
    \node[poly, cod, "$r$" right, right=of l, yshift=-0.5ex] (r) {$c$\at$k$};
    \draw (l_pos) -- node[below] {$f^r$} (r_pos);
    \draw (r_dir) -- node[above] {} (l_dir);
\end{tikzpicture}
\]
Here the on-directions function encodes the behaviors of both $f^q$ and $f^\sharp$ by sending each $r[k]$-direction $c$ to both a $q$-position $j$, as $f^q$ does, and a function sending $q[j]$-directions to $p[i]$-directions, as $f^\sharp$ does.
So the polyboxes on the left represent a polynomial whose positions are the same as those of $p$, but whose directions at $i\in p(\1)$ are pairs $(j,f^\sharp)$ consisting of a $q$-position $j$ and a function $f^\sharp\colon q[j]\to p[i]$.
Such pairs are precisely the elements of $q(p[i])$, so the polynomial represented by the polyboxes on the left is indeed the one defined as $\lchom{q}{p}$ in \eqref{eqn.lchom_def}.
It follows that there is a natural isomorphism between lenses $p\to r\tri q$ and lenses $\lchom{q}{p}\to r$.
\end{proof}

\begin{exercise} \label{exc.comp_left_coclosed_calc}
Translate the polyboxes proof of \cref{prop.comp_left_coclosed} into standard mathematical notation, i.e.\ the $\sum$ and $\prod$ notation we have been using up till now.
\begin{solution}
We prove \cref{prop.comp_left_coclosed} by observing that
\begin{align*}
    \poly(p,r\tri q)&\iso\prod_{i\in p(\1)}r(q(p[i])) \tag*{\eqref{eqn.main_formula}} \\
    &\iso\poly\left(\sum_{i\in p(\1)}\yon^{q(p[i])}, r\right) \tag*{\eqref{eqn.main_formula}} \\
    &\iso\poly\left(\lchom{q}{p}, r\right) \tag*{\eqref{eqn.lchom_def}}.
\end{align*}
\end{solution}
\end{exercise}

\begin{remark}
The proof you came up with in \cref{exc.comp_left_coclosed_calc} may be more obviously rigorous and concise than the one we presented in the main text.
But polyboxes help us see right on paper exactly what is going on in this adjunction: how data on the codomain-side of a lens $p\to r\tri q$ can be simply repackaged and transferred to the domain-side of a new lens $\lchom{q}{p}\to r$.
\end{remark}

\begin{exercise} \label{exc.lchom_func}
In stating \cref{prop.comp_left_coclosed}, we implicitly assumed that $\lchom{-}{-}$ is a functor $\poly\op\times\poly\to\poly$.
Here we show that this is indeed the case.
\begin{enumerate}
    \item Given a polynomial $q$ and a lens $g\colon p\to p'$, to what lens $\lchom{q}{p}\to\lchom{q}{p'}$ should the covariant functor $\lchom{q}{-}$ send $g$?
    Prove that your construction is functorial.
    
    \item Given a polynomial $p$ and a lens $h\colon q'\to q$, to what lens $\lchom{q}{p}\to\lchom{q'}{p}$ should the contravariant functor $\lchom{-}{p}$ send $h$?
    Prove that your construction is functorial.
    \qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item Given a polynomial $q$ and a lens $g\colon p\to p'$, the functor $\lchom{q}{-}$ should send $g$ to a lens $\lchom{q}{p}\to\lchom{q}{p'}$; by \eqref{eqn.lchom_def}, this is a lens
    \[
        \lchom{q}{g}\colon\sum_{i\in p(\1)}\yon^{q(p[i])}\to\sum_{i'\in p'(\1)}\yon^{q(p'[i'])}.
    \]
    We give $\lchom{q}{g}$ the same on-positions function $p(\1)\to p'(\1)$ that $g$ has.
    Then viewing $q$ as a functor, we define the on-directions function $\lchom{q}{g}^\sharp_i\colon q(p'[g_\1(i)])\to q(p[i])$ for each $i\in p(\1)$ to be the function obtained by applying $q$ to the corresponding on-directions function $g^\sharp_i\colon p'[g_\1(i)]\to p[i]$.
    Functoriality follows trivially on positions and by the functoriality of $q$ itself on directions.

    \item Given a polynomial $p$ and a lens $h\colon q'\to q$, the functor $\lchom{-}{p}$ should send $h$ to a lens $\lchom{q}{p}\to\lchom{q'}{p}$; by \eqref{eqn.lchom_def}, this is a lens
    \[
        \lchom{h}{p}\colon\sum_{i\in p(\1)}\yon^{q(p[i])}\to\sum_{i\in p(\1)}\yon^{q'(p[i])}.
    \]
    We let the on-positions function of $\lchom{h}{p}$ be the identity on $p(\1)$.
    Then viewing $h$ as a natural transformation, we define the on-directions function $\lchom{h}{p}^\sharp_i\colon q'(p[i])\to q(p[i])$ for each $i\in p(\1)$ to be the $p[i]$-component of $h$.
    Functoriality follows trivially on positions and because natural transformations compose componentwise on directions.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
Let $A$ and $B$ be sets, and let $p$ and $q$ be polynomials.
\begin{enumerate}
    \item Prove that the following natural isomorphism holds:
    \begin{equation}\label{eqn.monomials_and_comp}
    	\poly(A\yon^B,p)\iso\smset(A,p(B)).
    \end{equation}
    
    \item Prove that the following natural isomorphism holds:
    \begin{equation}\label{eqn.flip_reps_lins}
        \poly\left(A\yon\tri p\tri \yon^B, q\right)\iso\poly\left(p,\yon^A\tri q\tri By\right). %**Natural in $A\in\smset\op$ and $B\in\smset$
    \end{equation}
    (Hint: Break the isomorphism down into two parts.
    You may find \cref{eqn.two_var_adj} helpful.)
    %**Something about polyboxes??
    \qedhere
\end{enumerate}
\begin{solution}
We are given $A,B\in\smset$ and $p,q\in\poly$
\begin{enumerate}
    \item By \eqref{eqn.lchom_def},
    \[
        \lchom{B}{A}=\sum_{i\in A}\yon^{B}\iso A\yon^B,
    \]
    so by \eqref{eqn.lchom_adj_iso},
    \[
        \poly(A\yon^B,p)\iso\poly(A,p\tri B).
    \]
    But $A$ and $p\tri B\iso p(B)$ are both constants, so a lens $A\to p\tri B$ is just a function $A\to p(B)$ on positions.
    Hence \eqref{eqn.monomials_and_comp} follows.

    \item We prove \eqref{eqn.flip_reps_lins} in two parts: that
    \begin{equation} \label{eqn.flipping1}
        \poly\left(A\yon\tri p, q\right)\iso\poly\left(p,\yon^A\tri q\right)
    \end{equation}
    and that
    \begin{equation} \label{eqn.flipping2}
        \poly\left(p \tri \yon^B, q\right)\cong\poly\left(p, q\tri B\yon\right).
    \end{equation}
    We have that $A\yon \tri p \iso Ap$ and $\yon^A \tri q \iso q^A$, so \eqref{eqn.flipping1} follows from \cref{eqn.two_var_adj}.
    Meanwhile, for \eqref{eqn.flipping2}, we have by \eqref{eqn.lchom_def} that
    \[
        \lchom{B\yon}{p}=\sum_{i\in p(\1)}\yon^{Bp[i]}\iso p\tri\yon^B,
    \]
    so \eqref{eqn.flip_reps_lins} follows from \eqref{eqn.lchom_adj_iso}.
    Then combining \cref{eqn.flipping1} and \cref{eqn.flipping2} yields
    \[
        \poly\left(A\yon\tri p\tri\yon^B,q\right)\iso\poly\left(p\tri\yon^B,\yon^A\tri q\right)\iso\poly\left(p,\yon^A\tri q\tri B\yon\right).
    \]
\end{enumerate}
\end{solution}
\end{exercise}

% \[
% \begin{tikzpicture}
% 	\node (p1) {
%   \begin{tikzpicture}[polybox,tos]
%   	\node[poly, "$p$" left] (p) {};
%   	\node[poly, linear, below=of p, "$A\yon$" left] (Ay) {};
%   	\node[poly, pure, above=of p, "$\yon^B$" left] (yB) {};
%   	\node[poly, right=2 of p, "$q$" right] (q) {};
%   	\node at ($(p.east)!.5!(q.west)$) {$\leftrightarrows$};
%   \end{tikzpicture}
%   };
%  \node[right=4 of p1] (p2) {
%  \begin{tikzpicture}[polybox,tos]
%   	\node[poly, "$p$" left] (p) {};
%   	\node[poly, right=2 of p, "$q$" right] (q) {};
%   	\node[poly, linear, above=of q, "$B\yon$" right] (By) {};
%   	\node[poly, pure, below=of q, "$\yon^A$" right] (yA) {};
% 		\draw (p_pos) to[first] (yA_pos);
% 		\draw (yA_dir) to[climb] (q_pos);
% 		\draw (q_dir) to[climb] (By_pos);
% 		\draw (By_dir) to[last] (p_dir);
%  \end{tikzpicture}
%  };
%  \node[align=center] at ($(p1)!.5!(p2)$) {is the\\same as};
% \end{tikzpicture} 
% \]
% Do you see how polyboxes with a black (one-element) part can flip upside-down to go to the other side?

\begin{example}[Dynamical systems as coalgebras] \label{ex.coalgebras}
Taking $A=B=S\in\smset$ in \eqref{eqn.monomials_and_comp}, we find that there is a natural isomorphism between dynamical systems $S\yon^S\to p$ and functions $S\to p(S)$, also known as a \emph{coalgebra for the functor} $p$ or a $p$\emph{-coalgebra}.\footnote{There are two versions of coalgebras we are interested in (and more that we are not) with distinct definitions: a \emph{coalgebra for a functor}, which is the version used here, and a \emph{coalgebra for a comonoad}, which is a coalgebra for a functor with extra conditions that we will introduce later.
The version we are using will usually be clear from context---here, for example, we do not expect $p$ to be a comonad---but we will try to be explicit with our terminology whenever the interpretation may be ambiguous.}

Coalgebras as models of dynamical systems have been studied extensively in the context of computer science, most notably by Jacobs in \cite{jacobs2017introduction}.
Indeed, much of what we developed in \label{sec.poly.dyn_sys.moore,sec.poly.dyn_sys.depend_sys} stems from the theory of coalgebras.
The coalgebraic perspective has the benefit of staying in the familiar category of sets; moreover, it can be generalized to functors $\smset\to\smset$ that are not polynomial, although many of the interesting examples are.

On the other hand, we have already seen that viewing dynamical systems as lenses $S\yon^S\to p$ rather than as functions $S\to p(S)$ has the benefit of isolating the internal state system to the domain and the external interface to the codomain, aiding both intuition and functionality.
Plus, our adjunction lets us switch to the coalgebraic perspective whenever we see fit: $\poly$ lets us talk about both.
\end{example}

%** Should we discuss morphisms of coalgebras vs. morphisms of dynamical systems?

\begin{proposition}[Left preservation of limits] \label{prop.left_pres_lim}
The operation $\tri$ preserves limits on the left (up to natural isomorphism).
That is, if $\cat{J}$ is a category, $p_-\colon\cat{J}\to\poly$ is a functor, and $q\in\poly$ is a polynomial, then there is a natural isomorphism
\begin{equation} \label{eqn.comp_left_pres_lim}
    \left(\lim_{j\in\cat{J}}p_j\right)\tri q\iso\lim_{j\in\cat{J}}(p_j\tri q).
\end{equation}
\end{proposition}
\begin{proof}
By \cref{prop.comp_left_coclosed}, the functor $(-\tri q)\colon\poly\to\poly$ is the right adjoint of the functor $\lchom{q}{-}\colon\poly\to\poly$, and right adjoints preserve limits.
\end{proof}

\begin{exercise} \label{exc.comp_left_pres_lim}
\begin{enumerate}
    \item Complete \cref{exc.composing_with_constants} \cref{exc.composing_with_constants.appl} using \eqref{eqn.comp_left_pres_lim} and \eqref{eqn.comp_left_pres_sum}.
    \item \label{exc.comp_left_pres_lim.prod} Deduce \eqref{eqn.comp_left_pres_prod} using \eqref{eqn.comp_left_pres_lim}.\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item We wish to solve \cref{exc.composing_with_constants} \cref{exc.composing_with_constants.appl} using \eqref{eqn.comp_left_pres_lim} and \eqref{eqn.comp_left_pres_sum}.
    If we set $\cat{J}$ in \eqref{eqn.comp_left_pres_lim} to be the empty category, then the limit of the functor from $\cat{J}$ is just the terminal object.
    It follows that $\1\tri p\iso\1$.
    In other words, since $\tri$ preserves limits on the left, and since terminal objects are limits, $\tri$ preserves terminal objects on the left.
    
    Then a set $X$ can be written as a sum $\sum_{x\in X}\1$, so by \eqref{eqn.comp_left_pres_sum},
    \[
        X\tri p\iso\left(\sum_{x\in X}\1\right)\tri p\iso\sum_{x\in X}(\1\tri p)\iso\sum_{x\in X}\1\iso X.
    \]
    
    \item If we set $\cat{J}$ in \eqref{eqn.comp_left_pres_lim} to be the discrete category on the set $A$, then the limit of a functor from $\cat{J}$ is just an $A$-fold product, so \eqref{eqn.comp_left_pres_prod} follows.
    In other words, since $\tri$ preserves limits on the left, and since products are limits, $\tri$ preserves products on the left.
\end{enumerate}
\end{solution}
\end{exercise}


\subsection{Interaction with limits on the right} \label{subsec.comon.comp.prop.lim_right}

So $\tri$ preserves limits on the left.
How about limits on the right?
We saw in \cref{exc.right_not_dist_prod} that $\tri$ does not even preserve products on the right, so it certainly does not preserve all limits.
But it turns out that there is a special class of limits that $\tri$ does preserve on the right.

\begin{definition}[Connected limit]
A \emph{connected limit} is one whose indexing category $\cat{J}$ is nonempty and connected. That is, $\cat{J}$ has at least one object, and any two objects are connected by a finite zigzag of arrows.
\end{definition}

\begin{example}
The following categories are connected:
\[
\fbox{$\bullet$}
\qquad
\fbox{$\bullet\tto\bullet$}
\qquad
\fbox{$\bullet\to\bullet\from\bullet$}
\qquad
\fbox{$\bullet\from\bullet\from\bullet\from\cdots$}
\]
In particular, equalizers, pullbacks, and directed limits are examples of connected limits. 

The following categories are \emph{not} connected:
\[
\fbox{$\phantom{\bullet}$}
\qquad
\fbox{$\bullet\quad\bullet$}
\qquad
\fbox{$\bullet\quad\bullet\to \bullet$}
\]
In particular, terminal objects and products are \emph{not} examples of connected limits.
\end{example}

Connected limits are intimately related to slice categories, which we defined back in \cref{def.slice}.
For example, products in a slice category $\cat{C}/c$ are just pullbacks in $\cat{C}$, allowing us to view a non-connected limit as a connected one.
By relating $\poly$ to its slice categories via an adjunction, we'll be able to show that $\tri$ preserves connected limits.
(An alternative proof of this fact can be found in \cite[Proposition 1.16]{kock2012polynomial}.)
%The claim for the right side comes down to the fact that polynomials are sums of representables; representable functors commute with all limits and sums commute with connected limits in $\smset$.

Recall that objects in a slice category $\cat{C}/c$ are just morphisms with codomain $c$.
For ease of notation, we'll often suppress the actual morphism and just write down the name of its domain when there is a canonical choice for the morphism, or when it is clear from context.
So for example, on the left hand side of \eqref{eqn.rchom_adj_iso} below, $p$ represents the lens $f\colon p\to q\tri 1$ and $q\tri r$ represents the lens $q\:\tri\:!\colon q\tri r\to q\tri\1$, both objects in the slice category $\poly/q\tri\1$.

\begin{proposition} \label{prop.comp_right_slice_coclosed}
Given polynomials $p,q,r\in\poly$ and a lens $f\colon p\to q\tri\1$, there is a natural isomorphism
\begin{equation} \label{eqn.rchom_adj_iso}
    \poly/q\tri\1\left(p, q\tri r\right)\iso\poly\left(p\rchom{f}q, r\right),
\end{equation}
where
\begin{equation} \label{eqn.rchom_def}
    p\rchom{f}q\coloneqq\sum_{i\in p(\1)}q[f_\1(i)]\yon^{p[i]}.
\end{equation}
\end{proposition}
\begin{proof}
Again, we present an argument using polyboxes; we leave it to the reader to write this proof in more standard mathematical notation in \cref{exc.comp_right_slice_coclosed_calc}.

By definition, morphisms from $f$ to $q\:\tri\:!$ in $\poly/q\tri\1$ are lenses $g\colon p\to q\tri r$ for which $g\then(q\:\tri\:!)=f$.
We can write this equation using polyboxes:
\[
\begin{tikzpicture}
	\node (a) {
  \begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$p$" left] (p) {\at$i$};
	\node[poly, right=1.8 of p.south, yshift=-2.5ex, "$q$" below] (q) {$b$\at$j$};
	\node[poly, above=.8 of q, "$r$" above] (r) {\at$k$};
	\node[poly, cod, right=of q, "$q$" right] (q') {$b$\at$j$};
	\node[poly, terminal, above=.8 of q', "$\1$" right] (1) {};
	\draw[double] (q_pos) -- node[below] {} (q'_pos);
	\draw[double] (q'_dir) -- node[above] {} (q_dir);
	\draw (r_pos) -- node[below] {} (1_pos);
	\draw[densely dotted] (1_dir) -- node[above] {} (r_dir);	
	\draw (p_pos) to[first] node[below] {$g^q$} (q_pos);
	\draw (q_dir) to[climb] node[right] {$g^r$} (r_pos);
	\draw (r_dir) to[last] node[above] {$g^\sharp$} (p_dir);
  \end{tikzpicture}
	};
	\node[right=1.8 of a] (b) {
  \begin{tikzpicture}[polybox, mapstos]
  	\node[poly, dom, "$p$" left] (p) {\at$i$};
  	\node[poly, cod, right=1.8 of p.south, yshift=-1ex, "$q$" right] (q) {$b$\at$f_\1(i)$};
  	\node[poly, terminal, above=of q, "$\1$" right] (1) {};
  	\draw (p_pos) to[first] node[below] {$f_\1$} (q_pos);
  	\draw (q_dir) to[climb] node[right] {} (1_pos);
  	\draw[densely dotted] (1_dir) to[last] node[above] {$f^\sharp$} (p_dir);
  \end{tikzpicture}
	};
	\node at ($(a.east)!.5!(b.west)$) {=};
\end{tikzpicture}
\]
We can read off the picture that a lens $g\colon p\to q\tri r$ is a morphism from $f$ to $q\:\tri\:!$ in $\poly/q\tri\1$ if and only if $g^q=f_\1$.
% , so specifying such a morphism amounts to specifying a position $k$ of $r$ and an on-directions function $r[k]\to p[i]$ for each $i\in p(\1)$ and $b\in q[f_\1(i)]$.
So morphisms from $f$ to $q\:\tri\:!$ are equivalent to gadgets
\[
\begin{tikzpicture}[polybox, mapstos]
    \node[poly, dom, "$p$" left] (p) {$a$\at$i$};
    \node[poly, cod, right=1.8 of p.south, yshift=-2.5ex, "$q$" below] (q) {$b$\at$f_\1(i)$};
    \node[poly, cod, above=.8 of q, "$r$" above] (r) {$c$\at$k$};
    \draw (p_pos) to[first] node[below] {$f_\1$} (q_pos);
    \draw (q_dir) to[climb] node[right] {$g^r$} (r_pos);
    \draw (r_dir) to[last] node[above] {$g^\sharp$} (p_dir);
\end{tikzpicture}
\]
with $f_\1$ fixed.
But this, in turn, is equivalent to the following gadget (to visualize this equivalence, imagine leaving the polyboxes for $r$, the arrow $g^\sharp$, and the directions box for $p$ untouched, while dragging the polyboxes for $q$ leftward to the positions box for $p$, merging the data from $q$ and the predetermined arrow $f^\1$ into a single positions box and adapting the arrow $g^r$ into an on-positions arrow):
\[
\begin{tikzpicture}[polybox, mapstos]
    \node[poly, dom, "$p\rchom{f}q$" left] (h) {$a$\at$(i,b)$};
    \node[poly, cod, "$r$" right, right=of h] (r) {$c$\at$k$};
    \draw (h_pos) -- node[below] {$g^r$} (r_pos);
    \draw (r_dir) -- node[above] {$g^\sharp$} (h_dir);
\end{tikzpicture}
\] % ** center??
Here the user can provide both the $p$-position $i$ and the $q[f_\1(i)]$-direction $b$ right from the start, as they know what to expect from $f_\1$ ahead of time.
Then the on-positions function encodes the behavior of $g^r$.
So the polyboxes on the left represent a polynomial whose positions are pairs $(i,b)$ with $i\in p(\1)$ and $b\in q[f_\1(i)]$, and whose directions at $(i,b)$ are the directions of the original polynomial $p$ at $i$.
This is precisely the polynomial we defined in \eqref{eqn.rchom_def}, so the isomorphism holds.
\end{proof}

\begin{remark}
As a lens $p\to q\tri\1$ can be identified with its on-positions function $p(\1)\to q(\1)$, we'll use the notation $p\rchom{f}q$ interchangeably for lenses $f\colon p\to q\tri\1$ and functions $f\colon p(\1)\to q(\1)$.
\end{remark}


\begin{exercise} \label{exc.comp_right_slice_coclosed_calc}
\begin{enumerate}
    \item Translate the polyboxes proof of \cref{prop.comp_right_slice_coclosed} into standard mathematical notation.
    
    \item Prove that the following natural isomorphism holds:
    \begin{equation}
        \poly(p,q\tri r)\iso\sum_{f\colon p(\1)\to q(\1)}\poly\left(p\rchom{f}q,r\right).
    \end{equation}
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item We prove \cref{prop.comp_right_slice_coclosed} by observing that **
    \begin{align*}
        \poly(p,r\tri q)&\iso\prod_{i\in p(\1)}r(q(p[i])) \tag*{\eqref{eqn.main_formula}} \\
        &\iso\poly\left(\sum_{i\in p(\1)}\yon^{q(p[i])}, r\right) \tag*{\eqref{eqn.main_formula}} \\
        &\iso\poly\left(\lchom{q}{p}, r\right) \tag*{\eqref{eqn.lchom_def}}.
    \end{align*}
    
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise} \label{exc.rchom_func}
In stating \cref{prop.comp_right_slice_coclosed}, we implicitly assumed that $p\rchom{f}q\in\poly$ is functorial in each variable: covariantly on the left and contravariantly on the right.
Here we show that this is indeed the case.
\begin{enumerate}
    \item Given lenses $f\colon p\to q\tri\1$ and $g\colon p'\to p$, to what lens $p'\rchom{g\then f}q\to p\rchom{f}q$ should the covariant functor $-\rchom{f}q$ send $g$?
    Prove that your construction is functorial.
    
    \item Given lenses $f\colon p\to q\tri\1$ and $h\colon q\to q'$, to what lens $p\rchom{f\then(h\tri\1)}q'\to p\rchom{f}q$ should the contravariant functor $p\rchom{f}-$ send $h$?
    Prove that your construction is functorial.
    \qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item Given lenses $f\colon p\to q\tri\1$ and $g\colon p'\to p$, the functor $-\rchom{f}q$ should send $g$ to a lens $p'\rchom{g\then f}q\to p\rchom{f}q$; by \eqref{eqn.rchom_def}, this is a lens
    \[
        g\rchom{f}q\colon\sum_{i'\in p'(\1)}q[f_\1(g_\1(i'))]\yon^{p'[i']}\to\sum_{i\in p(\1)}q[f_\1(i)]\yon^{p[i]}.
    \]
    We give $g\rchom{f}q$ an on-positions function that is the on-positions function $p'(\1)\to p(\1)$ of $g$ on the first coordinate $i'\in p'(\1)$ and the identity on $q[f_\1(g_\1(i'))]$ on the second.
    Then we let the on-directions function at every position with first coordinate $i'\in p'(\1)$ be the on-directions function $g^\sharp_{i'}\colon p[g_\1(i')]\to p'[i']$.
    Functoriality follows trivially on both positions and directions.

    \item Given a polynomial $p$ and lenses $f\colon p\to q\tri\1$ and $h\colon q\to q'$, the functor $p\rchom{f}-$ should send $h$ to a lens $p\rchom{f\then(h\tri\1)}q'\to p\rchom{f}q$; by \eqref{eqn.rchom_def}, this is a lens
    \[
        p\rchom{f}h\colon\sum_{i\in p(\1)}q'[h_\1(f_\1(i))]\yon^{p[i]}\to\sum_{i\in p(\1)}q[f_\1(i)]\yon^{p[i]}.
    \]
    We let the on-positions function of $p\rchom{f}h$ be the identity on the first coordinate $i\in p(\1)$ and the on-directions function $h^\sharp_{f_\1(i)}\colon q'[h_\1(f_\1(i))]\to q[f_\1(i)]$ on the second.
    Then we let the on-directions function at every position with first coordinate $i\in p(\1)$ be the identity on $p[i]$.
    Functoriality follows trivially on both positions and directions.
\end{enumerate}
\end{solution}
\end{exercise}



\begin{theorem}[Preservation of connected limits]\label{thm.connected_limits}
The operation $\tri$ preserves connected limits on both sides.
That is, if $\cat{J}$ is a connected category, $p\colon \cat{J}\to\poly$ is a functor, and $q\in\poly$ is a polynomial, then there are natural isomorphisms
\[
	\left(\lim_{j\in \cat{J}} p_j\right)\tri q\iso \lim_{j\in \cat{J}}(p_j\tri q)
	\qqand
	q\tri\left(\lim_{j\in \cat{J}} p_j\right)\iso \lim_{j\in \cat{J}}(q\tri p_j)
\]
\end{theorem}
\begin{proof}
The claim for the left side is just a special case of \cref{prop.left_pres_lim}; it remains to prove the claim on the right.

By \cref{thm.poly_limits}, $\poly$ is complete, so by \cite[Theorem~4.3]{nlab:connected-limit}, it suffices to show that the functor $(q\tri-)\colon\poly\to\poly$ preserves wide pullbacks on the right.
By \cref{prop.comp_right_slice_coclosed}, the functor $(q\tri-)\colon\poly\to\poly/q\tri\1$ is a right adjoint, so it preserves limits, including wide pullbacks.
Thus $(q\tri-)$ sends a wide pullback over $r\in\poly$ to a wide pullback over the canonical lens $q\tri r\to q\tri\1$ in $\poly/q\tri\1$, corresponding to a limit in $\poly$ of a diagram consisting of arrows to $q\tri r$ and arrows to $q\tri\1$ factoring through $q\tri r$.
So up to isomorphism, this limit is just a wide pullback in $\poly$ over $q\tri r$, namely $(q\tri-)\colon\poly\to\poly$ applied to the original wide pullback.
So $\tri$ preserves wide pullbacks on the right.
\end{proof}


\begin{exercise}\label{ex.connected_limits_and_tri}
Use \cref{thm.connected_limits} in the following.
\begin{enumerate}
	\item Let $p$ be a polynomial, thought of as a functor $p\colon\smset\to\smset$. Show that $p$ preserves connected limits (of sets).
	\item Show that for any polynomials $p,q,r$ we have an isomorphism:
	\begin{equation} \label{eqn.right_prod_pullback}
	p\tri(qr)\iso (p\tri q)\times_{(p\tri\1)}(p\tri r).
	\end{equation}
	\item Take the polynomials $p,q,r$ from the counterexample you found in \cref{exc.right_not_dist_prod} \cref{exc.right_not_dist_prod.prod} and check that \eqref{eqn.right_prod_pullback} holds.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item Given a polynomial functor $p \colon \smset \to \smset$, we wish to show that $p$ preserves connected limits of sets; that is, for a connected category $\cat{J}$ and a functor $X \colon \cat{J} \to \smset$, we have
    \[
        p\left(\lim_{j \in \cat{J}} X_j\right) \iso \lim_{j \in \cat{J}} p(X_j).
    \]
    But we can identify $\smset$ with the full subcategory of constant functors in $\poly$ and instead view $X$ as a functor into $\poly$.
    Then by \cref{exc.composing_with_constants} \cref{exc.composing_with_constants.appl}, the left hand side of the isomorphism we seek is isomorphic to $p\tri\left(\lim_{j \in \cat{J}} X_j\right)$, while the right hand side is isomorphic to $\lim_{j \in \cat{J}} \left(p \tri X_j\right)$.
    These are isomorphic by \cref{thm.connected_limits}.
    \item Given $p,q,r \in \poly$, we wish to show that \eqref{eqn.right_prod_pullback} holds.
    As $\1$ is terminal in $\poly$, the product $qr$ can also be written as the pullback $q \times_\1 r$.
    While products are not connected limits, pullbacks are, so by \cref{thm.connected_limits}, they are preserved by precomposition with $p$.
    Hence the desired isomorphism follows.
    \item We'll show that \eqref{eqn.right_prod_pullback} holds for $p\coloneqq\yon+\1, q\coloneqq\1,$ and $r\coloneqq\0$.
    We have $p\tri q = p\tri\1 \iso (\yon+\1)\tri\1 \iso \2$ and $p\tri r \iso (\yon+\1)\tri\0 \iso \1$, so $(p\tri q)\times_{(p\tri\1)}(p\tri r) \iso \2 \times_\2 \1$.
    We saw in \cref{ex.pullbacks_in_poly} that the position-set of a pullback in $\poly$ is just the pullback of the position-sets in $\smset$, while the direction-sets are given by a pushout of direction-sets in $\smset$.
    As our polynomials have empty direction-sets, their pullback must have an empty direction-set as well, so this pullback is just a pullback of sets: $(p\tri q)\times_{(p\tri\1)}(p\tri r) \iso \2 \times_\2 \1\iso\1$.
    And indeed we have $p\tri(qr) \iso (\yon+\1)\tri\0 \iso \1$ as well.
\end{enumerate}
\end{solution}
\end{exercise}

While we're here, it will be helpful to record the following.
\begin{proposition} %Make this an exercise, mimicking earlier stuff
For any polynomial $q\in\poly$, tensoring with $q$ (on either side) preserves connected limits. That is, if $\cat{J}$ is connected and $p\colon \cat{J}\to\poly$ is a functor, then there is a natural isomorphism:
\[
	\left(\lim_{j\in \cat{J}} p_j\right)\otimes q\cong
	\lim_{j\in \cat{J}} (p_j\otimes q).
\]
\end{proposition}


\subsection{Interaction with parallel products} \label{subsec.comon.comp.prop.par}

Before we get into how $\otimes$ interacts with $\tri$, here is a warm-up exercise.

\begin{exercise}
Let $A$ and $B$ be arbitrary sets, and let $p$ be an arbitrary polynomial.
Which of the following isomorphisms always hold?

If the isomorphism does not always hold, is there still a canonical lens in one direction or the other?
\begin{enumerate}
	\item $(A\yon)\otimes(B\yon) \iso^? (A\yon)\tri (B\yon)$.
	\item $\yon^A\otimes\yon^B\iso^?\yon^A\tri\yon^B$.
	\item $A\otimes B\iso^? A\tri B$.
	\item $B\yon\otimes p\iso^? B\yon\tri p$.
	\item $\yon^A\otimes p\iso^? \yon^A\tri p$.
	\item $p\otimes B\yon\iso^? p\tri B\yon$.
	\item $p\otimes \yon^A\iso^? p\tri\yon^A$.
	\qedhere
\end{enumerate}
What do all of the lenses you found in this exercise have in common (whether or not they were isomorphisms)?
\begin{solution}
Here $A$ and $B$ are sets and $p$ is a polynomial.
\begin{enumerate}
	\item The isomorphism always holds: we have that $(A\yon)\otimes(B\yon) \iso AB\yon \iso (A\yon)\tri (B\yon)$.
	\item The isomorphism always holds: we have that $\yon^A\otimes\yon^B \iso \yon^{AB} \iso \yon^A\tri\yon^B$.
	\item The isomorphism does not always hold: while $A\otimes B \iso AB$, we have that $A\tri B \iso A$.
	There is, however, always a canonical projection $AB\to B$; but there is not always a canonical lens $B\to AB$ (for example, take $A=\0\neq B$).
	\item The isomorphism always holds: we have that $B\yon \otimes p \iso \sum_{i \in p(\1)} B\yon \otimes \yon^{p[i]} \iso \sum_{i \in p(\1)} B\yon^{p[i]} \iso Bp \iso B\yon\tri p$.
	\item The isomorphism does not always hold: if, say, $p = B$, then $\yon^A \otimes B \iso B$, while $\yon^A \tri B \iso B^A$.
	If $A=B=\0$, then $B^A\iso\1$, so there is not always a canonical lens from right to left, either.
	There is, however, always a canonical lens from left to right: $\yon^A\otimes p\iso\sum_{i \in p(\1)}\yon^{Ap[i]}$ while $\yon^A\tri p\iso\sum_{\ol{i}\colon A\to p(\1)}\yon^{\sum_{a\in A}p[\ol{i}(a)]}$.
	So there is a lens from left to right whose on-positions function sends $i\in p(\1)$ to the constant function $A\to p(\1)$ that always evaluates to $i$; and whose on-directions function at $i$ is the identity on $Ap[i]$.
	\item The isomorphism does not always hold: if, say, $p = \yon^A$, then $\yon^A \otimes B\yon \iso B\yon^A$, while $\yon^A \otimes B\yon \iso (B\yon)^A \iso B^A\yon^A$.
	If $A=B=\0$, then $B\yon^A\iso\0$ while $B^A\yon^A\iso\0^\0\yon^\0\iso\1$, so there is not always a canonical lens from right to left, either.
	There is, however, always a canonical lens from left to right: $p\otimes B\yon\iso Bp$ while $p\tri B\yon\iso\sum_{i\in p(\1)}\sum_{\ol{b}\colon p[i]\to B}\yon^{\sum_{a\in p[i]}\1}\iso\sum_{i\in p(\1)}B^{p[i]}\yon^{p[i]}$.
	So there is a lens from left to right whose on-positions function sends $(b,i)\in Bp(\1)$ to $(i,c_b)\in\sum_{i\in p(\1)}B^{p[i]}$, where $c_b\colon p[i]\to B$ is the constant function that always evaluates to $b$; and whose on-directions function at $(b,i)$ is the identity on $p[i]$.
	\item The isomorphism always holds: we have that $p \otimes \yon^A \iso \sum_{i \in p(\1)} \yon^{Ap[i]} \iso p \tri \yon^A$.
\end{enumerate}
Every on-directions function of every lens we found in this exercise are isomorphisms, so every lens we found in this exercise is cartesian.
\end{solution}
\end{exercise}

\begin{example}[Lenses from $\otimes$ to $\tri$]
For any $p$ and $q$, there is an interesting cartesian lens $o_{p,q}\colon p\otimes q\to p\tri q$ that, stated informally, ``orders'' the operation, taking the symmetric monoidal product $\otimes$ and reinterprets it as a special case of the asymmetric monoidal product $\tri$.
Defining this lens in the usual way is rather tedious and unilluminating, but written in polyboxes, the lens looks like this (recall that positions of $p\otimes q$ are just pairs of positions of $p$ and $q$, while directions at each such pair are pairs of directions of $p$ and $q$, one at each position in the pair):
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$p\otimes q$" left] (p) {$(a,b)$\nodepart{two}$(i,j)$};
	\node[poly, cod, "$p$" right, right= 1.5cm of p.south, yshift=-1ex] (q) {$a$\nodepart{two}$i$};
	\node[poly, cod, "$q$" right, above=of q] (r) {$b$\nodepart{two}$j$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
\end{tikzpicture}
\]
Usually, the positions box of $q$ is allowed to depend on the directions box of $p$ in the polyboxes for $p\tri q$ on its own.
But in the polyboxes above, $j$ is not allowed to depend on $a$ in $p\otimes q$ on the left, so the arrow from the positions box of $q$ to the directions box of $p$ on the right doesn't actually take $a$ into account at all.
So the lens $o_{p,q}$ is in some sense the inclusion of the order-independent positions of $p\tri q$; when drawn as trees, the positions in its image are the ones whose upper-level corollas are all the same.
And of course we can flip the order using the symmetry $q\otimes p\iso p\otimes q$.
This is, we just as well have a lens $p\otimes q\to q\tri p$.

Both $\otimes$ and $\tri$ have the same monoidal unit, the identity functor $\yon$, whose identity is the unique lens $\yon\to\yon$.
In fact the lenses $o_{p,q}$ constitute a lax monoidal functor $(\poly,\yon,\otimes)\to(\poly,\yon,\tri)$.
In particular, $o_{p,q}$ commutes with associators and unitors. 

This can be used in the following way. Lenses $p\to q\tri r$ into composites are fairly easy to understand (through polyboxes, for example), whereas lenses $q\tri r\to p$ are not so easy to think about. However, given such a lens, one may always compose it with $o_{q,r}$ to obtain a lens $q\otimes r\to p$.
This is quite a bit simpler to think about: they are our familiar interaction patterns from \cref{sec.poly.dyn_sys.interact}.
\end{example}

%** Different notation for \otimes in polyboxes??

%** Exposition on duoidality

\begin{proposition}
For any polynomials $p,p',q,q'$ there are natural maps
\begin{align}\label{eqn.plus_duoidal}
	(p\tri p')+(q\tri q')&\to (p+q)\tri(p'+q')\\\label{eqn.otimes_duoidal}
	(p\tri p')\otimes(q\tri q')&\to(p\otimes q)\tri(p'\otimes q')\\\label{eqn.times_duoidal}
	(p\tri p')\times (q\tri q')&\from(p\times q)\tri(p'\times q')
\end{align}
making $(+,\tri)$ and $(\otimes,\tri)$ duoidal structures and $(\times,\tri)$ op-duoidal.
\end{proposition}
\begin{proof}
For \eqref{eqn.plus_duoidal} we have inclusion maps $p\to p+q$ and $p'\to p'+q'$, inducing a map $p\tri p'\to(p+q)\tri(p'+q')$. Similarly we obtain a map $q\tri q'\to(p+q)\tri(p'+q')$, so we get the desired map from the universal property of coproducts. It is straightforward to check that this is duoidal. The result for \eqref{eqn.times_duoidal} is similar. 

It remains to give a map \eqref{eqn.times_duoidal}.**
\end{proof}

%\begin{exercise}\label{exc.plus_duoidal}
%\begin{enumerate}
%	\item Give maps $0\to 0+0$, $\yon\to\yon\tri\yon$, and $0\to\yon$.
%	\item Check that the following diagrams commute:
%\[ 
%\begin{tikzcd}
%	(p\tri p')+0\ar[r]&
%	(p\tri p)+(0\tri 0)\ar[d]\\
%	p\tri p'&
%	(p+0)\tri (p'+0)\ar[l]
%\end{tikzcd}
%\hspace{1in}
%\begin{tikzcd}
%	((p\tri p')+(q\tri q'))+(r\tri r')\ar[r]\ar[d]&
%	(p\tri p')+((q\tri q')+(r\tri r'))\ar[r]&
%	(p\tri p')+((q+r)\tri(q'+r'))\ar[d]\\
%	((p+ q)\tri(p'+ q'))+(r\tri r')\ar[r]&
%	((p+q)+r)\tri((p'+q')+r')\ar[r]&
%	(p+(q+r))\tri(p'+(q'+r'))
%\end{tikzcd}
%\]
%\qedhere
%\end{enumerate}
%\end{exercise}

\subsection{Interaction with vertical and cartesian lenses} \label{subsec.comon.comp.prop.cart}

We conclude this section by examining how $\tri$ interacts with vertical and cartesian lenses, as defined in \cref{def.vert_cart}.

\begin{proposition}[Preservation of cartesian lenses]\label{prop.comp_pres_cart}
If $f\colon p\to p'$ and $g\colon q\to q'$ are cartesian lenses, then so is $f\tri g\colon p\tri q \to p'\tri q'$.
\end{proposition}
\begin{proof}
We use the third characterization of cartesian lenses given in \cref{prop.cart_as_nt}, as lenses whose naturality squares are pullbacks.
For any sets $A,B$ and function $h\colon A\to B$, consider the diagram
\[
\begin{tikzcd}[column sep=small]
    p\tri q\tri A\ar[r]\ar[d] & p'\tri q\tri A\ar[r]\ar[d] & p'\tri q'\tri A\ar[d] \\
    p\tri q\tri B\ar[r] & p'\tri q\tri B\ar[r] & p'\tri q'\tri B.
\end{tikzcd}
\]
The square on the left is a pullback because $f\colon p\to p'$ is cartesian.
Meanwhile, the square on the right is a pullback because $g\colon q\to q'$ is cartesian and $\tri$ preserves pullbacks by \cref{thm.connected_limits}.
Hence the outer rectangle is a pullback as well, implying that $f\tri g\colon p\tri q \to p'\tri q'$ is cartesian.
\end{proof}

\begin{exercise}
Let $f\colon p\to p'$ and $g\colon q\to q'$ be lenses.
\begin{enumerate}
	\item Show that if $f$ is an isomorphism and $g$ is vertical, then $f\tri g$ is vertical.
	\item Find a vertical lens $f$ and a polynomial $q$ for which $f\tri q\colon p\tri q\to p'\tri q$ is not vertical.
\qedhere
\end{enumerate}
\begin{solution}
Here $f\colon p\to p'$ and $g\colon q\to q'$ are lenses.
\begin{enumerate}
    \item If $f$ is an isomorphism and $g$ is vertical, then $g\tri\1\colon q\tri\1\to q'\tri\1$ is an isomorphism, so $f\tri g\tri\1\colon p\tri q\tri\1\to p'\tri q'\tri\1$ is an isomorphism as well.
    Thus $f\tri g$ is vertical.
    \item If $f$ is the unique lens $\yon\to\1$ and $q=\0$, then $f$ is vertical, but since $\yon\tri\0\iso\0$ and $\1\tri\0\iso\1$, the lens $f\tri\0\colon\0\to\1$ is not.
\end{enumerate}
\end{solution}
\end{exercise}

%-------- Section --------%
\section{Exercise solutions}
\Closesolutionfile{solutions}
{\footnotesize
\input{solution-file5}}

\Opensolutionfile{solutions}[solution-file6]

%------------ Chapter ------------%
\chapter{Polynomial comonoids}\label{ch.comon.sharp}

\slogan{Imagine a realm where there are various positions you can be in. From every position, there are a number of moves you can make, possibly infinitely many. But whatever move you make, you'll end up in a new position. Well, technically it counts as a move to simply stay where you are, so you might end up in the same position. But wherever you move to, you can move again, and any number of moves from the original position counts as a single move. What sort of realm is this?}

The most surprising aspects of $\poly$ really begin with its comonoids.
In 2018, researchers Daniel Ahman and Tarmo Uustalu presented a characterization of comonoids in $(\poly,\yon,\tri)$ as a surprisingly familiar construct.
For us, this story will emerge naturally as we continue to expand our understanding of the humble state system of a dependent dynamical system.
Let's go through it.

%-------- Section --------%
\section{State systems, categorically}\label{sec.comon.sharp.state}

Since defining dependent dynamical systems in \cref{def.gen_moore}, we have evolved our understanding of their state systems over the course of the last few chapters. %** compile all the refs?? or make this section stand on its own more?
Let's take this moment to review what we know about these state systems so far. %** maybe more like...? comonoids will arise from state system story naturally as we review it?

Our original definition of a state system was as a monomial $S\yon^S$ for some set $S$.
But in \cref{ex.do_nothing}, we noted that this formulation requires us to discuss the positions and directions of a state system at the level of sets rather than in the language of $\poly$.
Instead, let's take an arbitrary polynomial $\ema{s}\in\poly$ and attempt to characterize what it means for $\ema{s}$ to be a state system using only the categorical machinery of $\poly$.
We will continue to refer to the positions of $\ema{s}$ as \emph{states}, but we will shift from thinking of the directions of $\ema{s}$ as states to thinking of them as transitions from one state to another.

\subsection{The do-nothing enclosure}\label{subsec.comon.sharp.state.nothing}

In \cref{ex.do_nothing}, we saw that every state system $\ema{s}$ is equipped with a \emph{do-nothing enclosure}: a lens $\epsilon\colon\ema{s}\to\yon$ that picks out a direction at each state that we would like to interpret as ``doing nothing'' and remaining at that state.

We drew $\epsilon$ in polyboxes in \cref{ex.do_nothing_polybox}, but that was when we let ourselves assume that the position-set of a state system was equal to each of its direction-sets.
Now all we know is that for each state $s\in\ema{s}(\1)$, the do-nothing enclosure chooses an $\ema{s}[s]$-direction to signify staying at the same state; it doesn't make sense to say that this direction is literally equal to $s$.
So we need a different name for the $\ema{s}[s]$-direction that $\epsilon$ identifies: call it $\id_s$, because it behaves like a sort of identity operation on the state $s$.

So the revised polyboxes for the do-nothing enclosure $\epsilon\colon\ema{s}\to\yon$ are as follows:
\begin{equation} \label{eqn.do_nothing_polybox}
\begin{tikzpicture}[polybox, mapstos]
    \node[poly, dom, "$\ema{s}$" left] (S) {$\id_s$\at$s$};

    \draw (S_pos) to[climb'] node[right] {$\epsilon$} (S_dir);
\end{tikzpicture}
\end{equation}

\begin{exercise}
Say I have a polynomial $\ema{s}\in\poly$, and I tell you that there is a lens $\epsilon\colon\ema{s}\to\yon$.
What can you say about the polynomial $\ema{s}$?
\begin{solution}
Given a polynomial $\ema{s}\in\poly$ equipped with a lens $\epsilon\colon\ema{s}\to\yon$, we know that $\epsilon$ picks out a direction at every position of $\ema{s}$.
So all we can say about $\ema{s}$ is that there is at least one direction at each of its positions.
Equivalently, we could say that $\ema{s}$ can be written as the product of $\yon$ and some other polynomial.
\end{solution}
\end{exercise}

\begin{example}[The do-nothing enclosure in tree pictures] \label{ex.nothing_trees}
We have seen the do-nothing enclosure drawn in polyboxes, but let's see what it looks like in our tree pictures.
We'll take $\ema{s}\coloneqq\{\bul[red],\bul[dgreen],\bul[blue]\}\yon^{\{\bul[red],\bul[dgreen],\bul[blue]\}}$, drawn as follows:
\[
\begin{tikzpicture}[rounded corners]
\node (p1) [draw, "$\ema{s}\coloneqq$" left] {
    \begin{tikzpicture}[trees, sibling distance=4mm]
        \foreach \i/\c in {1/red, 2/dgreen, 3/blue}
        {
            \node[\c] at (1.8*\i,0) {$\bullet$} 
                child [red]
                child [dgreen]
                child [blue]
                ;
        };
    \end{tikzpicture}
};
\end{tikzpicture}
\]
Then the do-nothing enclosure $\epsilon\colon\ema{s}\to\yon$ can be drawn like so:
\[
\begin{tikzpicture}[trees, bend right]
    \foreach \i/\c in {1/red, 2/dgreen, 3/blue}
    {
        \node[\c] (\i) at (3*\i, 0) {$\bullet$} 
            child [red] {coordinate (\i1)}
            child [dgreen] {coordinate (\i2)}
            child [blue] {coordinate (\i3)}
            ;
        \node[right=of \i] (y\i) {$\bullet$}
            child{coordinate (y\i')}
            ;
        \draw[|->, shorten <= 3pt, shorten >= 3pt] (\i) -- (y\i);
        \draw[densely dotted, postaction={decorate}] (y\i') to (\i\i);
    };
\end{tikzpicture}
\]
It picks out one direction at each position, namely the one of the same color.
\end{example}


There is not much else we can say about the do-nothing enclosure on its own, so let us revisit the other lens that every state system is equipped with before considering the relationship between the two.

\subsection{The transition lens}\label{subsec.comon.sharp.state.trans}

We saw in \cref{ex.dyn_sys_trans_polyboxes} that $\ema{s}$ also comes equipped with a \emph{transition lens}: a lens $\delta\colon\ema{s}\to\ema{s}\tri\ema{s}$, which we can draw as
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$\ema{s}$" left] (r) {$a_2'$\at$s_0$};
	\node[poly, cod, right=1.8 of r.south, yshift=-2.5ex, "$\ema{s}$" below] (p) {$a_1$\at$s_0$};
	\node[poly, cod, above=.8 of p, "$\ema{s}$" above] (p') {$a_2$\at$s_1$};

	\draw[double] (r_pos) to[first] node[below] {} (p_pos);
	\draw (p_dir) to[climb] node[right] {tgt} (p'_pos);
	\draw (p'_dir) to[last] node[above=.3] {run} (r_dir);
  \end{tikzpicture}
\]
The arrow labeled tgt is the \emph{target function}: given a state $s_0$ and a direction $a_1$ at that state, $\text{tgt}(s_0,a_1)$ tells us the new state $s_1$ that following $a_1$ from $s_0$ will lead to.
We know that when $s_0$ is fixed, the target function on the second component $a_1$ should be an isomorphism $\ema{s}[s_0]\to\ema{s}(\1)$; that is, there is exactly one direction at $s_0$ that leads to each state of $\ema{s}$.
But this property is a little tricky to state in the language of $\poly$; in fact, we won't attempt to do so just yet.
Instead, we'll use it to make a notational choice: given $s,t\in\ema{s}$, we will let $s\to t$ denote the unique direction at $s$ that leads to $t$, so that $\text{tgt}(s,s\to t)=t$.
So we can redraw our transition lens as
\begin{equation} \label{eqn.trans_lens_polybox}
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$\ema{s}$" left] (r) {$s_0\to s_2$\at$s_0$};
	\node[poly, cod, right=2 of r.south, yshift=-2.5ex, "$\ema{s}$" right] (p) {$s_0\to s_1$\at$s_0$};
	\node[poly, cod, above=.8 of p, "$\ema{s}$" right] (p') {$s_1\to s_2$\at$s_1$};

	\draw[double] (r_pos) to[first] node[below] {} (p_pos);
	\draw (p_dir) to[climb] node[right] {tgt} (p'_pos);
	\draw (p'_dir) to[last] node[above=.4] {run} (r_dir);
  \end{tikzpicture}
\end{equation}
In addition to the fact that $\text{tgt}(s_0,s_0\to s_1)=s_1$ as intended, this picture tells us two more properties of $\delta$.

The first is that the bottom arrow is the identity on $\ema{s}(\1)$.
This is something we would like to be able to express categorically in the language of $\poly$.
We'll see that this property falls out naturally when we express how the transition lens plays nicely with the do-nothing enclosure in \cref{subsec.comon.sharp.state.cohere}.

The second is that the run arrow, which runs the transition $s_0\to s_1$ and the transition $s_1\to s_2$ together into a transition starting at $s_0$, should have the same target as tfhe second transition it follows: in this case, $s_2$.
Equationally, writing the left and right hand sides only in terms of the contents of the blue boxes, we have that
\begin{equation} \label{eqn.state_run_tgt}
    \text{tgt}(s_0,\text{run}(s_0,s_0\to s_1,s_1\to s_2))=s_2=\text{tgt}(\text{tgt}(s_0,s_0\to s_1),s_1\to s_2).
\end{equation}
We'll see that this property arises naturally when we we generalize the transition lens to more than two steps in \cref{subsec.comon.sharp.state.coassoc}.

\begin{example}[The transition lens in tree pictures] \label{ex.trans_trees}
Continuing from \cref{ex.nothing_trees}, we draw the transition lens $\delta\colon\ema{s}\to\ema{s}\tri\ema{s}$ of $\ema{s}\coloneqq\3\yon^\3\iso\{\bul[red],\bul[dgreen],\bul[blue]\}\yon^{\{\bul[red],\bul[dgreen],\bul[blue]\}}$ (where directions are labeled with their targets) in tree pictures as well, recalling that the trees of $\ema{s}\tri\ema{s}$ are obtained by taking an $\ema{s}$-corolla and gluing more $\ema{s}$-corollas to each of its leaves:
\[
\begin{tikzpicture}[trees, 
  level 1/.style={sibling distance=5mm},
  level 2/.style={sibling distance=1.5mm},
	bend right=60]
	\foreach \i/\c in {1/red, 2/dgreen, 3/blue}
	{
  	\node[\c] (\i) at (4*\i, 0) {$\bullet$} 
    	child [red] {coordinate (\i1)}
      child [dgreen] {coordinate (\i2)}
      child [blue] {coordinate (\i3)}
     	;
  	\node[right=1.7 of \i, \c] (SS\i) {$\bullet$}
  		child [red] {node (S\i1) {$\bullet$} 
				child [red] {coordinate (\i11)}
				child [dgreen] {coordinate (\i12)} 
				child [blue] {coordinate (\i13)}
				}
  		child [dgreen] {node (S\i2) {$\bullet$} 
				child [red] {coordinate (\i21)}
				child [dgreen] {coordinate (\i22)} 
				child [blue] {coordinate (\i23)}
				}
  		child [blue] {node (S\i3) {$\bullet$} 
				child [red] {coordinate (\i31)}
				child [dgreen] {coordinate (\i32)} 
				child [blue] {coordinate (\i33)}
				}
  		;
	\draw[|->, shorten <= 3pt, shorten >= 3pt] (\i) -- (SS\i);
	\foreach \j in {1,2,3}
	{
		\foreach \k\d in {1/red, 2/dgreen, 3/blue}
		{
			\draw[densely dotted, postaction={decorate}, \d] (\i\j\k) to (\i\k);
		};
	};
	};
\end{tikzpicture}
\]
On positions, the target function of $\delta$ tells us which root of $\ema{s}$ to glue to each leaf of $\ema{s}$.
Then on directions, the run function of $\delta$ tells us how to collapse the level-$2$ leaves of the trees we obtain in $\ema{s}\tri\ema{s}$ down to the original level-$1$ leaves of the corollas of $\ema{s}$.

We can draw what the target function is doing more compactly by taking the corollas of $\ema{s}$ and ``bending the arrows'' so that they point to their targets, like so:
\[
\begin{tikzpicture}
    \node[circle,minimum size=2cm] (b) {};
    \foreach\x/\c in {1/red, 2/dgreen, 3/blue} {
        \node[minimum size=0.1cm,draw,circle,\c,fill=\c] (3-\x) at (b.{360/3*\x}){};
    }
    \foreach\x/\c in {1/red, 2/dgreen, 3/blue} {
        \foreach\y/\d in {1/red, 2/dgreen, 3/blue}{
            \ifnum\x=\y
                \draw[\d,->] (3-\x) to [in=360/3*\x-15,out=360/3*\x+15,loop] ();
                \relax
            \else
                \draw[\d] (3-\x) edge[->,bend right=10] (3-\y);
            \fi
        }
    }
\end{tikzpicture}
\]
So the target function of $\delta$ turns our corolla picture of $\ema{s}$ into a complete graph on its roots!
Then the run function takes any two arrows that form a path in the graph and collapses them down to a single arrow that starts (and, according to \eqref{eqn.state_run_tgt}, ends) at the same vertex as the two-arrow path.

If this all sounds suspiciously familiar to you, you're on the right track---hang tight.
\end{example}

\subsection{The do-nothing enclosure coheres with the transition lens}\label{subsec.comon.sharp.state.cohere}

For each state $s\in\ema{s}(\1)$, the do-nothing enclosure $\epsilon\colon\ema{s}\to\yon$ picks out the $\ema{s}[s]$-direction $\id_s$ that ``does nothing'' and keeps the system in the same state $s$.
But it is the transition lens $\delta\colon\ema{s}\to\ema{s}\tri\ema{s}$ that actually sets our state system in motion, specifying the target of each direction and how two directions run together.
Either of these directions could be our do-nothing direction $\id_s$, so let's try to figure out what should happen when we set each one in turn to $\id_s$.

We can draw in polyboxes what happens when we set $\id_s$, as specified by $\epsilon$, to be the first direction that $\delta$ runs together like this:
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$\ema{s}$" left] (r) {\at$s$};
	\node[poly, right=2 of r.south, yshift=-2.5ex, "$\ema{s}$" below] (p) {$\id_s$\at$s$};
	\node[poly, cod, above=.8 of p, xshift=2.5ex, "$\ema{s}$" above] (p') {tgt$(s,\id_s)\to t$\at tgt$(s,\id_s)$};

	\draw[double] (r_pos) to[first] node[below] {} (p_pos);
	\draw (p_pos) to[climb'] node[right] {$\epsilon$} (p_dir);
	\draw (p_dir) to[climb] node[right] {tgt} (p'_pos);
	\draw (p'_dir) to[last] node[above=.4] {run} (r_dir);
\end{tikzpicture}
\]
Reading this picture from left to right, we see that it depicts the polyboxes of the composite lens $\delta\then(\epsilon\tri\ema{s})\colon\ema{s}\to\yon\tri\ema{s}\iso\ema{s}$ (recall that we sometimes denote the identity lens on $\ema{s}$ also by $\ema{s}$).
To make this interpretation more transparent, we could be a little more verbose with our polybox picture if we wanted to (omitting the contents of the boxes clarity):
\[
\begin{tikzpicture}
    \node (1) {
        \begin{tikzpicture}[polybox, tos]
        	\node[poly, dom, "$\ema{s}$" left] (r) {};
        	\node[poly, right=2 of r.south, yshift=-2.5ex, "$\ema{s}$" below] (p) {};
        	\node[poly, cod, above=.8 of p, "$\ema{s}$" above] (p') {};
        
        	\draw[double] (r_pos) to[first] node[below] {} (p_pos);
        	\draw (p_pos) to[climb'] node[right] {$\epsilon$} (p_dir);
        	\draw (p_dir) to[climb] node[right] {tgt} (p'_pos);
        	\draw (p'_dir) to[last] node[above=.3] {run} (r_dir);
        \end{tikzpicture}
	};
	\node[right=1 of 1] (2) {
	    \begin{tikzpicture}[polybox, tos]
            \node[poly, dom, "$\ema{s}$" left] (yX) {};
        	\node[poly, right=2 of yX.south, yshift=-2.5ex, "$\ema{s}$" below] (p) {};
            \node[poly, above=.8 of p, "$\ema{s}$" above] (p') {};
            \node[poly, cod, identity, right=of p, "$\ema{s}$" below] (q) {};
            \node[poly, cod, above=.8 of q, "$\ema{s}$" above] (q') {};
            \draw (p_pos) -- node[below] {$\epsilon_\1$} (q_pos);
            \draw (q_dir) -- node[above] {$\epsilon^\sharp$} (p_dir);
            \draw[double] (p'_pos) -- (q'_pos);
            \draw[double] (q'_dir) -- (p'_dir);
            \draw[double] (yX_pos) to[first] node[below] {} (p_pos);
            \draw (p_dir) to[climb] node[right] {tgt} (p'_pos);
            \draw (p'_dir) to[last] node[above=.3] {run} (yX_dir);
        \end{tikzpicture}
	};
	\node at ($(1.east)!.5!(2.west)$) {=};
\end{tikzpicture}
\]
Now what should $\text{tgt}(\id_s)$ be, and what should go in the direction box on the left?

If following the direction $\id_s$ from the state $s$ is really the same as doing nothing, then its target state should be the same state $s$ that it emerged from.
Moreover, running together $\id_s$ with any other direction $s\to t$ from $s$ should be no different from the direction $s\to t$ on its own.
So
\[
    \text{tgt}(s,\id_s)=s \qqand \text{run}(s,\id_s,s\to t)=s\to t.
\]
In fact, $\id_s$ should really just be the direction $s\to s$.
Pictorially, we have the equation
\[
\begin{tikzpicture}
	\node (1) {
        \begin{tikzpicture}[polybox, mapstos]
        	\node[poly, dom, "$\ema{s}$" left] (r) {\at$s$};
        	\node[poly, right=2 of r.south, yshift=-2.5ex, "$\ema{s}$" below] (p) {$\id_s$\at$s$};
        	\node[poly, cod, above=.8 of p, xshift=2.5ex, "$\ema{s}$" above] (p') {tgt$(s,\id_s)\to t$\at tgt$(s,\id_s)$};
        
        	\draw[double] (r_pos) to[first] node[below] {} (p_pos);
        	\draw (p_pos) to[climb'] node[right] {$\epsilon$} (p_dir);
        	\draw (p_dir) to[climb] node[right] {tgt} (p'_pos);
        	\draw (p'_dir) to[last] node[above=.4] {run} (r_dir);
        \end{tikzpicture}
	};
	\node[right=1.8 of 1] (2) {
        \begin{tikzpicture}[polybox, mapstos]
          	\node[poly, dom, "$\ema{s}$" left] (c) {$s\to t$\at$s$};
          	\node[poly, cod, right=of c, "$\ema{s}$" right] (c') {$s\to t$\at$s$};
          	\draw[double] (c_pos) -- (c'_pos);
          	\draw[double] (c'_dir) -- (c_dir);
	    \end{tikzpicture}
	};
	\node at ($(1.east)!.5!(2.west)$) {=};
\end{tikzpicture}
\]
Or, if you prefer, we might say that $\delta\then(\epsilon\tri\ema{s})=\id_{\ema{s}}$, or that the following diagram commutes:
\[
\begin{tikzcd}[row sep=large]
    \yon\tri\ema{s} & \ema{s}\ar[d, "\delta"]\ar[l, equal] \\
    & \ema{s}\tri\ema{s}\ar[ul, "\epsilon\:\tri\:\ema{s}"]
\end{tikzcd}
\]
This commutative diagram captures one way in which $\epsilon$ and $\delta$ always relate---and it's written entirely in the language of $\poly$, without having to talk about individual sets!

What about setting the second direction that $\delta$ runs together to what is specified by $\epsilon$, rather than the first?
To answer this, we should look at the composite lens $\delta\then(\ema{s}\tri\epsilon)\colon\ema{s}\to\ema{s}\tri\yon\iso\ema{s}$ instead.
But the do-nothing direction should still do nothing, so here's what the polybox picture should look like:
\[
\begin{tikzpicture}
	\node (1) {
        \begin{tikzpicture}[polybox, mapstos]
        	\node[poly, dom, "$\ema{s}$" left] (r) {$s\to t$\at$s$};
        	\node[poly, cod, right=2 of r.south, yshift=-2.5ex, "$\ema{s}$" below] (p) {$s\to t$\at$s$};
        	\node[poly, above=.8 of p, "$\ema{s}$" above] (p') {$\id_t$\at $t$};
        
        	\draw[double] (r_pos) to[first] node[below] {} (p_pos);
        	\draw (p_dir) to[climb] node[right] {tgt} (p'_pos);	\draw (p'_pos) to[climb'] node[right] {$\epsilon$} (p'_dir);
        	\draw (p'_dir) to[last] node[above=.4] {run} (r_dir);
        \end{tikzpicture}
	};
	\node[right=1.8 of 1] (2) {
        \begin{tikzpicture}[polybox, mapstos]
          	\node[poly, dom, "$\ema{s}$" left] (c) {$s\to t$\at$s$};
          	\node[poly, cod, right=of c, "$\ema{s}$" right] (c') {$s\to t$\at$s$};
          	\draw[double] (c_pos) -- (c'_pos);
          	\draw[double] (c'_dir) -- (c_dir);
	    \end{tikzpicture}
	};
	\node at ($(1.east)!.5!(2.west)$) {=};
\end{tikzpicture}
\]
The lens depicted on the right hand side of the equation is again the identity lens on $\ema{s}$.

If we match up the two white boxes on the right hand side of the equation with the corresponding white boxes on the left, we can actually read two equations off of this polybox picture.
Matching up positions in the codomain tells us that the bottom arrow of $\delta$ on the left must send $s$ to itself: it is the identity function on $\ema{s}(\1)$.
Indeed, this is exactly what we wanted to say about that arrow in \cref{subsec.comon.sharp.state.trans}.

Meanwhile, matching up directions in the domain tells us that
\[
    \text{run}(s,s\to t,\id_t)=s\to t,
\]
as we would expect: $\id_t$ is just be the direction $t\to t$.

More concisely, we can express both these facts in $\poly$ via the equation $\delta\then(\ema{s}\tri\epsilon)=\id_{\ema{s}}$.
The corresponding commutative diagram is as follows:
\[
\begin{tikzcd}[row sep=large]
    \ema{s}\ar[d, "\delta"']\ar[r, equal] & \ema{s}\tri\yon \\
    \ema{s}\tri\ema{s}.\ar[ur, "\ema{s}\:\tri\:\epsilon"']
\end{tikzcd}
\]
We can combine this with our previous commutative diagram to say that the relationship between the do-nothing enclosure $\epsilon\colon\ema{s}\to\yon$ and the transition lens $\delta\colon\ema{s}\to\ema{s}\tri\ema{s}$ of a state system $\ema{s}$ is captured in $\poly$ by the following commutative diagram:
\begin{equation}\label{eqn.erasure_law_state}
\begin{tikzcd}[row sep=large]
	\yon\tri\ema{s}&\ema{s}\ar[d, "\delta" description]\ar[r, equal]\ar[l, equal]&\ema{s}\tri\yon\\&
	\ema{s}\tri\ema{s}.\ar[ul, "\epsilon\:\tri\:\ema{s}"]\ar[ur, "\ema{s}\:\tri\:\epsilon"']
\end{tikzcd}
\end{equation}

\subsection{The transition lens is coassociative}\label{subsec.comon.sharp.state.coassoc}

Toward the end of \cref{ex.dyn_sys_trans_polyboxes}, we noted that while the transition lens $\delta\colon\ema{s}\to\ema{s}\tri\ema{s}$ gives us a canonical way to model two steps of a dynamical system with state system $\ema{s}$, we have a choice of how to model three steps through the same system: we could obtain a lens $\ema{s}\to\ema{s}\tripow3$ that runs three directions together by taking either one of the composite lenses $\delta\then(\delta\tri\ema{s})$ or $\delta\then(\ema{s}\tri\delta)$.
That presents a problem for us: which one should we choose?

Happily, it turns out this choice is a false one.
If we write out the two composite lenses in polyboxes, with $\delta\then(\delta\tri\ema{s})$ on the left and $\delta\then(\ema{s}\tri\delta)$ on the right, we find that they are equal:
\begin{equation}\label{eqn.trans_lens_coassoc_polybox}
\begin{tikzpicture}
    \node (p1) {
        \begin{tikzpicture}[polybox, tos, font=\tiny]
            \node[poly, dom, "$\ema{s}$" left] (m') {$s_0\to s_3$\at$s_0$};
            \node[poly, right= of m'.south, yshift=-1ex, "$\ema{s}$" below] (mm') {$s_0\to s_2$\at$s_0$};
            \node[poly, above=of mm', "$\ema{s}$" above] (C') {$s_2\to s_3$\at$s_2$};
            \node[poly, cod, right= of mm'.south, yshift=-1ex, "$\ema{s}$" right] (D') {$s_0\to s_1$\at$s_0$};
            \node[poly, cod, above=of D', "$\ema{s}$" right] (mmm') {$s_1\to s_2$\at$s_1$};
            \node[poly, cod, above=of mmm', "$\ema{s}$" right] (CC') {$s_2\to s_3$\at$s_2$};
            %
            \draw[double] (m'_pos) to[first] (mm'_pos);
            \draw (mm'_dir) to[climb] node[right] {tgt} (C'_pos);
            \draw (C'_dir) to[last] node[above, sloped] {run} (m'_dir);
            \draw[double] (mm'_pos) to[first] (D'_pos);
            \draw (D'_dir) to[climb] node[right] {tgt} (mmm'_pos);
            \draw (mmm'_dir) to[last] node[above, sloped] {run} (mm'_dir);
            \draw[double] (C'_pos) to[first] (CC'_pos);
            \draw[double] (CC'_dir) to[last] (C'_dir);
        \end{tikzpicture}
	};
%
	\node (p2) [right=of p1] {
	    \begin{tikzpicture}[polybox, tos, font=\tiny]
            \node[poly, dom, "$\ema{s}$" left] (m) {$s_0\to s_3$\at$s_0$};
            \node[poly, right= of m.south, yshift=-1ex, "$\ema{s}$" below] (D) {$s_0\to s_1$\at$s_0$};
            \node[poly, above=of D, "$\ema{s}$" above] (mm) {$s_1\to s_3$\at$s_1$};
            \node[poly, cod, right= of D.south, yshift=-1ex, "$\ema{s}$" right] (DD) {$s_0\to s_1$\at$s_0$};
            \node[poly, cod, above=of DD, "$\ema{s}$" right] (mmm) {$s_1\to s_2$\at$s_1$};
            \node[poly, cod, above=of mmm, "$\ema{s}$" right] (C) {$s_2\to s_3$\at$s_2$};
            %
            \draw[double] (m_pos) to[first] (D_pos);
            \draw (D_dir) to[climb] node[right] {tgt} (mm_pos);
            \draw (mm_dir) to[last] node[above, sloped] {run} (m_dir);
            \draw[double] (D_pos) to[first] (DD_pos);
            \draw[double] (DD_dir) to[last] (D_dir);
            \draw[double] (mm_pos) to[first] (mmm_pos);
            \draw (mmm_dir) to[climb] node[right] {tgt} (C_pos);
            \draw (C_dir) to[last] node[above, sloped] {run} (mm_dir);
        \end{tikzpicture}
    };	
	\node at ($(p1.south)!.5!(p2.north)$) {$=$};
\end{tikzpicture}
\end{equation}
Remember: the way to read these polyboxes is to start at the lower blue square on the left and follow the arrows; and if you reach a box with no arrows leading out of it, go up to the blue box above it and continue to follow the arrows from there.

There's a lot going on here, so let's break it down---we'll focus on the run functions first.
On the left hand side, we run together $s_0\to s_1$ and $s_1\to s_2$ to obtain $s_0\to s_2$, before running that together with $s_2\to s_3$ to obtain $s_0\to s_3$, as we see in the upper left box.
Meanwhile, on the right, we run together $s_1\to s_2$ and $s_2\to s_3$ to obtain $s_1\to s_3$, before running $s_0\to s_1$ together with our newly obtained $s_1\to s_3$ to again obtain $s_0\to s_3$ in the upper left box.
We could write this all out equationally, but all this is saying is that ``running together'' the directions of a state system is an associative operation.
When running together three directions, it doesn't matter whether we run the first two together or the last two together to start.
Not only is this guaranteed by the way in which we constructed $\delta$, it also makes intuitive sense.

\begin{exercise}
Using only the contents of the blue boxes and the target and run functions, write down the equation that we can read off of \eqref{eqn.trans_lens_coassoc_polybox} expressing the associativity of the ``running together'' operation.
\begin{solution}
Following the arrows on either side of \eqref{eqn.trans_lens_coassoc_polybox} all the way to the domain's direction box, we obtain an expression for each box's contents that we can then set equal to each other.
The easiest way to actually write down these expressions is probably to start at the end with $s_0\to s_3$ and follow the arrows backward, unpacking each term until only the contents of the blue boxes remain (namely $s_0, s_0\to s_1, s_1\to s_2,$ and $s_2\to s_3$).
Here's what we get when we follow this process for the left hand side of \eqref{eqn.trans_lens_coassoc_polybox} (remember where to look for the three inputs to the run function):
\begin{align*}
    s_0\to s_3&=\text{run}(s_0,s_0\to s_2,s_2\to s_3)\\
    &=\text{run}(s_0,\text{run}(s_0,s_0\to s_1,s_1\to s_2),s_2\to s_3)\\
    &=\text{run}(s_0,\text{run}(s_0,s_0\to s_1,s_1\to s_2),s_2\to s_3);
\end{align*}
and here's what we get for the right (also remember where to look for the two inputs to the target function):
\begin{align*}
    s_0\to s_3&=\text{run}(s_0,s_0\to s_1,s_1\to s_3)\\
    &=\text{run}(s_0,s_0\to s_1,\text{run}(s_1,s_1\to s_2,s_2\to s_3))\\
    &=\text{run}(s_0,s_0\to s_1,\text{run}(\text{tgt}(s_0,s_0\to s_1),s_1\to s_2,s_2\to s_3)).
\end{align*}
Setting these equal yields our desired associativity equation:
\[
    \text{run}(s_0,\text{run}(s_0,s_0\to s_1,s_1\to s_2),s_2\to s_3)=\text{run}(s_0,s_0\to s_1,\text{run}(\text{tgt}(s_0,s_0\to s_1),s_1\to s_2,s_2\to s_3)).
\]
\end{solution}
\end{exercise}

This associative property is what we get by matching up the white direction boxes on each domain side, but there are three more white position boxes on each codomain side that we can match up as well.
The fact that the lower two of these pairs coincide is a consequence of the fact that the bottom arrow of $\delta$ is the identity, which we already knew from \cref{subsec.comon.sharp.state.cohere}; so we don't learn anything new there.
On the other hand, the fact that both the upper position boxes in the codomain contain $s_2$ implies that
\begin{align*}
    \text{tgt}(s_0,\text{run}(s_0,s_0\to s_1,s_1\to s_2))&=\text{tgt}(s_0,s_0\to s_2)\\
    &=s_2\\
    &=\text{tgt}(s_1,s_1\to s_2)\\
    &=\text{tgt}(\text{tgt}(s_0,s_0\to s_1),s_1\to s_2),
\end{align*}
which is exactly what we wanted in \eqref{eqn.state_run_tgt}.
In English, this says that when we run together $s_0\to s_1$ and $s_1\to s_2$, the new direction's target is the same as the direction of $s_1\to s_2$, the latter of the two directions that we ran together.
Again, this coincides with our intuition: if we follow two directions in order, we should end up at wherever the latter direction leads us.

Hence both the associativity of running directions together and the relationship between the target and run functions from \eqref{eqn.state_run_tgt} are captured by the equality of lenses $\delta\then(\delta\tri\ema{s})=\delta\then(\ema{s}\tri\delta)$.
Equivalently, the following diagram in $\poly$ commutes:
\begin{equation}\label{eqn.coassoc_law_states}
\begin{tikzcd}[row sep=large]
	\ema{s}\ar[r, "\delta"]\ar[d, "\delta"']&
	\ema{s}\tri\ema{s}\ar[d, "\ema{s}\:\tri\:\delta"]\\
	\ema{s}\tri\ema{s}\ar[r, "\delta\:\tri\:\ema{s}"']&
	\ema{s}\tri\ema{s}\tri\ema{s}.
\end{tikzcd}
\end{equation}
Another way to say this is that $\delta$ is \emph{coassociative}: while $\delta$ is only a lens $\ema{s}\to\ema{s}\tripow2$ as defined, the commutativity of \eqref{eqn.coassoc_law_states} tells us that the two ways of getting a lens $\ema{s}\to\ema{s}\tripow3$ out of $\delta$ are actually the same.
(This is dual to an \emph{associative} operation, which is a binary operation that gives rise to two identical ternary operations.)

So $\delta$ induces a canonical lens $\ema{s}\to\ema{s}\tripow3$, which in an abuse of notation we will call $\delta^3$, as it has $3$ copies of $\ema{s}$ in its codomain.
Armed with this new lens, we can model three steps through a system $\phi\colon\ema{s}\to p$ with interface $p\in\poly$ as the composite lens
\[
    \ema{s}\To{\delta^3}\ema{s}\tripow3\To{\phi\tripow3}p\tripow3.
\]

In fact, coassociativity guarantees that $\delta$ induces a canonical lens $\delta^n\colon\ema{s}\to\ema{s}\tripow{n}$ for every integer $n\geq2$, starting with $\delta^2\coloneqq\delta$.%
\footnote{Perhaps this abuse of notation seems rather unnatural, but it helps to think of the original $\delta\colon\ema{s}\to\ema{s}\tri\ema{s}$ as the $n=2$ case of a generalized transition lens modeling $n$ steps through the state system.}
For concreteness, we could then define $\delta^n$ for $n>2$ inductively by $\delta^n\coloneqq\delta\then(\delta^{n-1}\tri\ema{s})$, or just as well by $\delta^n\coloneqq\delta\then(\ema{s}\tri\delta^{n-1})$ or even $\delta^n\coloneqq\delta\then(\delta^\ell\tri\delta^m)$ for some pair of integers $\ell,m>1$ satisfying $\ell+m=n$.
Regardless, the coassociativity of $\delta$ means that it doesn't matter how we build a lens $\ema{s}\to\ema{s}\tripow{(n+1)}$ out of $\delta,\then,\tri,$ and identity lenses: we'll always end up with the same lens.
We will state this in more generality in \cref{prop.n_duplication}, but here's some practice with the $n=4$ case for a taste of what's to come. %**prove this in more generality?

\begin{exercise}
\begin{enumerate}
    \item Say we know nothing about $\ema{s}$ or $\delta$ apart from the fact that $\ema{s}\in\poly$ and that $\delta$ is a lens $\ema{s}\to\ema{s}\tri\ema{s}$.
    List all the ways to obtain a lens $\ema{s}\to\ema{s}\tripow4$ using only copies of $\delta,\id_\ema{s}$, $\tri$, and $\then$.
    (You may write $\ema{s}$ for $\id_\ema{s}$.)

    \item Now assume that \eqref{eqn.coassoc_law_states} commutes.
    Show that all the lenses on your list are equal.
    (Hint: Use the fact that $(f\then g)\tri(h\then k)=(f\tri h)\then(g\tri k)$ for lenses $f,g,h,k$).
    \qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item Given $\ema{s}\in\poly$ and a lens $\delta\colon\ema{s}\to\ema{s}\tri\ema{s}$, we want all the ways to obtain a lens $\ema{s}\to\ema{s}\tripow4$ using $\delta,\id_\ema{s}$ (i.e.\ $\ema{s}$), $\tri,$ and $\then$.
    Starting with $\ema{s}$, the only way to get to $\ema{s}\tripow2$ is with a single $\delta\colon\ema{s}\to\ema{s}\tripow2$.
    From there, we can get to $\ema{s}\tripow4$ directly by composing with $\delta\tri\delta$ to obtain $\delta\then(\delta\tri\delta)$.
    Alternatively, we can preserve either the first or the second $\ema{s}$ using the identity, then get to $\ema{s}\tripow3$ from the other $\ema{s}$ in one of two ways: either $\delta\then(\delta\tri\ema{s})$ or $\delta\then(\ema{s}\tri\delta)$.
    This gives us $4$ more ways to write a lens $\ema{s}\to\ema{s}\tripow4$: either $\delta\then(\ema{s}\tri(\delta\then(\delta\tri\ema{s})))$ or $\delta\then(\ema{s}\tri(\delta\then(\ema{s}\tri\delta)))$ if we chose to preserve the first $\ema{s}$, and either $\delta\then((\delta\then(\delta\tri\ema{s}))\tri\ema{s})$ or $\delta\then((\delta\then(\ema{s}\tri\delta))\tri\ema{s})$ if we chose to preserve the second.
    Here's the full list, sorted roughly by how far to the left we try to apply each $\delta$:
    \begin{enumerate}[label=(\arabic*)]
        \item $\delta\then((\delta\then(\delta\tri\ema{s}))\tri\ema{s})$
        \item $\delta\then((\delta\then(\ema{s}\tri\delta))\tri\ema{s})$
        \item $\delta\then(\delta\tri\delta)$
        \item $\delta\then(\ema{s}\tri(\delta\then(\delta\tri\ema{s})))$
        \item $\delta\then(\ema{s}\tri(\delta\then(\ema{s}\tri\delta)))$
    \end{enumerate}
    This coincides with the $5$ different ways to parenthesize a $4$-term expression.
    
    \item We wish to show that if \eqref{eqn.coassoc_law_states} commutes, then all the lenses on our list are equal.
    The commutativity of \eqref{eqn.coassoc_law_states} implies that $\delta\then(\delta\tri\ema{s})=\delta\then(\ema{s}\tri\delta)$; so (1) and (2) from our list are equal, as are (4) and (5).
    Meanwhile, since $\ema{s}=\ema{s}\then\ema{s}$, we can rewrite (1) as
    \[
        \delta\then((\delta\then(\delta\tri\ema{s}))\tri(\ema{s}\then\ema{s}))=\delta\then(\delta\tri\ema{s})\then(\delta\tri\ema{s}\tri\ema{s}),
    \]
    where the associativity of $\tri$ and $\then$ allows us to drop some parentheses.
    Then the commutativity of \eqref{eqn.coassoc_law_states} allows us to further rewrite this as
    \begin{align*}
        \delta\then(\ema{s}\tri\delta)\then(\delta\tri\ema{s}\tri\ema{s})&=\delta\then((\ema{s}\then\delta)\tri(\delta\then(\ema{s}\tri\ema{s})))\\
        &=\delta\then(\delta\tri\delta),
    \end{align*}
    so (1) and (3) are equal.
    Similarly, we can rewrite (5) as
    \begin{align*}
        \delta\then((\ema{s}\then\ema{s})\tri(\delta\then(\ema{s}\tri\delta)))&=\delta\then(\ema{s}\tri\delta)\then(\ema{s}\tri\ema{s}\tri\delta)\\
        &=\delta\then(\delta\tri\ema{s})\then(\ema{s}\tri\ema{s}\tri\delta)\\
        &=\delta\then((\delta\then(\ema{s}\tri\ema{s}))\tri(\ema{s}\then\delta))\\
        &=\delta\then(\delta\tri\delta)
    \end{align*}
    so (3) and (5) are equal.
    Hence all the lenses on our list are equal.
\end{enumerate}
\end{solution}
\end{exercise}

\subsection{Running dynamical systems}\label{subsec.comon.sharp.state.run}

Finally, we are ready to fulfill our promise from way back in \cref{ex.do_nothing} by using the language of $\poly$ to describe stepping through a dynamical system $n$ times for arbitrary $n\in\nn$.
Given a dynamical system $\phi\colon\ema{s}\to p$ with interface $p\in\poly$, we can construct a new dynamical system that we call $\text{Run}_n(\phi)$, with the same state system $\ema{s}$ but a new interface $p\tripow{n}$, by defining $\text{Run}_n(\phi)\coloneqq\delta^n\then\phi\tripow{n}$.
Visually, we define $\text{Run}_n(\phi)$ so that the following diagram commutes:
\begin{equation}\label{eqn.speedup}
\begin{tikzcd}
	\ema{s}\ar[r, "\delta^n"]\ar[rr, bend right, "{\text{Run}_n(\phi)}"']&
	\ema{s}\tripow{n}\ar[r, "\phi\tripow{n}"]&
	p\tripow n
\end{tikzcd}
\end{equation}
One way to think of this is that $\text{Run}_n(\phi)$ is a sped-up version of $\phi$: one step through $\text{Run}_n(\phi)$ is equivalent to $n$ steps through $\phi$.
But this is just because a single interaction with the interface $p\tripow{n}$ models a sequence of $n$ interactions with the interface $p$, as detailed in \cref{subsec.comon.comp.def.dyn_sys,ex.dyn_sys_comp_polyboxes}.
So $\text{Run}_n(\phi)$ repackages $n$ cycles through $\phi$ into a single step.
Crucially, $\delta^n$ is what tells us how to sequence all $n$ of these steps together on the state system side.
We illustrated how $\delta$ does this for the $n=2$ case in \cref{ex.dyn_sys_trans_polyboxes}, and here's a polybox picture for the $n=3$ case:
\[
\begin{tikzpicture}
	\node (given) {
	\begin{tikzpicture}[polybox, tos]
		\node[poly, dom, blue, "$\ema{s}$" left] (S) {};
		\node[poly, cod, dgreen, right=of S, "$p$" right] (p) {};
		\draw (S_pos) to[first] (p_pos);
		\draw (p_dir) to[last]  (S_dir);
		\node at ($(S.east)!.5!(p.west)$) {$\phi$};
	\end{tikzpicture}
	};
	\node[right=of given] (obtain) {
	\begin{tikzpicture}[polybox, tos]
		\node[poly, dom, blue, "$\ema{s}$" left] (S) {};
		\node[poly, blue, right=of S] (S2) {};
		\node[poly, blue, below=of S2] (S1) {};
		\node[poly, blue, above=of S2] (S3) {};
		\node[poly, dgreen, cod, right=of S1, "$p$" right] (p1) {};
		\node[poly, dgreen, cod, right=of S2, "$p$" right] (p2) {};
		\node[poly, dgreen, cod, right=of S3, "$p$" right] (p3) {};
%
		\draw (S1_pos) to[first] (p1_pos);
		\draw (p1_dir) to[last] (S1_dir);		
		\draw (S2_pos) to[first] (p2_pos);
		\draw (p2_dir) to[last]  (S2_dir);		
		\draw (S3_pos) to[first] (p3_pos);
		\draw (p3_dir) to[last]  (S3_dir);
		\draw[blue] (S_pos) to[first] (S1_pos);
		\draw[blue] (S1_dir) to[climb] (S2_pos);
		\draw[blue] (S2_dir) to[climb] (S3_pos);
		\draw[blue] (S3_dir) to[last] (S_dir);
		\node[blue] at ($(S.east)!.33!(S2.west)$) {$\delta^3$};
		\node at ($(S1.east)!.33!(p1.west)$) {$\phi$};
		\node at ($(S2.east)!.33!(p2.west)$) {$\phi$};
		\node at ($(S3.east)!.33!(p3.west)$) {$\phi$};		
  \end{tikzpicture}	
	};
	\node[above] at (obtain.north) (obtain_lab) {obtain $\text{Run}_3(\phi)$:};
	\node at (given|-obtain_lab) {Given $\phi\colon \ema{s}\to p$,};
\end{tikzpicture}
\]
Notice that we have only defined $\delta^n$, and thus $\text{Run}_n(\phi)$, for integers $n\geq2$.
But $n=0$ runs through $n$ is doing nothing, modeled by the do-nothing enclosure $\epsilon\colon\ema{s}\to\yon$, while $n=1$ run through $\phi$ is modeled by $\phi\colon\ema{s}\to\ema{s}$ itself.
So we want $\text{Run}_0(\phi)=\epsilon$ and $\text{Run}_1(\phi)=\phi$; we can achieve this by setting $\delta^0\coloneqq\epsilon$ and $\delta^1\coloneqq\id_\ema{s}$.
Here we should think of the do-nothing enclosure $\delta^0$ as the transition lens modeling $0$ steps through our state system, and the identity $\delta^1$ as the transition lens modeling a single step.

\begin{exercise}
Verify that when $\delta^0=\epsilon$ and $\delta^1=\id_\ema{s}$, if $\text{Run}_n(\phi)$ is defined as $\delta^n\then\phi\tripow{n}$ for all $n\in\nn$, then $\text{Run}_0(\phi)=\epsilon$ and $\text{Run}_1(\phi)=\id_\ema{s}$.
\begin{solution}
We have $\text{Run}_n(\phi)=\delta^n\then\phi\tripow{n}$ for all $n\in\nn$, as well as $\delta^0=\epsilon$ and $\delta^1=\id_\ema{s}$.
Then $\text{Run}_0(\phi)=\epsilon\then\phi\tripow0=\epsilon\then\id_\yon=\epsilon$ and $\text{Run}_1(\phi)=\id_\ema{s}\then\phi\tripow1=\phi\tripow1=\phi$.
\end{solution}
\end{exercise}

One drawback of the $\text{Run}_n(-)$ operation is that we need to keep track of a separate morphism $S\yon^S\to p\tripow{n}$ for every $n\in\nn$, as well as various ways to relate these morphisms for different values of $n$.
Is there a way to package all this information into a single morphism that can model arbitrarily long runs through the system?
We will answer this question in \cref{ch.comon.cofree}; but for now, let us investigate what's really going on with our state systems algebraically.

\subsection{State systems as comonoids}

It turns out that objects equipped with morphisms like those in \cref{subsec.comon.sharp.state.nothing,subsec.comon.sharp.state.trans} that satisfy the commutative diagrams from \cref{subsec.comon.sharp.state.cohere,subsec.comon.sharp.state.coassoc} are well-known to category theorists.

\begin{definition}[Comonoid]\label{def.comonoid}
In a monoidal category $(\cat{C},\yon,\tri)$, a \emph{comonoid} $\com{C}\coloneqq(\ema{c},\epsilon,\delta)$ consists of:
\begin{itemize}
    \item an object $\ema{c}\in\cat{C}$, called the \emph{carrier};
    \item a morphism $\epsilon\colon\ema{c}\to\yon$ in $\cat{C}$, called the \emph{eraser} (or the \emph{counit}); and
    \item a morphism $\delta\colon\ema{c}\to\ema{c}\tri\ema{c}$ in $\cat{C}$, called the \emph{duplicator} (or the \emph{comultiplication});
\end{itemize}
such that the following diagrams, collectively known as the \emph{comonoid laws}, commute: 
\begin{equation}\label{eqn.erasure_law}
\begin{tikzcd}[background color=definitioncolor, row sep=large]
	\yon\tri \ema{c}&\ema{c}\ar[d, "\delta" description]\ar[r, equal]\ar[l, equal]&\ema{c}\tri\yon\\&
	\ema{c}\tri\ema{c},\ar[ul, "\epsilon\:\tri\:\ema{c}"]\ar[ur, "\ema{c}\:\tri\:\epsilon"']
\end{tikzcd}
\end{equation}
where the left triangle is known as the \emph{left erasure} (or \emph{counit}) \emph{law} and the right triangle is known as the \emph{right erasure} (or \emph{counit}) \emph{law}; and
\begin{equation}\label{eqn.coassoc_law}
\begin{tikzcd}[row sep=large]
	\ema{c}\ar[r, "\delta"]\ar[d, "\delta"']&
	\ema{c}\tri\ema{c}\ar[d, "\ema{c}\:\tri\:\delta"]\\
	\ema{c}\tri \ema{c}\ar[r, "\delta\:\tri\:\ema{c}"']&
	\ema{c}\tri\ema{c}\tri\ema{c},
\end{tikzcd}
\end{equation}
known as the \emph{coassociative law}.

We may also say that the eraser and duplicator morphisms comprise a \emph{comonoid structure} on the carrier, or we may identify a comonoid with its carrier if the eraser and duplicator can be inferred from context.

We refer to a comonoid $\com{C}$ in $(\poly,\yon,\tri)$ as a \emph{polynomial comonoid}.
\end{definition}

\begin{remark}
The concept of a \emph{comonoid} in a monoidal category is dual to that of a \emph{monoid}, which may be more familiar.
Monoids come with \emph{unit} and \emph{multiplication} morphisms that point the other way, so named because they generalize the unit and multiplication operations of a monoid in $\smset$.
(We'll talk more about monoids in $\smset$ in \cref{ex.monoids}.)
Prepending `co-' to each term yields the corresponding terms for comonoids.

The alternative names \emph{eraser} for the \emph{counit} and \emph{duplicator} for the \emph{comultiplication} are less standard, but we will favor them to avoid confusion between the counit of a \emph{comonoid} and the counit of an \emph{adjunction}---and so that their names match up with the Greek letters $\epsilon$ and $\delta$ that we will so often use to label them.
The word ``duplicator'' comes from the fact that $\delta\colon\ema{c}\to\ema{c}\tri\ema{c}$ effectively turns one $\ema{c}$ into two, while the ``eraser'' $\epsilon\colon\ema{c}\to\yon$ erases the $\ema{c}$ altogether, leaving only the monoidal unit $\yon$.
Still, it can be helpful to think of comonoids as having a \emph{coassociative} comultiplication along with a counit satisfying \emph{left and right counit laws}.
\end{remark}

\begin{remark}
Comonoids in a functor category with respect to the composition product are generally known as \emph{comonads}.
So it would be a little more precise and familiar to refer to our polynomial comonoids as \emph{polynomial comonads}.
But since we think of our polynomials more often as arenas than as functors, well favor the term comonoid over comonad.
\end{remark}

\begin{example}[State systems are polynomial comonoids]
Nearly all our work on state systems up until now can be summarized thusly:
\slogan{
    every state system is a polynomial comonoid,\\
    whose eraser is the do-nothing enclosure\\
    and whose duplicator is the transition lens.
}
The comonoid structure on a state system $\ema{s}$ is what allows us to write canonical lenses $\ema{s}\to\ema{s}\tripow{n}$ for any $n\in\nn$.
We can then model $n$ steps through a dynamical system $\phi\colon\ema{s}\to p$ with interface $p\in\poly$ by composing this canonical lens with $\phi\tripow{n}$ to obtain a ``sped-up'' dynamical system $\text{Run}_n(\phi)$.
This new system has the same state system $\ema{s}$, but its interface is now $p\tripow{n}$.

The canonicity of $\ema{s}\to\ema{s}\tripow{n}$ is due to the following standard result about comonoids, which can be proved inductively. %**remove this last part if you end up including the proof
\end{example}
% The fact that a state system $\ema{s}$ has a comonoid structure is well-known: it is called the \emph{state comonad} in computer science literature. **Check that this is actually true...

\begin{proposition}[Defining $\delta^n$] \label{prop.n_duplication}
Given a comonoid $(\ema{c},\epsilon,\delta)$, by mild abuse of notation let $\delta^0\coloneqq\epsilon$ and inductively define $\delta^{n+1}\coloneqq\delta\then\left(\delta^n\tri\ema{c}\right)$ for all $n\in\nn$.
Then we have the following:
\begin{enumerate}[label=(\alph*)]
    \item $\delta^n$ is a morphism $\ema{c}\to\ema{c}\tripow{n}$ for all $n\in\nn$;
    \item $\delta^1=\id_\ema{c}$;
    \item $\delta^2=\delta$; and
    \item $\delta^n=\delta\then\left(\delta^k\tri\delta^{n-k}\right)$ for all $k,n\in\nn$ with $k\leq n$, so our choice of morphism $\ema{c}\to\ema{c}\tripow{(n+1)}$ is canonical. % More generally: $\delta^n=\delta^m\then\left(\delta^{k_1}\tri\cdots\tri\delta^{k_m}\right)$ for $m,n\in\nn$ and each $k_i\in\nn$ such that $k_1+\cdots+k_m=n$.
\end{enumerate}
\end{proposition}
%** come back and fill this in
% \begin{proof}
% We leave parts (a), (b), and (c) for \cref{exc.n_duplication} and prove part (d).

% When $n=k$, (d) follows from (b) and the construction of $\delta^n$.
% We prove the rest of (d) by induction on $n\in\nn$.
% For $n=0$, it remains to consider the $k=1$ case, which follows from (b) and the right erasure law from \eqref{eqn.erasure_law}:
% \begin{align*}
%     \delta\then\left(\delta^0\tri\delta^{-1}\right)&=\delta\then\left(\ema{c}\tri\epsilon\right) \tag{b}\\
%     &=\id_\ema{c} \tag*{\eqref{eqn.erasure_law}}\\
%     &=\delta^0 \tag{b}.
% \end{align*}

% Then for $n>0$, **.
% \end{proof}
We'll continue to use the notation introduced here throughout for general comonoids.

\begin{exercise} \label{exc.n_duplication}
Prove the first three parts of \cref{prop.n_duplication}. %Finish the proof of \cref{prop.n_duplication} as follows.
\begin{enumerate}
    \item Prove part (a).
    \item Prove part (b).
    \item Prove part (c).\qedhere
\end{enumerate}
\begin{solution}
We complete the proof of \cref{prop.n_duplication}, where we are given a comonoid $(\ema{c},\epsilon,\delta)$ along with $\delta^0\coloneqq\epsilon$ and $\delta^{n+1}\coloneqq\delta\then\left(\delta^n\tri\ema{c}\right)$ for all $n\in\nn$.
\begin{enumerate}
    \item We will show that $\delta^n$ is a map $\ema{c}\to\ema{c}\tripow{n}$ for every $n\in\nn$ by induction on $n$.
    We know $\delta^0=\epsilon$ is a map $\ema{c}\to\yon=\ema{c}\tripow0$, and for each $n\in\nn$, if $\delta^n$ is a map $\ema{c}\to\ema{c}\tripow{n}$, then the composite $\delta^{n+1}=\delta\then\left(\delta^n\tri\ema{c}\right)$ is a map
    \[
        \ema{c}\To\delta\ema{c}\tri\ema{c}\To{\delta^n\:\tri\:\ema{c}}\ema{c}\tripow{n}\tri\ema{c}\iso\ema{c}\tripow{(n+1)}
    \]
    Hence the result follows by induction.
    
    \item We have $\delta^1=\delta\then(\delta^0\tri\ema{c})=\delta\then(\epsilon\tri\ema{c})=\id_\ema{c}$ by the left erasure law from \eqref{eqn.erasure_law}.
    
    \item By the previous part, we have $\delta^2=\delta\then(\delta^1\tri\ema{c})=\delta\then(\ema{c}\tri\ema{c})=\delta$.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{example}[Not all polynomial comonoids are state systems] \label{ex.not_all_com_state}
At this point, a natural question to ask is whether everything we know about a state system $\ema{s}$ is captured by the fact that state systems are polynomial comonoids.
In other words, are state systems the only polynomial comonoids there are?

The answer turns out to be no.
After all, there is one fact about state systems from \cref{subsec.comon.sharp.state.trans} that we did not encode in $\poly$: for a fixed state $s\in\ema{s}(\1)$, the target function $\ema{s}[s]\to\ema{s}(\1)$ assigning directions at $s$ to their target states is a bijection.

Nothing in our comonoid laws guarantees this bijectivity.
An arbitrary polynomial comonoid might assign different directions at $s$ to the same target---given a second state $t$, there may be multiple ways to get from $s$ to $t$.
It might even assign \emph{no} directions at $s$ to a target $t$, making it impossible to get from $s$ to $t$.
(We'll give an explicit example of a comonoid that is not a state system in \cref{ex.walking_arrow_com}.)
State systems as we have defined them are just the polynomial comonoids that do not allow either of these variations, for which the bijective property holds.

We consider this a feature, not a bug.
After all, it is an abstraction to say that there is exactly one way to get from any one state in a system to another.
It is perfectly plausible that the inner workings of a state system do not permit traveling between some states and differentiate ways of traveling between others.
We won't formally introduce this idea into our theory of dependent dynamical systems, %**unless we do??
but we will often think of polynomial comonoids as a sort of generalized state system throughout the rest of the book.
\end{example}

%** update w/o category language yet
\begin{example}[A comonoid that is not a state system]\label{ex.walking_arrow_com}
The polynomial $\yon^\2+\yon$ is not a state system: one of its direction-sets has one fewer element than its position-set.
But it can still be given a comonoid structure.
We describe that structure here, but we will go a little quickly, because we'll soon discover a much more familiar way to think about comonoids.

Define $\ema{w}\coloneqq\{A\}\yon^{\{i_A,f\}}+\{B\}\yon^{\{i_B\}}\iso\yon^\2+\yon$.
Here is its tree picture:
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "$\ema{w}\coloneqq$" left] {
	\begin{tikzpicture}[trees, sibling distance=5mm]
    \node["\tiny $A$" below, red] (1) {$\bullet$} 
      child  {coordinate (iA) \idchild}
      child {coordinate (f)};
    \node[right=.8 of 1,"\tiny $B$" below, blue] (2) {$\bullet$} 
      child  {coordinate (iB) \idchild};
    \node[below left=0 of iA, font=\tiny] {$i_A$};
    \node[below left=0 of iB, font=\tiny] {$i_B$};
    \node[below right=0 of f, font=\tiny] {$f$};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Notice that we have drawn one direction out of each position---$i_A$ and $i_B$---with a double bar.
We let these be the directions that the eraser $\epsilon\colon\ema{w}\to\yon$ picks out.
The double bar is meant to evoke an equals sign from the root position to the eventual target position, which is appropriate, as these two positions should be equal for every direction that the eraser selects.
We can draw the selections that $\epsilon$ makes like so:
\[
\begin{tikzpicture}[trees, bend right=60]
  \node[red] (1) {$\bullet$} 
  	child  {coordinate (11) \idchild}
    child {coordinate (12)};
  \node[right=1.5 of 1] (1y) {$\bullet$}
  	child {coordinate (1y1)};
%
  \node[right=2 of 1y, blue] (2) {$\bullet$} 
  	child  {coordinate (21) \idchild};
  \node[right=1.5 of 2] (2y) {$\bullet$}
  	child {coordinate (2y1)};
	\draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (1y);
	\draw[|->, shorten <= 3pt, shorten >= 3pt] (2) -- (2y);
	\draw[densely dotted, postaction={decorate}] (1y1) to (11);
	\draw[densely dotted, postaction={decorate}] (2y1) to (21);
\end{tikzpicture}
\]

Now we need a duplicator $\delta\colon\ema{w}\to\ema{w}\tri\ema{w}$.
Before we define it, let's draw out $\ema{w}\tri\ema{w}$ to see what it looks like.
Remember that we need to glue corollas of $\ema{w}$ to leaves of $\ema{w}$ in every possible way:
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "$\ema{w}\tri\ema{w}=$" left] {
	\begin{tikzpicture}[trees,
	  level 1/.style={sibling distance=5mm},
  	level 2/.style={sibling distance=2.5mm}]
    \node[red] (1) {$\bullet$} 
      child  {
        node [red] {$\bullet$} 
 		    child  {\idchild}
      	child {}
			\idchild
			}
      child  {
        node [red] {$\bullet$} 
 		    child  {\idchild}
      	child {}
			};
    \node[right=1 of 1, red] (2) {$\bullet$} 
      child  {
        node [red]{$\bullet$} 
 		    child  {\idchild}
      	child {}
			\idchild
			}
      child {node [blue] {$\bullet$} 
      	child  {\idchild}
			};
    \node[right=1 of 2, red] (3) {$\bullet$} 
      child {node [blue] {$\bullet$} 
      	child  {\idchild}
				\idchild
			}
      child  {
        node [red] {$\bullet$} 
 		    child {\idchild}
      	child {}
			};
    \node[right=1 of 3, red] (4) {$\bullet$} 
      child {node [blue] {$\bullet$} 
      	child  {\idchild}
			\idchild
			}
      child {node [blue] {$\bullet$} 
      	child  {\idchild}
			};
    \node[right=.8 of 4, blue] (5) {$\bullet$} 
      child  {
        node [red] {$\bullet$} 
 		    child  {\idchild}
      	child {}
			\idchild
			};
    \node[right=.6 of 5, blue] (6) {$\bullet$} 
      child {node [blue] {$\bullet$} 
      	child  {\idchild}
			\idchild
			};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Each of these trees gives a way to match directions out of one position to positions they could lead to.
On positions, $\delta$ will decide which matchings to pick by sending $A$ to one of the four positions on the left and $B$ to one of the two positions on the right.
We want the double-barred directions that the eraser picked out to have the same position on either end (in fact, the erasure laws guarantee this).
So the only choice to be made is whether we want the other direction $f$ at $A$ to point to $A$ or to $B$.
Let's pick $B$ for the time being, so that on positions, $\delta$ looks like this:
\[
\begin{tikzpicture}[trees, sibling distance=5mm,	bend right=60]
	\node (1A) [red] {$\bullet$} 
  	child  {coordinate (1A1) \idchild}
    child {coordinate (1A2)};
  \node (2A) [right=1.5 of 1A, red] {$\bullet$} 
      child  {
        node [red] {$\bullet$} 
 		    child  {coordinate (2A1) \idchild}
      	child {coordinate (2A2)}
			\idchild
			}
      child {node [blue] {$\bullet$} 
      	child  {coordinate (2A3) \idchild}
			};
	\draw[|->, shorten <= 3pt, shorten >= 3pt] (1A) -- (2A);
% 	\draw[densely dotted, postaction={decorate}] (2A1) to (1A1);
% 	\draw[densely dotted, postaction={decorate}] (2A2) to (1A2);
% 	\draw[densely dotted, postaction={decorate}] (2A3) to (1A2);
%
  \node[right=2 of 2A, blue] (1B) {$\bullet$} 
  	child  {coordinate (1B1) \idchild};
  \node[right=1.5 of 1B, blue] (2B) {$\bullet$} 
  	child {node [blue] {$\bullet$} 
    child  {coordinate (2B1) \idchild}
		\idchild
	};
	\draw[|->, shorten <= 3pt, shorten >= 3pt] (1B) -- (2B);
% 	\draw[densely dotted, postaction={decorate}] (2B1) to (1B1);
\end{tikzpicture}
\]
As in \cref{ex.trans_trees}, we can interpret this as telling us how to ``bend'' the arrows of $\ema{w}$ so that they point to other positions:
\begin{equation} \label{eqn.walking_arrow_bent_cor}
\begin{tikzpicture}
    \node[circle,minimum size=2cm] (b) {};
    \foreach\x/\c in {1/red, 2/blue} {
        \node[minimum size=0.1cm,draw,circle,\c,fill=\c] (2-\x) at (b.{360/2*\x}){};
        \draw[double] (2-\x) to [in=360/2*\x-30,out=360/2*\x+30,loop] ();
        \relax
    }
    \draw (2-1) edge[->] (2-2);
\end{tikzpicture}
\end{equation}

Meanwhile, on directions, $\delta$ should tell us how to run two directions together into one.
Fortunately, there's not much for us to do here---we know that if one of the two directions $\delta$ runs together is one of the double-barred directions that the eraser picked out, then $\delta$ should ignore that ``do-nothing'' direction and yield the other direction (again, the erasure laws ensure this).
Here's what that looks like:
\[
\begin{tikzpicture}[trees, sibling distance=5mm,	bend right=60]
	\node (1A) [red] {$\bullet$} 
  	child  {coordinate (1A1) \idchild}
    child {coordinate (1A2)};
  \node (2A) [right=1.5 of 1A, red] {$\bullet$} 
      child  {
        node [red] {$\bullet$} 
 		    child  {coordinate (2A1) \idchild}
      	child {coordinate (2A2)}
			\idchild
			}
      child {node [blue] {$\bullet$} 
      	child  {coordinate (2A3) \idchild}
			};
	\draw[|->, shorten <= 3pt, shorten >= 3pt] (1A) -- (2A);
	\draw[densely dotted, postaction={decorate}] (2A1) to (1A1);
	\draw[densely dotted, postaction={decorate}] (2A2) to (1A2);
	\draw[densely dotted, postaction={decorate}] (2A3) to (1A2);
%
  \node[right=2 of 2A, blue] (1B) {$\bullet$} 
  	child  {coordinate (1B1) \idchild};
  \node[right=1.5 of 1B, blue] (2B) {$\bullet$} 
  	child {node [blue] {$\bullet$} 
    child  {coordinate (2B1) \idchild}
		\idchild
	};
	\draw[|->, shorten <= 3pt, shorten >= 3pt] (1B) -- (2B);
	\draw[densely dotted, postaction={decorate}] (2B1) to (1B1);
\end{tikzpicture}
\]
And that's all we need to specify the triple $(\ema{w},\epsilon,\delta)$.

Here are $\epsilon\colon\ema{w}\to\yon$ and $\delta\colon\ema{w}\to\ema{w}\tri\ema{w}$ again, in terms of polyboxes.
\[
\begin{tikzpicture}
	\node (p1) {
	    \begin{tikzpicture}[polybox, mapstos]
            \node[poly, dom, "$\ema{w}$" left] (S) {$i_A$\at$A$};

            \draw (S_pos) to[climb'] node[right] {$\epsilon$} (S_dir);
        \end{tikzpicture}  
	};
    \node[right=1 of p1] (p2) {
        \begin{tikzpicture}[polybox, mapstos]
            \node[poly, dom, "$\ema{w}$" left] (S) {$i_B$\at$B$};

            \draw (S_pos) to[climb'] node[right] {$\epsilon$} (S_dir);
        \end{tikzpicture}  
	};
\end{tikzpicture}
\]
\[
\begin{tikzpicture}
	\node (p1) {
	  \begin{tikzpicture}[polybox, mapstos]
  	\node[poly, dom, "$\ema{w}$" left] (p) {$i_A$\at$A$};
  	\node[poly, cod, right=of p.south, yshift=-1ex, "$\ema{w}$" below] (q) {$i_A$\at$A$};
  	\node[poly, cod, above=of q, "$\ema{w}$" above] (r) {$i_A$\at$A$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb, "$\delta$" left] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}  
	};
	\node[right=.4 of p1] (p2) {
	  \begin{tikzpicture}[polybox, mapstos]
  	\node[poly, dom, "$\ema{w}$" left] (p) {$f$\at$A$};
  	\node[poly, cod, right= of p.south, yshift=-1ex, "$\ema{w}$" below] (q) {$i_A$\at$A$};
  	\node[poly, cod, above=of q, "$\ema{w}$" above] (r) {$f$\at$A$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb, "$\delta$" left] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}  
	};
	\node[right=.4 of p2] (p3) {
	  \begin{tikzpicture}[polybox, mapstos]
  	\node[poly, dom, "$\ema{w}$" left] (p) {$f$\at$A$};
  	\node[poly, cod, right= of p.south, yshift=-1ex, "$\ema{w}$" below] (q) {$f$\at$A$};
  	\node[poly, cod, above=of q, "$\ema{w}$" above] (r) {$i_B$\at$B$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb, "$\delta$" left] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}  
	};
	\node[right=.4 of p3] (p4) {
	  \begin{tikzpicture}[polybox, mapstos]
  	\node[poly, dom, "$\ema{w}$" left] (p) {$i_B$\at$B$};
  	\node[poly, cod, right= of p.south, yshift=-1ex, "$\ema{w}$" below] (q) {$i_B$\at$B$};
  	\node[poly, cod, above=of q, "$\ema{w}$" above] (r) {$i_B$\at$B$};
  	\draw (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb, "$\delta$" left] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}  
	};
\end{tikzpicture}
\]

Of course, we have yet to check that $(\ema{w},\epsilon,\delta)$ really is a comonoid, i.e.\ that the diagrams in \eqref{eqn.erasure_law} and \eqref{eqn.coassoc_law} commute.
We leave that for \cref{exc.walking_arrow_com}.
\end{example}

\begin{exercise} \label{exc.walking_arrow_com}
Verify that $(\ema{w},\epsilon,\delta)$ as defined in \cref{ex.walking_arrow_com} obeys the erasure laws in \eqref{eqn.erasure_law} and the coassociative law in \eqref{eqn.coassoc_law}.
\begin{solution}
** % probably do it with polyboxes

% We will check unitality only for $A$; it is easier for $B$.
% \[
% \begin{tikzpicture}[trees, sibling distance=5mm,	bend right=60]
% 	\node (1A) [red] {$\bullet$} 
%   	child  {coordinate (1A1) \idchild}
%     child {coordinate (1A2)};
%   \node (2A) [right=1.5 of 1A, red] {$\bullet$} 
%       child  {
%         node [red] {$\bullet$} 
%  		    child  {coordinate (2A1) \idchild}
%       	child {coordinate (2A2)}
% 			\idchild
% 			}
%       child {node [blue] {$\bullet$} 
%       	child  {coordinate (2A3) \idchild}
% 			};
% 	\draw[|->, shorten <= 3pt, shorten >= 3pt] (1A) -- (2A);
% 	\draw[densely dotted, postaction={decorate}] (2A1) to (1A1);
% 	\draw[densely dotted, postaction={decorate}] (2A2) to (1A2);
% 	\draw[densely dotted, postaction={decorate}] (2A3) to (1A2);
% 	\node (3A) [right=1.5 of 2A, red] {$\bullet$}
% 		child {
% 			node {$\bullet$}
% 			child {coordinate (3A1)}
% 		\idchild
% 		}
% 		child {
% 			node {$\bullet$}
% 			child {coordinate (3A2)}
% 		};
% 	\draw[|->, shorten <= 3pt, shorten >= 3pt] (2A) -- (3A);
% 	\draw[densely dotted, postaction={decorate}] (3A1) to (2A1);
% 	\draw[densely dotted, postaction={decorate}] (3A2) to (2A3);
% \end{tikzpicture}
% \hspace{1in}
% \begin{tikzpicture}[trees, sibling distance=5mm,	bend right=60]
% 	\node (1A) [red] {$\bullet$} 
%   	child  {coordinate (1A1) \idchild}
%     child {coordinate (1A2)};
%   \node (2A) [right=1.5 of 1A, red] {$\bullet$} 
%       child  {
%         node [red] {$\bullet$} 
%  		    child  {coordinate (2A1) \idchild}
%       	child {coordinate (2A2)}
% 			\idchild
% 			}
%       child {node [blue] {$\bullet$} 
%       	child  {coordinate (2A3) \idchild}
% 			};
% 	\draw[|->, shorten <= 3pt, shorten >= 3pt] (1A) -- (2A);
% 	\draw[densely dotted, postaction={decorate}] (2A1) to (1A1);
% 	\draw[densely dotted, postaction={decorate}] (2A2) to (1A2);
% 	\draw[densely dotted, postaction={decorate}] (2A3) to (1A2);
% 	\node (3A) [right=1.5 of 2A] {$\bullet$}
% 		child {
%         node [red] {$\bullet$} 
%  		    child  {coordinate (3A1) \idchild}
%       	child {coordinate (3A2)}
% 		};
% 	\draw[|->, shorten <= 3pt, shorten >= 3pt] (2A) -- (3A);
% 	\draw[densely dotted, postaction={decorate}] (3A1) to (2A1);
% 	\draw[densely dotted, postaction={decorate}] (3A2) to (2A2);
% \end{tikzpicture}
% \]
% In both pictures, one can see that the composite map is the identity. We would do associativity here, but because the category $\cat{W}$ is so simple, associativity is guaranteed; this makes the pictures too trivial.
\end{solution}
\end{exercise}

\begin{exercise}\label{exc.linear_poly_comon}
Show that if $A$ is a set, then there exists a unique comonoid structure on the linear polynomial $A\yon$.
\begin{solution}
Given a set $A$, we wish to give a comonoid structure on $A\yon$ and show that it is unique.
There is only one way to define an eraser lens $\epsilon\colon A\yon\to\yon$: the on-position function is the unique map $!\colon A\to\1$, while every on-directions function $\1\to\1$ must be the identity.
Meanwhile $A\yon\tri A\yon\iso A^\2\yon$, so to specify a duplicator lens $\delta\colon A\yon\to A^\2\yon$, it suffices to specify an on-positions function $\delta_\1\colon A\to A^\2$, and every on-directions function will again be the identity.

All the comonoid laws should then hold trivially on directions, so it suffices to consider each law on positions.
The erasure laws imply that the composite functions
\[
    A\To{\delta_\1}A\times A\To{A\:\times\:!}A\times\1\iso A,
\]
where the second map is just the canonical left projection, and
\[
    A\To{\delta_\1}A\times A\To{!\:\times\:A}\1\times A\iso A,
\]
where the second nap is just the canonical right projection, are both the identity on $A$.
The only function $\delta_\1\colon A\to A\times A$ that satisfies this condition is the diagonal $a\mapsto(a,a)$.
It is easy to verify that the diagonal is coassociative, so this does define a unique comonoid structure on $A\yon$.
(It turns out that this is equivalent to the well-known result that there is a unique comonoid structure on every set in $(\smset,\1,\times)$.)
\end{solution}
\end{exercise}

Once you know that state systems are comonoids in $\poly$, but not the only ones, the natural question to ask is ``what are all the other comonoids in $\poly$?''
Or perhaps, as we led you through this case study of $\ema{s}$, you have already suspected the truth (or simply remembered what we told you back in \cref{prop.ahman_uustalu1}): a polynomial comonoid---what with its directions leading from one position to another, directions that can be run together associatively among which there are directions at every position that do nothing---is just another name for a category.

%-------- Section --------%
\section{Polynomial comonoids are categories}

What Ahman and Uustalu showed was that polynomial comonoids can be identified with categories.
Every category in the usual sense is a comonoid in $\poly$, and every comonoid in $\poly$ is a category. 
We find their revelation to be truly shocking, and it suggests some very different ways to think about categories.
But let's go over their result first.

\begin{theorem}[Ahman-Uustalu]\label{thm.ahman_uustalu}
There is a one-to-one isomorphism-preserving correspondence between polynomial comonoids and (small) categories.
\end{theorem}

Our goal is to spell out this correspondence so that we can justly proclaim:

\slogan{Comonoids in $\poly$ are precisely categories!}

\subsection{Translating between polynomial comonoids and categories}

First, we describe how to translate between the carrier $\ema{c}$ of a comonoid $\com{C}\coloneqq(\ema{c},\delta,\epsilon)$ and the objects and morphisms of the corresponding category $\cat{C}$.
The idea is pretty simple, and you may have already guessed it: positions are objects and directions are morphisms.

\subsubsection{Positions as objects, directions as morphisms}

More precisely, the positions of $\ema{c}$ are the objects of $\cat{C}$:
\begin{equation} \label{eqn.pos_obj}
    \ema{c}(\1)=\Ob\cat{C}.
\end{equation}
Then for each such position or object $i$, the $\ema{c}[i]$-directions are the morphisms of $\cat{C}$ with domain $i$:
\begin{equation} \label{eqn.dir_mor}
    \ema{c}[i]=\sum_{j\in\Ob\cat{C}}\cat{C}(i,j).
\end{equation}
The right hand side above is a little clumsier than the left; this is because while we are used to thinking of hom-sets of categories such as $\cat{C}(i,j)$, consisting of all morphisms in $\cat{C}$ with a fixed domain and codomain, we aren't used to thinking about the collection of all morphisms in $\cat{C}$ with a fixed domain and an arbitrary codomain quite as often.%
\footnote{Except, perhaps, in the context of coslice categories.}
On the other hand, the carrier \emph{only} encodes which morphisms have each object as its domain, i.e.\ which directions are at each position.
Codomains will be encoded in the data of the comonoid elsewhere.

This is the key difference in perspective between the polynomial comonoid perspective of categories, in contrast to our usual hom-set perspective: the polynomial perspective is in a sense domain-centric, as highlighted by the following definition.

\begin{definition}[Polynomial carrier]
Let $\cat{C}$ be a category.
For every object $i$ in $\cat{C}$, denote the morphisms in $\cat{C}$ with domain $i$ by $\cat{C}[i]$, so that\footnote{We may also write $f\colon i\to\_$ to denote an arbitrary morphism $f\in\cat{C}[i]$, i.e.\ a morphism $f$ in $\cat{C}$ with domain $i$ and an unspecified codomain.}
\[
    \cat{C}[i]\coloneqq\sum_{j\in\Ob\cat{C}}\cat{C}(i,j).
\]
Then the \emph{polynomial carrier}, or simply \emph{carrier}, of $\cat{C}$ is the polynomial
\[
    \sum_{i\in\Ob\cat{C}}\yon^{\cat{C}[i]}.
\]
\end{definition}

So everything we have said so far about the correspondence from \cref{thm.ahman_uustalu} can be summarized by saying that it preserves carriers: the carrier of the category $\cat{C}$ is the carrier $\ema{c}$ of the comonoid $\com{C}$, so that $\Ob\cat{C}=\ema{c}(\1)$ and $\cat{C}[i]=\ema{c}[i]$.

\begin{remark}
If we take the perspective that categories are equal if and only if their objects and morphisms are equal and obey the same laws, and similarly that polynomials are equal if and only if their position-sets and direction-sets are equal sets, then \eqref{eqn.pos_obj} and \eqref{eqn.dir_mor} really can be just strict equalities.
This is why we are comfortable naming a ``one-to-one correspondence'' in \cref{thm.ahman_uustalu} rather than just, say, some form of equivalence.
Since the positions and directions of our polynomials always form \emph{sets}, however, the categories we obtain under this correspondence are also necessarily \emph{small}: their objects form a set, as do all of their morphisms.
But we won't worry too much about size issues beyond this.
\end{remark}

\begin{exercise} \label{exc.ema_polys}
What is the carrier of each of the following categories (up to isomorphism)?
\begin{enumerate}
	\item The category
	\begin{center}
	    \boxCD{exercisecolor}{$A\Too{f}B$}
	\end{center}
	where we have drawn every morphism except for the identity morphisms.
	\item The category
	\begin{center}
	    \boxCD{exercisecolor}{$B\To{g}A\From{h}C$}
	\end{center}
	where we have drawn every morphism except for the identity morphisms.
	\item The empty category.
	\item \label{exc.ema_polys.nat_monoid} A category with exactly $1$ object and a morphism $i$, for which every morphism can be written uniquely as the $n$-fold composite of $i$ for some $n\in\nn$.
	\item \label{exc.ema_polys.nat_poset} The category
	\begin{center}
	    \boxCD{exercisecolor}{$0\to1\to2\to3\to\cdots$}
	\end{center}
	where there is a unique morphism $m\to n$ if $m\leq n$ (and no other morphisms).
	\item The category
	\begin{center}
	    \boxCD{exercisecolor}{$0\from1\from2\from3\from\cdots$}
	\end{center}
	where there is a unique morphism $m\from n$ if $m\leq n$ (and no other morphisms).\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
	\item The category \boxCD{white}{$A\Too{f}B$} has $2$ morphisms out of $A$, namely $\id_A$ and $f$; and $1$ morphism out of $B$, namely $\id_B$.
	So its carrier is $\{A\}\yon^{\{\id_A,f\}}+\{B\}\yon^{\{\id_B\}}\iso\yon^\2+\yon$.
	\item The category \boxCD{white}{$B\To{g}A\From{h}C$} has $1$ morphism out of $A$, namely $\id_A$; $2$ morphisms out of $B$, namely $\id_B$ and $g$; and $2$ morphisms out of $C$, namely $\id_C$ and $h$.
	So its carrier is $\{A\}\yon^{\{\id_A\}}+\{B\}\yon^{\{\id_B,g\}}+\{C\}\yon^{\{\id_C,h\}}\iso\2\yon^\2+\yon$.
	\item The empty category has no objects or morphisms, so its carrier is just $\0$.
	\item The category in question has $1$ object, and its set of morphisms is in bijection with $\nn$, so its carrier is isomorphic to $\yon^\nn$.
	(This category is the monoid $(\nn,0,+)$ viewed as a $1$-object category; see \cref{ex.monoids} for the general case.)
	\item The category in question has $\nn$ as its set of objects, and for each $m\in\nn$, the morphisms out of $m$ are determined by their codomains: there is exactly $1$ morphism $m\to n$ for every $n\in\nn$ satisfying $m\leq n$, and no other morphisms out of $m$.
	So the carrier of the category is isomorphic to
	\[
	    \sum_{m\in\nn}\yon^{\{n\in\nn\mid m\leq n\}}\iso\nn\yon^\nn,
	\]
	as $\{n\in\nn\mid m\leq n\}\iso\nn$ under the bijection $n\mapsto n-m$.
	(This category is the poset $(\nn,\leq)$; see \cref{**} for the general case.)
	\item The category in question has $\nn$ as its set of objects, and for each $n\in\nn$, the morphisms out of $n$ are again determined by their codomains: there is exactly $1$ morphism $n\to m$ for every $m\in\nn$ satisfying $m\leq n$, and no other morphisms out of $n$.
	So the carrier of the category is isomorphic to
	\[
	    \sum_{n\in\nn}\yon^{\{m\in\nn\mid m\leq n\}}\iso\sum_{n\in\nn}\yon^{\ord{n+1}}\iso\yon^\1+\yon^\2+\yon^\3+\cdots.
	\]
    (This category is the poset $(\nn,\geq)$; again, see \cref{**} for the general case.)
\end{enumerate}
\end{solution}
\end{exercise}

But a category $\cat{C}$ is more than its carrier polynomial, just as a comonoid $\com{C}$ is more than its carrier $\ema{c}$.
In particular, we have said nothing about the codomains of morphisms in $\cat{C}$, nor anything about identity morphisms, composition, or how the laws of a category are satisfied.
Similarly, we have said nothing about the eraser $\epsilon$ or the duplicator $\delta$ of $\com{C}$, nor anything about how the comonoid laws are satisfied.
It turns out that all of these constituents and laws correspond to one another, as summarized by the following table.
Here each item in the comonoid column---either a polynomial, a lens, or a lens equation---spans two rows, with the top row corresponding to positions and the bottom row corresponding to directions.
\begin{center}
\begin{tabular}{cc|cc}
  \textbf{Comonoid} & $\com{C}=(\ema{c},\epsilon,\delta)$ & \textbf{Category} & $\cat{C}$ \\ 
  \hline
  \multirow{2}{*}{carrier} & $i\in\ema{c}(\1)$ & objects & $i\in\Ob\cat{C}$ \\
  & $f\in\cat{c}[i]$ & morphisms & $f\colon i\to\_$ \\
  \hline
  \multirow{2}{*}{eraser} & $\epsilon_\1\colon\ema{c}(\1)\to\1$ & --- & --- \\
  & $\epsilon_i^\sharp\colon\1\to\ema{c}[i]$ & identities & $\id_i\colon i\to\_$ \\
  \hline
  \multirow{2}{*}{duplicator} & $\delta_\1\colon\ema{c}(\1)\to(\ema{c}\tri\ema{c})(\1)$ & codomains* & $\cod\colon\cat{C}[i]\to\Ob\cat{C}$ \\
  & 
  $\delta_i^\sharp\colon(\ema{c}\tri\ema{c})[\delta_\1(i)]\to\ema{c}[i]$ & composition* & $\then$ \\ %$\displaystyle\comp\colon\sum_{f\in\cat{C}[i]}\cat{C}[\cod(f)]\to\cat{C}[i]$
  \hline
  \multicolumn2{c|}{\multirow{2}{*}{right erasure law}} & \multicolumn2{c}{$\ast$} \\
  \multicolumn2{c|}{} & \multicolumn2{c}{right identity law} \\
  \hline
  \multicolumn2{c|}{\multirow{2}{*}{left erasure law}} & codomains of identities & $\cod\id_i=i$ \\
  \multicolumn2{c|}{} & \multicolumn2{c}{left identity law} \\
  \hline
  \multicolumn2{c|}{\multirow{2}{*}{coassociative law}} & codomains of composites & $\cod(f\then g)=\cod g$ \\
  \multicolumn2{c|}{} & \multicolumn2{c}{associative law of composition}
\end{tabular}
\end{center}
Note that the on-positions function of $\epsilon$, being a function into the terminal set, encodes no actual data.
The asterisk $\ast$ indicates that the right erasure law on positions works together with the duplicator to ensure that codomains and composites are properly specified.

We have already covered the correspondence between the first two rows, so let us consider each of the following rows in turn.
In some sense, we have already seen each piece of this correspondence in action for state systems in \cref{sec.comon.sharp.state}, so we'll go through it a little faster this time for the general case.

\subsubsection{The eraser assigns identities}

We know that the eraser $\epsilon\colon\ema{c}\to\yon$ can be identified with a dependent function $(i\in\ema{c}(\1))\to\com{c}[i]$, sending each position $i\in\com{c}(\1)$ to a $\com{c}[i]$-direction.
In terms of our category $\cat{C}$, the eraser sends each object $i\in\Ob\cat{C}$ to a morphism $i\to\_$.
But this is exactly what we need to specify identity morphisms---a morphism out of each object.
So the eraser of $\ema{c}$ specifies the identity morphisms of the corresponding category $\cat{C}$.
We can interpret the polybox picture for $\epsilon$ like so:
\[
 \begin{tikzpicture}[polybox, mapstos]
  	\node[poly, dom, "$\ema{c}$" left] (c) {$\id_i$\at$i$};
  	\draw (c_pos) to[climb'] node[right] {$\idy$} (c_dir);
	\end{tikzpicture}
\]
Here we have given the label $\idy$ to the arrow sending objects to their identity morphisms.

Keep in mind that from the domain-centric polynomial perspective, we have not yet specified that the codomain of an identity morphism is equal to its domain; that comes later.

\subsubsection{The right erasure law on positions: a bit of bookkeeping}

Keeping our label $\idy$ for the arrow in $\epsilon$, the right erasure law $\delta\then(\ema{c}\tri\epsilon)=\id_\ema{c}$ from \eqref{eqn.erasure_law} can be drawn in polyboxes like so:
\[
\begin{tikzpicture}
	\node (1) {
        \begin{tikzpicture}[polybox, mapstos]
        	\node[poly, dom, "$\ema{c}$" left] (r) {\at$i$};
        	\node[poly, cod, right=2 of r.south, yshift=-2.5ex, "$\ema{c}$" below] (p) {\at$i$};
        	\node[poly, above=.8 of p, "$\ema{c}$" above] (p') {};
        	
        	\draw (r_pos) to[first] node[below] {} (p_pos);
        	\draw (p_dir) to[climb] node[left=.1] {$\delta$} (p'_pos);
        	\draw (p'_pos) to[climb'] node[right] {$\idy$} (p'_dir);
        	\draw (p'_dir) to[last] node[above=.4] {} (r_dir);
        \end{tikzpicture}
	};
	\node[right=1.8 of 1] (2) {
        \begin{tikzpicture}[polybox, mapstos]
          	\node[poly, dom, "$\ema{c}$" left] (c) {\at$i$};
          	\node[poly, cod, right=of c, "$\ema{c}$" right] (c') {\at$i$};
          	\draw[double] (c_pos) -- (c'_pos);
          	\draw[double] (c'_dir) -- (c_dir);
	    \end{tikzpicture}
	};
	\node at ($(1.east)!.5!(2.west)$) (3) {=};
\end{tikzpicture}
\]
We have only filled in a few of the boxes, but that is enough to interpret what the right erasure law tells us on positions: that the bottom arrow of the duplicator must be the identity function on $\ema{c}(\1)$.
Equipped with this knowledge, we can focus our attention on the other two arrows of $\delta$.

\subsubsection{The duplicator assigns codomains and composites}

In fact, in the polybox picture for $\delta\colon\ema{c}\to\ema{c}\tri\ema{c}$, the middle arrow specifies codomains, and the top arrow specifies composition.
We therefore label these arrows as follows:\footnote{Compare these labels to the names ``target'' and ``run'' that we gave to the arrows of a state system's transition lens.}
\[
\begin{tikzpicture}[polybox, tos]
    \node[poly, dom, "$\ema{c}$" left] (yX) {};
    \node[poly, cod, right=1.8 of yX.south, yshift=-2.5ex, "$\ema{c}$" right] (p) {};
    \node[poly, cod, above=.8 of p, "$\ema{c}$" right] (p') {};
    
    \draw[double] (yX_pos) to[first] node[below] {} (p_pos);
    \draw (p_dir) to[climb] node[right] {$\cod$} (p'_pos);
    \draw (p'_dir) to[last] node[above] {$\then$} (yX_dir);
\end{tikzpicture}
\]
To check that this makes sense, we fill in the boxes:
\[
\begin{tikzpicture}[polybox, mapstos]
    \node[poly, dom, "$\ema{c}$" left] (yX) {$f\then g$\at$i$};
    \node[poly, cod, right=2 of yX.south, yshift=-2.5ex, "$\ema{c}$" right] (p) {$f$\at$i$};
    \node[poly, cod, above=.8 of p, "$\ema{c}$" right] (p') {$g$\at$\cod f$};
    
    \draw[double] (yX_pos) to[first] node[below] {} (p_pos);
    \draw (p_dir) to[climb] node[right] {$\cod$} (p'_pos);
    \draw (p'_dir) to[last] node[above] {$\then$} (yX_dir);
\end{tikzpicture}
\]
Remember: each position box contains an object of $\cat{C}$, while each direction box contains a morphism of $\cat{C}$ emanating from the object below.
So $\delta$ takes an object $i\in\Ob\cat{C}$ and a morphism $f\colon i\to\_$ in $\cat{C}$ and assigns another object $\cod f\in\Ob\cat{C}$ to be the codomain of $f$.
It then takes another morphism $g\colon\cod f\to\_$ in $\cat{C}$ and assigns a morphism $f\then g\colon i\to\_$ to be the composite of $f$ and $g$.
In this way, every morphism gets a codomain, and every pair of morphisms that can be composed (i.e.\ the codomain of one matches the domain of the other) is assigned a composite.
As with the identity morphism, we don't know what the codomain of this composite morphism is yet; but we do know that the domain of $f\then g$ matches the domain of $f$, as it should.

\subsubsection{The left erasure law on positions: codomains of identities}

As with the right erasure law, we can partially fill in the polyboxes for the left erasure law $\delta\then(\epsilon\tri\ema{c})=\id_\ema{c}$ from \eqref{eqn.erasure_law} to read what it says on positions:
\[
\begin{tikzpicture}
	\node (1) {
        \begin{tikzpicture}[polybox, mapstos]
        	\node[poly, dom, "$\ema{c}$" left] (r) {\at$i$};
        	\node[poly, right=2 of r.south, yshift=-2.5ex, "$\ema{c}$" below] (p) {$\id_i$\at$i$};
        	\node[poly, cod, above=.8 of p, "$\ema{c}$" above] (p') {\at$\cod\id_i$};
        	
        	\draw[double] (r_pos) to[first] node[below] {} (p_pos);
        	\draw (p_pos) to[climb'] node[right] {$\idy$} (p_dir);
        	\draw (p_dir) to[climb] node[right] {$\cod$} (p'_pos);
        	\draw (p'_dir) to[last] node[above] {$\then$} (r_dir);
        \end{tikzpicture}
	};
	\node[right=1.8 of 1] (2) {
        \begin{tikzpicture}[polybox, mapstos]
          	\node[poly, dom, "$\ema{c}$" left] (c) {\at$i$};
          	\node[poly, cod, right=of c, "$\ema{c}$" right] (c') {\at$i$};
          	\draw[double] (c_pos) -- (c'_pos);
          	\draw[double] (c'_dir) -- (c_dir);
	    \end{tikzpicture}
	};
	\node at ($(1.east)!.5!(2.west)$) (3) {=};
\end{tikzpicture}
\]
So the left erasure law on positions guarantees that $\cod\id_i=i$ for all $i\in\Ob\cat{C}$.
It makes sense that we would find this here: the eraser assigns identities, while the duplicator assigns codomains, so a statement about codomains of identities is a coherence condition between the eraser and the duplicator.

\subsubsection{The erasure laws on directions are the identity laws}

Let us finish filling in the polyboxes for the left and right erasure laws to see what they have to say on directions.
In the picture below, the left equality depicts the left erasure law (to conserve space, we'll substitute $i$ for $\cod\id_i$ on the left, which we now know we can do), while the right equality depicts the right erasure law:
\[
\begin{tikzpicture}
	\node (1) {
        \begin{tikzpicture}[polybox, mapstos]
        	\node[poly, dom, "$\ema{c}$" left] (r) {$\id_i\then f$\at$i$};
        	\node[poly, right=2 of r.south, yshift=-2.5ex, "$\ema{c}$" below] (p) {$\id_i$\at$i$};
        	\node[poly, cod, above=.8 of p, "$\ema{c}$" above] (p') {$f$\at$i$};
        	
        	\draw[double] (r_pos) to[first] node[below] {} (p_pos);
        	\draw (p_pos) to[climb'] node[right] {$\idy$} (p_dir);
        	\draw (p_dir) to[climb] node[right] {$\cod$} (p'_pos);
        	\draw (p'_dir) to[last] node[above] {$\then$} (r_dir);
        \end{tikzpicture}
	};
	\node[right=.1 of 1] (2) {
        \begin{tikzpicture}[polybox, mapstos]
          	\node[poly, dom, "$\ema{c}$" left] (c) {$f$\at$i$};
          	\node[poly, cod, right=of c, "$\ema{c}$" right] (c') {$f$\at$i$};
          	\draw[double] (c_pos) -- (c'_pos);
          	\draw[double] (c'_dir) -- (c_dir);
	    \end{tikzpicture}
	};
	\node[right=.25 of 2] (3) {
        \begin{tikzpicture}[polybox, mapstos]
        	\node[poly, dom, "$\ema{c}$" left] (r) {$f\then\id_{\cod f}$\at$i$};
        	\node[poly, cod, right=2.1 of r.south, yshift=-2.5ex, "$\ema{c}$" below] (p) {$f$\at$i$};
        	\node[poly, above=.8 of p, xshift=1.5ex, "$\ema{c}$" above] (p') {$\id_{\cod f}$\at$\cod f$};
        	
        	\draw (r_pos) to[first] node[below] {} (p_pos);
        	\draw (p_dir) to[climb] node[right] {$\cod$} (p'_pos);
        	\draw (p'_pos) to[climb'] node[right] {$\idy$} (p'_dir);
        	\draw (p'_dir) to[last] node[above] {$\then$} (r_dir);
        \end{tikzpicture}
	};
    \node at ($(1.east)!.2!(2.west)$) {=};
    \node at ($(2.east)!.5!(3.west)$) {=};
\end{tikzpicture}
\]
We find that on directions, the erasure laws state that for every object $i\in\Ob\cat{C}$ and morphism $f\colon i\to\_$ in $\cat{C}$,
\[
    \id_i\then f=f=f\then\id_{\cod f}.
\]
But these are precisely the identity laws of the category $\cat{C}$.

\subsubsection{The coassociative law on positions: codomains of composites}

It remains to consider the comonoid's coassociative law \eqref{eqn.coassoc_law}, $\delta\then(\delta\tri\ema{s})=\delta\then(\ema{s}\tri\delta)$.
To read what it says on positions, we draw the polyboxes and fill them in, stopping just short of the uppermost direction box of the codomain:
\[
\begin{tikzpicture}
    \node (p1) {
        \begin{tikzpicture}[polybox, tos]
            \node[poly, dom, "$\ema{s}$" left] (m') {\at$i$};
            \node[poly, right=1.8 of m'.south, yshift=-1ex, "$\ema{s}$" below] (mm') {$f\then g$\at$i$};
            \node[poly, above=of mm', "$\ema{s}$" above] (C') {\at$\cod(f\then g)$};
            \node[poly, cod, right=2.3 of mm'.south, yshift=-1ex, "$\ema{s}$" right] (D') {$f$\at$i$};
            \node[poly, cod, above=of D', "$\ema{s}$" right] (mmm') {$g$\at$\cod f$};
            \node[poly, cod, above=of mmm', "$\ema{s}$" right] (CC') {\at$\cod(f\then g)$};
            %
            \draw[double] (m'_pos) to[first] (mm'_pos);
            \draw (mm'_dir) to[climb] node[right] {$\cod$} (C'_pos);
            \draw (C'_dir) to[last] node[above] {$\then$} (m'_dir);
            \draw[double] (mm'_pos) to[first] (D'_pos);
            \draw (D'_dir) to[climb] node[right] {$\cod$} (mmm'_pos);
            \draw (mmm'_dir) to[last] node[above] {$\then$} (mm'_dir);
            \draw[double] (C'_pos) to[first] (CC'_pos);
            \draw[double] (CC'_dir) to[last] (C'_dir);
        \end{tikzpicture}
	};
%
	\node (p2) [right=of p1] {
	    \begin{tikzpicture}[polybox, tos]
            \node[poly, dom, "$\ema{s}$" left] (m) {\at$i$};
            \node[poly, right=1.8 of m.south, yshift=-1ex, "$\ema{s}$" below] (D) {$f$\at$i$};
            \node[poly, above=of D, "$\ema{s}$" above] (mm) {\at$\cod f$};
            \node[poly, cod, right=2.1 of D.south, yshift=-1ex, "$\ema{s}$" right] (DD) {$f$\at$i$};
            \node[poly, cod, above=of DD, "$\ema{s}$" right] (mmm) {$g$\at$\cod f$};
            \node[poly, cod, above=of mmm, "$\ema{s}$" right] (C) {\at$\cod g$};
            %
            \draw[double] (m_pos) to[first] (D_pos);
            \draw (D_dir) to[climb] node[right] {$\cod$} (mm_pos);
            \draw (mm_dir) to[last] node[above] {$\then$} (m_dir);
            \draw[double] (D_pos) to[first] (DD_pos);
            \draw[double] (DD_dir) to[last] (D_dir);
            \draw[double] (mm_pos) to[first] (mmm_pos);
            \draw (mmm_dir) to[climb] node[right] {$\cod$} (C_pos);
            \draw (C_dir) to[last] node[above] {$\then$} (mm_dir);
        \end{tikzpicture}
    };	
	\node at ($(p1.south)!.5!(p2.north)$) {$=$};
\end{tikzpicture}
\]
So on positions, the coassociative law states that given an object $i\in\Ob\cat C$ and morphisms $f\colon i\to\_$ and $g\colon\cod f\to\_$ in $\cat C$,
\[
    \cod(f\then g)=\cod g.
\]
Hence composites are assigned the proper codomains.

\subsubsection{The coassociative law on directions is the associative law of composition}

Finally, let us fill in the remaining polyboxes for the coassociative law (we'll substitute $\cod g$ for $\cod(f\then g)$ on the left, which we now know we can do):
\[
\begin{tikzpicture}
    \node (p1) {
        \begin{tikzpicture}[polybox, tos]
            \node[poly, dom, "$\ema{s}$" left] (m') {$(f\then g)\then h$\at$i$};
            \node[poly, right=1.8 of m'.south, yshift=-1ex, "$\ema{s}$" below] (mm') {$f\then g$\at$i$};
            \node[poly, above=of mm', "$\ema{s}$" above] (C') {$h$\at$\cod g$};
            \node[poly, cod, right=2 of mm'.south, yshift=-1ex, "$\ema{s}$" right] (D') {$f$\at$i$};
            \node[poly, cod, above=of D', "$\ema{s}$" right] (mmm') {$g$\at$\cod f$};
            \node[poly, cod, above=of mmm', "$\ema{s}$" right] (CC') {$h$\at$\cod g$};
            %
            \draw[double] (m'_pos) to[first] (mm'_pos);
            \draw (mm'_dir) to[climb] node[right] {$\cod$} (C'_pos);
            \draw (C'_dir) to[last] node[above] {$\then$} (m'_dir);
            \draw[double] (mm'_pos) to[first] (D'_pos);
            \draw (D'_dir) to[climb] node[right] {$\cod$} (mmm'_pos);
            \draw (mmm'_dir) to[last] node[above] {$\then$} (mm'_dir);
            \draw[double] (C'_pos) to[first] (CC'_pos);
            \draw[double] (CC'_dir) to[last] (C'_dir);
        \end{tikzpicture}
	};
%
	\node (p2) [right=.8 of p1] {
	    \begin{tikzpicture}[polybox, tos]
            \node[poly, dom, "$\ema{s}$" left] (m) {$f\then(g\then h)$\at$i$};
            \node[poly, right=2.2 of m.south, yshift=-1ex, "$\ema{s}$" below] (D) {$f$\at$i$};
            \node[poly, above=of D, "$\ema{s}$" above] (mm) {$g\then h$\at$\cod f$};
            \node[poly, cod, right=2 of D.south, yshift=-1ex, "$\ema{s}$" right] (DD) {$f$\at$i$};
            \node[poly, cod, above=of DD, "$\ema{s}$" right] (mmm) {$g$\at$\cod f$};
            \node[poly, cod, above=of mmm, "$\ema{s}$" right] (C) {$h$\at$\cod g$};
            %
            \draw[double] (m_pos) to[first] (D_pos);
            \draw (D_dir) to[climb] node[right] {$\cod$} (mm_pos);
            \draw (mm_dir) to[last] node[above] {$\then$} (m_dir);
            \draw[double] (D_pos) to[first] (DD_pos);
            \draw[double] (DD_dir) to[last] (D_dir);
            \draw[double] (mm_pos) to[first] (mmm_pos);
            \draw (mmm_dir) to[climb] node[right] {$\cod$} (C_pos);
            \draw (C_dir) to[last] node[above] {$\then$} (mm_dir);
        \end{tikzpicture}
    };	
	\node at ($(p1.south)!.5!(p2.north)$) {$=$};
\end{tikzpicture}
\]
Thus, on directions, the coassociative law states that given an object $i\in\Ob\cat C$ and morphisms $f\colon i\to\_, g\colon\cod f\to\_,$ and $h\colon\cod g\to\_$ in $\cat C$,
\[
    (f\then g)\then h = f\then(g\then h).
\]
But this is precisely the associative law of composition in a category.

We've seen that the data and equations of polynomial comonoids correspond exactly to the data and equations of categories.
This proves \cref{thm.ahman_uustalu}.

\subsubsection{Generalized duplicators as unbiased composition}

Before we move onto examples, one more note about the theory: notice that both sides of our coassociative law are given by $\delta^3\colon\ema{c}\to\ema{c}\tripow3$, as defined in \cref{prop.n_duplication}.
On directions, $\delta^3$ tells us how to compose three morphisms $i\To{f}\_\To{g}\_\To{h}\_$ in $\cat{C}$ all at once to obtain $i\To{f\:\then\:g\:\then\:h}\_$, and (co)associativity ensures this is well-defined.

In general, $\delta^n\colon\ema{c}\to\ema{c}\tripow{n}$ on directions tells us how to compose $n$ morphisms in $\cat{C}$ for each $n\in\nn$.
After all, we have already seen that $\delta^2=\delta$ performs binary composition, that $\delta^1=\id_\ema{c}$ performs ``unary'' composition (the ``unary composite'' of a single morphism $f$ is just $f$ itself), and that $\delta^0=\epsilon$ performs ``nullary'' composition (the ``nullary composite'' at any object is just its identity).
The directions of $\ema{c}\tripow{n}$ at positions in the image of $\delta^n$ are exactly the sequences of composable morphisms of length $n$, and $\delta^n$ sends each sequence to the single direction that is its composite.

% \begin{exercise}
% Let $\cat{C}$ be a category, $\ema{c}$ its carrier, and $i\in\Ob\cat{C}$ an object. This exercise is for people who know the definition of the coslice category $i/\cat{C}$ of objects under $i$. Is it true that there is an isomorphism
% \[\Ob(c/\cat{C})i\cong^?\ema{c}[i]\]
% If so, describe it; if not, give a counterexample.
% \begin{solution}
% **
% \end{solution}
% \end{exercise}

%---- Subsection ----%
\subsection{Examples of categories as comonoids}
Now that we know that polynomial comonoids are just categories, let's review some simple examples of categories and see how they may be interpreted as comonoids.
As we go through these examples, pay attention to how the polynomial perspective causes us to view these familiar categories somewhat differently than usual. %**Does it?

\subsubsection{Preorders}

A \emph{preorder} (or \emph{thin category}) is a category in which every morphism $f\colon c\to d$ is the \emph{only} morphism $c\to d$.%
\footnote{Sometimes these are also called \emph{posets}, short for \emph{partially ordered sets}, but strictly speaking the only isomorphisms in a poset are its identities, while a preorder allows objects to be isomorphic without being equal.}
Composition in preorders is easy to describe, because the composite of $c\to d$ and $d\to e$ is always just the unique arrow $c\to e$.
As such, preorders are some of the simplest examples of categories to consider---we already saw several in \cref{exc.ema_polys}---so let us interpret these as comonoids first.

\begin{example}\label{ex.walking_arrow_cat}
Let us revisit \cref{ex.walking_arrow_com}, where we first wrote down a comonoid that was not a state system.
We defined $\ema{w}\coloneqq\{A\}\yon^{\{\id_A,f\}}+\{B\}\yon^{\{\id_B\}}\iso\yon^\2+\yon$ and gave it a comonoid structure, with eraser $\epsilon\colon\ema{w}\to\yon$ specifying directions $\id_A$ and $\id_B$ and duplicator $\delta\colon\ema{w}\to\ema{w}\tri\ema{w}$ pointing the direction $f$ at $B$.

Looking at the picture we drew of the comonoid in \eqref{eqn.walking_arrow_bent_cor}, it should come as no surprise that the corresponding category $\cat{W}$ is the \emph{walking arrow category}, which is a preorder with two objects and one morphism between them:
\begin{center}
    $\cat{W}\coloneqq\:$\boxCD{examplecolor}{
    $A\Too{f}B$}
\end{center}
Here we omit the identity morphisms from our picture, but we know that they exist.

The category $\cat{W}$ has two objects, the $\ema{w}$-positions $A$ and $B$.
It has two morphisms with domain $A$, the $\ema{w}[A]$-directions $\id_A$ and $f$; and one morphism with domain $B$, the $\ema{w}[B]$-direction $\id_B$.
The morphisms $\id_A$ and $\id_B$ picked out by the erasure are the identity morphisms, and the duplicator assigns them codomains that are equal to their domains.
The duplicator also assigns $f$ the codomain $B$; and as $\cat{W}$ is then a preorder, composites are determined automatically.
\end{example}

\begin{exercise}
Let $(\ema{c},\epsilon,\delta)$ be the comonoid corresponding to the preorder depicted as follows (identity morphisms omitted):
\begin{center}
    \boxCD{exercisecolor}{$B\From{f}A\To{g}C$}
\end{center}
\begin{enumerate}
    \item What is the carrier $\ema{c}$?
    \item Characterize the eraser $\epsilon$.
    \item Characterize the duplicator $\delta$.\qedhere
\end{enumerate}
\begin{solution}
We are given a comonoid $(\ema{c},\epsilon,\delta)$ corresponding to the preorder \boxCD{white}{$B\From{f}A\To{g}C$}.
\begin{enumerate}
    \item There are three morphisms with domain $A$, namely $\id_A,f,$ and $g$; the only other morphisms are the identity morphisms on $B$ and $C$.
    So the carrier is $\ema{c}=\{A\}\yon^{\{\id_A,f,g\}}+\{B\}\yon^{\{\id_B\}}+\{C\}\yon^{\{\id_C\}}$.
    \item It suffices to specify the eraser $\epsilon\colon\ema{c}\to\yon$ on directions: as always, $\epsilon_i^\sharp\colon\1\to\ema{c}[i]$ picks out $\id_i$ for each $i\in\ema{c}(\1)=\{A,B,C\}$.
    \item The duplicator $\delta\colon\ema{c}\to\ema{c}\tri\ema{c}$ tells us the codomain of each morphism, as well as how every pair of composable morphisms compose (which in the case of a preorder can be deduced automatically).
    So we can completely characterize the behavior of $\delta$ using polyboxes as follows:
\[
\begin{tikzpicture}[polybox, mapstos, node distance=2ex and 1.4cm, font=\tiny]
  \node (a) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$\id_A$\at$A$};
  	\node[poly, cod, right=of p.south, yshift=-1ex] (q) {$\id_A$\at$A$};
  	\node[poly, cod, above=of q] (r) {$\id_A$\at$A$};
  	\draw[double] (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
  };
  \node[right=.6 of a] (b) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$f$\at$A$};
  	\node[poly, cod, right=of p.south, yshift=-1ex] (q) {$\id_A$\at$A$};
  	\node[poly, cod, above=of q] (r) {$f$\at$A$};
  	\draw[double] (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
  };
  \node[right=.6of b] (c) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$g$\at$A$};
  	\node[poly, cod, right=of p.south, yshift=-1ex] (q) {$\id_A$\at$A$};
  	\node[poly, cod, above=of q] (r) {$g$\at$A$};
  	\draw[double] (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
  };
  \node[right=.6 of c] (d) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$f$\at$A$};
  	\node[poly, cod, right=of p.south, yshift=-1ex] (q) {$f$\at$A$};
  	\node[poly, cod, above=of q] (r) {$\id_B$\at$B$};
  	\draw[double] (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
  };
  \node[below=.6 of a] (e) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$g$\at$A$};
  	\node[poly, cod, right=of p.south, yshift=-1ex] (q) {$g$\at$A$};
  	\node[poly, cod, above=of q] (r) {$\id_C$\at$C$};
  	\draw[double] (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
  };
  \node[below=.6 of b] (f) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$\id_B$\at$B$};
  	\node[poly, cod, right=of p.south, yshift=-1ex] (q) {$\id_B$\at$B$};
  	\node[poly, cod, above=of q] (r) {$\id_B$\at$B$};
  	\draw[double] (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
	};
  \node[below=.6 of c] (g) {
  \begin{tikzpicture}
  	\node[poly, dom] (p) {$\id_C$\at$C$};
  	\node[poly, cod, right=of p.south, yshift=-1ex] (q) {$\id_C$\at$C$};
  	\node[poly, cod, above=of q] (r) {$\id_C$\at$C$};
  	\draw[double] (p_pos) to[first] (q_pos);
  	\draw (q_dir) to[climb] (r_pos);
  	\draw (r_dir) to[last] (p_dir);
  \end{tikzpicture}
	};
\end{tikzpicture}
\]
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
We showed in \cref{exc.linear_poly_comon} that for any set $A$, the linear polynomial $A\yon$ has a unique comonoid structure.
To what category does this comonoid correspond?
\begin{solution}
The linear polynomial $A\yon$ corresponds to a category whose objects form the set $A$ and whose only morphisms are identities: in other words, it is the discrete category on $A$.
\end{solution}
\end{exercise}

\begin{exercise}\label{ex.star_shaped}
\begin{enumerate}
	\item Find a comonoid structure for the polynomial $p\coloneqq\yon^{\ord{n}+\1}+\ord{n}\yon$ whose corresponding category is a preorder.
	(It is enough to fully describe the category that it corresponds to.)
	\item Would you call your category ``star-shaped''?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item The polynomial $p\coloneqq\yon^{\ord{n}+\1}+\ord{n}\yon$ has $n+1$ positions: $1$ with $n+1$ directions and the rest with $1$ direction each.
    So any category carried by $p$ has $n+1$ objects, of which only $1$ has any nonidentity morphisms coming out of it: in fact, it has $n$ nonidentity morphisms coming out of it.
    But if the category is to be a preorder, each of these $n$ nonidentity morphisms must have a distinct codomain.
    As there are exactly $n$ other objects, this completely characterizes the category.
    Equivalently, it is the discrete category on $\ord{n}$ adjoined with a unique initial object, so that the only nonidentity morphisms are the morphisms out of that initial object to each of the other objects exactly once.
    \item This category can be thought of as ``star-shaped'' if we picture the initial object in the center with morphisms leading out to the other $n$ objects like spokes.
\end{enumerate}
\end{solution}
\end{exercise}

% ** Figure out what's up with all this stuff...
%
%\begin{exercise}\label{ex.fleece}
%\begin{enumerate}
%	\item Use \cref{ex.const_to_const} to show that for any polynomial comonoid $(c,\epsilon,\delta)$, the polynomial $c$ is divisible by $\yon$.
%	\item Show that there exists a polynomial $\fl{c}$ and a vertical morphism $\phi_c\colon c\to \fl{c}$ such that the induced map $(\phi_c,\epsilon)\colon c\to \fl{c}\yon$ is an isomorphism, i.e.\ $\phi_c$ is a product projection.
%	\item Show that $\phi_c$ is an epimorphism using \cref{prop.epis_in_poly}.
%\qedhere
%\end{enumerate}
%\end{exercise}
%
%\begin{definition}\label{def.fleece}
%Suppose $\com{C}=(c,\epsilon,\delta)$ is a comonoid, and let $\phi_c\colon c\to \fl{c}$ be as in \cref{ex.fleece}. We refer to the polynomial $\fl{c}$ as the \emph{fleece} of $c$ and $\phi_c$ as the \emph{fleecing map}.
%
%If there exists a map $\fl{\delta}\colon \fl{c}\to \fl{c}\tri \fl{c}$ making the diagram
%\[
%\begin{tikzcd}
%	c\ar[r, "\delta"]\ar[d, "\phi_c"']&
%	c\tri c\ar[d, "\phi_c\tri\phi_c"]\\
%	\fl{c}\ar[r, "\fl{\delta}"']&
%	\fl{c}\tri \fl{c}
%\end{tikzcd}
%\]
%commute,%
%\footnote{Note that such a morphism $\fl{\delta}$ must be unique since $\phi_c$ is an epimorphism.}
%we say that $(\fl{c},\fl{\delta})$ is the \emph{fleece comagma} of $\com{C}$.
%\end{definition}
%
%By using just the fleece, we can leave off identity arrows, making things just that much easier to draw. (We call it ``fleece'' because to some extent we're cheating the comonoid of its identities, and also because we're taking just its wool, leaving the identity behind.)
%
%\begin{example}[Associativity]\label{ex.associativity_pics}
%Consider the non-category drawn here:
%\[
%\boxCD{examplecolor}{
%\begin{tikzcd}[ampersand replacement=\&]
%	A\ar[r, "f"]\ar[rrr, bend left, "i"]\ar[rrr, bend right, "j"]\&
%	B\ar[r, "g"]\&
%	C\ar[r, "h"]\&
%	D
%\end{tikzcd}
%\leavevmode\\\bigskip
%$(f\then g)\then h=i\qqand f\then(g\then h)=j$
%}
%\]
%We can see represent this in a polynomial $p$ with a map $\delta\colon p\to p\tri p$, and see that it is not associative. To show this it suffices to consider the fleece comagma $\fl{\delta}\colon \fl{p}\to \fl{p}\tri \fl{p}$; see \cref{def.fleece}, so that $\fl{p}\cong \yon^\4+\yon^\2+\yon+\1$. Let's rename $\fl{p}$ to an isomorphic polynomial with more names around:
%\[
%\fl{p}\coloneqq\{A\}\yon^{\{f,f\then g, i, j\}}+\{B\}\yon^{\{g,g\then h\}}+C\yon^{\{h\}}+\{D\}.
%\]
%Every symbol used there, excluding $\yon$, +, $\{$, and $\}$, but including ``$f$'' and ``$f\then g$'', etc., is just a variable name. Below is a picture of $\fl{p}$, where we use arrow lengths to help us remember which arrow is which: $f$, $g$, and $h$ are small, $f\then g$ and $g\then h$ are longer, and $i$ and $j$ are longest:
%\[
%\begin{tikzpicture}[rounded corners]
%\node[draw, "$\fl{p}$" above] {
%\begin{tikzpicture}[trees, sibling distance=1cm]
%	\node["\tiny $A$" below, red] (A) {$\bullet$}
%  	child[level distance=4mm] {coordinate (1)}
%		child[level distance=8mm] {coordinate (2)}
%		child[level distance=12mm] {coordinate (3)}
%		child[level distance=12mm] {coordinate (4)};
%%
%	\node["\tiny $B$" below, blue, right=3 of A] (B) {$\bullet$}
%		child[level distance=4mm] {coordinate (B1)}
%		child[level distance=8mm] {coordinate (B2)};
%%
%	\node["\tiny $C$" below, dgreen, right=2 of B] (C) {$\bullet$}
%		child[level distance=4mm] {coordinate (C1)};
%%
%	\node["\tiny $D$" below, right=1 of C] (D) {$\bullet$};
%	\begin{scope}[font=\scriptsize]
%  	\node[below left=1mm of 1] {$f$};
%  	\node[below left=1mm of 2] {$f\then g$};
%  	\node[below right=1mm of 3] {$i$};
%  	\node[below right=1mm of 4] {$j$};
%  	\node[below left=1mm of B1] {$g$};
%  	\node[below right=1mm of B2] {$g\then h$};
%  	\node[below left=1mm of C1] {$h$};
%	\end{scope}
%\end{tikzpicture}
%};
%\end{tikzpicture}
%\]
%Here's a picture of our map $\fl{\delta}\colon \fl{p}\to \fl{p}\tri \fl{p}$.
%\begin{equation}\label{eqn.delta_misc33}
%\begin{tikzpicture}[trees, bend right=60,
%level 1/.style={sibling distance=5mm},
%level 2/.style={sibling distance=2.5mm}]
%	\node [red] (A1) {$\bullet$}
%		child[level distance =4mm] {coordinate (A11)}
%		child[level distance =8mm] {coordinate (A12)}
%		child[level distance =12mm] {coordinate (A13)}
%		child[level distance =12mm] {coordinate (A14)};
%	\node [right=2.5 of A1, red] (A2) {$\bullet$}
%		child[level distance =4mm] {node [blue]{$\bullet$}
%			child[level distance=4mm] {coordinate (A21)}
%			child[level distance=8mm] {coordinate (A22)}
%		}
%		child[level distance =8mm] {node [dgreen] {$\bullet$}
%			child[level distance=4mm] {coordinate (A23)}
%		}
%		child[level distance =12mm] {node {$\bullet$}}
%		child[level distance =12mm] {node {$\bullet$}};			
%	\draw[|->, shorten <= 3pt, shorten >= 3pt] (A1) -- (A2);
%	\draw[densely dotted, postaction={decorate}] (A21) to (A12);
%	\draw[densely dotted, postaction={decorate}] (A22) to (A14);
%	\draw[densely dotted, postaction={decorate}] (A23) to (A13);
%%
%	\node [blue, right=1.5 of A2] (B1) {$\bullet$}
%		child[level distance=4mm] {coordinate (B11)}
%		child[level distance=8mm] {coordinate (B12)};
%	\node [blue, right=1.5 of B1] (B2) {$\bullet$}
%		child[level distance=4mm] {node[dgreen] {$\bullet$}
%			child {coordinate (B21)}
%		}
%		child[level distance=8mm] {node {$\bullet$}};
%	\draw[|->, shorten <= 3pt, shorten >= 3pt] (B1) -- (B2);
%	\draw[densely dotted, postaction={decorate}] (B21) to (B12);
%%
%	\node [dgreen, right=1.5 of B2] (C1) {$\bullet$}
%		child[level distance=4mm] {coordinate (C11)};
%	\node[right=1 of C1, dgreen] (C2) {$\bullet$}
%		child[level distance=4mm] {node {$\bullet$}
%	};
%	\draw[|->, shorten <= 3pt, shorten >= 3pt] (C1) -- (C2);
%%
%	\node [right=1 of C2] (D1) {$\bullet$};
%	\node [right=1 of D1] (D2) {$\bullet$};
%	\draw[|->, shorten <= 3pt, shorten >= 3pt] (D1) -- (D2);	
%\end{tikzpicture}
%\end{equation}
%One should check in the red position that $(f\then g)\then h$ is going to $i$ and that $f\then (g\then h)$ is going to $j$. This should cause a failure in the associativity of $\delta$ and hence of $\fl{\delta}$.%
%\footnote{Note that if $\fl{\delta}$ is not associative, then $\delta$ cannot be associative either; see \cref{ex.fleece_assoc}.}
%
%Now we draw $\delta\then(\delta\tri \fl{p})$ and X$\delta\then(\fl{p}\tri\delta)$ and see that they disagree at the $A$ position. Here is $\delta\then(\delta\tri \fl{p})$ whose second map $\delta\tri \fl{p}$ does $\delta$ as in \eqref{eqn.delta_misc33} on the bottom layer and copies the top layer; to differentiate the intermediary $\delta$, which comes before the top layer, we use dashed lines:
%\[
%\begin{tikzpicture}[trees, bend right=60,
%level 1/.style={sibling distance=5mm},
%level 2/.style={sibling distance=2.5mm}]
%	\node [red] (A1) {$\bullet$}
%		child[level distance =4mm] {coordinate (A11)}
%		child[level distance =8mm] {coordinate (A12)}
%		child[level distance =12mm] {coordinate (A13)}
%		child[level distance =12mm] {coordinate (A14)};
%%
%	\node [right=2.5 of A1, red] (A2) {$\bullet$}
%		child[level distance =4mm] {node [blue]{$\bullet$}
%			child[level distance=4mm] {coordinate (A21)}
%			child[level distance=8mm] {coordinate (A22)}
%		}
%		child[level distance =8mm] {node [dgreen] (A23') {$\bullet$}
%			child[level distance=4mm] {coordinate (A23)}
%		}
%		child[level distance =12mm] {node (A24') {$\bullet$}}
%		child[level distance =12mm] {node (A25') {$\bullet$}};			
%%
%	\node [right=3.5 of A2, red] (A3) {$\bullet$}
%		child[level distance =4mm] {node [blue]{$\bullet$}
%			child[level distance=4mm] {node [dgreen] (A31') {$\bullet$}
%				child [level distance=4mm] {coordinate (A31)}}
%			child[level distance=8mm] {node (A32') {$\bullet$}}
%		}
%		child[level distance =8mm] {node [dgreen] {$\bullet$}
%			child[level distance=4mm] {node (A33') {$\bullet$}}
%		}
%		child[level distance =12mm] {node {$\bullet$}}
%		child[level distance =12mm] {node {$\bullet$}};			
%%
%	\draw[|->, shorten <= 3pt, shorten >= 3pt] (A1) -- (A2);
%	\draw[|->, shorten <= 3pt, shorten >= 3pt] (A2) -- (A3);
%	\draw[densely dotted, postaction={decorate}] (A21) to (A12);
%	\draw[densely dotted, postaction={decorate}] (A22) to (A14);
%	\draw[densely dotted, postaction={decorate}] (A23) to (A13);
%	\draw[densely dotted, bend right=20, dashed] (A31') to (A23');
%	\draw[densely dotted, bend right=20, dashed] (A32') to (A25');
%	\draw[densely dotted, bend right=20, dashed] (A33') to (A24');
%	\draw[densely dotted, postaction={decorate}] (A31) to (A23);
%\end{tikzpicture}
%\]
%We can see that the unique leaf of $\fl{p}\tri \fl{p}\tri \fl{p}$ is mapping to $i$. Now we draw $\delta\then(\fl{p}\tri\delta)$. Its second map $\fl{p}\tri\delta$ copies the bottom layer and does $\delta$ as in \eqref{eqn.delta_misc33} on the top layer; we have no need for dashed lines.
%\[
%\begin{tikzpicture}[trees, bend right=60,
%level 1/.style={sibling distance=5mm},
%level 2/.style={sibling distance=2.5mm}]
%	\node [red] (A1) {$\bullet$}
%		child[level distance =4mm] {coordinate (A11)}
%		child[level distance =8mm] {coordinate (A12)}
%		child[level distance =12mm] {coordinate (A13)}
%		child[level distance =12mm] {coordinate (A14)};
%%
%	\node [right=2.5 of A1, red] (A2) {$\bullet$}
%		child[level distance =4mm] {node [blue]{$\bullet$}
%			child[level distance=4mm] {coordinate (A21)}
%			child[level distance=8mm] {coordinate (A22)}
%		}
%		child[level distance =8mm] {node [dgreen]  {$\bullet$}
%			child[level distance=4mm] {coordinate (A23)}
%		}
%		child[level distance =12mm] {node {$\bullet$}}
%		child[level distance =12mm] {node {$\bullet$}};			
%%
%	\node [right=3.5 of A2, red] (A3) {$\bullet$}
%		child[level distance =4mm] {node [blue]{$\bullet$}
%			child[level distance=4mm] {node [dgreen] {$\bullet$}
%				child [level distance=4mm] {coordinate (A31)}}
%			child[level distance=8mm] {node {$\bullet$}}
%		}
%		child[level distance =8mm] {node [dgreen] {$\bullet$}
%			child[level distance=4mm] {node {$\bullet$}}
%		}
%		child[level distance =12mm] {node {$\bullet$}}
%		child[level distance =12mm] {node {$\bullet$}};			
%%
%	\draw[|->, shorten <= 3pt, shorten >= 3pt] (A1) -- (A2);
%	\draw[|->, shorten <= 3pt, shorten >= 3pt] (A2) -- (A3);
%	\draw[densely dotted, postaction={decorate}] (A21) to (A12);
%	\draw[densely dotted, postaction={decorate}] (A22) to (A14);
%	\draw[densely dotted, postaction={decorate}] (A23) to (A13);
%	\draw[densely dotted, postaction={decorate}] (A31) to (A22);
%\end{tikzpicture}
%\]
%We can see that the unique leaf of $\fl{p}\tri \fl{p}\tri \fl{p}$ is mapping to $j$.
%\end{example}
%
%\begin{exercise}\label{ex.fleece_assoc}
%Let $p$, $\delta$, $\fl{p}$, and $\fl{\delta}$ be as in \cref{ex.associativity_pics}.
%\begin{enumerate}
%	\item Redraw \eqref{eqn.delta_misc33} using $\delta\colon p\to p\tri p$ in place of the fleeced version $\fl{\delta}\colon \fl p\to \fl p$ shown there.
%	\item Use \cref{ex.fleece,def.fleece} to show that if $\delta$ is associative then $\fl{\delta}$ must be too.
%\qedhere
%\end{enumerate}
%\end{exercise}
%
%\begin{exercise}
%In \cref{ex.associativity_pics} we have maps $\delta\then(\delta\tri c)$ and $\delta\then(c\tri\delta)$ $c\to c\tri c\tri c$. Which of these corresponds to composing from the left, e.g.\ $(f\then g)\then h$, and which corresponds to composing to the right, e.g.\ $f\then (g\then h)$?
%\end{exercise}
%

\begin{example}[State systems as categories] \label{ex.state_cat}
We know that every state system $\ema{s}\iso S\yon^S$ with its do-nothing enclosure $\epsilon\colon\ema{s}\to\yon$ and its transition lens $\delta\colon\ema{s}\to\ema{s}\tri\ema{s}$ is a comonoid, so what category $\cat{S}$ does $(\ema{s},\epsilon,\delta)$ correspond to?

Recall from \cref{ex.not_all_com_state} that state systems are exactly those comonoids whose codomain (i.e.\ ``target'') functions $\cod\colon\ema{s}[s]\to\ema{s}(\1)$ for $s\in\ema{s}(\1)$ are bijections.
That is, from every object $s\in\Ob\cat S=\ema{s}(\1)$, there is exactly $1$ morphism to every object $t\in\Ob\cat S$.
So not only is $\cat S$ a preorder, it is the \emph{codiscrete preorder} on $\ema{s}(\1)$, where there is always a morphism between every pair of objects.

Let's redraw the polyboxes for the do-nothing enclosure of $\ema{s}$ from \eqref{eqn.do_nothing_polybox} and the transition lens of $\ema{s}$ from \eqref{eqn.trans_lens_polybox}, this time with our new arrow labels, as a sanity check:
\[
\begin{tikzpicture}
\node (erase) {

\begin{tikzpicture}[polybox, mapstos]
    \node[poly, dom, "$\ema{s}$" left] (S) {$\id_s$\at$s$};

    \draw (S_pos) to[climb'] node[right] {$\idy$} (S_dir);
\end{tikzpicture}

};
\node[right=of erase] (dupl) {

\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom, "$\ema{s}$" left] (r) {$s_0\to s_2$\at$s_0$};
	\node[poly, cod, right=2 of r.south, yshift=-2.5ex, "$\ema{s}$" right] (p) {$s_0\to s_1$\at$s_0$};
	\node[poly, cod, above=.8 of p, "$\ema{s}$" right] (p') {$s_1\to s_2$\at$s_1$};

	\draw[double] (r_pos) to[first] node[below] {} (p_pos);
	\draw (p_dir) to[climb] node[right] {$\cod$} (p'_pos);
	\draw (p'_dir) to[last] node[above] {$\then$} (r_dir);
  \end{tikzpicture}

};
\end{tikzpicture}
\]
Indeed, we had already been writing the directions of $\ema{s}$ as arrows $s\to t$, knowing that each was uniquely specified by its source $s$ and its target $t$ in $\ema{s}(\1)$.
And in \cref{subsec.comon.sharp.state.cohere}, we had already noted that $\id_s$ was just the arrow $s\to s$.
So state systems have been categories with exactly one morphism between every pair of objects all along.

Other names for this category include the \emph{indiscrete preorder} and the \emph{codiscrete} or \emph{indiscrete category}.
These names highlight the fact that every object of this category is isomorphic to every other object: in fact, every arrow $s\to t$ is an isomorphism with inverse $t\to s$, for these compose as $\id_s\colon s\to s$ in one direction and $\id_t\colon t\to t$ in the other.
Thus this category is also a \emph{groupoid}, and it may be called the \emph{codiscrete}, \emph{indiscrete}, or \emph{contractible groupoid}\dots but we will call it the \emph{state category on} $S$, where $S$ is the set of positions of $\ema{s}$ or objects of $\cat S$.%** Is this the best name? All categories are essentially state categories. Is there some universal property that this satisfies that we can name it after? 

% Anyway, to avoid confusion, we'll refer to $\cat{S}$ as the \emph{state category on $S$}, because we will use these to think about states of dynamical systems, and also because the state comonad in functional programming is $S\yon^S$.

Here are the state categories on $\3$ and on $\1\5$, with all maps (even identities) drawn:
\[
\begin{tikzpicture}
\def\n{3}% how many nodes
\def\size{2cm}
\node[circle,minimum size=\size] (b) {};
\foreach\x in{1,...,\n}{
  \node[minimum size=0.75cm,draw,circle] (n-\x) at (b.{360/\n*\x}){\x};
}
\foreach\x in{1,...,\n}{
  \foreach\y in{1,...,\n}{
    \ifnum\x=\y\draw[->] (n-\x) to [in=360/\n*\x-15,out=360/\n*\x+15,loop] ();\relax\else
      \draw (n-\x) edge[->,bend right=10] (n-\y);
    \fi
  }
}
\def\n{15}% how many nodes
\def\size{4cm}
\node[circle,minimum size=\size, right=4 of b] (b) {};
\foreach\x in{1,...,\n}{
  \node[minimum size=0.75cm,draw,circle] (n-\x) at (b.{360/\n*\x}){\x};
}
\foreach\x in{1,...,\n}{
  \foreach\y in{1,...,\n}{
    \ifnum\x=\y\draw[->] (n-\x) to [in=360/\n*\x-15,out=360/\n*\x+15,loop] ();\relax\else
      \draw (n-\x) edge[->,bend right=3] (n-\y);
    \fi
  }
}
% Source: Asterix: https://tex.stackexchange.com/questions/390647/understanding-complete-graph-example-in-tikz
\end{tikzpicture}
\]
The picture on the left should look familiar: it's what we drew in \cref{ex.trans_trees} when took the corolla picture for $\3\yon^\3$ and bent the arrows to point at their targets according to its transition lens.
Notice that the graphs we obtain in this way are always complete.
\end{example}

\begin{exercise} \label{exc.not_state_cat_but_same_carrier}
Let $S$ be a set. Is there any comonoid structure on $S\yon^S$ other than that of the state category?
\begin{solution}
In the case of $S\coloneqq\0$, the only comonoid structure on $S\yon^S\iso\0$ is given by the empty category, the only category with no objects; and in the case of $S\coloneqq\1$, the only comonoid structure on $S\yon^S\iso\yon$ is given by the category with $1$ object and no nonidentity morphisms, again the only such category.
So in those cases, the comonoid structure on $S\yon^S$ is unique.

Now assume $|S|\geq2$.
The state category is always connected, but we can always find a comonoid structure on $S\yon^S$ given by a category that is not connected---and thus not isomorphic to the state category---as follows.
Consider a category whose object set is $S$ that has no morphisms between distinct objects, so that it is certainly not connected.
Then to specify the category, it suffices to specify a monoid associated with each object that will give the morphisms whose domain and codomain are equal to that object.
But there is always a monoid structure on a given set $S$.
If $S$ is finite, we can take the cyclic group $\zz/|S|\zz$ of order $|S|$, so that the resulting category has carrier $S\yon^{\zz/|S|\zz}\iso S\yon^S$.
On the other hand, if $S$ is infinite, we can take the free monoid on $S$, which has cardinality $\sum_{n\in\nn}|S|^\ord{n}=|\nn||S|=|S|$.
So the resulting category will again have carrier $S\yon^S$.
\end{solution}
\end{exercise}

Not only does \cref{ex.state_cat} finally explain what our state systems really are (they're just special categories!), it illustrates two important features of our story.
One is that on positions, the duplicator $\delta\colon\ema{c}\to\ema{c}\tri\ema{c}$ of a comonoid takes the corolla picture of $\ema{c}$ and ``bends the arrows'' so that they point to other roots, yielding the underlying graph of a category.
Then $\delta$ on directions collapses two-arrow paths in the graph down to individual arrows, while the eraser $\epsilon\colon\ema{c}\to\yon$ identifies empty paths with identity arrows.

Another important point is that we can view any category as a \emph{generalized state system}: its objects as \emph{states}, and its morphisms as \emph{transitions} between states.
The polynomial comonoid perspective is particularly suited for thinking about categories in this way: each object is a position that we could be in, and each morphism out of that object is a direction that we might take.
What is special about a comonoid is that each direction will always have another position at the end of it, making it reasonable to think of these directions as transitions between different states; and any sequence of transitions that we can follow is itself a transition.

Comparing these ideas, we see that they say the same thing: the first from the perspective of trees and graphs, the second from the perspective of arenas and dynamics.
We might say that
\slogan{
    a comonoid structure on a corolla forest turns\\
    roots into vertices and\\
    leaves into composable arrows between vertices;
}
or that
\slogan{
    a comonoid structure on an arena turns\\
    positions into states and\\
    directions into composable transitions between states.
}

\subsubsection{Monoids and monoid actions}

Here we use \emph{monoid} to refer to a monoid in the monoidal category $(\smset,\1,\times)$.
We denote such a monoid by $(M,e,*)$, where $M$ is the underlying set, $e\in M$ is the unit, and $*\colon M\times M\to M$ is the binary operation.

\begin{example}[Monoids as representable comonoids]\label{ex.monoids}
Recall that every monoid $(M,e,*)$ can be identified with a $1$-object category $\cat{M}$ with a single hom-set $M$, a single identity morphism $e$, and composition given by $*$.
Now we know that a $1$-object category $\cat{M}$ is also a polynomial comonoid $(\ema{m},\epsilon,\delta)$ whose carrier has $1$ position, with all of the morphisms of $\cat{M}$ becoming its directions.
So the carrier of $\cat{M}$ is the representable polynomial $\yon^M$.

Then the eraser $\epsilon\colon\yon^M\to\yon$ picks out the identity morphism $e\in M$ on directions, while the duplicator $\delta\colon\yon^M\to\yon^M\tri\yon^M\iso\yon^{M\times M}$ can be identified with the binary operation $*\colon M\times M\to M$.
(We don't have to worry about codomains, since there's only one possible codomain to choose from.)
In this way, every monoid $(M,e,*)$ in $\smset$ gives rise to a representable comonoid $(\yon^M,\epsilon,\delta)$ in $\poly$.
We can just as easily invert this construction, obtaining a monoid for every representable comonoid by taking the underlying set to be the carrier's set of directions, the unit to be the direction picked out by the erasure, and the binary operation to be the duplicator's on-directions function.

% Let $(M,e,*)$ be a monoid.
% Recall that a 

% Then we can construct a comonoid structure on the representable $\yon^M$. A morphism $\yon^M\to\yon$ can be identified with an element of $M$; under that identification we take $\epsilon\coloneqq e$. Similarly, $\yon^M\tri\yon^M\cong\yon^{M^\2}$ and a morphism $\yon^M\to\yon^{M^\2}$ can be identified with a function $M^\2\to M$; under that identification we take $\delta\coloneqq *$.
\end{example}

\begin{exercise}
Verify \cref{ex.monoids} by showing that $(M,e,*)$ satisfies the unitality and associativity requirements of a monoid in $(\smset,\1,\times)$ if and only if $(\yon^M,\epsilon,\delta)$ satisfies the erasure and coassociativity requirements of a comonoid in $(\poly,\yon,\tri)$.
\begin{solution} %** Do we want to write it out??
The fact that monoids $(M,e,*)$ in $(\smset,\1,\times)$ are just comonoids $(\yon^M,\epsilon,\delta)$ in $(\poly,\yon,\tri)$, following the construction of \cref{ex.monoids}, is a direct consequence of the fully faithful Yoneda embedding $\smset\op\to\poly$ sending $A\mapsto\yon^A$ that maps $\1\mapsto\yon, A\times B\mapsto\yon^{A\times B}\iso\yon^A\tri\yon^B$ naturally, and $M\mapsto\yon^M$.

We can also state the laws and the correspondences between them explicitly, keeping in mind that $e$ and $*$ are just the on-directions functinos of $\epsilon$ and $\delta$.
The monoid's unitality condition states that $e$ is a $2$-sided unit for $*$, or that
\[
\begin{tikzcd}[row sep=large]
	\1\times M & M\ar[from=d, "*" description]\ar[from=r, equal]\ar[from=l, equal]&M\times\1\\&
	M\times M,\ar[from=ul, "e\:\times\:M"']\ar[from=ur, "M\:\times\:e"]
\end{tikzcd}
\]
commutes---equivalent to the comonoid's erasure laws, which state that 
\[
\begin{tikzcd}[row sep=large]
	\yon\tri \yon^{M}&\yon^{M}\ar[d, "\delta" description]\ar[r, equal]\ar[l, equal]&\yon^{M}\tri\yon\\&
	\yon^{M}\tri\yon^{M},\ar[ul, "\epsilon\:\tri\:\yon^{M}"]\ar[ur, "\yon^{M}\:\tri\:\epsilon"']
\end{tikzcd}
\]
commutes (trivial on positions, equivalent to the monoid's unitality condition on directions).

Similarly, the monoid's associativity condition states that $*$ is associative, or that
\[
\begin{tikzcd}[row sep=large]
	M \ar[from=r, "*"']\ar[from=d, "*"]&
	M \times M \ar[from=d, "M\:\times\:*"']\\
	M \times M \ar[from=r, "*\:\times\:M"]&
	M \times M \times M,
\end{tikzcd}
\]
commutes---equivalent to the comonoid's coassociative law, which state that 
\[
\begin{tikzcd}[row sep=large]
	\yon^{M}\ar[r, "\delta"]\ar[d, "\delta"']&
	\yon^{M}\tri\yon^{M}\ar[d, "\yon^{M}\:\tri\:\delta"]\\
	\yon^{M}\tri \yon^{M}\ar[r, "\delta\:\tri\:\yon^{M}"']&
	\yon^{M}\tri\yon^{M}\tri\yon^{M},
\end{tikzcd}
\]
commutes (trivial on positions, equivalent to the monoid's associativity condition on directions).
\end{solution}
\end{exercise}

\begin{example}[Cyclic lists]
For any $n\in\nn$, consider $\zz/n\zz$, the cyclic group of order $n$, viewed as a monoid or, equivalently, a $1$-object category.
Its carrier is $\yon^{\zz/n\zz}$.

As a polynomial functor, $\yon^{\zz/n\zz}$ sends each set $X$ to the set of length-$n$ tuples in $X$.
But the comonoid structure lets us think of these tuples as \emph{cyclic lists}: once we reach the last element, we can loop back around to the first element.
Indeed, as a natural transformation, $\epsilon\colon\yon^{\zz/n\zz}\to\yon$ picks out the ``current'' element via its $X$-component $\epsilon\tri X\colon\yon^{\zz/n\zz}\tri X\to\yon\tri X$, which is just a function $\epsilon_X\colon X^{\zz/n\zz}\to X$; and $\delta$ lets us move around the list.%**what does this mean? exercise??

We will see later that comonoids are closed under coproducts, so $\sum_{n\in\nn}\yon^{\zz/n\zz}$ is also a comonoid.
\end{example}

\begin{example}[Monoid actions]\label{ex.monoid_action}
Suppose that $(M,e,*)$ is a monoid, $S$ is a set, and $\alpha\colon S\times M\to S$ is a \emph{(right) monoid action}.
That is, for all $s\in S$ we have $\alpha(s,e)=s$ and $\alpha(s,m*n)=\alpha(\alpha(s,m),n)$ for $m,n\in M$; equivalently, the diagrams
\[
\begin{tikzcd}
	S\times\1\ar[rd,equals]\ar[r,"S\:\times\:e"] & S\times M\ar[d,"\alpha"]\\
	& S
\end{tikzcd}
\qqand
\begin{tikzcd}[row sep=large]
    S\times M\times M\ar[r,"S\:\times\:*"]\ar[d,"\alpha\:\times\:M"] & S\times M\ar[d,"\alpha"]\\
    S\times M\ar[r,"\alpha"] & S
\end{tikzcd}
\]
commute.

Then there is an associated category $\cat{A}$ with objects in $S$ and morphisms $s\To{m}\alpha(s,m)$ for each $s\in S$ and $m\in M$.
This, in turn, corresponds to a comonoid $(S\yon^M,\epsilon,\delta)$, as we will see in the next exercise.
\end{example}

\begin{exercise}
With notation as in \cref{ex.monoid_action}, characterize the comonoid structure on $S\yon^M$.
\begin{enumerate}
    \item How can we define the erasure $\epsilon$?
    \item How can we define the duplicator $\delta$?
    \item Verify that the erasure laws hold.
    \item Verify that the coassociative law holds.
    \item Describe the corresponding category $\cat{A}$.
    In particular, what are the morphisms between any fixed pair of objects, what are the identity morphisms, and how do morphisms compose?
	\item $M$ always acts on itself by multiplication. Is the associated comonoid structure on $M\yon^M$ the same or different from the one coming from \cref{ex.state_cat}?
\qedhere
\end{enumerate}
\begin{solution}
Here $(M,e,*)$ is a monoid, $S$ is a set, $\alpha\colon S\times M\to S$ is a monoid action, and $\cat{A}$ is the associated category, whose corresponding comonoid is $(S\yon^M,\epsilon,\delta)$.
We also know that for each $s\in S$ and $m\in M$, there is a morphism $s\To{m} \alpha(s,m)$ in $\cat{A}$.
\begin{enumerate}
    \item The erasure $\epsilon\colon S\yon^M\to\yon$ picks out an element of $m\in M$ for every element $s\in S$ that will play the role of an identity, which in particular should also have $s$ as its codomain.
    Since we want the codomain of the morphism $m$ out of $s$ to be $\alpha(s,m)$, we can take $m=e$ to guarantee that its codomain will be $\alpha(s,e)=s$.
    So we let $\epsilon$ be the lens whose on-directions function at each $s\in S$ is $\epsilon^\sharp_s\colon\1\to M$ always maps to $e$.
    \item The duplicator $\delta\colon S\yon^M\to S\yon^M\tri S\yon^M$ is determined by what we want the codomain of each morphism to be and how we want the morphisms to compose.
    We already know that we want the morphism $m\in M$ out of each $s\in S$ to have the codomain $\alpha(s,m)$.
    If we then have another morphism $n\in M$ out of $\alpha(s,m)$, its codomain will be $\alpha(\alpha(s,m),n)=\alpha(s,m*n)$, the same as the codomain of the morphism $m*n$ out of $s$.
    So it makes sense for the composite $s\To{m}\alpha(s,m)\To{n} \alpha(\alpha(s,m),n)$ to be the morphism $s\To{m*n}\alpha(s,m*n)$.
    Thus, we can define $\delta$ in polyboxes as
    \[
    \begin{tikzpicture}[polybox, mapstos, font=\tiny]
        \node[poly, dom] (p) {$m*n$\at$s$};
        \node[poly, cod, right=1.5 of p.south, yshift=-1ex] (q) {$m$\at$s$};
        \node[poly, cod, above=of q, xshift=3] (r) {$n$\at$\alpha(s,m)$};
        \draw[double] (p_pos) to[first] (q_pos);
        \draw (q_dir) to[climb] node[right] {$\cod$} (r_pos);
        \draw (r_dir) to[last] node[above] {$\then$} (p_dir);
    \end{tikzpicture}
    \]
    \item We constructed $\delta$ above so that its bottom arrow is an identity function, so verifying the erasure laws amounts to checking that the direction $e\in M$ that $\epsilon$ picks out at each position $s\in S$ really does function as an identity morphism $s\To{e}\alpha(s,e)$ under the codomain and composition operations specified by $\delta$.
    We have already ensured that the codomain of $e$ at $s$ is $\alpha(s,e)=s$; meanwhile, given $m\in M$ we have that the composite of $s\To{m}\alpha(s,m)\To{e}\alpha(s,m)$ is $m*e=m$ and that the composite of $s\To{e}s\To{m}\alpha(s,m)$ is $e*m=m$ by the monoid's own unit laws.
    So the erasure laws hold.
    \item Verifying the coassociativity of $\delta$ amounts to checking that composition plays nicely with codomains and is associative.
    We already checked the former when defining $\delta$, and the latter follows from the monoid's own associativity laws: given $m,n,p\in M$, we have $(m*n)*p=m*(n*p)$.
    \item The associated category $\cat{A}$ is a category whose objects are the elements of the set $S$ being acted on, and whose morphisms $s\to t$ for each $s,t\in S$ are the elements of the monoid $m\in M$ that send $s$ to $t$, i.e.\ $\alpha(s,m)=t$.
    The identity morphism on each object is just the unit $e\in M$, while morphisms compose via the multiplication $*$.
    
    \item ** % usually different, only same if multiplication is bijective
\end{enumerate}
\end{solution}
\end{exercise}

\begin{example}[The category of $A$-streams]\label{ex.streams_category}
Fix a set $A$.
The set $A^\nn$ consists of infinite sequences of elements in $A$, which we will call \emph{$A$-streams}.
We can write an $A$-stream $\ol{a}\in A^\nn$ as follows:
\[
    \ol{a}\coloneqq(a_0\leadsto a_1\leadsto a_2\leadsto a_3\leadsto\cdots),
\]
with $a_n\in A$ for each $n\in\nn$.

Then there is a monoid action $\tau\colon A^\nn\times\nn\to A^\nn$ for which
\[
    \tau(\ol{a},n)\coloneqq(a_n\leadsto a_{n+1}\leadsto a_{n+2}\leadsto a_{n+3}\leadsto\cdots).
\]
Roughly speaking, $\nn$ acts on $A$-streams by shifting them forward by a natural number of steps.
We can check that this is a monoid action by observing that $\tau(\ol{a},0)=\ol{a}$ and that $\tau(\ol{a},m+n)=\tau(\tau(\ol{a},m),n)$.

So by \cref{ex.monoid_action}, the corresponding comonoid is carried by $A^\nn\yon^\nn$.
Each $A$-stream $\ol{a}$ is a position, and each $n\in\nn$ is a direction at $\ol{a}$ that can be visualized as the sequence of $n$ wavy arrows starting from $a_0$ and ending at $a_n$.
Then at the end of the direction $n$ is a new $A$-stream: the rest of $\ol{a}$ starting at $a_n$.
Indeed, this $A$-stream is exactly $\tau(\ol{a},n)$, the codomain assigned to the direction $n$ at $\ol{a}$.

Alternatively, if we shift from the domain-centric perspective to the usual hom-set perspective, this comonoid corresponds to a category whose objects are $A$-streams and whose morphisms $\ol{a}\to\ol{b}$ consist of every way in which $\ol{b}$ can be viewed as a continguous substream of $\ol{a}$: that is, there is a morphism $n\colon\ol{a}\to\ol{b}$ for each $n\in\nn$ satisfying
\[
    (a_n\leadsto a_{n+1}\leadsto\cdots)=(b_0\leadsto b_1\leadsto\cdots).
\]
The identity on $\ol{a}$ is given by $0\colon\ol{a}\to\ol{a}$; and the composite of two morphisms is the sum of the corresponding natural numbers, as a substream of a substream of $\ol{a}$ is just a substream of $\ol{a}$ shifted by the appropriate amount.

We will see this category again in \cref{ex.streams_cofree}.
\end{example}

% \begin{exercise}
% Let $A\coloneqq\{0,1,2\}$ and consider the category of $A$-streams as defined in \cref{ex.streams_category}.
% \begin{enumerate}
%     \item % ** some practice problems ``classify/how many morphisms are between...?'' and the like
% \end{enumerate}
% \end{exercise}

\subsubsection{The degree of an object}

We could continue to list examples of polynomial comonoids, but of course any list of small categories is already a list of such comonoids.
So instead, we conclude this section with some terminology that the polynomial perspective on a category affords.

\begin{definition}[Degree, linear]
Let $\cat{C}$ be a category and $c\in\Ob\cat{C}$ an object. The \emph{degree of $c$}, denoted $\deg(c)$, is the set of arrows in $\cat{C}$ that emanate from $c$.

If $\deg(c)\iso\1$, we say that $c$ is \emph{linear}.
If $\deg(c)\iso\ord{n}$ for $n\in\nn$, we say $c$ has \emph{degree $n$}.
\end{definition}

\begin{exercise}
\begin{enumerate}
	\item If every object in $\cat{C}$ is linear, what can we say about $\cat{C}$?
	\item Is it possible for an object in $\cat{C}$ to have degree $0$?
	\item Find a category that has an object of degree $\nn$.
	\item Up to isomorphism, how many categories are there that have just one linear and one quadratic (degree 2) object?
	\item Is the above the same as asking how many comonoid structures on $\yon^\2+\yon$ there are?\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item If every object in $\cat{C}$ is linear, then the only morphisms in $\cat{C}$ are the identity morphisms, so $\cat{C}$ must be a discrete category.
    \item It is not possible for an object in $\cat{C}$ to have degree $0$, as every object must have at least an identity morphism emanating from it.
    \item Some possible examples of categories with objects of degree $\nn$ are the monoid $(\nn, 0, +)$ (see \cref{exc.ema_polys} \cref{exc.ema_polys.nat_monoid}), the poset $(\nn, \leq)$ (see \cref{exc.ema_polys} \cref{exc.ema_polys.nat_poset}), and the state category on $\nn$ (see \cref{ex.state_cat}).
    \item Up to isomorphism, there are $3$ categories with just one linear and one quadratic object.
    They can be distinguished by the behavior of the single nonidentity morphism.
    Either its domain and its codomain are distinct, in which case we have the walking arrow category; or its domain and its codomain are the same, in which case it can be composed with itself to obtain either itself or the identity.
    So there are $3$ possible categories in total.
    \item Yes: since (isomorphic) categories correspond to (isomorphic) comonoids, there are as many categories with one linear and one quadratic object up to isomorphism as there are comonoid structures on $\yon^\2+\yon$.
\end{enumerate}
\end{solution}
\end{exercise}


%-------- Section --------%
\section{Morphisms of polynomial comonoids are cofunctors}

Now that we have characterized the comonoids of $\poly$, let us consider the morphisms between them.
These turn out to correspond to a rather odd kind of map between categories known as a \emph{cofunctor}.

%---- Subsection ----%
\subsection{Introducing comonoid morphisms and cofunctors}

First, let us define morphisms of comonoids in the most general setting.
If you've seen the definition of a monoid homomorphism (or even a group homomorphism), then this definition may look familiar.

\begin{definition}[Comonoid morphism]\label{def.morphism_comonoids}
Given a monoidal category $(\cat{C},\yon,\tri)$ with comonoids $\com{C}\coloneqq(\ema{c},\epsilon,\delta)$ and $\com{C}'\coloneqq(\ema{c'},\epsilon',\delta')$, a \emph{comonoid morphism} (or \emph{morphism of comonoids}) $\com{C}\to\com{C}'$ is a morphism $F\colon \ema{c}\to\ema{c'}$ in $\cat{C}$ for which the following diagrams commute:
\begin{equation}\label{eqn.pres_era}
\begin{tikzcd}
    \ema{c}\ar[r, "F"]\ar[d, "\epsilon"']&
    \ema{c'}\ar[d, "\epsilon'"]\\
    \yon\ar[r, equal]&
    \yon,
\end{tikzcd}
\end{equation}
called the \emph{eraser preservation law} (we say $F$ \emph{preserves erasure}); and
\begin{equation}\label{eqn.pres_dup}
\begin{tikzcd}
    \ema{c}\ar[r, "F"]\ar[d, "\delta"']&
    \ema{c'}\ar[d, "\delta'"]\\
    \ema{c}\tri\ema{c}\ar[r, "F\:\tri\:F"']&
    \ema{c'}\tri\ema{c'}
\end{tikzcd}
\end{equation}
called the \emph{duplicator preservation law} (we say $F$ \emph{preserves duplication}).
We may also say that $F$ \emph{preserves the comonoid structure}.

When the monoidal structure on $\cat{C}$ can be inferred, we let $\comon(\cat{C})$ denote the subcategory of $\cat{C}$ whose objects are comonoids in $\cat{C}$ and whose morphisms are comonoid morphisms.
\end{definition}

So when our monoidal category of interest is $(\poly,\yon,\tri)$, a morphism between polynomial comonoids is just a special kind of lens between their carriers that preserves erasure and duplication.

\begin{exercise}
There is something to be proved in the definition above: that comonoids and comonoid morphisms really do form a category.
Using the notation from \cref{def.morphism_comonoids}, verify the following:
\begin{enumerate}
    \item The identity morphism on a comonoid is a comonoid morphism.
    \item The composite of two comonoid morphisms is a comonoid morphism.
\end{enumerate}
This will show that $\comon(\cat{C})$ is indeed a subcategory of $\cat{C}$.
\begin{solution}
As in \cref{def.morphism_comonoids}, we have a monoidal category $(\cat{C},\yon,\tri)$ with comonoids $\com{C}\coloneqq(\ema{c},\epsilon,\delta)$ and $\com{C}'\coloneqq(\ema{c'},\epsilon',\delta')$ and a comonoid morphism $F\colon\com{C}\to\com{C'}$ (really a morphism $F\colon\ema{c}\to\ema{c'}$ in $\cat{C}$).
Let's throw in another comonoid $\com{C}''\coloneqq(\ema{c''},\epsilon'',\delta'')$ and another comonoid morphism $G\colon\com{C'}\to\com{C''}$ (really a morphism $G\colon\ema{c'}\to\ema{c''}$ in $\cat{C}$).
\begin{enumerate}
    \item To show that the identity morphism $\id_\ema{c}\colon\ema{c}\to\ema{c}$ is a comonoid morphism $\com{C}\to\com{C}$, we must check that it preserves erasure by showing that \eqref{eqn.pres_era} commutes, then check that it preserves duplication by showing that \eqref{eqn.pres_era} commutes:
    \[
    \begin{tikzcd}
        \ema{c}\ar[r, "\id_\ema{c}", equal]\ar[d, "\epsilon"']&
        \ema{c}\ar[d, "\epsilon"]\\
        \yon\ar[r, equal]&
        \yon
    \end{tikzcd}
    \hspace{.5in}
    \begin{tikzcd}[column sep=large]
        \ema{c}\ar[r, "\id_\ema{c}", equal]\ar[d, "\delta"']&
        \ema{c}\ar[d, "\delta"]\\
        \ema{c}\tri\ema{c}\ar[r, "\id_\ema{c}\:\tri\:\id_\ema{c}", equal]&
        \ema{c}\tri\ema{c}.
    \end{tikzcd}
    \]
    But they do commute, since $\id_\ema{c}$ is the identity on $\ema{c}$ and $\id_\ema{c}\tri\id_\ema{c}$ is the identity on $\ema{c}\tri\ema{c}$.
    
    \item To show that the composite $F\then G\colon\ema{c}\to\ema{c''}$ of the two comonoid morphisms $F$ and $G$ is itself a comonoid morphism $\com{C}\to\com{C''}$, we check that it preserves erasure by showing that \eqref{eqn.pres_era} commutes, then check that it preserves duplication by showing that \eqref{eqn.pres_era} commutes:
    \[
    \begin{tikzcd}
        \ema{c}\ar[r, "F\:\then\:G"]\ar[d, "\epsilon"']&
        \ema{c''}\ar[d, "\epsilon''"]\\
        \yon\ar[r, equal]&
        \yon
    \end{tikzcd}
    \hspace{.5in}
    \begin{tikzcd}[column sep=huge]
        \ema{c}\ar[r, "F\:\then\:G"]\ar[d, "\delta"']&
        \ema{c''}\ar[d, "\delta''"]\\
        \ema{c}\tri\ema{c}\ar[r, "(F\:\then\:G)\:\tri\:(F\:\then\:G)"]&
        \ema{c''}\tri\ema{c''}.
    \end{tikzcd}
    \]
    But we can rewrite these squares like so, using the fact that $(F\then G)\tri(F\then G)=(F\tri F)\then(G\tri G)$ on the right:
    \[
    \begin{tikzcd}
        \ema{c}\ar[r, "F"]\ar[d, "\epsilon"']&
        \ema{c}\ar[r, "G"]\ar[d, "\epsilon'"']&
        \ema{c''}\ar[d, "\epsilon''"]\\
        \yon\ar[r, equal]&
        \yon\ar[r, equal]&
        \yon
    \end{tikzcd}
    \hspace{.5in}
    \begin{tikzcd}
        \ema{c}\ar[r, "F"]\ar[d, "\delta"']&
        \ema{c'}\ar[r, "G"]\ar[d, "\delta"']&
        \ema{c''}\ar[d, "\delta'"]\\
        \ema{c}\tri\ema{c}\ar[r, "F\:\tri\:F"]&
        \ema{c'}\tri\ema{c'}\ar[r, "G\:\tri\:G"]&
        \ema{c''}\tri\ema{c''}.
    \end{tikzcd}
    \]
    Then the left square in each diagram commutes because $F$ is a comonoid morphism, while the right square in each diagram commutes because $G$ is a comonoid morphism.
    So both diagrams commute.
\end{enumerate}
\end{solution}
\end{exercise}

Notice that we were very careful in how we stated \cref{thm.ahman_uustalu}: while we asserted the existence of an isomorphism-preserving one-to-one correspondence between the objects of $\comon(\poly)$ and $\smcat$, we never claimed that these two categories are isomorphic or even equivalent.
The strange truth of the matter is that they are not: polynomial comonoid morphisms correspond not to functors, but to different maps of categories called \emph{cofunctors}.

How exactly do these maps behave?
If we specify \cref{def.morphism_comonoids} to the case of $(\poly,\yon,\tri)$, we can write the eraser preservation law \eqref{eqn.pres_era} in polyboxes as
\begin{equation}\label{eqn.pres_era_draw}
\begin{tikzpicture}
	\node (id1) {
	\begin{tikzpicture}[polybox, mapstos]
		\node[poly, dom, blue, "$\ema{c}\vphantom{\ema{c'}}$" above] (p) {\at$c$};
		\draw[blue] (p_pos) to[climb'] node[right] {$\idy$} (p_dir);
	\end{tikzpicture}	
	};
	\node[right=of id1] (id2) {
	\begin{tikzpicture}[polybox, mapstos]
		\node[poly, dom, blue, "$\ema{c}$" above] (p) {\at$c$};
		\node[poly, red, right=1 of p, "$\ema{c'}$" above] (q) {};
		\draw (p_pos) to[first] (q_pos);
		\draw (q_dir) to[last] (p_dir);
		\draw[red] (q_pos) to[climb'] node[right] {$\idy$} (q_dir);
		\node at ($(p.east)!.3!(q.west)$) {$F$};
	\end{tikzpicture}
	};
	\node at ($(id1.east)!.3!(id2.west)-(0,6pt)$) {$=$};
\end{tikzpicture}
\end{equation}
and the duplicator preservation law \eqref{eqn.pres_dup} in polyboxes as
\begin{equation}\label{eqn.pres_dup_draw}
\begin{tikzpicture}
	\node (sp1) {
	\begin{tikzpicture}[polybox, mapstos]
		\node[poly, dom, blue, "$\ema{c}$" above] (c) {\at$c$};
		\node[poly, blue, right=2 of c.south, yshift=-1ex, "$\ema{c}$" below] (c1) {};
		\node[poly, blue, above=of c1, "$\ema{c}$" above] (c2) {};
		\node[poly, cod, red, right=1 of c1, "$\ema{c'}$" below] (c'1) {$g$};
		\node[poly, cod, red, right=1 of c2, "$\ema{c'}$" above] (c'2) {$h$};
		\node at ($(c1.east)!.5!(c'1.west)$) {$F$};
		\node at ($(c2.east)!.5!(c'2.west)$) {$F$};
	%
		\draw[blue,double] (c_pos) to[first] (c1_pos);
		\draw[blue] (c1_dir) to[climb] node[right] {$\cod$} (c2_pos);
		\draw[blue] (c2_dir) to[last] node[above] {$\then$} (c_dir);
		\draw (c1_pos) to[first] (c'1_pos);
		\draw (c'1_dir) to[last] (c1_dir);
		\draw (c2_pos) to[first] (c'2_pos);
		\draw (c'2_dir) to[last] (c2_dir);
    \end{tikzpicture}	
	};
	\node[right=of sp1] (sp2) {
	\begin{tikzpicture}[polybox, mapstos]
		\node[poly, dom, blue, "$\ema{c}$" above] (c) {\at$c$};
		\node[poly, red, right=1 of c, "$\ema{c'}$" above] (c') {};
		\node[poly, cod, red, right=2 of c'.south, yshift=-1ex, "$\ema{c'}$" below] (c'1) {$g$};
		\node[poly, cod, red, above=of c'1, "$\ema{c'}$" above] (c'2) {$h$};
		\node at ($(c.east)!.3!(c'.west)$) {$F$};
	%
		\draw (c_pos) to[first] (c'_pos);
		\draw (c'_dir) to[last] (c_dir);
		\draw[red,double] (c'_pos) to[first] (c'1_pos);
		\draw[red] (c'1_dir) to[climb] node[right] {$\cod$} (c'2_pos);
		\draw[red] (c'2_dir) to[last] node[above] {$\then$} (c'_dir);
	\end{tikzpicture}
	};
	\node at ($(sp1.east)!.5!(sp2.west)-(0,4pt)$) {$=$};
\end{tikzpicture}
\end{equation}
If we read off the equations from these polyboxes, interpreting polynomial comonoids as categories, we derive the following definition of a cofunctor.
(Here \eqref{eqn.pres_id} is equivalent to \eqref{eqn.pres_era_draw}, while \eqref{eqn.pres_cod} and \eqref{eqn.pres_comp} are together equivalent to \eqref{eqn.pres_dup_draw}.)

\begin{definition}[Cofunctor]\label{def.cofunctor}
Let $\cat{C}$ and $\cat{C'}$ be (small) categories.
A \emph{cofunctor} $F\colon\cat{C}\cof\cat{C'}$ consists of:
\begin{itemize}
    \item a function $F\colon\Ob\cat{C}\to\Ob\cat{C'}$ \emph{forward on objects}\footnote{In keeping with standard functor notation, we omit the usual subscript $\1$ that we include for on-positions (in this case, on-objects) functions. We often omit parentheses when applying these functions as well.} and
    \item a function $F^\sharp_c\colon\cat{C'}[Fc]\to\cat{C}[c]$ \emph{backward on morphisms} for each $c\in\Ob\cat{C}$,
\end{itemize}
satisfying the following conditions, collectively known as the \emph{cofunctor laws}:
\begin{enumerate}[itemsep=0pt, label=\roman*.]
	\item $F$ \emph{preserves identities}:
	\begin{equation} \label{eqn.pres_id}
	    F^\sharp_c\,\id_{Fc}=\id_c
	\end{equation}
	for each $c\in\Ob\cat{C}$;
	\item $F$ \emph{preserves codomains}:
	\begin{equation} \label{eqn.pres_cod}
	    F\cod F^\sharp_c g=\cod g
	\end{equation}
	for each $c\in\Ob\cat{C}$ and $g\in\cat{C'}[Fc]$;
	\item $F$ \emph{preserves composites}:%
	\footnote{In particular, the codomains of either side of \eqref{eqn.pres_comp} are equal.
	This isn't actually guaranteed by the other laws, so it is worth noting on its own; see for example the proof of \cref{prop.cofunctors_isos}.}
	\begin{equation} \label{eqn.pres_comp}
	    F^\sharp_c g\then F^\sharp_{\cod F^\sharp_c g} h=F^\sharp_c\left(g\then h\right)
	\end{equation}
	for each $c\in\Ob\cat{C}, g\in\cat{C'}[Fc],$ and $h\in\cat{C'}[\cod g]$.
\end{enumerate}
We let $\smcat^\sharp\iso\comon(\poly)$ denote the category of (small) categories and cofunctors.
\end{definition}

Since cofunctors are just lenses between carrier polynomials, they compose the way lenses do.

\begin{exercise}
Let $\cat{C},\cat{D},\cat{E}$ be categories, and let $F\colon\cat{C}\cof\cat{D}$ and $G\colon\cat{D}\cof\cat{E}$ be cofunctors between them.
\begin{enumerate}
    \item Characterize the behavior of the identity cofunctor $\id_\cat{D}$ on $\cat{D}$.
    Where does it send each object?
    Where does it send each morphism?
    \item Characterize the behavior of the composite cofunctor $F\then G$.
    Where does it send each object and morphism?\qedhere
\end{enumerate}
\begin{solution}
Here $F\colon\cat{C}\cof\cat{D}$ and $G\colon\cat{D}\cof\cat{E}$ are cofunctors in $\smcat^\sharp$.
\begin{enumerate}
    \item The identity cofunctor $\id_\cat{D}$ on $\cat{D}$ should correspond to the identity lens on the carrier of $\cat{D}$, which is the identity on both positions (objects) and directions (morphisms).
    So $\id_\cat{D}$ sends each object $d\in\Ob\cat{D}$ to itself, while $\left(\id_\cat{D}\right)^\sharp_d\colon\cat{D}[d]\to\cat{D}[d]$ sends each morphism out of $d$ to itself as well.
    \item The composite cofunctor $F\then G\colon\cat{C}\cof\cat{D}$ should correspond to the composite of $F$ as a lens between the carriers of $\cat{C}$ and $\cat{D}$ with $G$ as a lens between the carriers of $\cat{D}$ and $\cat{E}$.
    So on objects, $F\then G$ sends each $c\in\Ob\cat{C}$ to $G(Fc)\in\Ob\cat{E}$.
    Then given $c\in\Ob\cat{C}$, the on-morphisms function $(F\then G)^\sharp_c\colon\cat{E}[G(Fc)]\to\cat{C}[c]$ is the composite of on-directions functions
    \[
        \cat{E}[G(Fc)]\To{G^\sharp_{Fc}}\cat{D}[Fc]\To{F^\sharp_c}\cat{C}[c],
    \]
    sending each morphism $h$ with domain $G(Fc)$ to $F^\sharp_c\left(G^\sharp_{Fc}h\right)$.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
We've justified the ``isomorphism-preserving'' part of \cref{thm.ahman_uustalu} implicitly, but let's make it explicit.

Recall that two categories $\cat{C}$ and $\cat{D}$ are isomorphic in $\smcat$ if there exist functors $F\colon\cat{C}\to\cat{D}$ and $G\colon\cat{D}\to\cat{C}$ that are mutually inverse, i.e.\ $F\then G$ and $G\then F$ are identity functors on $\cat{C}$ and $\cat{D}$.
Similarly, $\cat{C}$ and $\cat{D}$ are isomorphic in $\smcat^\sharp$ if there exist cofunctors $H\colon\cat{C}\cof\cat{D}$ and $K\colon\cat{D}\cof\cat{C}$ that are mutually inverse, i.e.\ $H\then K$ and $K\then H$ are identity cofunctors on $\cat{C}$ and $\cat{D}$.
Show that $\cat{C}$ and $\cat{D}$ are isomorphic in $\smcat$ if and only if they are isomorphic in $\smcat^\sharp$.
\begin{solution}
We want to show that categories $\cat{C}$ and $\cat{D}$ are isomorphic in $\smcat$ if and only if they are isomorphic in $\smcat^\sharp$.
First, assume that $\cat{C}$ and $\cat{D}$ are isomorphic in $\smcat$, so that there exist mutually inverse functors $F\colon\cat{C}\to\cat{D}$ and $G\colon\cat{D}\to\cat{C}$.
Then we can define a cofunctor $H\colon\cat{C}\cof\cat{D}$ such that for each $c\in\cat{C}$ we have $Hc\coloneqq Fc\in\cat{D}$, and for each $g\in\cat{D}[Fc]$ we have $H^\sharp_c g\coloneqq Gg\in\cat{C}[GFc]=\cat{C}[c]$.
We can verify that $H$ really is a cofunctor: it preserves identities and composition because $G$ does, and it preserves codomains because $H\cod H^\sharp_c g=F\cod Gg=FG\cod g=\cod g$.
Analogously, we can define a cofunctor $K\colon\cat{D}\cof\cat{C}$ with $Kd\coloneqq Gd$ and $K^\sharp_d f\coloneqq Ff$ for each $d\in\cat{D}$ and $f\in\cat{C}[Gd]$.
Then $H\then K$ is equal to $F\then G$ both on objects and on morphisms, so it is the identity cofunctor on $\cat{C}$; analogously, $K\then H$ is the identity cofunctor on $\cat{D}$.
Thus $\cat{C}$ and $\cat{D}$ are isomorphic in $\smcat^\sharp$.

Conversely, assume $\cat{C}$ and $\cat{D}$ are isomorphic in $\smcat^\sharp$, so that there exist mutually inverse cofunctors $H\colon\cat{C}\cof\cat{D}$ and $K\colon\cat{D}\cof\cat{C}$.
Given objects $c,c'$ and a morphism $f\colon c\to c'$ in $\cat{C}$, we have that $KHc=c$, so $K^\sharp_{Hc}$ is a function $\cat{C}[c]\to\cat{D}[Hc]$.
In particular, $K^\sharp_{Hc}f$ is a morphism in $\cat{D}$ whose domain is $Hc$ and whose codomain satisfies $K\cod K^\sharp_{Hc}f=\cod f=c'$, and thus $\cod K^\sharp_{Hc}f=Hc'$.
Hence we can define a functor $F\colon\cat{C}\to\cat{D}$ such that for each $c\in\cat{C}$ we have $Fc\coloneqq Hc\in\cat{D}$, and for each morphism $f\colon c\to c'$ in $\cat{C}$ we have $Ff\coloneqq K^\sharp_{Hc}f\colon Hc\to Hc'$.
Functoriality follows from the fact that $K$ preserves identities and composition.
Analogously, we can define a functor $G\colon\cat{D}\to\cat{C}$ with $Gd\coloneqq Kd$ for each $d\in\cat{D}$ and $Gg\coloneqq H^\sharp_{Kd}g$ for each $g\colon d\to d'$ in $\cat{D}$.
Then $F\then G$ is equal to $H\then K$ on objects; on morphisms, it sends each $f\colon c\to c'$ in $\cat{C}$ to $H^\sharp_{KHc}\left(K^\sharp_{Hc}f\right)=H^\sharp_c\left(K^\sharp_{Hc}f\right)=(K\then H)^\sharp_cf=f$ itself.
So $F\then G$ is the identity cofunctor on $\cat{C}$.
Analogously, $G\then F$ is the identity functor on $\cat{D}$.
Thus $\cat{C}$ and $\cat{D}$ are isomorphic in $\smcat$.
\end{solution}
\end{exercise}

% ** justifies why there is not much ambiguity if we use id, could be id functor or id cofunctor....

% isomorphisms are the same...non-isos are very different


% In one sense, these laws are exactly as you'd expect: objects, morphisms, identities, codomains, and composition...in another sense, deeply weird: need to specify codomains, etc.


\slogan{Cofunctors $F$ go forward on objects, and backward on morphisms. It's good to remember: codomains are objects, so $F$ preserves them going forward; identities and composites are morphisms, so $F$ preserves them going backward.}

% The rough idea is that a cofunctor $\cat{C}\cof\cat{D}$ is, in particular, a morphism $\ema{c}\to\ema{d}$ in $\poly$ between their carriers. This map preserves identities, codomains, and composition, which is great, but you still feel like you've got a map of polynomials on your hands: it goes forward on objects and backward on morphisms.


% ** preserve structure...not surprising that they preserve isos


\begin{proposition}\label{prop.cofunctors_isos}
Let $F\colon\cat{C}\cof\cat{D}$ be a cofunctor, $c\in\cat{C}$ be an object, and $g\colon Fc\to\_$ be an isomorphism in $\cat{D}$.
Then $F^\sharp_c g$ is also an isomorphism in $\cat{C}$.
\end{proposition}
\begin{proof}
Let $c'\coloneqq\cod F^\sharp_c g$, so that $Fc'=\cod g$ by \eqref{eqn.pres_cod}, and let $g^{-1}\colon Fc'\to Fc$ be the inverse of $g$.
Then
\begin{align*}
	\id_c&=
	F^\sharp_c\,\id_{Fc} \tag*{\eqref{eqn.pres_id}}\\&=
	F^\sharp_c\left(g\then g^{-1}\right)\\&=
	F^\sharp_c g\then F^\sharp_{c'}\left(g^{-1}\right), \tag*{\eqref{eqn.pres_comp}}
\end{align*}
so in particular $c=\cod\id_c=\cod F^\sharp_{c'}\left(g^{-1}\right)$, and
\begin{align*}
	\id_{c'}&=
	F^\sharp_{c'}\,\id_{Fc'} \tag*{\eqref{eqn.pres_id}}\\&=
	F^\sharp_{c'}\left(g^{-1}\then g\right)\\&=
	F^\sharp_{c'}\left(g^{-1}\right)\then F^\sharp_{\cod F^\sharp_{c'}\left(g^{-1}\right)}g \tag*{\eqref{eqn.pres_comp}}\\&=
	F^\sharp_{c'}\left(g^{-1}\right)\then F^\sharp_c g.
\end{align*}
Hence $F^\sharp_c g$ and $F^\sharp_{c'}\left(g^{-1}\right)$ are inverses, and the result follows.
\end{proof}

%---- Subsection ----%
\subsection{Examples of cofunctors}

From a realm where functors reign supreme, the back-and-forth behavior of cofunctors can seem foreign and  counterintuitive.
Whereas a functor $\cat{C}\to\cat{D}$ can be thought of as a \emph{diagram}---a picture in the shape of $\cat{C}$, drawn with the objects and arrows of $\cat{D}$---cofunctors are much more like the dynamical systems of \cref{ch.poly.dyn_sys}.\footnote{In fact, we will see in \cref{ch.comon.cofree} that cofunctors generalize our dynamical systems.}

That is, a cofunctor $F\colon\cat{C}\cof\cat{D}$ is a way of interacting with the states (objects) and transitions (morphisms) within $\cat{C}$ by way of $\cat{D}$.
Imagine the cofunctor as a box, with $\cat{C}$ on the inside and $\cat{D}$ on the outside.
Some $c\in\cat{C}$ may be the current state inside the box, but all anyone outside the box can see is the object $Fc\in\cat{D}$ that the box chooses to display in lieu of $c$.
Still, any transition $g$ out of $Fc$ can be selected from the outside; the box guarantees that whatever $c$ is on the inside, there is a corresponding transition $F^\sharp_c g$ out of that $c$.
As $g$ is followed from $Fc$ to $\cod g$ on the outside, $F^\sharp_c g$ is followed from $c$ to $\cod F^\sharp_c g$ on the inside.
But codomain preservation guarantees that the new state $\cod g$ on the outside is equal to what the box would want to display in lieu of the new state $\cod F^\sharp_c g$ on the inside, as $\cod g=F\cod F^\sharp_c g$,
Then the process repeats in a manner compatible with identities and composition.

Here we give a variety of examples of cofunctors to get a better handle on them.

\subsubsection{Cofunctors to preorders}


\subsubsection{Cofunctors to monoids}

\begin{example}[Admissible sections]\label{ex.admissible_section}
Consider the monoid $\cat{N}\coloneqq (\nn,0,+)$, viewed as a category with one object. 
For any category $\cat{C}$, a cofunctor $\varphi\colon\cat{C}\cof\cat{N}$ is called an \emph{admissible section} \cite{aguiar1997internal}.
We'll have more to say about these in \cref{thm.catsharp_to_mon}, but our goal here is simply to unpack the definition.

To specify $\varphi$, we first say what it does on objects, but this is trivial: there is only one object in $\cat{N}$, so each object of $\cat{C}$ is sent to it.
(This also means that codomains are automatically preserved.)
So $\varphi$ is characterized by its behavior on morphisms: for each object $i\in\cat{C}$, the cofunctor assigns every natural number $n\in\nn$ a morphism $\varphi^\sharp_i n$ of $\cat{C}$ emanating from $i$.
That's a lot of data, but we still have two cofunctor laws to pare it down:
\[
    \varphi^\sharp_i\,0=\id_i
        \qqand
    \varphi^\sharp_i(m+n)=\varphi^\sharp_i m\then\varphi^\sharp_{\cod\varphi^\sharp_i m}n.
\]
Then for each $i\in\cat{C}$, since every natural number $n\in\nn$ is a sum of 1's, the morphism $\varphi^\sharp_i n$ can be decomposed into $n$ copies of $\varphi^\sharp_{i_j}\,1$ for some objects $i=i_0,i_1,\ldots,i_n\in\cat{C}$, as follows:
\[
    i=i_0\To{\varphi^\sharp_{i_0}1}i_1\To{\varphi^\sharp_{i_1}1}\cdots\To{\varphi^\sharp_{i_{n-1}}1}i_n.
\]
Here each $i_{j+1}\coloneqq\cod\varphi^\sharp_{i_j}1$.

Thus an admissible section of $\cat{C}$ is given by independently choosing a morphism emanting from each $i\in\cat{C}$ to be $\varphi^\sharp_i\,1$; indeed, any such choice gives rise to a unique admissible section. 
\end{example}

\begin{exercise}
How many admissible sections does the category \fbox{$\bullet\to\bullet$} have?
\begin{solution}
We seek the number of admissible sections of the category \fbox{$\bullet\to\bullet$}.
There are $2$ choices of morphisms emanating from the object on the left, and $1$ choice of morphism emanating from the object on the right, for a total of $2 \cdot 1 = 2$ admissible sections.
\end{solution}
\end{exercise}

\begin{exercise}
Let $\cat{Z}\coloneqq(\zz,0,+)$ denote the monoid of integers, and let $\cat{N}$ be the monoid of natural numbers as above.
We view both $\cat{Z}$ and $\cat{N}$ as categories with one object each.
\begin{enumerate}
	\item For a category $\cat{C}$, describe the data of a cofunctor $\cat{C}\cof\cat{Z}$.
	\item What would you say is the canonical cofunctor $\cat{Z}\cof\cat{N}$?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

%** make terminology/definition precise
\begin{example}[Systems of ODEs]
A system of ordinary differential equations (ODEs) in $n$ variables, e.g.
\begin{align*}
    \dot{x}_1 &= f_1(x_1, \ldots, x_n) \\
    \dot{x}_2 &= f_2(x_1, \ldots, x_n) \\
    & \; \; \; \vdots \\
    \dot{x}_n &= f_n(x_1, \ldots, x_n),
\end{align*}
can be understood as a vector field on $\rr^n$.
We are often interested in integrating this vector field to get flow lines, or integral curves.
In other words, for each $x=(x_1, \ldots, x_n)\in\rr^n$, viewed as a point, and each $t\in\rr$, viewed as a quantity of time, we can begin at $x$ and move along the vector field for time $t$, arriving at a new point $x^{+t}$. These satisfy the equations
\begin{equation} \label{eqn.cofunctor_ode}
    x^{+0} = x \qqand x^{+t_1+t_2} = (x^{+t_1})^{+t_2}. 
\end{equation}
Let's call such things \emph{differentiable dynamical systems} with time domain $(T, 0, +)$; above, we used $T\coloneqq\rr$, but any monoid will do.

Dynamical systems in the above sense are cofunctors $F \colon \rr^n \yon^{\rr^n} \cof \yon^T$.
In order to say this, we first need to say how both $\cat{C} := \rr^n \yon^{\rr^n}$ and $\yon^T$ are being considered as categories.
The category $\cat{C}$ has objects $\rr^n$, and for each object $x \in \rr^n$ and outgoing arrow $v \in \rr^n$, the codomain of $v$ is $x + v$; in other words, $v$ is a vector emanating from $x$.
The identity is $v = 0$, and composition is given by addition.
The category $\yon^T$ is the monoid $T$ considered as a category with one object, $\bullet$.

The cofunctor assigns to every object $x \in \rr^n$ the unique object $F(x) = \bullet$, and to each element $t \in T$ the morphism $F^\sharp(x, t) = x^{+t} - x \in \rr^n$, which can be interpreted as a vector emanating from $x$.
Its codomain is $\cod F^\sharp(x, t) = x^{+t}$, and we will see that \eqref{eqn.cofunctor_ode} ensures the cofunctoriality properties.

The codomain law ii is vacuously true, since $\yon^T$ only has one object.
Law i follows because $F^\sharp(x, 0) = x^{+0} - x = 0$, and law iii follows as
\[
    F^\sharp(x^{+t_1}, t_2) + F^\sharp(x, t_1) = (x^{+t_1})^{+t_2} - x^{+t_1} + x^{+t_1} - x = x^{+t_1 + t_2} - x = F^\sharp(x, t_1+t_2).
\]
\end{example}

\begin{exercise}
\begin{enumerate}
	\item Suppose that $M,N$ are monoids (each is a category with one object). Are cofunctors between them related to monoid homomorphisms? If so, how?
	\item Suppose $\cat{C}$ and $\cat{D}$ are categories and $F\colon\cat{C}\cof\cat{D}$ is a cofunctor. Does there necessarily exist a cofunctor $\cat{C}\op\cof\cat{D}\op$ that acts the same as $F$ on objects?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

% ** displaced stuff ends




\begin{example}\label{ex.BGEG}
Let $(G,e,*)$ be a group and $(\yon^G,\epsilon,\delta)$ the corresponding comonoid. There is a cofunctor $G\yon^G\to\yon^G$ given by
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom] (p) {$g_1*g_2$\at$g_1$};
	\node[poly, pure cod, right=of p] (q) {$g_2$\at\vphantom{$g_1$}};
	\draw (p_pos) to[first] (q_pos);
	\draw (q_dir) to[last] (p_dir);
\end{tikzpicture}
\]
To see this is a cofunctor, we check that identities, codomains, and compositions are preserved. For any $g_1$, the identity $e$ is passed back to $g_1*e=g_1$, and this is the identity on $g_1$ in $G\yon^G$. Codomains are preserved because there is only one object in $\yon^G$. Composites are preserved because for any $g_2,g_3$, we have $g_1*(g_2*g_3)=(g_1*g_2)*g_3$.
\end{example}

\begin{exercise}\label{exc.BGEG}
Does the idea of \cref{ex.BGEG} work when $G$ is merely a monoid, or does something go subtly wrong somehow?
\begin{solution}
**
\end{solution}
\end{exercise}

\begin{proposition}\label{prop.monoids_ff}
There is a fully faithful functor $\Cat{Mon}\op\to\smcat^\sharp$, whose image is precisely those categories whose carriers are representable.
\end{proposition}
\begin{proof}
Given a monoid $(M,e,*)$, we think of it as a category with one object; its carrier $\yon^M$ is representable. A cofunctor between such categories carries no data in its on-objects part, and codomains are automatically preserved. Cofunctors $\yon^M\to\yon^N$ simply carry elements of $N$ to elements of $M$, preserving identity and composition, exactly the description of monoid homomorphisms.
\end{proof}

\begin{proposition}
There is an adjunction
\[
\smcat^\sharp(\cat{C},A\yon)\cong\smset(\Ob\cat{C},A)
\]
for $\cat{C}\in\smcat^\sharp$ and $A\in\smset$.
\end{proposition}

\begin{example}\label{ex.cof_to_rr}
Consider the category $\rr\yon^\rr$, where the codomain of $r$ emanating from $x$ is $x+r$, identities are $0$, and composition is given by addition. What are cofunctors into $\rr\yon^\rr$?

Let $\cat{C}$ be a category and $|\cdot|\colon\cat{C}\cof\rr\yon^\rr$ a cofunctor. It assigns to every object $c$ both a real number $|c|\in\rr$ and a choice of emanating morphism $|c|^\sharp(r)\colon c\to c_r$ such that $|c|+r=|c_r|$. This assignment satisfies some laws. Namely we have $c_0=c$ and, given reals $r,s\in\rr$, we have $(c_r)_s=c_{r+s}$. 
\end{example}

% ** Interpret above. Possible names: $(\rr,0,+)$-action on the objects of $\cat{C}$, filtration, valuation

\begin{exercise}
\begin{enumerate}
	\item Over two discrete objects $\{A,B\}$, how many cofunctors
    \[
        \yon^\2+\yon\cong\fbox{$A\to B$}\cof\fbox{$A\tto B$}\cong\yon^\3+\yon
    \]
    are there from the walking arrow category to the walking parallel-arrows category?
	\item What is meant more precisely by ``over two discrete objects $\{A,B\}$'' above?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
Let $\com{C}=(\ema{c},\epsilon,\delta)$ be a comonoid in $\poly$. We have a state category $\ema{c}(\1)\yon^{\ema{c}(\1)}$ on the set of objects of $\com{C}$. There is a map of polynomials $\ema{c}(\1)\yon^{\ema{c}(\1)}\to\ema{c}$ given by
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom] (s) {$\cod(m)$\at$i$};
	\node[poly, cod, right=of s] (c) {$m\vphantom{d}$\at$i$};
	\draw[double] (s_pos) -- (c_pos);
	\draw (c_dir) -- node[above] {$\cod$} (s_dir); 
\end{tikzpicture}
\]
for an object $i\in\ema{c}(\1)$ and an outgoing morphism $m\in\ema{c}[i]$. Is this map a cofunctor?
\begin{solution}
**
\end{solution}
\end{exercise}

\begin{example}[Canonical cofunctors from state categories]\label{ex.cof_from_state}
Let $\com{C}=(\ema{c},\epsilon,\delta)$ be a comonoid, where $\delta=(\id,\cod,\comp)$ as in \eqref{eqn.cod_comp}. For any position $i\in\ema{c}(\1)$, there is a cofunctor
\[
	(\cod,\comp)\colon\ema{c}[i]\yon^{\ema{c}[i]}\cof\ema{c}.
\]
That is, an object $f\in \ema{c}[i]$ is also a morphism in $\cat{C}$ and we send it to its codomain $\cod(f)$. A morphism in $\cat{C}$ emanating from $\cod(f)$ is passed back to its composite with $f$. 
\end{example}

\begin{exercise}
Suppose $\cat{C}=(\ema{c},\epsilon,\delta)$ is a comonoid.
\begin{enumerate}
	\item Show that the map $(\cod,\comp)\colon\ema{c}[i]\yon^{\ema{c}[i]}\cof\ema{c}$ from \cref{ex.cof_from_state} satisfies the conditions necessary for being a cofunctor (identities, codomains, and composites).
	\item Find a comonoid structure on the polynomial $p\coloneqq\sum_{i\in\ema{c}(\1)}\ema{c}[i]\yon^{\ema{c}[i]}$ and a cofunctor $p\to\ema{c}$.
	\item Is the polynomial map $p\to\ema{c}$ an epimorphism?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
Suppose $\ema{c},\ema{d},\ema{e}$ are polynomials, each with a comonoid structure, and that $f\colon \ema{c}\to\ema{d}$ and $g\colon\ema{d}\to\ema{e}$ are maps of polynomials.
\begin{enumerate}
	\item If $f$ and $f\then g$ are each cofunctors, is $g$ automatically a cofunctor? If so, sketch a proof; if not sketch a counterexample.
	\item If $g$ and $f\then g$ are each cofunctors, is $f$ automatically a cofunctor? If so, sketch a proof; if not sketch a counterexample.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
\begin{enumerate}
	\item For any category $\cat{C}$ with carrier $\ema{c}$, find a category with carrier $\ema{c}\yon$.
	\item Show your construction is functorial; i.e.\ given a cofunctor $\ema{c}\cof\ema{d}$, find one $\ema{c}\yon\cof\ema{d}\yon$, preserving identity and composition.
	\item Is your functor either a monad or a comonad on $\smcat^\sharp$?
	\item What category do you get by repeatedly applying this functor to $\yon$?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
Are cofunctors between posets interesting?
\begin{enumerate}
	\item Consider the chain poset $[n]\cong\sum_{i=1}^n\yon^i$. How many cofunctors are there from $[m]\to[n]$ for all $m,n\in\{0,1,2,3\}$?
	\item What does a cofunctor from $\yon$ into a poset represent? Is there anything you'd call ``asymmetric'' about it?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
\begin{enumerate}
	\item What is the finite set $\{\com{Q}_1,\ldots,\com{Q}_n\}$ of comonoids (defined up to isomorphism) for which the carrier polynomial is $\yon^\2+\yon$?
	\item For each category $\com{Q}_i$, describe how to imagine a cofunctor $\com{C}\to\com{Q}_i$ from an arbitrary category into it.
	\item What cofunctors exist between the various $\com{Q}_i$?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
Let $S$ be a set. Describe a way to visualize cofunctors from categories into the state category $S\yon^S$. Feel free to focus on the case where $S$ is a small finite set.
(Hint: Use \cref{prop.cofunctors_isos}.)
\begin{solution}
**
\end{solution}
\end{exercise}

\begin{exercise}
\begin{enumerate}
	\item Recall the star-shaped category $\yon^{\ord{n}+\1}+\ord{n}\yon$ from \cref{ex.star_shaped}. Describe cofunctors into it.
	\item Describe cofunctors into $A\yon$ for a set $A$.
	\item Describe cofunctors into $(\nn,\leq)$.
	\item Describe cofunctors into $(\nn,\geq)$.
	\item Let $\yon^\4+2\yon^\2+\yon$ denote the commutative square category. List the cofunctors from it to the walking arrow category $\yon^\2+\yon$? There should be six or so.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{example}[Objects aren't representable in $\smcat^\sharp$]\label{ex.rep_objects}
For categories and ordinary functors, there is a category $\cat{T}$ that \emph{represents objects}, in the sense that functors $\cat{T}\to\cat{C}$ are the same as objects in $\cat{C}$; indeed, take $\cat{T}=\fbox{$\bullet$}$ to be the terminal (one morphism) category.

This does not work for cofunctors, as we'll see in \cref{exc.rep_objects}. The comonoid corresponding to $\cat{T}$ is $\yon$ with its unique comonoid structure. Cofunctors $\cat{T}\cof\cat{C}$ are somewhat strange beasts: they can be identified with objects $c\in\cat{C}$ for which the codomain of every emanating morphism $c\to c'$ is $c'=c$ itself. The reason is the codomain condition (\cref{def.cofunctor}, condition 2).
\end{example}

\begin{exercise}\label{exc.rep_objects}
We saw in \cref{exc.linear_poly_comon} that $\2\yon$ has a unique comonoid structure.
\begin{enumerate}
	\item Show that for any category $\cat{T}$, there are $2^{\#\Ob\cat{T}}$-many cofunctors $\cat{T}\cof\2\yon$.
	\item Use the case of $\cat{C}\coloneqq\2\yon$ to show that if a category $\cat{T}$ is going to represent objects as in \cref{ex.rep_objects} then $\cat{T}$ must have one object.
	\item Now use a different $\cat{C}$ to show that if a category $\cat{T}$ is going to represent objects, it must have more than one object.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{example}[Policies are co-representable]\label{ex.trajectories_corep}
For a category $\cat{C}$, let's say that a \emph{policy in $\cat{C}$} is a choice, for each object $c\in\cat{C}$, of an emanating morphism $f\colon c\to c'$. For example, consider the category $(\nn,\leq)\times(\nn,\leq)$:
\[
\begin{tikzpicture}[shorten <=4pt, shorten >=4pt]
	\foreach \i in {0,1,2,3} 
	{
		\foreach \j in {0,1,2}
		{
			\node (\i\j) at (\i,\j) {$\bullet$};
			\draw[->] (\i,\j) -- (\i+1,\j);
			\draw[->] (\i,\j) -- (\i,\j+1);
		};
	};
	\begin{scope}[red, thick]
		\draw[->] (0,0) -- (0,1);
		\draw[->] (0,1) -- (1,3);
		\draw[->] (0,2) -- (1,2);
		\draw[->] (1,0) -- (1,1);
		\draw[->] (1,1) edge[in=30, out=60, loop] (1,1);
		\draw[->] (1,2) -- (2,2);
		\draw[->] (2,0) to[bend right] (2,2);
		\draw[->] (2,1) -- (2,2);
		\draw[->] (2,2) -- (3,2);
		\draw[->] (3,0) -- (3,1);
		\draw[->] (3,1) -- (3,2);
		\draw[->] (3,2) edge[in=30, out=60, loop] (3,2);
	\end{scope}
\end{tikzpicture}
\]
In red we have drawn a policy: every object has been assigned an emanating morphism to another object; there doesn't need to be any rhyme or reason to our choice.

For any category $\cat{C}$, the set of trajectories in $\cat{C}$ is in bijection with the set of cofunctors
\[
\cat{C}\cof\cat{N}
\]
where $\cat{N}=\yon^\nn$ is the monoid of natural numbers under addition.
\end{example}

\begin{exercise}
At the end of \cref{ex.trajectories_corep} we said that a policy on $\cat{C}$ can be identified with a cofunctor $F\colon\cat{C}\cof\cat{N}$. But at first it appears that $F$ includes more than just a policy: for every object $c\in\Ob\cat{C}$ and natural number $n\in\nn$, we have a morphism $F^\sharp_c(n)$ emanating from $c$. That's infinitely many emanating morphisms per object, whereas a policy seems to include only one emanating morphism per object.

Explain why looks are deceiving in this case: why is a policy on $\cat{C}$ the same as a cofunctor $\cat{C}\cof\cat{N}$?
\begin{solution}
**
\end{solution}
\end{exercise}

We will see later in \cref{prop.traj_mon_poly} that the trajectories on a category form a monoid, and that this operation $\smcat^\sharp\to\Cat{Mon}\op$ is functorial and in fact an adjoint.

\begin{exercise}[Continuous trajectories]
Suppose we say that a continuous policy in $\cat{C}$ is a cofunctor $\cat{C}\cof\cat{R}$, where $\cat{R}$ is the monoid of real numbers under addition, considered as a category with one object. 

Describe continuous trajectories in $\cat{C}$ using elementary terms, i.e.\ to someone who doesn't know what a cofunctor is and isn't yet ready to learn.
\begin{solution}
**
\end{solution}
\end{exercise}

\begin{exercise}
Let $\rr/\zz\cong[0,1)$ be the quotient of $\rr$ by the $\zz$-action sending $(r,n)\mapsto r+n$. More down to earth, it's the set of real numbers between 0 and 1, including 0 but not 1.%]
\begin{enumerate}
	\item Find a comonoid structure on $(\rr/\zz)\yon^\rr$.
	\item Is it a groupoid?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

%** related to earlier iso exercise
\begin{exercise}
\begin{enumerate}
	\item Is it true that for any two categories $\cat{C},\cat{D}$, there is a bijection between the set of isomorphisms $\cat{C}\To{\cong}\cat{D}$ in $\smcat$ and the set of isomorphisms $\cat{C}\overset{\cong}{\cof}\cat{D}$ between them in $\smcat^\sharp$?
	\item If so, prove it; if not, give a counterexample.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}




% **displaced content here
\begin{exercise}[Monoid actions]
Suppose that $(M,e,*)$ is a monoid, $S$ is a set, and $\alpha\colon M\times S\to S$ is an $M$-action.
Show that the projection $S\yon^M\to\yon^M$ is a comonoid homomorphism.
\begin{solution}
We are given a monoid $(M,e,*)$, a set $S$, and an $M$-action $\alpha\colon M\times S\to S$.
**
\end{solution}
\end{exercise}


\subsubsection{Very well-behaved lenses}

In the functional programming community, there is an important notion of very well-behaved lenses.
These turn out to be precisely the cofunctors between state categories.
Since state categories $S\yon^S$ play an important role in our theory, we take a bit of time to consider cofunctors between them.

\begin{example}[Very well-behaved lenses]\label{ex.well_behaved}
Recall from \cref{ex.state_comonad_1} that for any set $S$, we have the ``state'' category with carrier $S\yon^S$. What are the comonoid morphisms---cofunctors---between different state categories?

First, such a comonoid morphism includes a morphism of polynomials $f\colon S\yon^S\to T\yon^T$; we'll use the standard terminology of ``get'' and ``put'':
\[
\begin{tikzpicture}[polybox, tos]
	\node[poly, dom] (s) {};
	\node[poly, cod, right=of s] (t) {};
	\node[left=0pt of s_pos] {$S$};
	\node[left=0pt of s_dir] {$S$};
	\node[right=0pt of t_pos] {$T$};
	\node[right=0pt of t_dir] {$T$};
	%
	\draw (s_pos) to[first] node[below] {$\lensget$} (t_pos);
	\draw (t_dir) to[last] node[above] {$\lensput$} (s_dir);
\end{tikzpicture}
\]
Let's apply the unit-homomorphism property \eqref{eqn.pres_era_draw}
\[
\begin{tikzpicture}
	\node (id1) {
	\begin{tikzpicture}[polybox, tos]
  	\node[poly, dom] (s) {put$($get$(s))$\at$s\vphantom{(}$};
  	\node[poly, right=of s] (t) {get$(s$)\at get$(s$)};
  	%
  	\draw (s_pos) to[first] node[below] {get} (t_pos);
  	\draw (t_dir) to[last] node[above] {put} (s_dir);
  	\draw (t_pos) to[climb'] (t_dir);
	\end{tikzpicture}
	};
	\node[right=of id1] (id2) {
	\begin{tikzpicture}[polybox, tos]
		\node[poly, dom] (s) {$s$\at$s$};
		\draw (s_pos) to[climb'] (s_dir);
	\end{tikzpicture}	
	};
	\node at ($(id1.east)!.5!(id2.west)-(0,6pt)$) {$=$};
\end{tikzpicture}
\]
It says that $\lensput(\lensget(s))=s$. This is typically called the get-put law.

We leave the duplicator-homomorphism law to \cref{exc.well_behaved}, where we will see that it specifies that get and put must satisfy two other properties, called the put-put and the put-get laws.
\end{example}

\begin{exercise}\label{exc.well_behaved}
Complete \cref{ex.well_behaved}.
\begin{enumerate}
	\item Write out the duplicator law from \eqref{eqn.pres_era_draw} in terms of polyboxes.
	\item What set-theoretic equations are forced by the duplicator law?
	\item Can you see why they might be called put-put and put-get?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{example}[Very well-behaved lenses are kinda boring]\label{ex.well_behaved_boring}
We saw in \cref{exc.well_behaved} that a comomonoid homomorphism (cofunctor) $S\yon^S\cof T\yon^T$ between state comonoids can be characterized as a pair of functions $\lensget\colon S\to T$ and $\lensput\colon S\times T\to S$ satisfying get-put, put-get, and put-put. 

In fact, it turns out that this happens if and only if $\lensget$ is a product projection! For example, if the cardinalities $|S|$ and $|T|$ of $S$ and $T$ are finite and $|S|$ is not divisible by $|T|$, then there are no cofunctors $S\yon^S\cof T\yon^T$. A stringent condition, no? We'll explore it in  \cref{exc.how_many_vwbls} below.

Let's explain why cofunctors between state categories are just product projections. A product projection $A\times B\to A$ always has another factor ($B$); if every cofunctor between state categories is a product projection, what is the other factor? It turns out that the other factor will be:
\[
F\coloneqq\{f\colon T\to S\mid \forall t\in T,\;\lensget(f(t))=t\text{ and }\lensput(f(t),t)=f(t)\}.
\]
In other words we will see that if $(\lensget,\lensput)$ is a comonoid homomorphism then there is a bijection $S\cong T\times F$ and that $\lensget\colon S\to T$ is one of the projections. We will see that the converse is true in \cref{exc.well_behaved_boring}

So assume $(\lensget,\lensput)\colon S\yon^S\cof T\yon^T$ is a comonoid homomorphism, in particular that it satisfies put-get, get-put, and put-put. We obtain a function $\pi\colon S\to T\times F$ given by
\[s\mapsto\big(\lensget(s),t\mapsto\lensput(s,t)\big)\]
and it is well-defined since for all $s\in S$ and $t,t'\in T$ we have $\lensget(\lensput(s,t))=t$ by put-get and $\lensput(\lensput(s,t),t')=\lensput(s,t')$ by put-put. We also obtain a function $\pi'\colon T\times F\to S$ given by
\[
(t,f)\mapsto f(t).
\]
The two functions $\pi,\pi'$ are mutually inverse: the roundtrip on $S$ is identity because $\lensput(s,\lensget(s))=s$ by get-put; the roundtrip on $T\times F$ is identity because $\lensget(f(t))=t$ and $\lensput(f(t),t)=f(t)$ by assumption on $f\in F$.
\end{example}

\begin{exercise}\label{exc.well_behaved_boring}
Let $S,T,F$ be sets and suppose given an isomorphism $\alpha\colon S\to T\times F$.
\begin{enumerate}
	\item Show that there exists a very well behaved lens $\lensget\colon S\to T$ and $\lensput\colon S\times T\to S$.
	\item Show that there exists a cofunctor between the state category on $S$ and the state category on $T$.
	\item Show that there exists a comonoid homomorphism $S\yon^S\to T\yon^T$ between the state comonoids.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}\label{exc.how_many_vwbls}
\begin{enumerate}
	\item Suppose $|S|=3$. How many cofunctors are there $S\yon^S\to S\yon^S$?
	\item Suppose $|S|=4$ and $|T|=2$. How many cofunctors are there $S\yon^S\cof T\yon^T$?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
Let $S,T$ be sets and $\lensget\colon S\to T$ and $\lensput\colon S\times T\to S$ the parts of a very well behaved lens, i.e.\ a cofunctor $S\yon^S\to T\yon^T$ between state categories. Is it possible that $\lensput\colon S\times T\to S$ is itself a product projection, i.e.\ sends $(s,t)\mapsto s$?
\begin{solution}
**
\end{solution}
\end{exercise}

When we get to cofree comonoids, we'll obtain a whole new class of cofunctors that are interesting to consider. But for now, we move on to more theory.

% %-------- Section --------%

\section{Some categorical properties of $\smcat^\sharp$} %** more precise title??
Henceforth we will identify the category $\smcat^\sharp$ with the isomorphic category $\comon(\poly)$, eliding the difference between comonoids in $\poly$ and categories.
% ** more intro---what is all this?

% ** You may notice that the content of this section mirrors that of \cref{**chapter 4**}; indeed, the comonoid category $\cat^\sharp$ inherits much of the categorical structure of $\poly$.

%---- Subsection ----%
\subsection{Coproducts in $\smcat^\sharp$}

\begin{proposition}
The coproduct of polynomial comonoids in $\smcat^\sharp$ agrees with the coproduct of categories in $\smcat$, and its carrier agrees with the coproduct of carriers in $\poly$.
In particular, the unique comonoid carried by $\0$ is initial in $\smcat^\sharp$.
\end{proposition}
\begin{proof}
We defer the proof of the claim about $\0$ to \cref{exc.0_initial_com}.

Let $I$ be a set and $(\cat{C}_i)_{i\in I}$ be categories with carriers $(\ema{c}_i)_{i\in I}$.
Then the coproduct of $(\cat{C}_i)_{i\in I}$ in $\smcat$ is the category $\sum_{i\in I}\cat{C}_i$, whose objects are given by the disjoint union of the objects in each summand, so that
\[
    \Ob\left(\sum_{i\in I}\cat{C}_i\right)\iso\sum_{i\in I}\Ob\cat{C}_i=\sum_{i\in I}\ema{c}_i(\1)\iso\left(\sum_{i\in I}\ema{c}_i\right)(\1),
\]
and whose morphisms out of each $c\in\Ob\cat{C}_j\ss\Ob\sum_{i\in I}\cat{C}_i$ are just the morphisms out of $c$ in the summand $\cat{C}_j$, so
\[
    \left(\sum_{i\in I}\cat{C}_i\right)[c]\iso\cat{C}_j[c]=\ema{c}_j[c]\iso\left(\sum_{i\in I}\ema{c}_i\right)[c]
\]
Hence $\sum_{i\in I}\cat{C}_i$ is carried by the coproduct of polynomials $\sum_{i\in I}\ema{c}_i$.

% ** give inclusions as cofunctors

It remains to show that $\sum_{i\in I}\cat{C}_i$ is also the coproduct of $(\cat{C}_i)_{i\in I}$ in $\smcat^\sharp$.
For each $j\in J$, we define an inclusion cofunctor $\iota_j\colon\cat{C}_j\cof\sum_{i\in I}\cat{C}_i$ as follows: it is the canonical inclusion on objects, **. %**show all fully faithful functors can be interp as cofunctors first??

Suppose we have a category $\cat{D}$ and cofunctors $F_i\colon\cat{C}_i\cof\cat{D}$ for $i\in I$.
For every object $c\in\Ob\cat{C}_j\ss\Ob\sum_{i\in I}\cat{C}_i$, we have an object $F_j c\in\Ob\cat{D}$, so we can set $Fc\coloneqq F_j c$.
Then for every morphism $g\colon Fc\to\_$ in $\cat{D}$, we have a morphism $\left(F_j\right)^\sharp_c g\colon c\to\_$, so we can set $F^\sharp_c g\coloneqq\left(F_j\right)^\sharp_c g$.
As each $F_j$ satisfies the cofunctor laws, so does $F$.

% ** check cofunctor laws
% ** check commutes
% ** check uniqueness


It is easy to check that the cofunctor laws hold for $f$. Uniqueness of $f$ given $f_1,f_2$ is also straightforward.
\end{proof}

\begin{exercise}\label{exc.0_initial_com}
\begin{enumerate}
	\item Show that $\0$ has a unique comonoid structure.
	\item Show that $\0$ with its comonoid structure is initial in $\smcat^\sharp$.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item We actually already showed that $\0$ has a unique comonoid structure, corresponding to the empty category (which we will also denote by $\0$), in \cref{exc.not_state_cat_but_same_carrier}, for the case of $S\coloneqq\0$.
    \item For any category $\cat{D}$, there is a unique cofunctor $\0\cof\cat{D}$: it vacuously sends each object in $\0$ to an object in $\cat{D}$, and since there are no objects in $\0$, it does nothing to morphisms.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
Given a comonoid $(\ema{c},\epsilon,\delta)\in\smcat^\sharp$, show that there is an induced comonoid structure on the polynomial $\2\ema{c}$.
\begin{solution}
** % sum with itself
\end{solution}
\end{exercise}

\begin{exercise}
\begin{enumerate}
	\item Show that $\yon$ has a unique comonoid structure.
	\item Show that $\yon$ with its comonoid structure is terminal in $\smcat^\sharp$.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item We actually already showed that $\yon$ has a unique comonoid structure, corresponding to the category with $1$ object and no nonidentity morphisms (which we will also denote by $\yon$), in \cref{exc.not_state_cat_but_same_carrier}, for the case of $S\coloneqq\1$.
    \item For any category $\cat{C}$, there is a unique cofunctor $\cat{C}\cof\yon$: it sends every object in $\cat{C}$ to the only object in $\yon$, and it sends the only morphism in $\yon$, an identity morphism, to each identity morphism in $\cat{C}$.
\end{enumerate}
\end{solution}
\end{exercise}

%---- Subsection ----%
\subsection{Special categories and adjunctions}

\begin{proposition}
Let $\smcat^\sharp_{\text{rep}}$ be the full subcategory of $\smcat^\sharp$ consisting of categories with representable carriers $\yon^M$ for some $M\in\smset$.
Then there is an isomorphism of categories
\[
    \smcat^\sharp_{\text{rep}}\iso\Cat{Mon}\op,
\]
where $\Cat{Mon}$ is the category of monoids and monoid homomorphisms.
\end{proposition}
\begin{proof}
Let $\cat{C}$ be a category. It has only one object iff its carrier $\ema{c}$ has only one position, i.e.\ $\ema{c}\cong\yon^M$ for some $M\in\smset$, namely where $M$ is the set of morphisms in $\cat{C}$. It remains to show that cofunctors between monoids are dual---opposite---to morphisms between monoids.

A cofunctor $f\colon\yon^M\to\yon^N$ involves a single function $f^\sharp\colon N\to M$ that must satisfy a law coming from unitality and one coming from composition, as in \cref{def.morphism_comonoids}. The result can now be checked by hand, or seen formally as follows. Each object in the two diagrams of \eqref{def.morphism_comonoids} is representable by \cref{exc.composites_of_specials}. The Yoneda embedding $\smset\op\to\poly$ is fully faithful, so these two diagrams are equivalent to the unit and composition diagrams for monoid homomorphisms.
\end{proof}

\begin{exercise}\label{exc.lin_comon_set}
Let $\smcat^\sharp_{\text{lin}}$ be the full subcategory of $\smcat^\sharp$ consisting of categories with linear carriers $S\yon$ for some $S\in\smset$.
Show that there is an isomorphism of categories
\[
\smcat^\sharp_{\text{lin}}\iso\smset.
\qedhere
\]
\begin{solution}
**
\end{solution}
\end{exercise}

\begin{proposition}
The inclusion $\smcat^\sharp_{\text{lin}}\to\smcat^\sharp$ has a left adjoint sending each $(\ema{c},\epsilon,\delta)\in\smcat^\sharp$ to the unique comonoid carried by $(\ema{c}\tri\1)\yon$ in $\smcat^\sharp_{\text{lin}}$.
\end{proposition}
\begin{proof}
We need to show that for any comonoid $(\ema{c},\epsilon,\delta)$ and set $A$, we have a natural isomorphism
\[
  \smcat^\sharp(\ema{c},A\yon).
  \cong^?
  \smcat^\sharp((\ema{c}\tri\1)\yon,A\yon)
\]
But every morphism in $A\yon$ is an identity, so the result follows from the fact that every cofunctor must pass identities back to identities. 
\end{proof}

%---- Subsection ----%
\subsection{Vertical-cartesian factorization in $\smcat^\sharp$}

A cofunctor is called \emph{cartesian} if the underlying lens $f\colon\ema{c}\to\ema{d}$ is cartesian (i.e.\ for each position $i\in\ema{c}(\1)$, the map $f^\sharp_i\colon\ema{d}[f_1(i)]\to\ema{c}[i]$ is an isomorphism). %** refer back to earlier section where we defined this...also vertical cartesian...and make this its own section

\begin{proposition}\label{prop.factor_cofunctor}
Every cofunctor $f\colon\cat{C}\cof\cat{D}$ factors as a vertical morphism followed by a cartesian morphism
\[
\cat{C}\overset{\text{vert}}{\cof}\cat{C}'\overset{\text{cart}}{\cof}\com{D}.
\]
\end{proposition}
\begin{proof}
A cofunctor $\cat{C}\cof\cat{D}$ is a map of polynomials $\ema{c}\to\ema{d}$ satisfying some properties, and any map of polynomials $f\colon\ema{c}\to\ema{d}$ can be factored as a vertical morphism followed by a cartesian morphism
\[
	\ema{c}\To{g}\ema{c'}\To{h}\ema{d}.
\]
For simplicity, assume $g_1\colon\ema{c}(\1)\to\ema{c'}(\1)$ is identity (rather than merely isomorphism) on positions and similarly that for each $i\in\ema{c}$ the map $h^\sharp_i\colon\ema{c'}[i]\to\ema{d}[h_1(i)]$ is identity (rather than merely isomorphism) on directions. 

It suffices to show that the intermediate object $\ema{c'}$ can be endowed with the structure of a category such that $g$ and $h$ are cofunctors. Given an object $i\in\ema{c'}(\1)$, assign its identity to be the identity on $h_1(i)=f(i)$; then both $g$ and $h$ preserve identities because $f$ does. Given an emanating morphism $m\in\ema{c'}[i]=\ema{d}[f(i)]$, assign its codomain to be $\cod(m)\coloneqq\cod(f^\sharp_i(m))$, and given an emanating morphism $m'\in\ema{c'}[\cod(m)]$, assign the composite $m\then m'$ in $\ema{c'}$ to be $m\then m'$ in $\ema{d}$. In \cref{exc.factor_cofunctor} we will check that with these definitions, $\ema{c'}$ is a category and both $g$ and $h$ are cofunctors.
\end{proof}

\begin{exercise}\label{exc.factor_cofunctor}
We will complete the proof of \cref{prop.factor_cofunctor}, using the same notation.
\begin{enumerate}
	\item Show that composition is associative and unital in $\ema{c'}$.
	\item Show that $g$ preserves codomains.
	\item Show that $g$ preserves compositions.
	\item Show that $h$ preserves codomains.
	\item Show that $h$ preserves compositions.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}


\begin{proposition}
The wide subcategory of cartesian maps in $\smcat^\sharp$ is isomorphic to the category of wide subcategory of discrete opfibrations in $\smcat$.
\end{proposition}
\begin{proof}
Suppose that $\cat{C}$ and $\cat{D}$ are categories. Both a functor and a cofunctor between them involve a map on objects, say $f\colon\Ob\cat{C}\to\Ob\cat{D}$. For any object $c\in\Ob\cat{C}$, a functor gives a function, say $f_\sharp\colon\cat{C}[c]\to\cat{D}[f(c)]$ whereas a cofunctor gives a function $f^\sharp\colon\cat{D}[f(c)]\to\cat{C}[c]$. The cofunctor is cartesian iff $f^\sharp$ is an iso, and the functor is a discrete opfibration iff $f_\sharp$ is an iso. We thus transform our functor into a cofunctor (or vice versa) by taking the inverse function on morphisms. It is easy to check that this inverse appropriately preserves identities, codomains, and compositions.
\end{proof}

\begin{proposition}\label{prop.com_vert_cat_boo}
The wide subcategory of vertical maps in $\smcat^\sharp$ is isomorphic to the opposite of the wide subcategory bijective-on-objects maps in $\smcat$:
\[
\smcat^\sharp_{\text{vert}}\cong(\smcat_{\text{boo}})\op.
\]
\end{proposition}
\begin{proof}
Let $\cat{C}$ and $\cat{D}$ be categories. Given a vertical cofunctor $F\colon\cat{C}\cof\cat{D}$, we have a bijection $F_1\colon\Ob\cat{C}\to\Ob\cat{D}$; let $G_1$ be its inverse. We define a functor $G\colon\cat{D}\to\cat{C}$ on objects by $G_1$ and, for any $f\colon d\to d'$ in $\cat{D}$ we define $G(f)\coloneqq F^\sharp_{G_1(d)}$. It has the correct codomain: $\cod(G(f))=G_1(F_1(\cod(G(f)))=G_1(\cod f)$. And it sends identities and compositions to identities and compositions by the laws of cofunctors.

The construction of a vertical cofunctor from a bijective-on-objects functor is analogous, and it is easy to check that the two constructions are inverses.
\end{proof}

\begin{exercise}
Let $S$ be a set and consider the state category $\cat{S}\coloneqq(S\yon^S,\epsilon,\delta)$. Use \cref{prop.com_vert_cat_boo} to show that categories $\cat{C}$ equipped with a vertical cofunctor $\cat{S}\to\cat{C}$ can be identified with categories whose set of objects is $S$.
\begin{solution}
**
\end{solution}
\end{exercise}

\begin{exercise}
Consider the categories $\cat{C}\coloneqq\fbox{$\bullet\tto\bullet$}$ and $\cat{D}\coloneqq\fbox{$\bullet\to\bullet$}$. There is a unique bijective-on-objects (boo) functor $F\colon\cat{C}\to\cat{D}$ and two boo functors $G_1,G_2\colon\cat{D}\to\cat{C}$.
\begin{enumerate}
	\item Write down the morphism $\ema{d}\to\ema{c}$ of carriers underlying $F$.
	\item Write down the morphism $\ema{c}\to\ema{d}$ of carriers underlying either $G_1$ or $G_2$.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

%---- Subsection ----%
\subsection{Parallel products in $\smcat^\sharp$ are products in $\smcat$}

The usual product of categories is not the categorical product in $\smcat^\sharp$. %**show this
It is, however, a \emph{monoidal} product on $\smcat^\sharp$, coinciding with the parallel product $\otimes$ on $\poly$.

\begin{proposition}\label{prop.dirichlet_on_catsharp}
The parallel product $(\yon,\otimes)$ on $\poly$ extends to a monoidal structure $(\yon,\otimes)$ on $\smcat^\sharp$, such that the forgetful functor
$U\colon\smcat^\sharp\to\poly$
is strong monoidal with respect to $\otimes$.
The parallel product of two categories is their product in $\smcat$.
\end{proposition}
\begin{proof}
Given $(\ema{c},\epsilon_{\ema c},\delta_{\ema c}),(\ema{d},\epsilon_{\ema d},\delta_{\ema d})\in\smcat^\sharp$, 

be categories corresponding to comonoids $(\ema{c},\epsilon_{\ema c},\delta_{\ema c})$ and $(\ema{d},\epsilon_{\ema d},\delta_{\ema d})$.



The carrier of $\cat{C}\otimes\cat{D}$ is defined to be $\ema{c}\otimes\ema{d}$. A position in it is a pair $(c,d)$ of objects, one from $\cat{C}$ and one from $\cat{D}$; a direction there is a pair $(f,g)$ of a morphism emanating from $c$ and one emanating from $d$. 

We define $\epsilon_{\cat{C}\otimes\cat{D}}\colon\ema{c}\otimes\ema{d}\to\yon$ as
\[
\ema{c}\otimes\ema{d}\To{\epsilon_{\ema{C}}\otimes\epsilon_{\ema{D}}}\yon\otimes\yon\cong\yon.
\]
This says that the identity at $(c,d)$ is the pair of identities.

We define $\delta_{\cat{C}\otimes\cat{D}}\colon(\ema{c}\otimes\ema{d})\to(\ema{c}\otimes\ema{d})\tri(\ema{c}\otimes\ema{d})$ using the duoidal property:
\[
\ema{c}\otimes\ema{d}\To{\delta_{\ema{c}}\otimes\delta_{\ema{d}}}(\ema{c}\tri\ema{c})\otimes(\ema{d}\tri\ema{d})\to(\ema{c}\otimes\ema{d})\tri(\ema{c}\otimes\ema{d}).
\]
One can check that this says that codomains and composition are defined coordinate-wise, and that $(\ema{c}\otimes\ema{d},\epsilon_{\ema{c}\otimes\ema{d}},\delta_{\ema{c}\otimes\ema{d}})$ forms a comonoid. One can also check that this is functorial in $\cat{C},\cat{D}\in\smcat^\sharp$. See \cref{exc.dirichlet_on_catsharp}.
\end{proof}

\begin{exercise}\label{exc.dirichlet_on_catsharp}
We complete the proof of \cref{prop.dirichlet_on_catsharp}.
\begin{enumerate}
	\item Show that $(\ema{c}\otimes\ema{d},\epsilon_{\ema{c}\otimes\ema{d}},\delta_{\ema{c}\otimes\ema{d}})$, as described in \cref{prop.dirichlet_on_catsharp}, forms a comonoid.
	\item Check that the construction $(\cat{C},\cat{D})\mapsto\cat{C}\otimes\cat{D}$ is functorial in $\cat{C},\cat{D}\in\smcat^\sharp$.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}
%
%As everyone reading this is probably aware, strict monoidal structure on a category $\cat{C}$ is a functor $1\to\cat{C}$ and a functor $\cat{C}\times\cat{C}\to\cat{C}$ that together satisfy the monoid equations. Here the $\times$ takes place in $\smcat$. 
%
%If we replace $(\smcat,\1,\times)$ with $(\smcat^\sharp,\yon,\otimes)$, then a monoid is a cofunctor $\intercal\colon\yon\cof\cat{C}$, which we call the \emph{terminus}, and a cofunctor $\curlyvee\colon\cat{C}\otimes\cat{C}\cof\cat{C}$, which we call the \emph{team-up product} satisfying the monoid equations. Let's call these $\otimes$-monoids in $\smcat^\sharp$. 
%
%It appears that $\otimes$-monoids $(\cat{C},\intercal,\curlyvee)$ in $\smcat^\sharp$ could be interesting for thinking about the dynamics of something like ``swarms'': collections of dynamical systems that work very well together as a population. Indeed, $\curlyvee$ takes a pair of objects $c_1,c_2$ and returns a single object $c_1\curlyvee c_2$, but it takes a morphism $f\colon c_1\curlyvee c_2\to d$ emanating that object to a pair of morphisms $f_1\colon c_1\to d_1$ and $f_2\colon c_2\to d_2$ with $d_1\curlyvee d_2=d$.
%
%
%\begin{example}[Representable and linear $\otimes$-monoids]
%Representable polynomials have at most one commutative $\otimes$-monoid structure by a theorem of Fox. Category (polynomial comonoid) structures on a representable polynomial $\yon^M$ are just monoid structures on its underlying set $M$. So a commutative monoid $(M,e,*)$ in $\smset$ can be identified with a $\otimes$-monoid in $\smcat^\sharp$ that has carrier $\yon^M$.
%
%A $\otimes$-monoidal structure on a linear $M\yon$ polynomial, on the other hand, can be identified with a monoid structure $(M,e,*)$ on the set $M$. But there is a unique comonoid structure on $M\yon$. So a monoid in $\smset$ can be identified with a $\otimes$-monoid in $\smcat^\sharp$ having carrier $M\yon$.
%\end{example}
%
%\begin{example}\label{ex.monaco_cat}
%Consider the comonoid $\com{C}=(\ema{c},0,+)$ corresponding to the category
%\[
%\fbox{
%\begin{tikzcd}[ampersand replacement=\&]
%	\cdots\ar[r, "-1"']\&
%	\LMO{n}\ar[r, "-1"']\&
%	\cdots\ar[r, "-1"']\&
%	\LMO{2}\ar[r, "-1"']\&
%	\LMO{1}\ar[r, "-1"']\&
%	\LMO{0}
%\end{tikzcd}
%}
%\]
%It is carried by the polynomial $\ema{c}\coloneqq\sum_{n\in\nn}\yon^{\{0,-1,-2\ldots,-n\}}\cong\yon+\yon^\2+\yon^\3+\cdots$, its codomain map is given by $(n,-i)\mapsto n+(-i)$ and its eraser and duplicator are given by $0$ and addition.
%
%This comonoid has a (non-symmetric) $\otimes$-monoid structure. Namely its terminus is $0$ and its team-up product $\curlyvee$ on an object $(n_1,n_2)$ is given by
%\[
%\curlyvee_1(n_1,n_2)\coloneqq n_1+n_2,\]
%and on a morphism $-n_1-n_2\leq i\leq 0$ works as follows:
%\[
%\curlyvee^\sharp_{n_1+n_2}(i)\coloneqq	\big(\min(n_1,n_1+n_2+i),\max(0,n_2+i)\big)
%\]
%For example, say $n_1=3$ and $n_2=2$, so $\curlyvee_1(n_1,n_2)=5$. Let's pick $-5\leq i\geq 0$. 
%\[
%\begin{array}{c|c}
%	i&\curlyvee^\sharp(i)\\\hline
%	0&(3,2)\\
%	1&(3,1)\\
%	2&(3,0)\\
%	3&(2,0)\\
%	4&(1,0)\\
%	5&(0,0)
%\end{array}
%\]
%\end{example}
%
%\begin{exercise}
%Let $\com{C}$ be the comonoid from \cref{ex.monaco_cat}. We need to check that everything works correctly.
%\begin{enumerate}
%	\item Check that the terminus $\intercal\colon\yon\to\com{C}$ is a cofunctor.
%	\item Check that $\curlyvee$ preserves identities.
%	\item Check that $\curlyvee$ preserves codomains and compositions, and hence is a cofunctor.
%\qedhere
%\end{enumerate}
%\end{exercise}
%
%\begin{exercise}
%Consider the polynomial
%\[
%  c\coloneqq
%  \sum_{n\in\nn}\sum_{\ell\colon\ord{n}\to\nn}
%  \yon^{\{\ell'\colon\ord{n}\to\nn\;\mid\; \ell'\leq\ell\}}
%\]
%A position in $c$ is a list of natural numbers, and a direction is a smaller list. 
%\begin{enumerate}
%	\item Find a comonoid structure on $c$.
%	\item Find a $\otimes$-monoid structure $(\intercal,\curlyvee)$ on the comonoid you just found. (If you can't, start over.)
%\qedhere
%\end{enumerate}
%\end{exercise}
%
%\begin{exercise}
%Every $\otimes$-monoid in $\smcat^\sharp$ has an underlying category. This forgetful functor has a left adjoint: to every category $\cat{C}\in\smcat^\sharp$ we can assign a \emph{free} $\otimes$-monoid.
%\begin{enumerate}
%	\item Make the above claim precise, but don't prove it yet.
%	\item We propose that if the carrier of $\cat{C}$ is $\ema{c}$ then the free $\otimes$-monoid on it has carrier $\ema{L_c}$ given by
%	\[
%	\ema{L_c}\coloneqq\sum_{[\ell_1,\ldots,\ell_n]\in\Set{List}(\ema{c}(\1))}\yon^{\ema{c}[\ell_1]\times\cdots\times\ema{c}[\ell_n]}.
%	\]
%	This is supposed to be a comonoid in $\poly$; what should be the identities, codomains, and composition?
%	\item	Propose a terminus $\intercal\colon\yon\to\ema{L_c}$.
%	\item Propose a team-up product $\curlyvee\colon\ema{L_c}\otimes\ema{L_c}\to\ema{L_c}$.
%	\item Does it look promising that these will satisfy the monoid laws?
%	\item Sketch an argument that this construction is left adjoint to the forgetful functor sending a $\otimes$-monoid in $\smcat^\sharp$ to its underlying category.
%\qedhere
%\end{enumerate}
%\end{exercise}
%



% ** displaced product stuff starts
%-------- Section --------%
% \section{Products in $\smcat^\sharp$}

% Products in $\smcat^\sharp$ are fascinating. Given categories $\cat{C}$ and $\cat{D}$, the set of objects in their $\smcat$-product is given by the product of their sets of objects, but this is not the case in $\smcat^\sharp$. So what is an object in $\cat{C}\times^\sharp\cat{D}$ (the usual categorical product, but taken in $\smcat^\sharp)$? 

% An object in $\cat{C}\times^\sharp\cat{D}$ is, roughly speaking, a tree for which each node is a pair of objects: some $i\in\cat{C}$ and some $j\in\cat{D}$.
% The edges leading out of node $(i, j)$ are then all the morphisms emanating from $i$ and all the morphisms emanating from $j$.
% The tree must respect identities, codomains, and composites in $\cat{C}$ and $\cat{D}$, as we'll explain.
% But before we do, we define the following category, which will be crucial to our understanding of products in $\smcat^\sharp$.

% \begin{definition}[Free monoidal category on monoids and comonoids] \label{def.free_monoid_cat}
% Given a (small) set $I$, define $\Delta_I$ to be the free monoidal category generated by $|I|$ distinct monoids.
% Dually, $\Delta_I\op$ is the free monoidal category generated by $|I|$ distinct comonoids.
% \end{definition}

% Essentially, what this definition says is that $\Delta_I\op$ is a monoidal category with $|I|$ distinct comonoids, each with its own eraser and duplicator, as well as all the objects and morphisms that can be obtained from these comonoids via composition and taking the monoidal product.
% These objects and morphisms are then subject to no relations beyond those implied by the standard comonoid axioms.

% In particular, we can identify the objects of $\Delta_I\op$ with the elements of the free monoid $\List(I)$, where the $|I|$ comonoids are the singleton lists $[i]$ for each $i \in I$.
% The monoidal product of $\Delta_I\op$ can then be interpreted as list concatenation, which---in a suggestive overloading of notation---we will denote by $\tri$.
% The monoidal unit must then be the empty list $[]$.
% We could give analogous notation for $\Delta_I$.

% The erasers $[i] \to []$ and duplicators $[i] \to [i,i]$ for each $i \in I$ generate all the morphisms of $\Delta_I\op$ via composition and taking the monoidal product, while satisfying associativity and left and right unit laws.
% For instance, with $I \coloneqq \3$, there are two distinct morphisms $[2,3,1,3] \to [2,2,3]$ in $\Delta_I\op$. One of them is given by
% \[
%     ([2] \to [2,2]) \tri \id_{[3]} \tri ([1] \to []) \tri ([3] \to []),
% \]
% and the other is given by
% \[
%     ([2] \to [2,2]) \tri ([3] \to []) \tri ([1] \to []) \tri \id_{[3]}.
% \]

% Another way to state \cref{def.free_monoid_cat} would be to say that $\Delta_I\op$ is initial among monoidal categories equipped with $|I|$ comonoids.
% That is, given any monoidal category $(\cat{C}, \yon, \tri)$ with a comonoid $(c_i, \epsilon_i, \delta_i)$ for each $i \in I$, there is a unique monoidal functor $\Delta_I\op \to \cat{C}$ that sends each $[i]$ to $c_i$, each $[i] \to []$ to $\epsilon_i$, and each $[i] \to [i,i]$ to $\delta_i$.
% Dually, $\Delta_I$ is initial among monoidal categories equipped with $|I|$ monoids.

% \begin{example}[The augmented simplex category]
% If we take $I \coloneqq \1$, then $\Delta \coloneqq \Delta_I$ is what is commonly known as the \emph{augmented simplex category} or the \emph{algebraist's simplex category}.
% It is the free monoidal category generated by the monoid $[1]$ with unit $[] \to [1]$ and multiplication $[1,1] \to [1])$.

% If we identify each $n$-element list $[1,\ldots,1]$ with the finite set $\ord{n}$, interpreted as an ordinal, we can see that $\Delta$ is in fact the category of all finite ordinals (i.e.\ $\0, \1, \2, \ldots$) and the order-preserving maps between them.
% In \cite[Chapter~VII, Section~8]{MacLane:1998a}, Mac Lane verifies that $\Delta$ is initial among monoidal categories equipped with a monoid.
% \end{example}

% Armed with the free monoidal category $\Delta_I\op$, we are now ready to state how products can be constructed in $\smcat^\sharp$.

% \begin{proposition}\label{prop.sharp_products}
% The category $\smcat^\sharp$ has all small products.

% In particular, for a small set $I$ and a category $\cat{C}_i \in \smcat^\sharp$ corresponding to a comonoid $\ema{c}_i \in \poly$ for each $i \in I$, the product of the $\cat{C}_i$'s is given by the limit of the canonical monoidal functor $C \colon \Delta_I\op \to \poly$ sending each $[i]$ to $\ema{c}_i$.
% \end{proposition}

% Before we give the proof of the proposition above, let us examine what it says concretely in the case of binary products.

% \begin{example}[Binary products in $\smcat^\sharp$] \label{ex.bin_prod}
% For each $i \in \2$, let $\cat{C}_i$ be the category corresponding to the comonoid $(\ema{c}_i, \epsilon_i, \delta_i)$ in $\poly$.
% Then we can define $C \colon \Delta_\2\op \to \poly$ to be the canonical monoidal functor sending each $[i]$ to $\ema{c}_i$.
% \cref{prop.sharp_products} asserts that $\lim C$ is the product of $\cat{C}_1$ and $\cat{C}_2$ in $\smcat^\sharp$. But what kind of a polynomial is $\lim C$, and what is its comonoid structure?

% Well, for every list $\ell \in \Ob\Delta_\2\op = \List(\2)$, the polynomial $\lim C$ should have a $C\ell$-component, i.e.\ a projection $\pi_\ell \colon \lim C \to C\ell$.
% For example, when $\ell \coloneqq [1,2,2,1,1,1]$, we have $C\ell = \ema{c}_1 \tri \ema{c}_2 \tri \ema{c}_2 \tri \ema{c}_1 \tri \ema{c}_1 \tri \ema{c}_1$, giving us a projection $\lim C \to \ema{c}_1 \tri \ema{c}_2 \tri \ema{c}_2 \tri \ema{c}_1 \tri \ema{c}_1 \tri \ema{c}_1$.
% These projections must commute with the morphisms in the image of $C$, which are precisely the morphisms generated by the $\epsilon_i$'s and the $\delta_i$'s via composition and taking the monoidal product.
% For instance, the diagram
% \begin{equation} \label{eqn.lim_example}
% \begin{tikzcd}
%     \lim C \ar[r, "\pi_{[1,2,1]}"] \ar[dr, "\pi_{[1,2,2,1,1,1]}"'] & \ema{c}_1 \tri \ema{c}_2 \tri \ema{c}_1 \ar[d, "\ema{c}_1 \tri \delta_2 \tri (\delta_1 \then (\ema{c}_1 \tri \delta_1))"] \\
%     & \ema{c}_1 \tri \ema{c}_2 \tri \ema{c}_2 \tri \ema{c}_1 \tri \ema{c}_1 \tri \ema{c}_1
% \end{tikzcd}
% \end{equation}
% commutes.
% In fact, notice that for all $\ell \in \List(\2)$, there exists a unique alternating list $\ell'$ of $1$'s and $2$'s with no repetitions (such as $[1,2,1], [2,1,2,1], [],$ or $[2]$) for which there is a unique morphism $d_{\ell, \ell'} \colon \ell' \to \ell$ generated by duplicators $[i] \to [i,i]$ (here uniqueness is guaranteed by associativity).
% So we can generalize \eqref{eqn.lim_example} to say that
% \begin{equation}
% \begin{tikzcd}
%     \lim C \ar[r, "\pi_{\ell'}"] \ar[dr, "\pi_\ell"'] & C\ell' \ar[d, "Cd_{\ell,\ell'}"] \\
%     & C\ell
% \end{tikzcd}
% \end{equation}
% commutes.

% Hence the family of projections $\pi_\ell$ for all $\ell \in \List(\2)$ is completely characterized by just the projections $\pi_{\ell'}$ for which $\ell'$ contains no repetitions.
% Let us focus, then, on only those projections.
% Together, they form the commutative diagram
% \begin{equation} \label{eqn.lim_projs}
% \begin{tikzcd}
%     \yon & \ema{c}_1 \ar[l, "\epsilon_1"'] & \ema{c}_1 \tri \ema{c}_2 \ar[l, "\ema{c}_1 \tri \epsilon_2"'] & \cdots \ar[l] \\
%     \lim C \ar[u, "\pi_{[]}"] \ar[d, "\pi_{[]}"'] \ar[ur, "\pi_{[1]}"] \ar[dr, "\pi_{[2]}"'] \ar[urr, "\pi_{[1,2]}"'] \ar[drr, "\pi_{[2,1]}"] \\
%     \yon & \ema{c}_2 \ar[l, "\epsilon_2"] & \ema{c}_2 \tri \ema{c}_1 \ar[l, "\ema{c}_2 \tri \epsilon_1"] & \cdots. \ar[l]
% \end{tikzcd}
% \end{equation}
% It follows that there are projections from $\lim C$ to both the limit of the top row of \eqref{eqn.lim_projs} and the limit of the bottom row of \eqref{eqn.lim_projs}.
% In particular, the limit of the top row of \eqref{eqn.lim_projs} can be thought of intuitively as the ``infinite'' monoidal product $\ema{c}_1 \tri \ema{c}_2 \tri \ema{c}_1 \tri \cdots$, corresponding to the polynomial whose positions are all of the infinite structures that can be constructed by following these instructions:
% \begin{quote}
% \begin{enumerate}[label=1.\arabic*.]
%     \item choose an object $c_1 \in \cat{C}_1$;
%     \item for each morphism $f_1$ in $\cat{C}_1$ with domain $c_1$:
%     \begin{enumerate}[label=2.\arabic*.]
%         \item choose an object $d_2 \in \cat{C}_2$;
%         \item for each morphism $g_2$ in $\cat{C}_2$ with domain $d_2$:
%         \begin{enumerate}[label=3.\arabic*.]
%             \item choose an object $c_3 \in \cat{C}_1$;
%             \item for each morphism $f_3$ in $\cat{C}_1$ with domain $c_3$:
            
%             $\quad \cdots$,
%         \end{enumerate}
%     \end{enumerate}
% \end{enumerate}
% \end{quote}
% Then the directions at each such position are the sequences of morphisms formed by starting from the top of the instructions above and taking the morphisms mentioned in steps $1.2, 2.2, \ldots, n.2$, for some finite $n$, to obtain sequences such as $(), (f_1), (f_1, g_2),$ and $(f_1, g_2, f_3)$.
% The limit of the bottom row of \eqref{eqn.lim_projs} can be characterized in the same way, but with the roles of $\cat{C}_1$ and $\cat{C}_2$ swapped.
% From these structures, we can read off the behavior of each projection $\pi_{\ell'}$ from $\lim C$; for instance, the projection $\pi_{[1,2]}$ sends each position of $\lim C$ to the position of $\ema{c}_1 \tri \ema{c}_2$ specified by following just the first three steps of the above instructions.

% So every position of $\lim C$ yields a pair of these structures.
% We'll call the structure obtained by following the instructions above the \emph{left} structure, and the structure obtained by following the instructions above, but with $\cat{C}_1$ and $\cat{C}_2$ swapped, the \emph{right} structure.
% But not every such pair of structures corresponds to a position of $\lim C$; they must satisfy additional conditions, given by morphisms in the image of $C$ that are not depicted in \eqref{eqn.lim_projs}.
% For instance, the fact that the diagram
% \begin{equation}
% \begin{tikzcd}
%     \lim C \ar[r, "\pi_{[1,2]}"] \ar[dr, "\pi_{[2]}"'] & \ema{c}_1 \tri \ema{c}_2 \ar[d, "\epsilon_1 \tri \ema{c}_2"] \\
%     & \ema{c}_2
% \end{tikzcd}
% \end{equation}
% commutes implies that, when following the above instructions, the object $d_2$ chosen for the identity morphism on $c_1$ in the left structure must also be the first object chosen when constructing the right structure.
% Similar diagrams render all such objects chosen for identity morphisms when constructing these structures redundant.
% So, in the end, we have a one-to-one correspondence between positions of $\lim C$ and pairs of structures that can be constructed by following these instructions:
% \begin{quote}
% \begin{enumerate}[label=1.\arabic*.]
%     \item choose an object $c_1 \in \cat{C}_1$;
%     \item for each nonidentity morphism $f_1$ in $\cat{C}_1$ with domain $c_1$:
%     \begin{enumerate}[label=2.\arabic*.]
%         \item choose an object $d_2 \in \cat{C}_2$;
%         \item for each nonidentity morphism $g_2$ in $\cat{C}_2$ with domain $d_2$:
%         \begin{enumerate}[label=3.\arabic*.]
%             \item choose an object $c_3 \in \cat{C}_1$;
%             \item for each nonidentity morphism $f_3$ in $\cat{C}_1$ with domain $c_3$:
            
%             $\quad \cdots$
%         \end{enumerate}
%     \end{enumerate}
% \end{enumerate}
% \end{quote}
% for the left structure, and
% \begin{quote}
% \begin{enumerate}[label=1.\arabic*.]
%     \item choose an object $d_1 \in \cat{C}_2$;
%     \item for each nonidentity morphism $g_1$ in $\cat{C}_2$ with domain $d_1$:
%     \begin{enumerate}[label=2.\arabic*.]
%         \item choose an object $c_2 \in \cat{C}_1$;
%         \item for each nonidentity morphism $f_2$ in $\cat{C}_1$ with domain $c_2$:
%         \begin{enumerate}[label=3.\arabic*.]
%             \item choose an object $d_3 \in \cat{C}_2$;
%             \item for each nonidentity morphism $g_3$ in $\cat{C}_2$ with domain $d_3$:
            
%             $\quad \cdots$
%         \end{enumerate}
%     \end{enumerate}
% \end{enumerate}
% \end{quote}
% for the right structure.
% These pairs are then the objects of $\cat{C}_1 \times^\sharp \cat{C}_2$.
% The morphisms from each object are the sequences of morphisms formed by starting from the top of either set of instructions above and taking the morphisms mentioned in steps $1.2, 2.2, \ldots, n.2$, for some finite $n$, to obtain sequences such as $(), (f_1), (g_1), (f_1, g_2), (g_1, f_2),$ $(f_1, g_2, f_3)$ and $(g_1, f_2, g_3)$.
% In particular, the identity morphism is $()$.

% We illustrate how to determine the codomain of each nonidentity morphism using an example.
% To find the codomain of the morphism $(g_1, f_2)$, obtained from steps 1.2 and 2.2 in the right structure, we need to determine the left and right structures of the codomain.
% Its right structure is easy to describe: it is simply the structure obtained by following the remaining instructions, starting from step 3.1, nested under step 2.2 for $f_2$; the recursive nature of these instructions ensures that this is, in fact, a valid right structure.
% As for the left structure of the codomain, we can construct it as follows:
% \begin{quote}
% \begin{enumerate}[label=1.\arabic*.]
%     \item choose the object $\cod(f_2) \in \cat{C}_1$;
%     \item for each nonidentity morphism $f'_2$ in $\cat{C}_1$ with domain $\cod(f_2)$:
%     \begin{enumerate}[label=2.\arabic*.]
%         \item if $f_2 \then f'_2$ is not the identity, then follow the steps nested under step 2.2 for $f_2 \then f'_2$ in the instructions above for constructing the original right structure;
%         \item otherwise, 
%     \end{enumerate}
% \end{enumerate}
% \end{quote}

% $\cod(f_2)$ in $\cat{C}_1$, then, for each nonidentity morphism $f'_2$ in $\cat{C}_1$ 


% %codomains...

% % example for (f_1, g_2)


% \end{example}

% \begin{example}[Products of discrete categories are products of sets]
% Given sets $S$ and $T$, consider the corresponding discrete categories $S\yon$ and $T\yon$.
% Then by \cref{ex.bin_prod}, the product $S\yon \times^\sharp T\yon$ is the discrete category $(S \times T)\yon$.
% \end{example}

% \begin{example}[Products of one-object categories are coproducts of monoids]
% Given monoids $M$ and $N$, consider the corresponding one-object categories $\yon^M$ and $\yon^N$.
% Then by \cref{ex.bin_prod}, the product $\yon^M \times^\sharp \yon^N$ is the one-object category $\yon^{M \ast N}$, where $M \ast N$ is the free product (i.e.\ the coproduct) of the monoids $M$ and $N$.
% \end{example}


% \begin{example}[Unexpectedly-many objects]\label{ex.unexpectedly_many_objects}
% Let $\cat{C}\coloneqq\fbox{$\LMO{A}\To{f}\LMO{B}$}$ be the walking arrow category. By \cref{ex.bin_prod}, the product $\cat{C}\times^\sharp\cat{C}$ has infinitely many objects. Namely, it has an object for every pair of sequences $(s_1, s_2)$, finite or infinite, that one can write in the alphabet $\{A_1, A_2, B_1, B_2\}$ subject to the following conditions:
% \begin{itemize}
%     \item the sequence $s_1$ starts with either $A_1$ or $B_1$;
%     \item the sequence $s_2$ starts with either $A_2$ or $B_2$; and
% 	\item in either sequence:
% 	\begin{itemize}
% 	    \item after $A_1$ comes either $A_2$ or $B_2$;
% 	    \item after $A_2$ comes either $B_1$ or $A_1$; and
% 	    \item after $B_1$ or $B_2$, the sequence stops.
% 	\end{itemize}
% \end{itemize}
% For example, here is an object in $\fbox{$\LMO{A}\To{f}\LMO{B}$}\times\fbox{$\LMO{A}\To{f}\LMO{B}$}$:
% \[
% ((A_1,A_2,A_1,A_2,\ldots), (A_2,A_1,A_2,A_1,B_2))
% \]
% \end{example}

% % \begin{exercise}
% % Again let $\cat{C}\coloneqq\fbox{$\LMO{A}\To{f}\LMO{B}$}$.
% % \begin{enumerate}
% % 	\item Use the official description of products, given in \cref{prop.sharp_products}, to justify the informal description of the objects in $\cat{C}\times^\sharp\cat{C}$, as given in \cref{ex.unexpectedly_many_objects}.
% % 	\item Describe the morphisms in $\cat{C}\times^\sharp\cat{C}$.
% % \qedhere
% % \end{enumerate}
% % \end{exercise}

% \begin{example}
% Let $I$ be a set and $I\yon$ the associated discrete category, and let $(M,e,*)$ be a monoid and $\yon^M$ the associated one-object category.
% Then by \cref{ex.bin_prod}, the product $I\yon \times^\sharp \yon^M$ is the category $I^M\yon^M$.
% Its objects are functions $i \colon M \to I$, while its morphisms have the form $i \To{m} (m' \mapsto i(m * m'))$ for each $i \colon M \to I$ and $m \in M$.

% Given $i \colon M \to I$, its identity morphism is the morphism $i \To{e} i$ corresponding to $e \in M$; given $m, n \in M$, the composite of the morphisms $i \To{m} (m' \mapsto i(m * m')) \To{n} (m' \mapsto i(m * n * m'))$ is the morphism $i \To{m * n} (m' \mapsto i(m * n * m'))$.

% % The product $I\yon\times^\sharp\yon^R$ can be thought of as an \emph{event-based system} with states in $I$. Namely, an object in it can be identified as a sequence consisting of an element in $I$, followed by a nonzero amount of time, followed by another element in $I$, followed by another nonzero amount of time, etc.
% \end{example}

% % \begin{example}[Event-based systems]
% % Let $R\coloneqq\{r\in\rr\mid r\geq 0\}$ denote the nonnegative real numbers, and let $\yon^R$ be the associated monoid (under addition). Let $I$ be a set and $I\yon$ the associated discrete category.

% % % The product $I\yon\times^\sharp\yon^R$ can be thought of as an \emph{event-based system} with states in $I$. Namely, an object in it can be identified as a sequence consisting of an element in $I$, followed by a nonzero amount of time, followed by another element in $I$, followed by another nonzero amount of time, etc.
% % \end{example}

% \begin{proof}[Proof of \cref{prop.sharp_products}]
% We first show that $\lim C$ actually is a comonoid in $\poly$ by giving its eraser and duplicator.
% The eraser $\epsilon \colon \lim C \to \yon$ is given by the projection $\pi_{[]} \colon \lim C \to C[]$, since $C[] \iso \yon$.

% To construct the duplicator, we observe that $\Delta_I\op$ is connected (every object has map to $[]$ given by a monoidal product of erasers), so by \cref{thm.connected_limits}, $\tri$ preserves $\Delta_I\op$-shaped limits.
% As $C$ is monoidal, it follows that
% \[
%     (\lim C) \tri (\lim C) \iso \lim_{\ell \in \Delta_I\op} \lim_{\ell' \in \Delta_I\op} C(\ell \tri \ell').
% \]
% So specifying a map to $(\lim C) \tri (\lim C)$ amounts to specifying a map to $C(\ell \tri \ell')$ for every $\ell, \ell' \in \Delta_I\op$ such that the appropriate diagrams commute.
% In particular, we can construct the duplicator $\delta \colon \lim C \to (\lim C) \tri (\lim C)$ by specifying the projection $\pi_{\ell \tri \ell'} \colon \lim C \to C(\ell \tri \ell')$ for each $\ell, \ell' \in \Delta_I\op$.
% It is routine to verify that the appropriate diagrams commute.

% (Verify comonoid laws)

% (Give projections; check that these are comonoid morphisms)

% (Verify universal property of product)
% \end{proof}

% ** displaced product stuff ends


%-------- Section --------%
\section{Exercise solutions}
\Closesolutionfile{solutions}
{\footnotesize
\input{solution-file6}}

\Opensolutionfile{solutions}[solution-file7]

%------------ Chapter ------------%
\chapter{Cofree polynomial comonoids} \label{ch.comon.cofree}

Consider a dynamical system $\phi\colon\ema{s}\to p$ with state system $\ema{s}$ and interface $p$.
In \cref{subsec.comon.sharp.state.run}, we posed the question of whether there was a single morphism that could capture all the information encoded by the family of lenses $\text{Run}_n(\phi)\colon\ema{s}\to p\tripow{n}$ for all $n\in\nn$, defined as the composite
\[
    \ema{s}\To{\delta^n}\ema{s}\tripow{n}\To{\phi\tripow{n}}p\tripow{n}
\]
that models $n$ runs through the system $\phi$.

It turns out that there is: the key is that there is a natural way to interpret every polynomial $p$ as a category $\cofree{p}$, so that cofunctors into $\cofree{p}$ are exactly lenses into $p$.
In other words, $\cofree{p}$ will turn out to be the \emph{cofree comonoid on $p$}.
Cofree comonoids in $\poly$ are beautiful objects, both in their visualizable structure as a category and in the metaphors we can make about them. They allow us to replace the interface of a dynamical system with a category and get access to a rich theory that exists there.
We'll go through this construction and its implications in this chapter.

%-------- Section --------%
\section{Constructing the cofree comonoid} \label{sec.comon.cofree.cons}

In \cref{sec.comon.cofree.**}, we'll give a purely formal proof of the following.
\begin{theorem}[Cofree comonoid] \label{thm.cofree}
The forgetful functor $U\colon \smcat^\sharp\to\poly$ has a right adjoint $\cofree{-}\colon\poly\to\smcat^\sharp$, giving rise to an adjunction
\[
    \adj{\smcat^\sharp}{U}{\cofree{-}}{\poly}
\]
where the carrier $\ema{t}_p\coloneqq U\cofree{p}$ of $\cofree{p}$ for $p\in\poly$ is given by the limit of the following diagram:
\begin{equation} \label{eqn.cofree_limit}
\begin{tikzcd}
	\yon \ar[d] &
	p \ar[d] &
	p\tri p \ar[d] &
	[10pt] p\tri p\tri p \ar[d] &
	\cdots\\
	\1 &
	p\tri\1 \ar[l, "!"'] &
	p\tri p\tri\1 \ar[l, "p\:\tri\:!"'] &
	p\tri p\tri p\tri\1 \ar[l, "p\:\tri\:p\:\tri\:!"'] &
	\cdots\ar[l]
\end{tikzcd}
\end{equation}
\end{theorem}
But first, let us investigate the implications of this theorem and give a concrete characterization of the cofree comonoid in terms of its positions, directions, and categorical structure.

%---- Subsection ----%
\subsection{The many (inter)faces of the cofree comonoid} \label{subsec.comon.cofree.cons.faces}

% ** maybe move all this later, except keep the notation

The forgetful-cofree adjunction of \cref{thm.cofree} tells us that given a category $\cat{C}\in\smcat^\sharp$ with carrier $\ema{c}\coloneqq U\cat{C}$ and a polynomial $p\in\poly$, there is a natural isomorphism
\[
    \poly(\ema{c},p)\iso\smcat^\sharp(\cat{C},\cofree{p}).
\]
So every lens $\phi\colon\ema{c}\to p$ has a corresponding cofunctor $F\colon\cat{C}\cof\cofree{p}$ that we call its \emph{mate}.

We can view $\phi$ as a dynamical system with an interface $p$ and a generalized state system $\ema{c}$, carrying an arbitrary category $\cat{C}$ of states and transitions.
Then the lens $\text{Run}_n(\phi)\colon\ema{c}\to p\tripow{n}$ for $n\in\nn$, defined as the composite
\[
    \ema{c}\To{\delta^n}\ema{c}\tripow{n}\To{\phi\tripow{n}}p\tripow{n}
\]
models $n$ runs through the system $\phi$.

Meanwhile, as the limit of the diagram \eqref{eqn.cofree_limit} with the row of polynomials of the form $p\tripow{n}$ across the top, the carrier $\ema{t}_p$ of the cofree comonoid on $p$ comes equipped with a lens $\epsilon^n_p\colon\ema{t}_p\to p\tripow{n}$ for each $n\in\nn$.
As the cofunctor $F\colon\cat{C}\cof\cofree{p}$ has an underlying lens between carriers $f\coloneqq UF\colon\ema{c}\to\ema{t}_p$, we can obtain another lens $\ema{c}\to\tripow{n}$ as the composite
\[
    \ema{c}\To{f}\ema{t}_p\To{\epsilon^n_p}p\tripow{n}.
\]

It turns out that these two composites are equal---that is, the following diagram commutes:
\[
\begin{tikzcd}
    \ema{c} \ar[r,"f"] \ar[d, "\delta^n"'] & \ema{t}_p \ar[d, "\epsilon^n_p"] \\
    \ema{c}\tripow{n} \ar[r, "\phi\tripow{n}"'] & p\tripow{n}
\end{tikzcd}
\]
We will prove this in \cref{**} once we have the tools to do so.

Now we have a better sense of what we mean when we say that $F\colon\cat{C}\cof\cofree{p}$ captures all the information that the lenses $\text{Run}_n(\phi)\colon\ema{c}\to p\tripow{n}$ encode: the category $\cofree{p}$ is carried by a polynomial $\ema{t}_p$ equipped with lenses $\epsilon^n_p\colon\ema{t}_p\to p\tripow{n}$, each of which exposes a part of the category as the $n$-fold interface $p\tripow{n}$.
All together, $\ema{t}_p$ acts as a giant interface that captures the $n$-fold behavior of $p\tripow{n}$ for every $n\in\nn$.
But to see all this explicitly, we need to be clear on what the positions and directions of $\ema{t}_p$ are and what category $\cofree{p}$ it carries, as well as how each lens $\epsilon^n_p\colon\ema{t}_p\to p\tripow{n}$ behaves.

%---- Subsection ----%
\subsection{The carrier of the cofree comonoid} \label{subsec.comon.cofree.cons.car}

We begin by characterizing the carrier $\ema{t}_p\coloneqq U\cat{T}_p$ of the cofree comonoid as a polynomial.

\subsubsection{Positions of the cofree comonoid, diagrammatically}

Recall from \cref{ex.compute_limits} that in $\poly$, the positions of a limit are the limit of the positions.
Moreover, in \eqref{eqn.cofree_limit}, every vertical map $p\tripow{n}\to p\tripow{n}\tri\1$ is, in fact, a \emph{vertical} lens in the sense of \cref{def.vert_cart}: an isomorphism on positions.
So on positions, the diagram collapses down to the following, viewed as a diagram in $\smset$:
\begin{equation} \label{eqn.cofree_limit_pos}
\begin{tikzcd}
	\1 &
	p(\1) \ar[l, "!"'] &
	p\tri p(\1) \ar[l, "p(!)"'] &
	[10pt] p\tri p\tri p(\1) \ar[l, "p\:\tri\:p(!)"'] &
	\cdots\ar[l]
\end{tikzcd}
\end{equation}
If you know about coalgebras for functors, as defined in \cref{ex.coalgebras}, then the limit of this diagram may be familiar to you: it is the \emph{terminal coalgebra for the functor} $p$ or the \emph{terminal $p$-coalgebra}.
But it will be convenient for us to think about this limit a little differently, as the set of \emph{$p$-trees}: trees comprised of $p$-corollas.

\subsubsection{Trees on polynomials}

\begin{definition}[Trees on a polynomial] \label{def.poly_tree}
Let $p\in\poly$ be a polynomial.
A \emph{tree on $p$}, or a \emph{$p$-tree}, is a rooted tree whose every vertex $v$ is assigned a $p$-position $i$ and a bijection from the children of $v$ to $p[i]$.
We denote the set of $p$-trees by $\tr_p$.
\end{definition}
We can think of a $p$-tree as being ``built'' out of $p$-corollas according to these instructions:
\begin{quote}
To choose a $p$-tree in $\tr_p$: 
\begin{enumerate}
    \item choose a $p$-corolla:
    \begin{itemize}
        \item its root $i_0\in p(\1)$ will be tree's root, and
        \item its leaves in $p[i_0]$ will be the edges out of the root;
    \end{itemize}
    \item for each $p[i_0]$-leaf $a_1$:
    \begin{enumerate}[label*=\arabic*.]
        \item choose a $p$-corolla:
        \begin{itemize}
            \item its root $i_1\in p(\1)$ will be the vertex adjoined to $a_1$, and
            \item its leaves in $p[i_1]$ will be the edges out of that vertex;
        \end{itemize}
        \item for each $p[i_1]$-leaf $a_2$:
        \begin{enumerate}[label*=\arabic*.]
            \item choose a $p$-corolla:
            \begin{itemize}
                \item its root $i_2\in p(\1)$ will be the vertex adjoined to $a_2$, and
                \item its leaves in $p[i_2]$ will be the edges out of that vertex;
            \end{itemize}
            \item for each $p[i_1]$-leaf $a_2$:
            
            $\cdots$
        \end{enumerate}
    \end{enumerate}
\end{enumerate}
\end{quote}
Of course, there may eventually be multiple copies of any one $p$-root as a vertex or $p$-leaf as an edge in our $p$-tree, and these vertices and edges are not literally the same.
So we should really think of the positions and directions of $p$ involved each step as \emph{labels} for the vertices and edges of a $p$-tree.

Although these instructions continue forever, we could abbreviate them by writing them recursively:
\begin{quote}
To choose a $p$-tree in $\tr_p$: 
\begin{enumerate}
    \item choose a $p$-corolla:
    \begin{itemize}
        \item its root $i_0\in p(\1)$ will be tree's root, and
        \item its leaves in $p[i_0]$ will be the edges out of the root;
    \end{itemize}
    \item for each $p[i_0]$-leaf $a_1$:
    \begin{enumerate}[label*=\arabic*.]
        \item choose a $p$-tree in $\tr_p$:
        \begin{itemize}
            \item it will be the subtree whose root is adjoined to $a_1$. 
        \end{itemize}
    \end{enumerate}
\end{enumerate}
\end{quote}

Note that a $p$-tree can have infinite height---in fact, it always will unless every one of its branches terminates at a $p$-corolla with no leaves, i.e.\ a position with an empty direction set.

\subsubsection{Pretrees on polynomials}

\begin{example}[A few partial $p$-trees]
Let $p\coloneqq\{\bul[red],\bul[blue]\}\yon^\2+\bul[dgreen]\yon+\bul[dyellow]$.
Here are four partially constructed $p$-trees:
\begin{equation}\label{eqn.some_trees_misc58}
\begin{tikzpicture}[trees,
  level 1/.style={sibling distance=10mm},
  level 2/.style={sibling distance=5mm},
  level 3/.style={sibling distance=2.5mm}]
	\node[red] (a) {$\bullet$}
		child {node[red] {$\bullet$}
			child {node[dyellow] {$\bullet$}}
			child {node[dyellow] {$\bullet$}}
		}
		child {node[dgreen] {$\bullet$}
			child {node[dgreen] {$\bullet$}
				child
			}
		}
		;
	\node[dgreen, right=2 of a] (b) {$\bullet$}
		child {node[blue] {$\bullet$}
			child {node[blue] {$\bullet$}
				child
				child
			}
			child {node[red] {$\bullet$}
				child
				child
			}
		};
	\node[dyellow, right=2 of b] (c) {$\bullet$};
	\node[red, right=2 of c] {$\bullet$}
		child {node[blue] {$\bullet$}
			child {node[red] {$\bullet$}
				child
				child
			}
			child {node[red] {$\bullet$}
				child
				child
			}
		}
		child {node[red] {$\bullet$}
			child {node[red] {$\bullet$}
				child
				child
			}
			child {node[red] {$\bullet$}
				child
				child
			}
		};
\end{tikzpicture}
\end{equation}
Note that only the third one---the single yellow dot---would count as an element of $\tr_p$. 
After all, in \cref{def.poly_tree}, when we speak of a tree on $p$, we mean a tree for which every vertex is a position in $p$ with all of its emanating directions filled by another position in $p$.
Since three of the four trees shown in \eqref{eqn.some_trees_misc58} have leaves emanating from the top that have not been filled by any $p$-corollas, these trees are not elements of $\tr_p$.
However, each of them could be extended to an actual element of $\tr_p$ by continuing to fill in each open leaf with another $p$-corolla.
These might continue forever---or, if you're lazy, you could just cap them all off with the direction-less yellow dot.
\end{example}

The trees in \eqref{eqn.some_trees_misc58} can all be obtained by following just the first $3$ levels of instructions for building a $p$-tree (in fact, exactly as many instructions as we initially wrote out).
On the other hand, we know from \cref{subsec.comon.comp.def.corolla} that such a tree represents a position of $p\tripow3$, whose directions are its height-$3$ leaves---and this is true for any $n\in\nn$ in place of $3$.
So these trees are still important to our theory; but since they are not always complete $p$-trees, we will call them something else.

\begin{definition}[Pretrees on a polynomial] \label{def.pretree}
Let $p\in\poly$ be a polynomial and $n\in\nn$.
A \emph{stage-$n$ pretree on $p$}, or a \emph{$p\tripow{n}$-pretree} for short, is a rooted tree of height at most $n$ whose every vertex $v$ of height strictly less than $n$ is assigned a $p$-position $i$ and a bijection from the children of $v$ to $p[i]$.

The \emph{stage-$n$ pretree} or the \emph{$p\tripow{n}$-pretree} of a $p$-tree (or a $p\tripow{m}$-pretree with $m\geq n$) is the pretree obtained by removing all vertices of height strictly greater than $n$ from the $p$-tree (or $p\tripow{m}$-pretree).
\end{definition}

\begin{remark}
Technically, our abbreviated terminology for pretrees is ambiguous: after all, a $p\tripow{mn}$-pretree could be a stage $mn$ pretree on $p$, a stage $m$ pretree on $p\tripow{n}$, a stage $n$ pretree on $p\tripow{m}$, or even a stage $1$ pretree on $p\tripow{mn}$.
So we should really be thinking of the exponent $\tri n$ as a formal symbol, rather than telling us to actually evaluate the $n$-fold composite $p\tripow{n}$ in $\poly$.
On the other hand, we know from our discussion in \cref{subsec.comon.comp.def.corolla} that these are essentially all the same trees drawn differently, so this is not a terrible abuse of notation.
Nevertheless, we do want to refer to a stage $n$ pretree on $p$ as having up to $n$ levels of edges, rather than flattening it into, say, a corolla; so we will adopt the convention that if we write a polynomial out as $p\tripow{n}$ in ``$p\tripow{n}$-pretree,'' we mean a stage $n$ pretree on $p$ unless otherwise noted.
\end{remark}

\begin{remark}
In \cref{def.pretree}, we use \emph{stage} instead of \emph{height} to allow for the fact that a $p\tripow{n}$-pretree may not reach its maximum height $n$ if all of its branches terminate early.
For example, the yellow dot in \eqref{eqn.some_trees_misc58} is a $p\tripow1$-pretree, but it is also a $p\tripow2$-pretree, a $p\tripow{50}$-pretree, and indeed a $p$-tree.
On the other hand, even though it has height $0$, it is \emph{not} a $p\tripow0$-pretree, as we did assign its height-$0$ vertex a position of $p$, so it is not the case that we only assigned $p$-positions to vertices of height strictly less than $0$.
A similar statement can be made for all $p$-trees of finite height, and indeed only to $p$-trees of finite height.

In fact, there is exactly one stage-$0$ pretree on $p$ for any $p\in\poly$, and it is the stage-$0$ pretree of every possible $p$-tree.
It is the rooted tree with no vertices other than the root and no position assigned to that root.
This does follow from the definition, or you could accept it as a convention.
Note that the stage-$0$ pretree is \emph{not} itself a $p$-tree for any $p\in\poly$, as a $p$-tree requires at least a $p$-position $i$ as a label for its root.
More generally, any pretree on $p$ with unlabeled vertices is not yet a tree on $p$.
These unlabeled vertices are the leaves we have been representing with arrows this whole time.
\end{remark}

The following result summarizes our observations from \cref{subsec.comon.comp.def.corolla}.

\begin{proposition}
The $p\tripow{n}$-pretrees are in bijection with $p\tripow{n}(\1)$, and for each $i\in p\tripow{n}(\1)$ the height-$n$ leaves of the pretree corresponding to $i$ are in bijection with $p\tripow{n}[i]$.
\end{proposition}

Hence we can \emph{identify} the polynomial $p\tripow{n}$ with a forest of $p\tripow{n}$-pretrees, so that each $p\tripow{n}$-pretree is a $p\tripow{n}$-position whose directions are its height-$n$ leaves.
This subsumes our corolla language in the case of $n=1$.

\begin{example}[Trimming pretrees]
Since $p\tripow1(\1)\iso p(\1)$ and $p\tripow0(\1)\iso\yon(\1)\iso\1$, the unique function $!\colon p(\1)\to\1$ can be thought of as a function from $p\tripow1$-positions to $p\tripow0$-positions, or equivalently a function from stage-$1$ pretrees (i.e.\ corollas) to stage-$0$ pretrees on $p$.
We can interpret this function as taking a corolla and ``stripping away'' its leaves along with the position-label on its root, leaving only a single unlabeled root: a stage-$0$ pretree.

This deceptively boring function is what will make our whole theory work.
For any $n\in\nn$, we can take the composition product of the identity on $p\tripow{n}$ and $!$, interpreted as a lens between constant polynomials, to obtain a lens $p\tripow{n}\tri \:!\colon p\tripow{n}\tri p(\1)\to p\tripow{n}\tri\1$, or equivalently a function $p\tripow{n}(!)\colon p\tripow{n+1}(\1)\to p\tripow{n}(\1)$ from stage-$(n+1)$ pretrees to stage-$n$ pretrees on $p$.

We can deduce the behavior of this function on stage-$(n+1)$ pretrees from what we know about how the composition product interacts with pretrees on $p$.
The identity lens on $p\tripow{n}$ keeps the lower $n$ levels of each $p\tripow{(n+1)}$-pretree intact, while $!$ will ``strip away'' the $p\tripow{(n+1)}$-pretree's height-$(n+1)$ leaves, along with all the position-labels on its height-$n$ vertices.


we can deduce that $p\tripow{n}(!)$ keeps the lower $n$ levels of each $p\tripow{n}$-pretree intact, as $\id_{p\tripow{n}}$ does, while ``stripping away'' the height-$(n+1)$ leaves of 
\end{example}

% ** some pretree exercises?

\subsubsection{Back to trees}

Before we go further in the theory of $p$-trees, let us look at some more examples.

\begin{example}[A few more actual $p$-trees] \label{ex.imagining_trees}
Keeping $p\coloneqq\{\bul[red],\bul[blue]\}\yon^\2+\bul[dgreen]\yon+\bul[dyellow]$, here are some elements of $\tr_p$ that we could imagine (or even draw, at least in part):
\begin{itemize}
	\item The binary tree that's ``all red all the time.''
	\item The binary tree where odd layers are red and even layers are blue.
	\item The binary tree whose root is red, but after which every left child is red and every right child is blue.%
	\footnote{To formalize the notions of ``left'' and ``right,'' we could think of the direction-sets of the red and blue dots as $\2\iso\{\const{left},\const{right}\}$, so that out of every vertex there is an edge labeled $\const{left}$ and an edge labeled $\const{right}$.}
	\item The tree where all the nodes are red, except for the rightmost branch, which (apart from the red root) is always green.
	\item Any finite tree, where every branch terminates in a yellow dot.
	\item A completely random tree: for the root, randomly choose either red, blue, green, or yellow, and at every leaf, loop back to the beginning, i.e.\ randomly choose either red, blue, green, or yellow, etc.
\end{itemize}
In fact, there are uncountably many trees in $\tr_p$ (even just $\tr_{2\yon}$ has cardinality $\2^\nn$), but only countably many can be uniquely characterized in a finite language like English (and of course only finitely many can be uniquely characterized in the time we have!).
Thus most elements of $\tr_p$ cannot even be described.
\end{example}

\begin{exercise}\label{exc.trees_1}
% \begin{enumerate}
% 	\item Interpret each of the five tree examples imagined in \cref{ex.imagining_trees} by drawing three or four layers (your choice) of it.
% \end{enumerate}
For each of the following polynomials $p$, describe the set of trees $\tr_{p}$.
\begin{enumerate}[resume]
	\item $p=\1$.
	\item $p=\2$.
	\item $p=\yon$.
	\item $p=\yon^\2$.
	\item $p={\2\yon}$.
	\item $p={\yon+\1}$.
	\item $p={B\yon^A}$ for some sets $A,B\in\smset$.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

It turns out that $\tr_p$ is the position-set of the cofree comonoid on $p$.

%** show that it really is a p-coalgebra??


%---- Subsection ----%
\subsection{The directions of the cofree comonoid} \label{subsec.comon.cofree.cons.dir}


%---- Subsection ----%
\subsection{Cofree comonoids as categories} \label{subsec.comon.cofree.cons.cat}


\begin{definition}[Cofree comonoid]\label{def.cofree}
Let $p\in\poly$ be a polynomial. The comonoid $\cofree{p}=(\tr_p,\rt,\fs)$ as in \cref{thm.cofree} is called the \emph{cofree comonoid on $p$} or informally the category of \emph{(possibly infinite) $p$-trees}.

An object $t\in \tr_p(\1)$ is a called a \emph{(possibly infinite) tree in $p$.} Given such an object $t$ in the category, an emanating morphism $n\in\tr_p[t]$ is called a \emph{path from root}.
\end{definition}

The terminology of \cref{def.cofree} is alluding to a specific way we like to imagine the comonoid $\cofree{p}=(\tr_p,\rt,\fs)$, namely in terms of trees. To every polynomial $p$, we will associate a new polynomial $\tr_p$ whose positions are (possibly infinite) $p$-trees. To choose such a tree we first choose its root to be some position $i\in p(\1)$. Then for every direction $d\in p[i]$ there, we choose another position, and for every direction from each of those we choose another position, and so on indefinitely.

So a position in $\tr_p$ is one of these trees. Such a tree may end, namely if none of the top-level positions has any directions, but often it will not end. Given such a tree, say $t$, a direction $d\in\tr_p[t]$ there is simply a path from the root to some node in the tree. 

We'll explain the eraser $\rt$ and the duplicator $\fs$ after going through an example.

**

Now that we've explained the underlying polynomial $\tr_p$ of the cofree comonoid $\cofree{p}=(\tr_p,\rt,\fs)$, we just need to explain how identities, codomains, and composition work, i.e.\ we just need to give the eraser map $\rt\colon\tr_p\to\yon$ and the duplicator map $\fs\colon\tr_p\to\tr_p\tri\tr_p$. 

Again, the objects in the category $\cofree{p}$ are $p$-trees, and a morphism emanating from such a tree $t$ is a path from its root $r$ to some node. The map $\rt$, applied to $t$, returns $t$'s root $r$, or more precisely the path from $r$ to itself. The map $\fs$, applied to $t$, first needs to give a codomain (tree) to every path from the root to some other node $n$. It is just the subtree of $t$ whose root is $n$: the tree of all nodes starting at $n$. Now, given a path from the root of that tree (namely $n$) to another node, say $n'$, we need to give a path from $r$ to $n'$; we take it to be the composite of the path $r\to n$ and the path $n\to n'$.

\begin{exercise}
Let $p\coloneqq\{\bul[red],\bul[blue]\}\yon^\2+\bul[dgreen]\yon+\bul[dyellow]$ as in \cref{ex.imagining_trees}.
\begin{enumerate}
	\item Choose an object $t\in \tr_p$, i.e.\ a tree in $p$, and draw a finite approximation of it (say four layers).
	\item What is the identity morphism at $t$?
	\item Choose a nonidentity morphism $f$ emanating from $t$ and draw it.
	\item What is the codomain of $f$? Draw a finite approximation of it.
	\item Choose a morphism emanating from the codomain of $f$ and draw it.
	\item What is the composite of your two morphisms? Draw it on $t$.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{example}
Let's take $p\coloneqq\1$. An element in $\tr_p(\1)$ is given by choosing an element $i\in p(\1)$ and filling each of its direction $p[i]$ with another element of $p(\1)$, and so on. But there is only one element of $p(\1)$ and it has no directions. So $\tr_\1$ has only one position, and the only emanating morphism there is the identity. In other words, $\tr_\1=\yon$.

Since $\yon$ has a unique comonoid structure, we've described the cofree comonoid $\cofree(\1)$. It is a single tree consisting of a single node, and the only outgoing morphism is the identity on that node.
\end{example}

\begin{exercise}
Let $A$ be a set.
\begin{enumerate}
	\item What is $\tr_A$? 
	\item How is it given the structure of a category?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{example}
Let $p\coloneqq\yon$. An element in $\tr_p(\1)$ is given by choosing an element $i\in p(\1)$ and filling each of its direction $p[i]$ with another element of $p(\1)$, and so on. There is only one way to do this, i.e.\ there is only one such tree, namely $t\coloneqq\fbox{$\bullet\to\bullet\to\bullet\to\cdots$}$.

So $\tr_p$ has a single position, namely $t$. That position has an emanating morphism for each path out of the root, so it has $\nn$-many emanating morphisms: one for every length. Hence $\tr_\yon=\yon^\nn$.

Of course the codomain of each morphism emanating from $t$ is again $t$: that's the only object. The composite of two paths, one of length $m$ and one of length $n$ is $m+n$. Hence we see that the category $\cofree(\yon)$ is the monoid $(\nn,0,+)$ considered as a category with one object.
\end{example}

\begin{exercise}
Let $A$ be a set.
\begin{enumerate}
	\item What is $\tr_{A\yon}$? 
	\item How is it given the structure of a category?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{example}
Let $p\coloneqq\nn\yon^\2$. An element of $\tr_p$ might start like this:
\[
\begin{tikzpicture}[trees,
  level 1/.style={sibling distance=10mm},
  level 2/.style={sibling distance=5mm},
  level 3/.style={sibling distance=2.5mm}]
	\node {$17$}
		child {node {$3$}
			child {node {$0$}
				child
				child
			}
			child {node {$3$}
				child
				child
			}
		}
		child {node {$1$}
			child {node {$92$}
				child
				child
			}
			child {node {$6$}
				child
				child
			}
		};
\end{tikzpicture}
\]
Any element of $\tr_p$ goes on forever: it's an infinite binary tree. At each node it has a choice of some natural number, since $\nn=p(\1)$ is the position-set of $p$.

So such trees are the objects of the category $\cofree{p}=(\tr_p,\rt,\fs)$. A morphism emanating from a tree $t$ is a path from its root to another node, which is an element of $\Set{List}(\2)$, i.e.\ a finite list of choices in $\2$, which you can think of as a finite sequence of left/right choices. The codomain is whatever tree this path ends up on. 

So the carrier of $\cofree{p}$ is
\[\tr_p\cong\nn^{\Set{List}(\2)}\yon^{\Set{List}(\2)}\]
with identities given by the empty list. An object $t\in\tr_p(\1)$ is a function $t\colon\Set{List}(\2)\to\nn$, a way to put a natural number at every node of the infinite binary tree. An emanating morphism $\ell\in\Set{List}(\2)$ is just a path from the root to another node, and its codomain is the other node. Formally it is the function $t'\colon\Set{List}(\2)\to\nn$ given by $t'(\ell')\coloneqq t(\ell:\ell')$, where $\ell:\ell'$ is the concatenation of these lists. Composition of morphisms is also given by concatenation of the corresponding lists.
\end{example}

\begin{exercise}
Let $p\coloneqq B\yon^A$ for sets $A,B\in\smset$.
\begin{enumerate}
	\item Describe the objects of the cofree category $\cofree{p}$.
	\item For a given such object, describe the emanating morphisms.
	\item Describe how to take the codomain of a morphism.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{example}[$\cofree{A\yon}$ for linear polynomials]\label{ex.streams_cofree}
Let $A\in\smset$ be a set. The cofree comonoid $\cofree{A\yon}$ on the associated linear polynomial has as its carrier $\tr_{A\yon}\cong (A\yon)^\nn$. Its objects are $A$-streams. For each stream $t\colon \nn\to A$, an emanating morphism is just an element $n\in\nn$. The identity is $0\in\nn$, the codomain of $n$ is the composite function $\nn\To{+n}\nn\To{t}A$, and if we denote it by $n\colon t\to (t+n)$ then the composite of morphisms $n,n'$ is $(n+n')\colon t\to (t+n+n')$.

We first saw this category in \cref{ex.streams_category}
\end{example}

\begin{exercise}
Let $p\coloneqq \yon+\1$.
\begin{enumerate}
	\item Describe the objects of the cofree category $\cofree{p}$.
	\item For a given such object, describe the emanating morphisms.
	\item Describe how to take the codomain of a morphism.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
Let $p\coloneqq \{a,b,c,\ldots,z,\text{\textvisiblespace}\}\yon+\1$.
\begin{enumerate}
	\item Describe the objects of the cofree category $\cofree{p}$, and draw one.
	\item For a given such object, describe the emanating morphisms.
	\item Describe how to take the codomain of a morphism.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
Let $p$ be a polynomial, let $Q\coloneqq\{q\in\qq\mid q\geq 0\}$ and consider the monoid $\yon^Q$ of nonnegative rational numbers under addition. Is it true that any cofunctor $\varphi\colon\cofree{p}\cof\yon^\qq$ is constant, i.e.\ that it factors as
\[
\cofree{p}\cof\yon\cof\yon^\qq?
\]
\begin{solution}
Take $p\coloneqq\2\yon$, and consider the object $x\in\cofree{p}(\1)$ given by the stream
\[
x\coloneqq(2\,12\,112\,1112\,11112\,111112\ldots)
\]
(with spaces only for readability); note that every morphism emanating from $x$ has a different codomain. We need to give $\varphi^\sharp_i(q)$ for every $i\in\cofree{p}(\1)$ and $q\geq 0$. Define
\[
	\varphi^\sharp_i(q)\coloneqq
	\begin{cases}
		i&\tn{ if }i\neq x \tn{ or } q=0\\
		x'&\tn{ if }i=x\tn{ and } q>0
	\end{cases}
\]
where $x'\coloneqq(12\,112\,1112\,11112\,111112\ldots)$. There are three cofunctor conditions to check, namely identity, codomains, and composition. The codomain condition is vacuous since $\yon^Q$ has one object, and the identity condition holds by construction, because we always have $\varphi^\sharp_i(0)=i$. Now take $q_1,q_2\in Q$; we need to check that
\[\varphi^\sharp_{\cod\varphi^\sharp_i(q_1)}(q_2)=^?\varphi^\sharp_i(q_1+q_2)\]
holds. If $i\neq x$ or $q_1=q_2=0$, then it holds because both sides equal $i$. If $i=x$ and either $q_1>0$ or $q_2>0$, it is easy to check that both sides equal $x'$, so again it holds.
\end{solution}
\end{exercise}

%---- Subsection ----%
\subsection{Decision trees}

When you talk about your future, what exactly might you be talking about? In some sense you can make choices that change what will happen to you, but in another sense it's as though for each such choice there is something beyond your control that makes a new situation for you. You're constantly in the position of needing to make a choice, but its results are beyond your control.

This is very much how positions $t\in\cofree{p}$ look. Such a position is a decision tree: at each stage (node), you have an element $i\in p(\1)$, which we've been calling a decision. It has $p[i]$-many options, each of which, say $d\in p[i]$ results in a new node $\cod(d)$ of the tree.

So a position $t$ is like a future: it is a current decision, and for every option there, a new decision tree. It's all the decisions you could possibly make, and for each actual choice, it's a new future. A direction at $t$ is just a choice of finite path through the tree: a sequence of choices. 

\begin{exercise}
If someone says that they understand a future to be a decision tree $t\in\cofree{p}$, explain in your own words how they're thinking about the term ``future.'' How does it agree or disagree with your own intuition about what a ``future'' is?
\begin{solution}
**
\end{solution}
\end{exercise}

\begin{exercise}
Let $G$ be a finite directed graph, and let $\Cat{Fr}(G)$ be the associated free category. 
\begin{enumerate}
	\item Construct a cofunctor $\Cat{Fr}(G)\cof\cofree{\1+\yon+\yon^\2+\yon^\3+\cdots}$.
	\item Would you say it associates to each node in $G$ its ``future'' decision tree?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

%-------- Section --------%
\section{Formal construction of $\cofree{p}$}

We will sketch how one can formally construct $\cofree{p}$ from $p$. The first step is called copointing, and it's pretty easy: just multiply $p$ by $\yon$. It adds a kind of ``default'' direction to each position in $p$.

%---- Subsection ----%
\subsection{Copointing}

\begin{definition}[Copointed polynomial]
A \emph{copointed polynomial} is a pair $(p,\epsilon)$, where $p\in\poly$ is a polynomial and $\epsilon\colon p\to\yon$ is a morphism in $\poly$.

A \emph{morphism} of copointed polynomials $f\colon (p,\epsilon)\to(p',\epsilon')$ is a morphism $f\colon p\to p'$ such that $\epsilon=f\then\epsilon'$.
\end{definition}

Comonoids in $\poly$ are triples $(p,\epsilon,\delta)$, with $(p,\epsilon)$ a copointed polynomial, so there are forgetful functors
\[
\Cat{Comon}(\poly)\to\Cat{Cpt}(\poly)\to\poly.
\]
We want to find the right adjoint to the composite---that's the functor $\cofree{-}\colon\poly\to\Cat{Comon}(\poly)$---and we will obtain it in two steps. 

\begin{proposition}\label{prop.copointing}
For any polynomial $p$, the polynomial $p\yon$ is naturally copointed by the projection to $\yon$, and the functor sending $p\mapsto p\yon$ is right adjoint to the forgetful functor
\[
\adj{\Cat{Cpt}(\poly)}{p\yon}{q}{\poly},
\]
where the functors are named by where they send $p\in\poly$ and $(q,\epsilon)\in\Cat{Cpt}(\poly)$.
\end{proposition}
\begin{proof}
Clearly the product $p\yon\cong p\times\yon$ is copointed by the projection map, call it $\pi\colon p\yon\to\yon$, and the map $p\mapsto p\yon$ is functorial in $p$. For any copointed polynomial $q\To{\epsilon}\yon$, there is an obvious bijection between morphisms of polynomials $q\to p$ and commutative triangles
\[
\begin{tikzcd}[column sep=small]
	q\ar[dr, "\epsilon"']\ar[rr]&&
	p\yon\ar[dl, "\pi"]\\&
	\yon
\end{tikzcd}
\]
natural in both $q$ and $p$. This completes the proof.
\end{proof}

\begin{exercise}
Show that the copointing functor is essentially surjective. That is, every polynomial $p$ equipped with a map $\epsilon\colon p\to\yon$ is isomorphic to one of the form $p'\yon$ (equipped with the projection $p'\yon\to\yon$).
\begin{solution}
**
\end{solution}
\end{exercise}

The reader might not remember any sort of copointing showing up in the tree description of $\cofree{p}=(\tr_p,\rt,\fs)$. Indeed, it was hidden in the fact that we allowed for trivial paths in the tree (e.g.\ the path from the root to itself). But we'll get to that.

The copointing $p\mapsto p\yon$ just adds an extra direction to each position; we can denote this extra direction with an $=$, as we did in \cref{ex.walking_arrow_cat}. So for example if $p=\yon^\3+\yon$, drawn as left, then $p\yon\cong\yon^\4+\yon^\2$ can be drawn as right:
\[
\begin{tikzpicture}
	\node[draw, "$p$" below] (p1) {
	\begin{tikzpicture}[trees, sibling distance=4mm]
    \node (1) {$\bullet$} 
      child 
      child 
      child;
    \node[right=.75 of 1] (2) {$\bullet$} 
      child;
  \end{tikzpicture}
  };
	\node[draw, "$p\yon$" below] (p2) [right=of p1] {
	\begin{tikzpicture}[trees, sibling distance=3mm]
    \node (1) {$\bullet$} 
      child {\idchild}
      child 
      child 
      child;
    \node[right=.75 of 1] (2) {$\bullet$} 
      child {\idchild}
      child;
  \end{tikzpicture}
	};
\end{tikzpicture}
\]
It just adds a default direction to each position. A copointed map from $(q,\epsilon)$ to $(p\yon,\pi)$ must pass the default direction back to the default direction in $q$, but leaves the other directions in $p$ to go wherever they want to.

\begin{example}[Slowing down dynamical systems]
Given a dynamical system $f\colon S\yon^S\to p$, we automatically get a map $S\yon^S\to p\yon$ to the cofree pointing. We called this ``adding a pause button'' in \cref{ex.pause}. Thus we can take any dynamical system and replace it with one whose interface is copointed.

We can use a copointed interface to slow down a dynamical system, in a kind of inverse to how we sped up dynamical systems in \eqref{eqn.speedup}. There we took a dynamical system $f$ with interface $p$ and produced one with interface $p\tripow{k}$. Here we will take one with interface $p\tripow{k}$ and produce one with interface $p$.

To do this, we need $p$ to be copointed, i.e.\ we need to have in hand a map $\epsilon\colon p\to\yon$, and as we saw above that we can always assume that. Now for any $k\in\nn$ we have $k$-many maps $p\tripow{k}\to p$. For example, if $k=3$, we have
\[
\{\epsilon\tri\epsilon\tri p,\epsilon\tri p\tri\epsilon,p\tri\epsilon\tri\epsilon\}\ss\poly(p\tripow3,p)
\]
So given a dynamical system $S\yon^S\to p\tripow{k}$, which outputs as its position a whole $k$-fold strategy at one time and which takes as input sequences of $k$-many inputs, we can feed it one input and $k-1$ pauses. This is what you get when you compose $S\yon^S\to p\tripow{k}\to p$.

Given a dynamical system $f\colon S\yon^S\to p$, where $p$ is copointed and $f$ preserves the copoint, we could speed it up as before to get $S\yon^S\to p\tripow{k}$ and then slow it down to get $S\yon^S\to p$, and we get back $f$. So slowing down is a retract of speeding up in this sense.
\end{example}

\begin{exercise}
\begin{enumerate}
	\item Show that there is a monoidal structure $(\yon,\otimes)$ on $\Cat{Cpt}(\poly)$ such that the forgetful functor $U\colon\Cat{Cpt}(\poly)\to\poly$ is strong monoidal.
	\item Show that this monoidal structure is closed, i.e.\ that there is an internal hom $[-,-]$ on $\Cat{Cpt}(\poly)$.
	(Hint: You should have $U([p\yon,q\yon]_{\Cat{Cpt}})\cong[p\yon,q]_{\poly}\yon$.)
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

%---- Subsection ----%
\subsection{Constructing the cofree comonoid}

It remains to show that we can functorially take any copointed polynomial $(q,\epsilon)$ and return a comonoid, and that this construction is right adjoint to the forgetful functor. From the description in \cref{subsec.comon.cofree.cons.car}, we know the cofree comonoid is supposed to have something to do with infinite trees. And we know that the set of height-$n$ $p$-trees is given by $p\tripow{n}$. So we might think we can somehow take a limit of these height-$n$ trees for various $n$. 

The problem is there's no obvious maps between $p\tripow{n}$ and $p\tripow{n+1}$. Luckily, the copointing fixes that problem. Given $\epsilon\colon q\to\yon$, we have two maps $q\tri q\tto q$, namely $q\tri\epsilon$ and $\epsilon\tri q$.

\begin{example}
Suppose $q=\{A\}\yon^{\{i_A,f\}}+\{B\}\yon^{i_B}$ with copointing $\epsilon$ selecting $i_A$ and $i_B$:
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "$q\coloneqq$" left] {
	\begin{tikzpicture}[trees, sibling distance=5mm]
    \node["\tiny $A$" below, red] (1) {$\bullet$} 
      child  {coordinate (iA) \idchild}
      child {coordinate (f)};
    \node[right=.8 of 1,"\tiny $B$" below, blue] (2) {$\bullet$} 
      child  {coordinate (iB) \idchild};
    \node[below left=0 of iA, font=\tiny] {$i_A$};
    \node[below left=0 of iB, font=\tiny] {$i_B$};
    \node[below right=0 of f, font=\tiny] {$f$};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Then $q\tri q$ looks as follows
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "$q\tri q=$" left] {
	\begin{tikzpicture}[trees,
	  level 1/.style={sibling distance=5mm},
  	level 2/.style={sibling distance=2.5mm}]
    \node[red] (1) {$\bullet$} 
      child  {
        node [red] {$\bullet$} 
 		    child  {\idchild}
      	child {}
			\idchild
			}
      child  {
        node [red] {$\bullet$} 
 		    child  {\idchild}
      	child {}
			};
    \node[right=1 of 1, red] (2) {$\bullet$} 
      child  {
        node [red]{$\bullet$} 
 		    child  {\idchild}
      	child {}
			\idchild
			}
      child {node [blue] {$\bullet$} 
      	child  {\idchild}
			};
    \node[right=1 of 2, red] (3) {$\bullet$} 
      child {node [blue] {$\bullet$} 
      	child  {\idchild}
				\idchild
			}
      child  {
        node [red] {$\bullet$} 
 		    child {\idchild}
      	child {}
			};
    \node[right=1 of 3, red] (4) {$\bullet$} 
      child {node [blue] {$\bullet$} 
      	child  {\idchild}
			\idchild
			}
      child {node [blue] {$\bullet$} 
      	child  {\idchild}
			};
    \node[right=.8 of 4, blue] (5) {$\bullet$} 
      child  {
        node [red] {$\bullet$} 
 		    child  {\idchild}
      	child {}
			\idchild
			};
    \node[right=.6 of 5, blue] (6) {$\bullet$} 
      child {node [blue] {$\bullet$} 
      	child  {\idchild}
			\idchild
			};
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
How can we picture the maps $(q\tri\epsilon),(\epsilon\tri q)\colon q\tri q\to q$?

The map $q\tri\epsilon$ takes each position of $q\tri q$ to whatever is on the bottom layer: it takes the first four to $A$ and the last two to $B$. It passes back directions using the defaults ($i_A$ and $i_B$) on the top layer.

The map $\epsilon\tri q$ uses the defaults on the bottom layer instead. Every position in $q\tri q$ has a default direction, and the corolla sitting there in the top layer is where $\epsilon\tri q$ sends it, with identity on directions. 
\end{example}

Indeed, for every $n$, there are $(n+1)$-many morphisms $q\tripow{n+1}\to q\tripow{n}$, so we have a diagram
\begin{equation}\label{eqn.simplicial_diag}
\begin{tikzcd}
	\yon&
	q\ar[l, "\epsilon"']&
	q\tri q\ar[l, shift left, "q\tri\epsilon"]\ar[l, shift right, "\epsilon\tri q"']&[10pt]
	q\tripow3\ar[l, shift left=7pt, "q\tri q\tri\epsilon"]\ar[l, shift right=7pt, "\epsilon\tri q\tri q"']\ar[l, "q\tri\epsilon\tri q" description]&
	\cdots\ar[l, shift left=6pt]\ar[l, shift left=2pt]\ar[l, shift right=6pt]\ar[l, shift right=2pt]
\end{tikzcd}
\end{equation}
The cofree comonoid is given by the limit of this diagram.

Let's denote the shape of this diagram by $\Delta_+$: its objects are finite ordered sets---including the empty set---and its morphisms are order-preserving injections. For any copointed polynomial $q\To{\epsilon}\yon$, we get a diagram $Q\colon\Delta_+\to\poly$ as above, and this is functorial in $q$.

\begin{theorem}\label{thm.cofree2}
For any copointed polynomial $q\To{\epsilon}\yon$, let $\bar{q}$ denote the limit of $Q\colon\Delta_+\to\poly$. It naturally has the structure of a comonoid $(\bar{q},\epsilon,\delta)$, and this construction is right adjoint to the forgetful functor
\[
\adj{\Cat{Comon}(\poly)}{U}{\bar{q}}{\Cat{Cpt}(\poly)}.
\]
\end{theorem}
\begin{proof}[Proof sketch]
We first give $\bar{q}$ the structure of a comonoid. Since $\bar{q}$ is the limit of \eqref{eqn.simplicial_diag}, the inclusion the inclusion $\{0\}\to\Delta_+$ induces a projection map $\bar{q}\to\yon$, which we again call $\epsilon$. Since $\tri$ commutes with connected limits in both variables and $\Delta_+$ is connected, we have that $\bar{q}\tri\bar{q}$ is the limit of the following $\Delta_+\times\Delta_+$-shaped diagram:
\[
\bar{q}\tri\bar{q}\cong\lim\left(
\begin{tikzcd}
  q\tripow{(0+0)}&
  q\tripow{(0+1)}\ar[l]&
  q\tripow{(0+2)}\ar[l, shift left=2pt]\ar[l, shift right=2pt]&
  q\tripow{(0+3)}\ar[l]\ar[l, shift left=4pt]\ar[l, shift right=4pt]&
  \cdots\ar[l, shift left=6pt]\ar[l, shift left=2pt]\ar[l, shift right=2pt]\ar[l, shift right=6pt]\\
  q\tripow{(1+0)}\ar[u]&
  q\tripow{(1+1)}\ar[u]\ar[l]&
  q\tripow{(1+2)}\ar[u]\ar[l, shift left=2pt]\ar[l, shift right=2pt]&
  q\tripow{(1+3)}\ar[u]\ar[l]\ar[l, shift left=4pt]\ar[l, shift right=4pt]&
  \cdots\ar[l, shift left=6pt]\ar[l, shift left=2pt]\ar[l, shift right=2pt]\ar[l, shift right=6pt]\\
  q\tripow{(2+0)}\ar[u, shift left=2pt]\ar[u, shift right=2pt]&
  q\tripow{(2+1)}\ar[u, shift left=2pt]\ar[u, shift right=2pt]\ar[l]&
  q\tripow{(2+2)}\ar[u, shift left=2pt]\ar[u, shift right=2pt]\ar[l, shift left=2pt]\ar[l, shift right=2pt]&
  q\tripow{(2+3)}\ar[u, shift left=2pt]\ar[u, shift right=2pt]\ar[l]\ar[l, shift left=4pt]\ar[l, shift right=4pt]&
  \cdots\ar[l, shift left=6pt]\ar[l, shift left=2pt]\ar[l, shift right=2pt]\ar[l, shift right=6pt]\\
  q\tripow{(3+0)}\ar[u]\ar[u, shift left=4pt]\ar[u, shift right=4pt]&
  q\tripow{(3+1)}\ar[u]\ar[u, shift left=4pt]\ar[u, shift right=4pt]\ar[l]&
  q\tripow{(3+2)}\ar[u]\ar[u, shift left=4pt]\ar[u, shift right=4pt]\ar[l, shift left=2pt]\ar[l, shift right=2pt]&
  q\tripow{(3+3)}\ar[u]\ar[u, shift left=4pt]\ar[u, shift right=4pt]\ar[l]\ar[l, shift left=4pt]\ar[l, shift right=4pt]&
  \cdots\ar[l, shift left=6pt]\ar[l, shift left=2pt]\ar[l, shift right=2pt]\ar[l, shift right=6pt]\\
	\vdots\ar[u, shift left=6pt]\ar[u, shift left=2pt]\ar[u, shift right=2pt]\ar[u, shift right=6pt]&
	\vdots\ar[u, shift left=6pt]\ar[u, shift left=2pt]\ar[u, shift right=2pt]\ar[u, shift right=6pt]&
	\vdots\ar[u, shift left=6pt]\ar[u, shift left=2pt]\ar[u, shift right=2pt]\ar[u, shift right=6pt]&
	\vdots\ar[u, shift left=6pt]\ar[u, shift left=2pt]\ar[u, shift right=2pt]\ar[u, shift right=6pt]&
	\ddots
\end{tikzcd}
\right)
\]
There is a commutative diagram in $\smcat$
\begin{equation}\label{eqn.simplicial_poly_misc384}
\begin{tikzcd}[column sep=small]
	\Delta_+\times\Delta_+\ar[rr, "+"]\ar[dr, bend right, near start, "{(m_1,m_2)\mapsto q\tripow{(m_1+m_2)}}"']&&
	\Delta_+\ar[dl, bend left, near start, "n\mapsto q\tripow{n}"]\\&
	\poly
\end{tikzcd}
\end{equation}
which induces a map (in the opposite direction) between their limits $\delta\colon\bar{q}\to\bar{q}\tri\bar{q}$, which we take to be the duplicator. Appending \eqref{eqn.simplicial_poly_misc384} with the inclusion $\{0\}\times\Delta_+\to\Delta_+\times\Delta_+$, etc., it is easy to see that $(\bar{q},\epsilon,\delta)$ satisfies the axioms of a comonoid.

We sketch the proof that this construction is right adjoint to the forgetful functor. For any copointed polynomial $(q,\epsilon)$, there is a eraser map $\bar{q}\to q$, given by the obvious projection of the limit \eqref{eqn.simplicial_diag}. Given a comonoid $(\ema{c},\epsilon,\delta)$, there is a morphism $\ema{c}\to\bar{\ema{c}}$ induced by the maps $\delta^{n-1}\colon\ema{c}\to\ema{c}\tripow{n}$ from \cref{prop.n_duplication}. It is easy to check that these commute with the $\epsilon$'s in the diagram. To see that $\ema{c}\to\bar{\ema{c}}$ extends to a morphism of comonoids amounts to checking that the diagram
\[
\begin{tikzcd}[column sep=50pt]
	\ema{c}\ar[r, "\delta^{m+n-1}"]\ar[d, "\delta"']&
	\ema{c}\tripow{(m+n)}\ar[d, equal]\\
	\ema{c}\tri\ema{c}\ar[r, "\delta^{m-1}\tri\delta^{n-1}"']&
	\ema{c}\tripow{m}\tri\ema{c}\tripow{n}
\end{tikzcd}
\]
commutes for any $m,n\in\nn$. Both triangle equations are straightforward.
\end{proof}

\begin{remark}
The construction of the cofree comonoid from a copointed endofunctor in the proof of \cref{thm.cofree2} is fairly standard; see \cite{lack2010note}. Nelson Niu has also constructed the cofree comonoid on a polynomial using a different limit diagram
\[
\begin{tikzcd}
	\yon\ar[d]&
	p\ar[d]&
	p\tri p\ar[d]&[10pt]
	p\tri p\tri p\ar[d]&
	\cdots\\
	\1&
	p\tri \1\ar[l, "!"]&
	p\tri p\tri \1\ar[l, "p\tri\,!"]&
	p\tri p\tri p\tri \1\ar[l, "p\tri p\tri\,!"]&
	\cdots\ar[l]
\end{tikzcd}
\]
in terms of the original polynomial $p$, rather than from its copointing $p\yon$; that is, this construction is right adjoint to $\Cat{Comon}(\poly)\to\poly$. One could also construct this right adjoint using the following limit, again applied to the original polynomial $p$:
\[
\begin{tikzcd}[sep=small]
	\yon\ar[dr]&&
	p\ar[dl]\ar[dr]&&
	p\tri p\ar[dl]\ar[dr]&&
	p\tri p\tri p\ar[dl]\ar[dr]&
	\cdots\\&
	\1&&
	p\tri\1&&
	p\tri p\tri \1&&
	\cdots
\end{tikzcd}
\]
\end{remark}

We record the following proposition here; it will be useful in \cref{cor.cartesian_cof_extra_adjoint}.

\begin{proposition}
If $f\colon p\to q$ is a cartesian lens of polynomials, then $\tr_f\colon\tr_p\to\tr_q$ is a cartesian cofunctor. That is, for each tree $t\in\tr_p(\1)$ the function $\tr_f^\sharp\colon\tr_p[t]\To{\cong}\tr_q[\tr_f(t)]$ is a bijection.
\end{proposition}
\begin{proof}
**
\end{proof}

\begin{proposition}
The cofree comonoid functor is lax monoidal; in particular, we have maps
\[
\yon\to\cofree{\yon}
\qqand
\cofree{p}\otimes\cofree{q}\to\cofree{p\otimes q}
\]
for any $p,q\in\poly$.
\end{proposition}

%-------- Section --------%
\section{$\sys(p)$ is a topos}

\begin{theorem}\label{thm.cofree_coalgebras}
Let $\cofree{p}$ be the cofree comonoid on $p\in\poly$. There is an equivalence of categories
\[
\sys(p)\cong\smcat(\cofree{p},\smset)
\]
between the category of dynamical systems on $p$ and that of functors $\cofree{p}\to\smset.$
\end{theorem}
\begin{proof}
** (In general, coalgebras of comonoids are copresheaves on the corresponding category)
\end{proof}

A consequence of this is that $\sys(p)$ forms a topos, and hence has a ready-made type theory and internal logic. While we don't have space to do this justice, we will briefly discuss the sort of logical statement one can make about dynamical systems.




%-------- Section --------%
\section{Morphisms between cofree comonoids}
Given a morphism of polynomials $\varphi \colon p \to q$, the cofree functor gives us a map of comonoids $\cofree{\varphi} \colon \cofree {p} \to \cofree{q}$, which works as follows.

An object $t \in \tr_p$ is a tree; the tree $u \coloneqq \cofree{\varphi} (t) \in \tr_q $ is constructed recursively as follows. If the root of $t$ is $i \in p(\1)$ then the root of $u$ is $j \coloneqq \varphi_1 (i)$. To each branch $b \in q[j]$, we need to assign a new tree, and we use the one situated at $\varphi_i ^ \sharp (b)$.

\begin{exercise}
Let $p \coloneqq \yon ^\2 + \1$ and $q \coloneqq \2 \yon + \2$.
\begin{enumerate}
    \item Choose a map $\varphi \colon p \to q$, and write it out.
    \item Choose a tree $t \in \tr_p$ with at least height $2$.
    \item What is $\cofree{\varphi}(t)$?
    \qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
The following exercise is useful when considering the (topos-theoretic) logic of dynamical systems. Namely, it will allow us to specify legal subtrees of height $n$.
\begin{enumerate}
    \item Choose a polynomial $q$ and a map $\epsilon \colon q \to \yon$, i.e. a copointed polynomial.
    \item Recall from \cref{thm.cofree2} that the carrier $\bar{q}$ of the cofree comonoid $\cofree{q} = (\bar{q}, \epsilon, \delta)$ is constructed as a limit
    \[
      \bar{q} = \lim \left(
\begin{tikzcd}
	\yon&
	q\ar[l]&
	q\tri q\ar[l, shift left]\ar[l, shift right]&[10pt]
	q\tripow3\ar[l, shift left=7pt]\ar[l, shift right=7pt]\ar[l ]&
	\cdots\ar[l, shift left=6pt]\ar[l, shift left=2pt]\ar[l, shift right=6pt]\ar[l, shift right=2pt]
\end{tikzcd}
      \right)
    \]
      and in particular there is a structure map $\bar{q} \to q \tripow{n}$, for any $n \in \nn$. Where does it send a tree $t \in \tr_q$?
      \item There is an induced cofunctor $\cofree{q} \to \cofree{q \tripow{n}}$. Show that for all $n\geq 1$, it is it an isomorphism.
      \qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

%-------- Section --------%
\section{Consequences of adjointness}

%\[
%\begin{tikzpicture}[polybox, tos]
%	\node[poly, dom, "$q$" left] (q) {};
%	\node[poly, cod, below right=1.6 and 4 of q.south, "$p$" right] (p1) {};
%	\node[poly, cod, above=of p1, "$p$" right] (p2) {};
%	\node[poly, cod, above=of p2, "$p$" right] (p3) {};
%	\node[poly, cod, above=of p3, "$p$" right] (p4) {};
%	\node[poly, cod, above=of p4, "$p$" right] (p5) {};
%	\node[poly, draw=none, above=of p5] (ph) {};
%%
%	\draw (q_pos) to[first] (p1_pos);
%	\draw (p1_dir) to[climb] node[circle, inner sep=0, fill=white] (or2) {or}(p2_pos);
%	\draw (p2_dir) to[climb] node[circle, inner sep=0, fill=white] (or3) {or} (p3_pos);
%	\draw (p3_dir) to[climb] node[circle, inner sep=0, fill=white] (or4) {or} (p4_pos);
%	\draw (p4_dir) to[climb] node[circle, inner sep=0, fill=white] (or5) {or} (p5_pos);
%	\draw (p5_dir) to[climb] node[circle, inner sep=0, fill=white] (or6) {or} (ph_pos);
%	\draw[shorten <=4pt] (or2.center) to[last] (q_dir);
%	\draw[shorten <=4pt] (or3.center) to[last] (q_dir);
%	\draw[shorten <=4pt] (or4.center) to[last] (q_dir);
%	\draw[shorten <=4pt] (or5.center) to[last] (q_dir);
%	\draw[shorten <=4pt] (or6.center) to[last] (q_dir);
%\end{tikzpicture}
%\]

Recall from \cref{def.gen_moore} that a dependent system (or generalized Moore machine) is a map of polynomials $f\colon S\yon^S\to p$. Here $S$ is called the set of states and $p$ is the interface. 

But now we know that $S\yon^S$ is secretly the underlying polynomial of a comonoid. This means that $f$ has a mate, i.e.\ a corresponding cofunctor $S\yon^S\cof\cofree{p}$ to the category of $p$-trees. How does that work?

\begin{example}\label{ex.cofree_dyn_sys}
Let $S\coloneqq\{\bul[dgreen],\bul[dyellow],\bul[red]\}$ and $p\coloneqq\yon^\2+\1$, and consider the dynamical system $f\colon S\yon^S\to p$ from \cref{exc.det_fsa_misc_398}, depicted here again for your convenience:
\[
\begin{tikzcd}[column sep=small]
	\bul[dgreen]\ar[rr, bend left, orange]\ar[loop left, dgreen]&&
	\bul[dyellow]\ar[dl, bend left, orange]\ar[ll, dgreen, bend left]\\&
	\bul[red]
\end{tikzcd}
\]
The polynomial map $f$ is supposed to induce a cofunctor $F\colon S\yon^S\cof\cofree{p}$ from the state category on $S$ to the category of $p$-trees. Thus to each state $s\in S$, we need to associate a tree; which should it be? 
\end{example}

\begin{exercise}
Consider the walking arrow category $\cat{W}=\fbox{$\bullet\to\bullet$}$. Draw the cofunctor $\cat{W}\cof\cofree{\yon^\2+\yon}$.
\begin{solution}
**
\end{solution}
\end{exercise}

%---- Subsection ----%
\subsection{Dynamical systems and graph fibrations}

In \cref{ex.cofree_dyn_sys}, there's a certain relationship we can see between the graph we associate to the dynamical system $S\yon^S\to p$, namely 
\[
\begin{tikzcd}[column sep=small]
	\bul[dgreen]\ar[rr, bend left, orange]\ar[loop left, dgreen]&&
	\bul[dyellow]\ar[dl, bend left, orange]\ar[ll, dgreen, bend left]\\&
	\bul[red]
\end{tikzcd}
\]
and the trees (which are also graphs) that its mate $S\yon^S\to\cofree{p}$ associates to each element of $S$, e.g.\ for the green dot:
\[
\treepic
\]
Indeed, there is a map of graphs from the latter to the former, which sends all the green dots in the tree to the green dot in the dynamical system, etc. This map of graphs is a kind of \emph{fibration}, or maybe we should say op-fibration, in the sense that the set of arrows emanating from every dot in the tree is in bijection with the set of arrows emanating from its image in the dynamical system graph.

\begin{exercise}
\begin{enumerate}
	\item Draw the other two trees associated to the dynamical system in \cref{ex.cofree_dyn_sys}.
	\item Do they also have an op-fibration down to the dynamical system graph?
	\item Are these op-fibrations special in any way? That is, are they unique, or have any universal property?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

%---- Subsection ----%
\subsection{Replacing $S\yon^S$ by another comonoid}

For any interface $p$, we defined a dependent dynamical system---also called a generalized Moore machine---to be a set $S$ and a polynomial map $S\yon^S\to p$. But now it seems that what really makes this work is that $S\yon^S$ underlies a comonoid. This suggests that we could instead have defined a dependent dynamical system to be a comonoid $\cat{C}=(\ema{c},\epsilon,\delta)$ together with a map $\ema{c}\to p$. What are the similarities and differences?

Here are some similarities. We still get a cofunctor $F\colon\cat{C}\to\cofree{p}$, so we associate a $p$-tree to each object in $\cat{C}$ and pass back paths out of its root to morphisms in $\cat{C}$. In terms of dynamics, we would think of objects in $\cat{C}$ as internal states. We still have the situation from \eqref{eqn.comon_delta_k}, meaning that for every state $c\in\cat{C}$, we get a position $i\coloneqq F_1(c)$ in $p(\1)$, and for every direction $d\in p[i]$ there we get a new state $\cod(F^\sharp_c(d))\in\cat{C}$. 

But in fact we get a little more from $F$, and this is where the differences come in. Namely, given a direction $d\in p[i]$, we get the morphism $F^\sharp_c(d)$ itself. In the state category $S\yon^S$, there is a unique morphism between every two objects, so this passed-back morphism carries no data beyond what its codomain is. But for a more general comonoid $\cat{C}$, the morphisms \emph{do} carry data. 

Thus we can think of a map $\ema{c}\to p$ as a dynamical system that ``records its history.'' That is, given a path $\cofree{p}$, a sequence of inputs to our dynamical system, we get a morphism in $\cat{C}$. If, unlike in a state category $S\yon^S$, there are multiple morphisms between objects, we will know which one was actually taken by the system.

This seems like a nice generalization of dynamical systems---history-recording dynamical systems---and may have some use. However, we will see in \cref{chapter.bimod} that there are strong theoretical reasons to emphasize the ahistorical state categories $S\yon^S$. For one thing, the category of all such $S\yon^S$-style dynamical systems on $p$ forms a topos for any $p\in\poly$.


%-------- Section --------%
\section{Some categorical properties of cofree comonoids}

%**check precise conditions of applying Pare/Porst
\begin{proposition}[Porst]
The forgetful functor $\smcat^\sharp\to\poly$ is comonadic.
\end{proposition}
\begin{proof}
The fact that a forgetful functor $\smcat^\sharp\iso\Cat{Comon}(\poly)\to\poly$ is comonadic if it has a right adjoint follows from Beck's monadicity theorem via a straightforward generalization of an argument given by Par{\'e} in \cite[pp.~138-9]{pare1969absolute}, as pointed out by Porst in \cite[Fact~3.1]{porst2019colimits}.
\end{proof}

\begin{corollary}
The category $\smcat^\sharp$ has all small colimits.
They are created by the forgetful functor $\smcat^\sharp\to\poly$.
\end{corollary}
\begin{proof}
A comonadic functor creates all colimits that exist in its codomain (see \cite{nlab:created-limit}), and by \cref{thm.poly_colimits}, the category $\poly$ has all small colimits.
\end{proof}

\begin{proposition}\label{prop.cofree_free_on_graph}
For every polynomial $p$, the cofree category $\cofree{p}$ is free on a graph. That is, there is a graph $G_p$ whose associated free category in the usual sense (the category of vertices and paths in $G_p$) is isomorphic to $\cofree{p}$.
\end{proposition}
\begin{proof}
For vertices, we let $V_p$ denote the set of $p$-trees,
\[V_p\coloneqq\tr_p(\1).\]
For arrows we use the map $\pi\colon\tr_p\to p$ from \cref{**} to define
\[
A_p\coloneqq\sum_{t\in\tr_p(\1)}p[\pi_1(t)]
\]
In other words $A_p$ is the set $\{d\in p[\pi_1(t)]\,\mid\,t\in\tr_p\}$ of directions in $p$ that emanate from the root corolla of each $p$-tree. The source of $(t,d)$ is $t$ and the target is $\cod(\pi^\sharp_t(d))$. It is clear that every morphism in $\cofree{t}$ is the composite of a finite sequence of such morphisms, completing the proof.
\end{proof}


\begin{corollary}
Let $p$ be a polynomial and $\cofree{p}$ the cofree comonoid. Every morphism in $\cat{C}_p$ is both monic and epic.
\end{corollary}
\begin{proof}
The free category on a graph always has this property, so the result follows from \cref{prop.cofree_free_on_graph}.
\end{proof}

\begin{proposition}\label{prop.cofree_lax_monoidal}
The cofree functor $p\mapsto\cofree{p}=(\tr_p,\rt,\fs)$ is lax monoidal; in particular there is a map of polynomials $\yon\to\tr_\yon$, and for any $p,q\in\poly$ there is a natural map
\[
	\tr_p\otimes\tr_q\to\tr_{p\otimes q}.
\]
satisfying the usual conditions.
\end{proposition}
\begin{proof}
By \cref{prop.dirichlet_on_catsharp}, the left adjoint $U\colon\smcat^\sharp\to\poly$ is strong monoidal. A consequence of Kelly's doctrinal adjunction theorem \cite{kelly1974doctrinal} says that the right adjoint of an op-lax monoidal functor is lax monoidal.
\end{proof}

\begin{exercise}
\begin{enumerate}
	\item What polynomial is $\tr_\yon$?
	\item What is the map $\yon\to\tr_\yon$ from \cref{prop.cofree_lax_monoidal}?
	\item Explain in words how to think about the map $\tr_p\otimes\tr_q\to\tr_{p\otimes q}$ from \cref{prop.cofree_lax_monoidal}, for arbitrary $p,q\in\poly$.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item **
    \item **
    \item **
\end{enumerate}
\end{solution}
\end{exercise}

\begin{proposition}\label{prop.ynn_monoid}
The additive monoid $\yon^\nn$ of natural numbers has a $\times$-monoid structure in $\smcat^\sharp$.
\end{proposition}
\begin{proof}
The right adjoint $p\mapsto\cofree{p}$ preserves products, so $\yon^{\List(\ord{n})}\cong\cofree{\yon^{\ord{n}}}$ is the $n$-fold product of $\yon^\nn$ in $\smcat^\sharp$. We thus want to find cofunctors $e\colon \yon\to\yon^\nn$ and $m\colon\yon^{\List(\2)}\to\yon^\nn$ that satisfy the axioms of a monoid. 

The unique polynomial map $\yon\to\yon^\nn$ is a cofunctor (it is the mate of the identity $\yon\to\yon$). We take $m$ to be the mate of the polynomial map $\yon^{\List(\2)}\to\yon$ given by the list $[1,2]$. One can check by hand that these definitions make $(\yon^\nn,e,m)$ a monoid in $(\smcat^\sharp,\yon,\times)$.
\end{proof}

Recall from \cref{ex.admissible_section} that an admissible section of a category $\cat{C}$ is a cofunctor $\cat{C}\cof\yon^\nn$.

\begin{corollary}
For any category $\cat{C}$, the set $\smcat^\sharp(\cat{C},\yon^\nn)$ of admissible sections has the structure of a monoid. Moreover, this construction is functorial
\[\smcat^\sharp(-,\yon^\nn)\colon\smcat^\sharp\to\Cat{Mon}\op\]
\end{corollary}
\begin{proof}
We saw that $\yon^\nn$ is a monoid object in \cref{prop.ynn_monoid}.
\end{proof}

A cofunctor $\cat{C}\cof\yon^\nn$ is a policy in $\cat{C}$: it assigns an outgoing morphism to each object of $\cat{C}$. Any two such trajectories can be multiplied: we simply do one and then the other; this is the monoid operation. The policy assigning the identity to each object is the unit of the monoid.

We use the notation $\cat{C}\mapsto\vec{\cat{C}}$ for the monoid of admissible sections.

\begin{theorem}\label{thm.catsharp_to_mon}
The admissible sections functor
\[\smcat^\sharp\to\Cat{Mon}\op\]
is right adjoint to the inclusion $\Cat{Mon}\op\to\smcat^\sharp$ from \cref{prop.monoids_ff}.
\end{theorem}
\begin{proof}
Let $\cat{C}$ be a category and $(M,e,*)$ a monoid. A cofunctor $F\colon\cat{C}\cof\yon^M$ has no data on objects; it is just a way to assign to each $c\in \cat{C}$ and $m\in M$ a morphism $F^\sharp_c(m)\colon c\to c'$ for some $c'\coloneqq\cod(F^\sharp_c(m))$. This assignment must send identities to identities and composites to composites: given $m'\in M$ we have $F^\sharp_c(m\then m')=F^\sharp_c(m)\then F^\sharp_{c'}(m')$. This is exactly the data of a monoid morphism $M\to \vec{\cat{C}}$: it assigns to each $m\in M$ an admissible section $\cat{C}$, preserving unit and multiplication.
\end{proof}

\begin{proposition}\label{prop.traj_mon_poly}
There is a commutative square of left adjoints
\[
\begin{tikzcd}
	\Cat{Mon}\op\ar[r, "U"]\ar[d, "\yon^-"']&
	\smset\op\ar[d, "\yon^-"]\\
	\smcat^\sharp\ar[r, "U"']&
	\poly
\end{tikzcd}
\]
where the functors denoted $U$ are forgetful functors.
\end{proposition}
\begin{proof}
Using the fully faithful functor $\yon^-\colon\Cat{Mon}\op\fromto\smcat^\sharp$ from \cref{prop.monoids_ff}, it is easy to check that the above diagram commutes. 

The free-forgetful adjunction $\smset\fromto\Cat{Mon}$ gives an opposite adjunction $\smset\op\fromto\Cat{Mon}\op$, where $U$ is now left adjoint. We saw that $\yon^-\colon\smset\op\to\poly$ is a left adjoint in \cref{prop.yoneda_left_adjoint}, that $U\colon\smcat^\sharp\to\poly$ is a left adjoint in \cref{thm.cofree}, and that $\yon^-\colon\Cat{Mon}\to\smcat^\sharp$ is a left adjoint in \cref{thm.catsharp_to_mon}.
\end{proof}

%-------- Section --------%
\section{Exercise solutions}
\Closesolutionfile{solutions}
{\footnotesize
\input{solution-file7}}

\end{document}