\documentclass[Book-Poly]{subfiles}
\begin{document}
%


\setcounter{chapter}{0}%Just finished 0.
\Opensolutionfile{solutions}[solution-file1]

%------------ Chapter ------------%
\chapter{Polynomial functors and dynamics}\label{chapter.poly}

\begin{quote}
It is a treasury box!\\
Full of unexpected connections!\\
It is fascinating!\\
I will think about it.\\
\mbox{}\hfill --Andr\'e Joyal, Summer 2020,\\
\mbox{}\hfill personal communication.
\end{quote}

%\tableofcontents*

%-------- Section --------%
\section{Introduction}


In this book we will investigate a remarkable category called $\poly$. We will see its intimate relationship with dynamic processes, decision-making, and the storage and transformation of data. But our story begins with something quite humble: high school algebra.
\begin{align}\label{eqn.polynomial1892}
\yon^\2+\2\yon+\1 \quad&\quad
\textit{polynomial}
\intertext{
All our polynomials will involve one variable, $\yon$, chosen for reasons we'll explain soon. Polynomials in one variable can be depicted as a forest of mini-trees:
}
\label{eqn.poly1892}
\begin{tikzpicture}[trees]
  \node (1) {$\bullet$} 
    child {}
    child {};
  \node[right=.5 of 1] (2) {$\bullet$} 
    child {};
  \node[right=.5 of 2] (3) {$\bullet$} 
    child {};
  \node[right=.5 of 3] (4) {$\bullet$};
\end{tikzpicture}
\quad&\quad\textit{forest}
\end{align}
More technically, each mini-tree---a rooted tree whose \emph{leaves} (the arrows) are all children of the \emph{root} (the solid dot)---is called a \emph{corolla}.
So our \emph{forests} are always unions of corollas.
Each corolla in \eqref{eqn.poly1892} corresponds to a \emph{pure-power summand} of the form $\yon^A$ in the polynomial given in \eqref{eqn.polynomial1892}: the corolla with $2$ leaves corresponds to $\yon^\2$; the two corollas that each have $1$ leaf correspond to the two copies of $\yon = \yon^\1$; and the corolla with no leaves corresponds to $\1 = \yon^0$.

We can label the roots and leaves of our forest, like so:
\[
%\label{eqn.labeled_forest}
\begin{tikzpicture}[trees]
  \node["$1$" below] (1) {$\bullet$} 
    child {node {$1$}}
    child {node {$2$}};
  \node["$2$" below, right=.5 of 1] (2) {$\bullet$} 
    child {node {$1$}};
  \node["$3$" below, right=.5 of 2] (3) {$\bullet$} 
    child {node {$1$}};
  \node["$4$" below, right=.5 of 3] (4) {$\bullet$};
\end{tikzpicture}
\]
This suggests yet another depiction of the polynomial \eqref{eqn.polynomial1892}: as a \emph{dependent set} $(p[i])_{i \in I}$.
Here $I = \4 = \{1, 2, 3, 4\}$\footnote{
In standard font, 4 represents the usual natural number. In sans serif font \4 represents the set $\3=\{1,2,3,4\}$ with 4 elements.
}, the set of roots, and
\begin{align} \label{eqn.arena}
p[1] = \2 = \{1, 2\}, \quad p[2] = \1 = \{1\}, \quad p[3] = \1 = \{1\}, \quad p[4] = \0 = \varnothing, \quad&\quad\textit{arena}
\end{align}
so that for each root $i \in I$, the set $p[i]$ consists of the leaves at that root.
We call the entire dependent set $(p[i])_{i \in I}$ an \emph{arena}.
Each element $i \in I$ is a \emph{position} in the arena, and each element $d \in p[i]$ is a \emph{direction} at position $i$.
So the relationship between the arena perspective and the forest picture is that positions are roots and directions are leaves.

% In a polynomial like $\4\2\yon^\3+\1\7\yon$, the pure power term $\yon^\3$ has a coefficient of \4\2 next to it, so the corolla with three leaves shows up 42 times in the associated arena. Intuitively, there are 42 situations in which you have a decision with three options.
% Likewise, there are 17 situations in which you have a decision with a single option.
% When you put all those decisions together, you have the \emph{arena} associated to $\4\2\yon^\3+\1\7\yon$. 

Throughout this book, we will see several other ways of interpreting polynomials.
Here is a table of terminology, capturing five different perspectives from which we may view our objects of study. The first column the terminology we just introduced for polynomials as dependent sets, as in \eqref{eqn.arena}; the second is algebraic terminology, as in \eqref{eqn.polynomial1892}; the third is the pictorial terminology of corolla forests, as in \eqref{eqn.poly1892}; the fourth column is dynamical systems terminology, which we will explore in \cref{**}; and the fifth column is decision-making terminology, which we will introduce in \cref{sec.poly.intro.dec} and further develop in \cref{**}.

\begin{equation}\label{eqn.table_terminology}
\footnotesize
\begin{tabular}{lllll}
\multicolumn{5}{c}{\normalsize Polynomial Terminology}\\[3pt]
\textbf{Arena} & $p \coloneqq \sum_{i \in p(\1)} \yon^{p[i]}$ & \textbf{Corolla forest} & \textbf{Mode-dependent interface} & \textbf{Set (?) of decisions}\\\hline
Position & $i \in p(\1)$ & Root $\bullet$ & Output & Decision\\
% Interface (???) in position $i$ & Pure power (representable) summand $\yon^{p[i]}$ & Corolla & (???) & Decision\\
Direction & $d \in p[i]$ & Leaf $\uparrow$ & Input & Option
\end{tabular}
\end{equation}

\begin{remark}
Though a polynomial is a \emph{functor} and an arena is a \emph{dependent set}, they are so closely related that we often do not make a distinction between a polynomial $p$ and its arena $(p[i])_{i \in I}$; they are essentially two different syntaxes for the same object.
For example, we may often directly refer to the positions and directions of a polynomial, when we mean the positions and directions of its associated arena.
\end{remark}

\begin{exercise}\label{exc.forest}
Consider the polynomial $p\coloneqq\2\yon^\3+\2\yon+\1$ and the associated corolla forest and arena.
\begin{enumerate}
	\item Draw the polynomial $p$ as a corolla forest.
	\item How many roots does this forest have?
	\item How many positions in the arena does this represent?
	\item For each corolla in the forest, say how many leaves it has.
	\item For each position in the arena, how many directions does it have?\qedhere
\end{enumerate}
\begin{solution}
We consider the polynomial $p\coloneqq\2\yon^\3+\2\yon+\1$.
\begin{enumerate}
	\item Here is $p$ drawn as a forest of corollas (note that the order in which the corollas are drawn does not matter):
	\[
	\begin{tikzpicture}[trees, sibling distance=3mm]
    \node (1) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=.7 of 1] (2) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=.5 of 2] (3) {$\bullet$} 
      child {};
    \node[right=.3 of 3] (4) {$\bullet$} 
      child {};
    \node[right=.3 of 4] (5) {$\bullet$};
  \end{tikzpicture}
  \]
	\item It has five (5) roots.
	\item It represents five positions, one per root.
	\item \label{sol.forest.leaves} The first and second corollas have three leaves, the third and fourth corollas have one leaf, and the fifth corolla has no leaves.
	\item The set of directions for each position is the same as the set of leaves for each corolla, so just copy the answer from \cref{sol.forest.leaves}. Sheesh! Who wrote this.
\end{enumerate}
\end{solution}
\end{exercise}

One feature that sets our polynomials apart from the polynomials we are familiar with from high school algebra is that the coefficients and exponents are not, strictly speaking, numbers; rather, they are sets, like $\1 = \{1\}$ and $\2 = \{1, 2\}$.
In fact, they can be arbitrary sets, as in $B\yon^A + D\yon^C$ for sets $A, B, C, D$, including infinite ones, as in $\rr\yon^\nn + 2^\rr\yon^\rr$.
Of course, this makes their forests rather unwieldy to draw, but they can be approximated.
We sketch the polynomial $\yon^\3 + \nn\yon^{[0,1]}$ as a forest below.
\[%\label{eqn.represented_interval}
\begin{tikzpicture}[trees, sibling distance=0.0625mm]
  \node (1) {$\bullet$} 
    child foreach \i in {1,2,3}
    ;
  \node[right=.7 of 1] (2) {$\bullet$} 
    child foreach \i in {1,...,160}
    ;
  \node[right=1 of 2] (3) {$\bullet$} 
    child foreach \i in {1,...,160}
    ;
  \node[right=1 of 3] (4) {$\bullet$} 
    child foreach \i in {1,...,160}
    ;
  \node[right=.7 of 4] (5) {$\cdots$};
\end{tikzpicture}
\]

\begin{exercise}
Consider the polynomial $q\coloneqq\yon^\nn+\4\yon$.
\begin{enumerate}[resume]
	\item Does the polynomial $q$ have a pure-power summand $\yon^\2$?
	\item Does the polynomial $q$ have a pure-power summand $\yon$?
	\item Does the polynomial $q$ have a pure-power summand $\4\yon$?
	\qedhere
\end{enumerate}
\begin{solution}
We refer to the polynomial $q\coloneqq\yon^\nn+4\yon$.
\begin{enumerate}[resume]
	\item No, $q$ does not have $\yon^\2$ as a pure-power summand.
	\item Yes, $q$ does have $\yon$ as a pure-power summand.
	\item No, $q$ does not have $\4\yon$ as a pure-power summand, because $\4\yon$ is not a pure-power! But to make amends, we could say that $\4\yon$ is a summand; this means that there is some $q'$ such that $q=q'+\4\yon$. So $\3\yon$ is also a summand, but $\5\yon$ and $\yon^\2$ are not.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}\label{exc.suitor_love}
If you were a suitor choosing the corolla forest you love, aesthetically speaking, which would strike your interest? Answer by circling the associated polynomial:
\begin{enumerate}
	\item $\yon^\2+\yon+\1$
	\item $\yon^\2+\3\yon^\2+\3\yon+\1$
	\item $\yon^\2$
	\item $\yon+\1$
	\item $(\nn\yon)^\nn$
	\item $S\yon^S$
	\item $\yon^{\1\0\0}+\yon^\2+\3\yon$
	\item Your polynomial's name $p$ here.
\end{enumerate}
Any reason for your choice? Draw a sketch of your forest.
\begin{solution}
Aesthetically speaking, here's the associated polynomial of a beautiful corolla forest:
\[
\yon^\0+\yon^\1+\yon^\2+\yon^\3+\cdots
\]
It's reminiscent (and formally related) to the notion of lists: if $A$ is any set then $A^0+A^1+A^2+\cdots$ is the set of lists with entries in $A$. 

Here's a picture of this lovely forest:
\[
	\begin{tikzpicture}[trees, sibling distance=3mm]
    \node (1) {$\bullet$};
    \node[right=.3 of 1] (2) {$\bullet$}
      child {};
    \node[right=.4 of 2] (3) {$\bullet$} 
      child {}
      child {};
    \node[right=.6 of 3] (4) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=.6 of 4] {$\cdots$};
  \end{tikzpicture}
\]
\end{solution}
\end{exercise}

Before we can really get into this story, let's summarize where we're going: polynomials are going to have really surprising applications to dynamics, decisions, and data. We speak superlatively of $\poly$:
\slogan{
The category of polynomial functors is a jackpot. Its beauty flows without bound}
but we have not yet begun to deliver. So let's introduce some of the applications and mathematics to come.

%---- Subsection ----%
\subsection{Dynamical systems}

% Explain how people should think about dynamical systems: a clock, computer...
% connecting them
% maybe draw the same picture

You may already be familiar with dynamical systems---machines of various sorts---which have an internal state that can be read out to other systems, as well as updated based on input received from other systems. In the context of this chapter, we'll be looking mainly at deterministic systems, but with a lot of interesting new options:
\begin{enumerate}
	\item The interface of the system can change shape through time.
	\item The wiring diagram connecting a bunch of systems can change in time.
	\item One can speed up the dynamics of a system.
	\item One can introduce ``effects,'' i.e.\ as defined by monads on $\smset$.
	\item The dynamical systems on any interface form a topos.
\end{enumerate}

To give some intuition for the first two, imagine yourself as a system, wired up to other systems. You have some input ports: your eyes, your ears, etc., and you have some output ports: your speech, your gestures, etc. And you connect with other systems: your family, your colleagues, the GPS of your phone, etc.
\begin{equation}\label{eqn.wired_forever}
\begin{tikzpicture}[oriented WD, every fit/.style={inner xsep=\bbx, inner ysep=\bby}, bb min width =.5cm, bbx=.5cm, bb port sep =1,bb port length=0, bby=.15cm]
	\node[bb={2}{2}, green!25!black] (X11) {\tiny Alice};
	\node[bb={3}{3}, green!25!black, below right=of X11] (X12) {\tiny you};
	\node[bb={2}{1}, green!25!black, above right=of X12] (X13) {\tiny Bob};
	\node[bb={2}{2}, green!25!black, below right = -1 and 1.5 of X12] (X21) {\tiny GPS};
	\node[bb={1}{2}, green!25!black, above right=-1 and 1 of X21] (X22) {\tiny me};
  \node[bb={2}{2}, fit = {($(X11.north east)+(-1,4)$) (X12) (X13) ($(X21.south)$) ($(X22.east)+(.5,0)$)}, bb name = {\small Wired together like this forever?}] (Z) {};
	\draw (X21_out1) to (X22_in1);
	\draw let \p1=(X22.north east), \p2=(X21.north west), \n1={\y1+\bby}, \n2=\bbportlen in
          (X22_out1) to[in=0] (\x1+\n2,\n1) -- (\x2-\n2,\n1) to[out=180] (X21_in1);
	\draw (X11_out1) to (X13_in1);
	\draw (X11_out2) to (X12_in1);
	\draw (X12_out1) to (X13_in2);
	\draw (Z_in1'|-X11_in2) to (X11_in2);	
	\draw (Z_in2'|-X12_in2) to (X12_in2);
	\draw (X12_out2) to (X21_in2);
	\draw (X21_out2) to (Z_out2'|-X21_out2);
	 \draw let \p1=(X12.south east), \p2=(X12.south west), \n1={\y1-\bby}, \n2=\bbportlen in
	  (X12_out3) to[in=0] (\x1+\n2,\n1) -- (\x2-\n2,\n1) to[out=180] (X12_in3);
	\draw let \p1=(X22.north east), \p2=(X11.north west), \n1={\y2+\bby}, \n2=\bbportlen in
          (X22_out2) to[in=0] (\x1+\n2,\n1) -- (\x2-\n2,\n1) to[out=180] (X11_in1);
	\draw (X13_out1) to (Z_out1'|-X13_out1);
\end{tikzpicture}
\end{equation}
We wrote a little question for you at the top of the diagram. Isn't there something a little funny about wiring diagrams? Maybe for old-fashioned machines, you would wire things together once and they'd stay like that for the life of the machine. But my phone connects to different wifi stations at different times, I drop my connection to Alice for weeks at a time, etc. So wiring diagrams should be able to change in time; $\poly$ will let us do that.

\begin{example}\label{ex.intro_examples_bonds_supplier_assemble}
Here are some familiar circumstances where we see wiring diagrams changing in time.
\begin{enumerate}[itemsep=0pt]
%	\item Airplanes only communicate when they get near enough;
%	\item A phone is connected to 4G or to wifi depending on circumstances;
%	\item A person can choose when to open (receive input through) their eyes and when to speak (produce output);\goodbreak
	\item When too much force is applied to a material, bonds can break;
\end{enumerate}
\[
\begin{tikzpicture}[oriented WD, bb small, bb port length=0]
	\foreach \i in {0,...,4} {
		\node[bb={1}{1}, fill=blue!10] at (1.7*\i,0) (X\i) {};
	}
%	\node[bb={1}{1}, fit=(X0) (X4)] (X) {};
	\foreach \i in {0,...,3} {
		\draw[thick] (X\i_out1) -- (X\the\numexpr\i+1\relax_in1);
	};
	\draw[thick, ->] (X0_in1) -- node[above, font=\tiny] {Force} +(-2.5,0);
	\draw[thick, ->] (X4_out1) -- node[above, font=\tiny] {Force} +(2.5,0) node (R) {};
%
\def\x{21};
	\foreach \i in {0,...,2} {
		\node[bb={1}{1}, fill=blue!10] at (\x+1.7*\i,0) (Y\i) {};
	}
	\foreach \i in {3,...,4} {
		\node[bb={1}{1}, fill=blue!10] at (\x+1.3+1.7*\i,0) (Y\i) {};
	}
%	\node[bb={1}{1}, fit=(Y0) (Y4)] (Y) {};
	\foreach \i in {0,1,3} {
		\draw[thick] (Y\i_out1) -- (Y\the\numexpr\i+1\relax_in1);
	};
	\draw[thick, ->] (Y0_in1) -- node[above, font=\tiny] {Force} +(-2.5,0) node (L) {};
	\draw[thick, ->] (Y4_out1) -- node[above, font=\tiny] {Force} +(2.5,0);
	\node[starburst, draw, minimum width=2cm, minimum height=1.5cm,red,fill=orange,line width=1.5pt] at ($(L)!.5!(R)$)
{Snap!};
\end{tikzpicture}
\]
\begin{quote}
In materials science the Young's modulus accounts for how much force can be transferred across a material as its endpoints are pulled apart. When the material breaks, the two sides can no longer feel evidence of each other. Thinking of pulling as sending a signal (a signal of force), we might say that the ability of internal entities to send signals to each other---the connectivity of the wiring diagram---is being measured by Young's modulus. It will also be visible within $\poly$.
\end{quote}
\begin{enumerate}[resume]
	\item A company may change its supplier at any time;
\end{enumerate}
\begin{equation*}%\label{eqn.supplier}
\begin{tikzpicture}[oriented WD, font=\ttfamily, every node/.style={fill=blue!10}, baseline=(c)]
	\node[bb={0}{1}] (s1) {Supplier 1};
	\node[bb={0}{1}, below=of s1] (s2) {Supplier 2};
	\coordinate (helper) at ($(s1)!.5!(s2)$);
	\node[bb={1}{0}, right=1.5 of helper] (c) {Company};
	\draw (s1_out1) to (c_in1);
	\draw (s2_out1) to +(5pt,0) node[fill=none] {$\bullet$};
\begin{scope}[xshift=3.5in]
	\node[bb={0}{1}] (s1') {Supplier 1};
	\node[bb={0}{1}, below=of s1'] (s2') {Supplier 2};
	\coordinate (helper') at ($(s1')!.5!(s2')$);
	\node[bb={1}{0}, right=1.5 of helper'] (c') {Company};
	\draw (s2'_out1) to (c'_in1);
	\draw (s1'_out1) to +(5pt,0) node[fill=none] {$\bullet$};
\end{scope}
	\node[starburst, draw, minimum width=2cm, minimum height=2cm,align=center,fill=green!10, font=\small, fill=white, line width=1.5pt] at ($(c)!.5!(helper')$)
{Change\\supplier!};
\end{tikzpicture}
\end{equation*}
\begin{quote}
The company can get widgets either from supplier 1 or supplier 2; we could imagine this choice is completely up to the company. The company can decide based on the quality of widgets it has received in the past, i.e.\ when the company gets a bad widget, it updates an internal variable, and sometimes that variable passes a threshold making the company switch states. Whatever its strategy for deciding, we should be able to encode it in $\poly$.
\end{quote}
\begin{enumerate}[resume]
	\item When someone assembles a machine, their own outputs dictate the connection pattern of the machine's components.
\end{enumerate}
\begin{equation*}%\label{eqn.someone}
\begin{tikzpicture}[oriented WD, font=\ttfamily, bb port length=0, every node/.style={fill=blue!10}, baseline=(someone.north)]
	\node[bb port sep=.5, bb={0}{1}] (A) {unit A};
	\node[bb port sep=.5, bb={1}{0}, right=of A] (B) {unit B};
	\coordinate (helper) at ($(A)!.5!(B)$);
	\node[bb={1}{1}, below=2 of helper] (someone) {\tikzsymStrichmaxerl[3]};
	\draw[->, dashed, blue] (someone_in1) to[out=180, in=270] (A.270);
	\draw[->, dashed, blue] (someone_out1) to[out=0, in=270] (B.270);
	\draw (A_out1) -- +(10pt,0);
	\draw (B_in1) -- +(-10pt,0);
%
\begin{scope}[xshift=3.5in]
	\node[bb port sep=.5, bb={0}{1}] (A') {unit A};
	\node[bb port sep=.5, bb={1}{0}, right=.5of A'] (B') {unit B};
	\coordinate (helper') at ($(A')!.5!(B')$);
	\node[bb={1}{1}, below=2 of helper'] (someone') {\tikzsymStrichmaxerl[3]};
	\draw[->, dashed, blue] (someone'_in1) to[out=180, in=270] (A'.270);
	\draw[->, dashed, blue] (someone'_out1) to[out=0, in=270] (B'.270);
	\draw (A'_out1) -- (B'_in1);
\end{scope}
%
	\node[starburst, draw, minimum width=2cm, minimum height=2cm,fill=blue!50,line width=1.5pt, align=center, font=\upshape] at ($(B)!.5!(A')-(0,.6cm)$)
{Attach!};
\end{tikzpicture}
\end{equation*}
\begin{quote}
Have you ever assembled something? Your internal states dictate the wiring pattern of some other things. We can say this in $\poly$.
\end{quote}

All of the examples discussed here will be presented in some detail once we have the requisite mathematical theory (\cref{ex.bonds_break,ex.supplier_change,ex.assemble_machine}).
\end{example}

\begin{exercise}\label{exc.changing_types}
Think of another example where systems are sending each other information, but where the sort of information or who it's being sent to or received from can change based on the states of the systems involved. You might have more than two, say $\rr$-many, different wiring patterns in your situation.
\begin{solution}
When using an application, say a drawing program, there is often a menu at the top of the screen. The information I can send the system changes based on what menu I click. If no menu is clicked, I can interact in one way. When I click ``file" I can interact with the file system, saving or opening a file, and thus interacting with another ``part'' of the computer. The set of things I can do depends on context.
\end{solution}
\end{exercise}

But there's more that's intuitively wrong or limiting about the picture in \eqref{eqn.wired_forever}. Ever notice how you can change how you interface with the world? Sometimes I close my eyes, which makes that particular way of sending me information inaccessible: that port vanishes and you need to use your words. Sometimes I'm in a tunnel and my phone can't receive GPS. Sometimes I extend my hand to give or receive an object from another person, but sometimes I don't. Our ports themselves change in time. We will be able to say all this using $\poly$.

And there's even more that's wrong with the above description. Namely, when I move my eyes, that's actually something you can see---e.g.\ whether I'm looking at you. When I turn around, I see different things, and \emph{you can notice I'm turned around}! When I use my muscles or mouth to express things, my very position changes: my tongue moves, my body moves. So my output is actually achieved by changing position. The model in $\poly$ will be able to express this too.

\begin{example}\label{ex.pond_eyeballs}
Imagine a million little eyeballs, each of which has a tiny brain inside it, all together in a pond of eyeballs. All that an individual eyeball $e$ can do is open and close. When $e$ is open, it can make some distinction about all the rest of the eyeballs in view: maybe it can count how many are open, or maybe it can see whether just one certain eyeball $e'$ is open or closed. But when $e$ is closed, it can't see anything; whatever else is happening, it's all the same to $e$. All it can do in that state is process previous information.

Each eyeball in this system will correspond to the polynomial $\yon^\ord{n}+\yon$, which intuitively consists of two situations, one with $n$-many options, and the other with only one option. For simplicity, we could assume $n=2$, so that each eyeball makes a single yes-no distinction whenever it's open.

The point is, however, is that any other eyeball may be capable of noticing if $e$ is opened or closed. We can imagine some interesting dynamics in this system, e.g.\ waves of openings or closings sweeping over the group, a ripple of openings expanding through the pond.

Talk about real-world applications! 
\end{example}

Hopefully you now have an idea of what we mean by mode-dependence: interfaces and wiring diagrams changing in time, based on the states of all the systems involved. We'll see that $\poly$ speaks about mode-dependent systems and wiring diagrams in this sense. 

But $\poly$ is very versatile in its applications. In \cref{sec.poly.intro.dec} we'll show how it relates to the making of decisions. First a quick remark.

\begin{remark}
We ended \cref{ex.pond_eyeballs} by joking ``talk about real-world applications'', because a pond of eyeballs is about the most bizarre thing one can imagine. But recall Nobel physicist Frank Wilczek's quote from the preface:
\begin{quote}
For me, though, it is difficult to resist the idea that space-time is not essentially different from matter, which we understand more deeply. If so, it will consist of vast numbers of identical units---``particles of space''---each in contact with a few neighbors, exchanging messages, joining and breaking apart, giving birth and passing away.
\end{quote}
Suppose the world was made out of a vast number of identical units, each with its own behavior, able to connect and disconnect with neighbors, and even disappear from the world of cause and effect. We may not even be interested in what our world is actually made of, but just a theoretical one. Is there such an elementary unit that could produce all other dynamical systems? The $\yon^\2+\yon$ eyeballs give a sense of a very simple interface---open and perceiving a single distinction about the world, or closed and making no distinctions---that we could imagine building an entire world from.
\end{remark}


%---- Subsection ----%
\subsection{Decisions} \label{sec.poly.intro.dec}
We return to the example polynomial $\yon^\2 + \2\yon + \1$ from \eqref{eqn.polynomial1892} and its corresponding corolla forest, in which positions are expressed as roots and directions are represented as leaves:
\begin{equation} \label{eqn.forest2110}
\begin{tikzpicture}[trees]
  \node (1) {$\bullet$} 
    child {}
    child {};
  \node[right=.5 of 1] (2) {$\bullet$} 
    child {};
  \node[right=.5 of 2] (3) {$\bullet$} 
    child {};
  \node[right=.5 of 3] (4) {$\bullet$};
\end{tikzpicture}
\end{equation}
Concretely, we might think of each position as representing a \emph{decision}. Associated to every decision is a set of \emph{options} (directions). The three decisions we exhibit in \eqref{eqn.forest2110} are particularly interesting: they respectively have two options, one option, one option, and no options. Having two options is familiar from life---it's the classic yes/no decision---as well as from Claude Shannon's Information Theory. Having one option is also familiar theoretically and in life: ``sorry, ya just gotta go through it.'' Having no options is when you actually don't get through it: it's ``the end.'' While the corollas $\1,\yon,$ and $\yon^\2$ are each interesting as decisions, the sum $\yon^\2+2\yon+\1$ has very little theoretical interest; it's just an example.

Now consider the following three trees, the first two of which are infinite (though that's hard to draw):
\[
\begin{tikzpicture}[trees]
\begin{scope}[
  level 1/.style={sibling distance=20mm},
  level 2/.style={sibling distance=10mm},
  level 3/.style={sibling distance=5mm},
  level 4/.style={sibling distance=2.5mm},
  level 5/.style={sibling distance=1.25mm}]
  \node[dgreen] (a) {$\bullet$}
    child {node[dgreen] {$\bullet$}
    	child {node[dgreen] {$\bullet$}
    		child {node[dgreen] {$\bullet$}
  				child {node[dgreen] {$\bullet$}
    				child {}
    				child {}
    			}
  				child {node[dyellow] {$\bullet$}
    				child {}
    				child {}
    			}
  			}
    		child {node[dyellow] {$\bullet$}
					child {node[dgreen] {$\bullet$}
      			child {}
      			child {}
     			}
    			child  {node[red] {$\bullet$}}
  			}
    	}
    	child {node[dyellow] {$\bullet$}
    		child {node[dgreen] {$\bullet$}
  				child {node[dgreen] {$\bullet$}
    				child {}
    				child {}
    			}
  				child {node[dyellow] {$\bullet$}
    				child {}
    				child {}
    			}
  			}
    		child  {node[red] {$\bullet$}}
    	}
    }
    child {node[dyellow] {$\bullet$}
    	child {node[dgreen] {$\bullet$}
    		child {node[dgreen] {$\bullet$}
  				child {node[dgreen] {$\bullet$}
    				child {}
    				child {}
    			}
  				child {node[dyellow] {$\bullet$}
    				child {}
    				child {}
    			}
  			}
    		child {node[dyellow] {$\bullet$}
					child {node[dgreen] {$\bullet$}
      			child {}
      			child {}
     			}
    			child  {node[red] {$\bullet$}}
  			}
  		}
  		child {node[red] {$\bullet$}
  		}
  	}
  ;
\end{scope}
\begin{scope}[
  level 1/.style={sibling distance=13mm},
  level 2/.style={sibling distance=10mm},
  level 3/.style={sibling distance=5mm},
  level 4/.style={sibling distance=2.5mm},
  level 5/.style={sibling distance=1.25mm}]
\node (b) [right=4 of a, dyellow] {$\bullet$}
  child {node[dgreen] {$\bullet$}
  	child {node[dgreen] {$\bullet$}
  		child {node[dgreen] {$\bullet$}
  			child {node[dgreen] {$\bullet$}
    			child {}
    			child {}
   			}
 				child {node[dyellow] {$\bullet$}
   				child {}
   				child {}
   			}
			}
    		child {node[dyellow] {$\bullet$}
					child {node[dgreen] {$\bullet$}
      			child {}
      			child {}
     			}
    			child  {node[red] {$\bullet$}}
  			}
		}
  	child {node[dyellow] {$\bullet$}
  		child {node[dgreen] {$\bullet$}
  			child {node[dgreen] {$\bullet$}
    			child {}
    			child {}
   			}
 				child {node[dyellow] {$\bullet$}
   				child {}
   				child {}
   			}
			}
  		child  {node[red] {$\bullet$}}
  	}
	}
	child {node[red] {$\bullet$}}	
;
\end{scope}
\node (c) [red, right=2 of b] {$\bullet$};
\end{tikzpicture}
\]
These are patterned examples---and we'll understand what this pattern is more clearly in \cref{**}---of what we will call \emph{decision streams}. Decision streams form the objects in a category that also includes the following level-3 abbreviations of binary decision streams (the third of which is a level-3 abbreviation of a finite stream):
\[
\begin{tikzpicture}[trees]
\begin{scope}[
  level 1/.style={sibling distance=20mm},
  level 2/.style={sibling distance=10mm},
  level 3/.style={sibling distance=5mm},
  level 4/.style={sibling distance=2.5mm}]
  \node (a) {$\bullet$}
    child {node {$\bullet$}
    	child {node {$\bullet$}
    		child {node {$\bullet$}
  			}
    		child {node {$\bullet$}
  				child 
  				child
  			}
    	}
    	child {node {$\bullet$}
  			}
    }
    child {node {$\bullet$}
    	child {node {$\bullet$}
    		child {node {$\bullet$}
  				child
  				child
  			}
    		child {node {$\bullet$}
  				child
  				child
  			}
  		}
  		child {node {$\bullet$}
    		child {node {$\bullet$}
  			}
    		child {node {$\bullet$}
  			}
  		}
  	}
  ;
\end{scope}
\begin{scope}[
  level 1/.style={sibling distance=13mm},
  level 2/.style={sibling distance=10mm},
  level 3/.style={sibling distance=5mm},
  level 4/.style={sibling distance=2.5mm}]
  \node (b) [right=4 of a] {$\bullet$}
    child {node {$\bullet$}
    }
    child {node {$\bullet$}
    	child {node {$\bullet$}
    		child {node {$\bullet$}
  			}
    		child {node {$\bullet$}
  				child
  				child
  			}
  		}
  		child {node {$\bullet$}
    		child {node {$\bullet$}
  				child
  				child
  			}
    		child {node {$\bullet$}
  				child
  				child
  			}
  		}
  	}
  ;
\end{scope}
\begin{scope}[
  level 1/.style={sibling distance=13mm},
  level 2/.style={sibling distance=8mm},
  level 3/.style={sibling distance=5mm},
  level 4/.style={sibling distance=2.5mm}]
  \node (c) [right=4 of b] {$\bullet$}
    child {node {$\bullet$}
    	child {node {$\bullet$}
  		}
  		child {node {$\bullet$}
    		child {node {$\bullet$}
  			}
    		child {node {$\bullet$}
  			}
  		}
    }
    child {node {$\bullet$}
  	}
  ;
\end{scope}
\end{tikzpicture}
\]

The set of such decision streams forms the objects of a category with very nice properties (it's a topos), which we call $\sys(\yon^\2+\1)$. The idea is that every corolla in these diagrams has either two options, corresponding to $\yon^\2$, or no options, corresponding to $\1=\yon^\0$.
We say that each such decision stream has type $\yon^\2$

\begin{exercise}\label{exc.decision_streams}
\begin{enumerate}
	\item Draw a level-3 abbreviation of a decision stream of type $\yon^\2+\yon^\0$.
	\item Draw a level-4 abbreviation of a decision stream of type $\yon$.
	\item Draw a level-3 abbreviation of a decision stream of type $\nn\yon^\2$ by labeling every node with a natural number.
	\qedhere
\end{enumerate}

\begin{solution}
\begin{enumerate}
	\item Here's a level-3 abbreviation of a decision stream of type $\yon^\2+\yon^\0$.
\[
\begin{tikzpicture}[trees,
  level 1/.style={sibling distance=20mm},
  level 2/.style={sibling distance=10mm},
  level 3/.style={sibling distance=5mm},
  level 4/.style={sibling distance=2.5mm}]
  \node (a) {$\bullet$}
    child {node {$\bullet$}
    	child {node {$\bullet$}
    		child
    		child
    	}
    	child {node {$\bullet$}
  			}
    }
    child {node {$\bullet$}
    	child {node {$\bullet$}}
    	child {node {$\bullet$}
  		}
  	}
  ;
\end{tikzpicture}
\]
	\item Here's a level-4 abbreviation of a decision stream of type $\yon$.
\[
\begin{tikzpicture}[trees]
	\node (a) {$\bullet$}
		child {node {$\bullet$}
			child {node {$\bullet$}
				child {node {$\bullet$}
  				child
			}}};
\end{tikzpicture}
\]
	\item Here's a level-3 abbreviation of a decision stream of type $\nn\yon^\2$ where we indicate the position of each node by labeling it with a natural number.
\[
\begin{tikzpicture}[trees,
  level 1/.style={sibling distance=20mm},
  level 2/.style={sibling distance=10mm},
  level 3/.style={sibling distance=5mm},
  level 4/.style={sibling distance=2.5mm}]
  \node (a) {$27$}
    child {node {$5040$}
    	child {node {$192$}
    		child 
    		child
			}
    	child {node {$0$}
    		child 
    		child
  			}
    }
    child {node {$314159$}
    	child {node {$1000$}
   				child
  				child
  		}
			child {node {$1296$}
				child
				child
			}
  	}
  ;
\end{tikzpicture}
\]
\end{enumerate}
\end{solution}
\end{exercise}

But decisions aren't just about choosing; they're also about trying to accomplish something. The logic of accomplishment is exceptionally rich in this setting. We will concentrate on what we call a \emph{win condition}, which is an induced subgraph of the decision stream with the property that if $n$ is a winning node, then any child of $n$ is also a winning node. 
\[\begin{tikzpicture}[trees,
  level 1/.style={sibling distance=20mm},
  level 2/.style={sibling distance=10mm},
  level 3/.style={sibling distance=5mm},
  level 4/.style={sibling distance=2.5mm}]
  \node (root) {$\bullet$}
    child {node {$\bullet$}
    	child {node {$\bullet$}
    		child {node {$\bullet$}
  			}
    		child {node {$\bullet$}
  				child
  				child
  			}
    	}
    	child {node {$\bullet$}
  			}
    }
    child {node {$\bullet$}
    	child {node {$\bullet$}
    		child {node {$\bullet$}
  				child
  				child
  			}
    		child {node {$\bullet$}
  				child
  				child
  			}
  		}
  		child {node {$\bullet$}
    		child {node {$\bullet$}
  				child
  				child
  			}
    		child {node {$\bullet$}
  			}
  		}
  	}
  ;
 \begin{scope}[every node/.style={circle, inner sep=3pt, blue, draw}]
  \node at (root-1-2)     {};
  \node at (root-2-1-1-1) {};
  \node at (root-2-1-1-2) {};
  \node at (root-2-1-2-1) {};
	\node at (root-2-2) 		{};
  \node at (root-2-2-1) 	{};
  \node at (root-2-2-2) 	{};
  \node at (root-2-2-1-1) {};
  \node at (root-2-2-1-2) {};
 \end{scope}
\end{tikzpicture}
\]
More formally, these are called \emph{sieves}. They form the elements of a logical system called a Heyting algebra: you can take any two sieves and form the intersection or union (which correspond to AND and OR), or even things like implication, negation, and existential and universal quantification. This will give us a calculus of win-conditions for any type $p$ decision stream.

%---- Subsection ----%
\subsection{Data}

Data is information, maybe thought of as quantized into atomic pieces, but where these atomic pieces are somehow linked together according to a conceptual structure. When a person or organization uses certain data repeatedly, they often find it useful to put their data in a database. This requires organizing the little pieces into a conceptual structure. So when you hear ``database,'' just think of it as a conceptual structure filled with examples.

To fix a mental image, let's say that you need to constantly look up employees, what department they're in, who the admin person is for that department, who their manager is, etc. Here's an associated database
\begin{equation}\label{eqn.mytables}
\begin{tabular}{ c | c  c  c}
  \textbf{Employee}&\textbf{FirstName}&\textbf{WorksIn}&\textbf{Mngr}\\\hline
  1&Alan&101&2\\
  2&Ruth&101&2\\
  3&Carla&102&3
\end{tabular}
\hspace{.3in}
\begin{tabular}{ c | c  c}
  \textbf{Department}&\textbf{Name}&\textbf{Admin}\\\hline
  101&Sales&1\\
  102&IT&3\\~
\end{tabular}
%\hspace{.3in}
%\begin{tabular}{ c |}
%	\textbf{String}\\\hline
%	Alan\\
%	IT\\[-3pt]
%	\resizebox{!}{10pt}{$\vdots$}
%\end{tabular}
\end{equation}
We can see it as being associated to the following conceptual scheme, also called a \emph{schema}:
\begin{equation}\label{eqn.myschema}
\cat{C}\coloneqq
\boxCD{white}{
\begin{tikzcd}[row sep=large, ampersand replacement = \&]
 	\LTO{Employee}\ar[rr, shift left, "\text{WorksIn}"]\ar[dr, bend right, "\text{FirstName}"']\ar[loop left, "\text{Mngr}"]\&\&
  \LTO{Department}\ar[ll, shift left, "\text{Admin}"]\ar[dl, bend left, "\text{Name}"]\\
  \&\LTO[\circ]{String}
\end{tikzcd}
\leavevmode\\\bigskip
\text{Department.Admin.WorksIn = Department}
}
\end{equation}
The equation at the bottom says that for any department $d$, if you ask for the admin person and see which department they work in, it's required to be $d$.

What's called $\cat{C}$ in \eqref{eqn.myschema} is a \emph{finitely presented category}.
The objects of the category are the points, while each arrow corresponds to a morphism of $\cat{C}$ (there are additional morphisms, including identity morphisms, that are not depicted).
The equation at the bottom indicates that composing the morphism Admin with the morphism WorksIn yields the identity morphism on the object Department.

The database instance presented in \eqref{eqn.mytables} then corresponds to a functor $I\colon\cat{C}\to\smset$.
For example, $I$ sends the object $\text{Employee}\in\cat{C}$ to the set $I(\text{Employee})\coloneqq\{1,2,3\}$, the entries in the Employee column of the left table.

The functor also sends the morphism $\text{Mngr}\colon\text{Employee}\to\text{Employee}$ to the function $I(\text{Mngr})\colon\{1,2,3\}\to\{1,2,3\}$ that sends each entry in the Employee column to its corresponding entry in the Mngr column.
So $I(\text{Mngr})(1)=2$, $I(\text{Mngr})(2)=2$, and $I(\text{Mngr})(3)=3$.

A functor $\cat{C}\to\smset$ is called a \emph{copresheaf on $\cat{C}$}. So the story of database schemas and their data can be based on the story of categories and their copresheaves.

\begin{exercise} \label{exc.my_schema_and_tables}
As above, we define the finitely presented category $\cat{C}$ according to \eqref{eqn.myschema} and the copresheaf $I$ on $\cat{C}$ according to \eqref{eqn.mytables}.
\begin{enumerate}
    \item What is $I(\text{Department})$?
    \item What is $I(\text{Admin})$?
    \item Composing Admin with FirstName yields a morphism from Department to String that we denote by Admin.FirstName.
    What is $I(\text{Admin.FirstName})$?
    \item Say we require that managers work in the same department as the employees they oversee.
    Write down an equation in $\cat{C}$ (like the one at the bottom of \eqref{eqn.myschema} that expresses this condition.
    \item How might we define $I(\text{String})$? \qedhere
\end{enumerate}

\begin{solution}
We refer to \eqref{eqn.myschema} and \eqref{eqn.mytables} to characterize the category $\cat{C}$ and the functor $I \colon \cat{C} \to \smset$.
\begin{enumerate}
    \item Here Department is an object of $\cat{C}$, so $I(\text{Department})$ is a set. From the Department column in the table on the right of \eqref{eqn.mytables}, we observe that $I(\text{Department}) = \{101, 102\}$.
    \item Here Admin is an morphism of $\cat{C}$ from Department to Employee, so $I(\text{Admin})$ is a function from $I(\text{Department}) = \{101, 102\}$ to $I(\text{Employee}) = \{1, 2, 3\}$. From the Admin column in the table on the right of \eqref{eqn.mytables}, we observe that $I(\text{Admin})(101) = 1$ and $I(\text{Admin})(102) = 3$.
    \item By functoriality, $I(\text{Admin.FirstName})$ is the function $I(\text{Admin})$ composed with $I(\text{FirstName})$.
    We have that $I(\text{Admin})$ sends $101$ to $1$ and $102$ to $3$, while the FirstName column tells us that $I(\text{FirstName})$ sends $1$ to Alan and $3$ to Carla.
    So $I(\text{Admin.FirstName})$ sends $101$ to Alan and $102$ to Carla.
    \item If every employee works in the same department as their manager, then Employee.WorksIn = Employee.Mngr.WorksIn.
    \item The name suggests that $I(\text{String})$ is the set of all possible strings of characters.
    Perhaps this could be defined as $\bigcup_{n \in \nn} A^n$, where $A$ is our alphabet of allowed characters, which may include the English letters, spaces, digits, and whatever other characters we allow.
    At the very least, since FirstName and Name are both morphisms to String, every entry in the FirstName and Name columns must be in $I(\text{String})$.
    So all we know for sure is that $\{\text{Alan, Ruth, Carla, Sales, IT}\} \subseteq I(\text{String})$.
\end{enumerate}
\end{solution}
\end{exercise}

There's a very important thing that we do with databases: we query them. We ask them questions like ``tell me everyone that's either the admin person of the Math department or their manager.''
\begin{minted}{mysql}
 FOR    d: Department, e: Employee
 WHERE  Name(d)="Math" AND
        (e=Admin(d) OR e=Mngr(Admin(d)))
 RETURN FirstName(e)
\end{minted}
This sort of question is formally called a ``union of conjunctive queries.'' We will see this sort of query is intimately connected with $\poly$.
We will also see how databases can be conceived in terms of dynamical systems.

%---- Subsection ----%
\subsection{Implementation}

Everything we talk about can actually be implemented in a computer without much difficulty, at least if you have access to a language that supports dependent types, such as Agda.

What we have been calling polynomials---things like $\yon^\2+\2\yon+\1$---are often called \emph{containers} in the computer science literature. A container consists of a type $S$, usually called the type of \emph{shapes}, and a type $P(s)$ for each term $s:S$, called the type of positions in shape $s$. It's mildly unfortunate that the names clash with our own: for us a container-shape is a position and a container-position is a direction.

Luckily, the Agda code is pretty easy to understand.
\begin{agda}
record Arena : Set where  -- an arena consists of 
   field                      -- two fields
     pos : Set                -- one called pos, a set, and
     dir : pos -> Set         -- one called dir,
                              -- a set for each element of the set pos
\end{agda}

%---- Subsection ----%
\subsection{Mathematical theory}\label{subsec.math_theory}

The applications of $\poly$ are quite diverse and interesting, including dynamics, data, and decisions. However it is how the mathematics of $\poly$ supports these applications that is so fantastic. For experts, here are some reasons for the excitement.

\begin{proposition}
$\poly$ is a biCartesian closed category, meaning it has sums, products, and exponential objects. It supports the simply typed lambda calculus.
\end{proposition}

In fact $\poly$ has infinite coproducts, infinite products, and is completely distributive. We'll explain all of this in \cref{**}; for now we continue with the highlights.

\begin{proposition}
Beyond the coCartesian and Cartesian monoidal structures $(\0,+)$ and $(\1,\times)$, the category $\poly$ has two additional monoidal structures, denoted $(\yon,\otimes)$ and $(\yon,\circ)$, which are together duoidal. Moreover $\otimes$ is also a closed monoidal structure that distributes over $+$.
\end{proposition}

\begin{proposition}\label{prop.adjoint_quadruple}
$\poly$ has an adjoint quadruple with $\smset$ and an adjoint pair with $\smset\op$:
\begin{equation*}%\label{eqn.adjoints_galore}
\begin{tikzcd}[column sep=60pt]
  \smset
  	\ar[r, shift left=7pt, "A" description]
		\ar[r, shift left=-21pt, "A\yon"']&
  \poly
  	\ar[l, shift right=21pt, "p(\0)"']
  	\ar[l, shift right=-7pt, "p(\1)" description]
	\ar[l, phantom, "\scriptstyle\Leftarrow"]
	\ar[l, phantom, shift left=14pt, "\scriptstyle\Rightarrow"]
	\ar[l, phantom, shift right=14pt, "\scriptstyle\Rightarrow"]
\end{tikzcd}
\hspace{.6in}
\adjr[50pt]{\smset\op}{\yon^A}{\Gamma p}{\poly}.
\end{equation*}
Each functor is labeled by where it sends $p\in\poly$ or $A\in\smset$.
\end{proposition}

There's a lot we're leaving out of this summary, just so we can hit the highlights.

\begin{proposition}
The functor $\poly\to\smset$ given by $p\mapsto p(\1)$ is a monoidal fibration.
\end{proposition}

In fact it's a monoidal $*$-bifibration in the sense of \cite{shulman2008framed}. But here's where things get really interesting.

\begin{proposition}[Ahman-Uustalu]\label{prop.ahman_uustalu1}
Comonoids in $(\poly,\yon,\circ)$ are categories (up to isomorphism).
\end{proposition}

\begin{proposition}
The category $\comon$ has finite coproducts and products, and coproducts in $\comon$ agree with those in $\smcat$.
\end{proposition}

\begin{proposition}
The functor $\comon\to\poly$ has a right adjoint
\[
\adjr{\poly}{\com{K}_-}{u_-}{\comon},
\]
called the \emph{cofree comonoid} construction. It is lax monoidal with respect to $\otimes$.
\end{proposition}

\begin{proposition}
The category $\comon$ has a third symmetric monoidal structure $(\yon,\otimes)$, and the functor $u_-\colon(\comon,\yon,\otimes)\to(\poly,\yon,\otimes)$ is strong monoidal.
\end{proposition}



\begin{proposition}\label{prop.sysp[i]s_topos}
For any polynomial $p$, the category
\[\sys(p)\cong\com{K}_p\set\]
of dynamical systems on $p$ forms a topos.
\end{proposition}

The proposition above indicates that there is a full-fledged logic of dynamical systems inhabiting any interface, while the following proposition implies that these logics can be combined and compared.

\begin{proposition}\label{prop.poly_map_pregeo_topos}
A morphism $p\to q$ of polynomials induces a pre-geometric morphism between their respective toposes
\[
\adj{\sys(p)}{}{}{\sys(q)}.
\]
\end{proposition}

The following propositions suggest that the whole story of dynamics carries a strong connection to database theory.

\begin{proposition}
Suppose that the category $\cat{C}$ corresponds under \cref{prop.ahman_uustalu1} to the comonoid $\com{C}$. Then there is an equivalence of categories
\[
\Cat{Bimod}(\com{C},0)\cong\cat{C}\set
\]
between $(\com{C},0)$-bimodules and $\cat{C}$-copresheaves.
\end{proposition}
We will use the convention that the comonoid $\com{C}$ corresponds to category $\cat{C}$, and similarly for $\com{D}$ and $\cat{D}$, etc. 

\begin{proposition}[Garner]
For any categories $\cat{C}$ and $\cat{D}$, there is an equivalence of categories
\[
\Cat{Bimod}(\com{C},\com{D})\cong\Cat{pra}(\cat{C}\set,\cat{D}\set)
\]
between that of bimodules between comonoids in $\poly$ and parametric right adjoints between copresheaf categories.
\end{proposition}

\begin{proposition}
For any category $\cat{C}$ the category of left $\com{C}$-modules is equivalent to the category of functors $\cat{C}\to\poly$,
\[\Cat{Bimod}(\com{C},\yon)\cong\Cat{Fun}(\cat{C},\poly).\]
\end{proposition}

If you skipped over any of that---or all of that---it'll be no problem whatsoever! We will cover each of the above results in detail over the course of this book. There are many avenues for study, but we need to push forward.

Let's begin.


%-------- Section --------%
\section{Introduction to $\poly$ as a category}\label{sec.poly}


In this section, we will set down the basic category-theoretic story of $\poly$, so that we can have a firm foundation from which to speak about dynamical systems, decisions, and data. We begin with the category $\smset$ of sets and functions, and what is arguably the fundamental theorem of category theory, the Yoneda lemma.

%---- Subsection ----%
\subsection{Representable functors and the Yoneda lemma}

\begin{definition} \label{def.representable}
Given any set $S$, we denote by $\yon^S\colon\smset\to\smset$ the functor that sends any set $X$ to the set $X^S=\smset(S,X)$, and sends any function $h\colon X\to Y$ to the function $h^S\colon X^S\to Y^S$, the one that sends $g\colon S\to X$ to $g\then h\colon S\to Y$.\footnote{Throughout this text, in any category, given objects $A, B, C$ and morphisms $f \colon A \to B$ and $g \colon B \to C$, we denote their composite morphism $A \to C$ as $f \then g$ (instead of the usual $g \circ f$).}

We refer to $\yon^S$ as the functor \emph{represented by} $S$.
\end{definition}

The symbol $\yon$ stands for Yoneda, for reasons we will get to in \cref{lemma.yoneda}. For now, here are some pictures for your eyes to gaze at; they are the polys corresponding to various representables, namely the pure powers:
\begin{equation}\label{eqn.trees_for_gazing}
\begin{tikzpicture}[trees, sibling distance=2mm]
  \node["$\yon^{\5}$" below] (1) {$\bullet$} 
    child foreach \i in {1,...,5}
    ;
\end{tikzpicture}
\qquad
\begin{tikzpicture}[trees, sibling distance=1mm]
  \node["$\yon^{\1\0}$" below] (1) {$\bullet$} 
    child foreach \i in {1,...,10}
    ;
\end{tikzpicture}
\qquad
\begin{tikzpicture}[trees, sibling distance=0.5mm]
  \node["$\yon^{\2\0}$" below] (1) {$\bullet$} 
    child foreach \i in {1,...,20}
    ;
\end{tikzpicture}
\qquad
\begin{tikzpicture}[trees, sibling distance=0.25mm]
  \node["$\yon^{\4\0}$" below] (1) {$\bullet$} 
    child foreach \i in {1,...,40}
    ;
\end{tikzpicture}
\qquad
\begin{tikzpicture}[trees, sibling distance=0.0625mm]
  \node["$\yon^{[0,1]}$" below] (1) {$\bullet$} 
    child foreach \i in {1,...,160}
    ;
\end{tikzpicture}
\end{equation}

\begin{example}
The functor that sends every set $X$ to $X\times X$, and sends $h\colon X\to Y$ to $(h\times h)\colon (X\times X)\to(Y\times Y)$, is representable. After all, $X \times X \iso X^\2$, so this functor is just a pure power we are already familiar with: $\yon^\2$.
\end{example}

\begin{exercise}\label{exc.representable_fun}
For each of the following functors $\smset\to\smset$, say if it is representable or not; if it is, say what the representing set is.
\begin{enumerate}
	\item The identity functor $X\mapsto X$, which sends each function to itself.
	\item The constant functor $X\mapsto\2$, which sends every function to the identity on $\2$.
	\item The constant functor $X\mapsto\1$, which sends every function to the identity on $\1$.
	\item The constant functor $X\mapsto\0$, which sends every function to the identity on $\0$.
	\item A functor $X\mapsto X^\nn$.
	If it were representable, where would it send each function?
	\item A functor $X\mapsto 2^X$.
	If it were representable, where would it send each function?
\qedhere
\end{enumerate}

\begin{solution}
Our goal is to say whether various functors are representable (of the form $X\mapsto\smset(S,X)$ for some $S$, called the representing set).
\begin{enumerate}
	\item The identity functor $X\mapsto X$ is represented by $S=\1$: a function $\1 \to X$ is just an element of $X$, so $\smset(\1,X) \iso X$.
	Alternatively, note that $X^1 \iso X$.
	\item \label{sol.representable_fun.2} The constant functor $X\mapsto\2$ is not representable: the functor sends $\1$ to $\2$, but $\1^S \iso \1 \not\iso \2$ for any set $S$.
	\item The constant functor $X\mapsto\1$ is representable by $S=\0$: there is exactly one function $\0 \to X$, so $\smset(\0,X) \iso \1$.
	Alternatively, note that $X^0 \iso \1$.
	\item The constant functor $X\mapsto\0$ is not representable, for the same reason as in \cref{sol.representable_fun.2}.
	\item The functor $\yon^\nn$ that sends $X\mapsto X^\nn$ is represented by $S=\nn$, by definition.
	It sends each function $h \colon X \to Y$ to the function $h^\nn \colon X^\nn \to Y^\nn$ that sends each $g \colon \nn \to X$ to $g \then h \colon \nn \to Y$.
	\item No $\smset \to \smset$ functor $X\mapsto \2^X$ is representable, for the same reason as in \cref{sol.representable_fun.2}.
	(There \emph{is}, however, a functor $\smset\op \to \smset$ sending $X \mapsto 2^X$ that is understood to be representable in a more general sense.)
\end{enumerate}
\end{solution}
\end{exercise}

\begin{proposition}\label{prop.representable_nt}
For any function $f\colon R\to S$, there is an induced natural transformation $\yon^f\colon\yon^S\to \yon^R$; on any set $X$ the $X$-component $X^f\colon X^S\to X^R$ is given by sending $g\colon S\to X$ to $f\then g\colon R\to X$.
\end{proposition}

\begin{exercise} \label{exc.representable_nt}
Prove that for any function $f\colon R\to S$, what we said was a natural transformation in \cref{prop.representable_nt} really is natural. That is, for any function $h\colon X\to Y$, show that the following diagram commutes:
\[
\begin{tikzcd}[bottom base]
	X^S\ar[r, "h^S"]\ar[d, "X^f"']&
	Y^S\ar[d, "Y^f"]\\
	X^R\ar[r, "h^R"']&
	Y^R\ar[ul, phantom, "?"]
\end{tikzcd}
\qedhere
\]

\begin{solution}
To show that
\[
\begin{tikzcd}[ampersand replacement=\&]
	X^S\ar[r, "h^S"]\ar[d, "X^f"']\&
	Y^S\ar[d, "Y^f"]\\
	X^R\ar[r, "h^R"']\&
	Y^R\ar[ul, phantom, "?"]\&
	\qedhere
\end{tikzcd}
\]
commutes, we note that by \cref{prop.representable_nt}, both vertical maps compose functions from $S$ with $f \colon R \to S$ from the left, and by \cref{def.representable}, both horizontal maps compose functions to $X$ with $h \colon X \to Y$ on the right.
So by the associativity of composition, the diagram commutes.
\end{solution}
\end{exercise}

\begin{exercise} \label{exc.representable_nt_components}
Let $X$ be an arbitrary set. For each of the following sets $R,S$ and functions $f\colon R\to S$, describe the $X$-component of, i.e.\ the function $X^S\to X^R$ coming from, the natural transformation $\yon^f\colon\yon^S\to\yon^R$.
\begin{enumerate}
	\item \label{exc.representable_nt_components.id} $R=\5$, $S=\5$, $f=\id$.  (Here you're supposed to give a function called $X^{\id_\5}\colon X^\5\to X^\5$.)
	\item $R=\2$, $S=\1$, $f$ is the unique function.
	\item $R=\1$, $S=\2$, $f(1)=1$.
	\item $R=\1$, $S=\2$, $f(1)=2$.
	\item $R=\0$, $S=\5$, $f$ is the unique function.
	\item $R=\nn$, $S=\nn$, $f(n)=n+1$.
\qedhere
\end{enumerate}

\begin{solution}
In each case, given $f \colon R \to S$, we can find the $X$-component $X^f \colon X^S \to X^R$ of the natural transformation $\yon^f\colon\yon^S\to\yon^R$ by applying \cref{prop.representable_nt}, which says that $X^f$ sends each $g \colon S \to X$ to $f \then g \colon R \to X$.
\begin{enumerate}
    \item If $R=\5$, $S=\5$, and $f=\id$, then $X^f$ is the identity function on $X^\5$.
    \item If $R=\2$, $S=\1$, and $f$ is the unique function, then $X^f$ sends each $g \in X$ (i.e.\ function $g \colon \1 \to X$) to the function that maps both elements of $\2$ to $g$.
    We can think of $X^f$ as the diagonal $X \to X \times X$.
	\item If $R=\1$, $S=\2$, and $f(1)=1$, then $X^f$ sends each $g \colon \2 \to X$ to $g(1)$, viewed as a function $\1 \to X$.
	We can think of $X^f$ as the left projection $X \times X \to X$.
	\item If $R=\1$, $S=\2$, and $f(1)=2$, then $X^f$ sends each $g \colon \2 \to X$ to $g(2)$, viewed as a function $\1 \to X$.
	We can think of $X^f$ as the right projection $X \times X \to X$.
	\item If $R=\0$, $S=\5$, and $f$ is the unique function, then $X^f$ is the unique function $X^\5 \to X^\0 \iso \1$.
	\item If $R=\nn$, $S=\nn$, and $f(n)=n+1$, then $X^f$ sends each $g \colon \nn \to X$ to the function $h \colon \nn \to X$ satisfying $h(n) = g(n+1)$ for all $n \in \nn$.
	We can think of $X^f$ as removing the first term of an infinite sequence of elements of $X$.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise} \label{exc.representable_nt_functorial}
Show that the construction in \cref{prop.representable_nt} is functorial
\begin{equation}
\yon^-\colon\smset\op\to\smset^\smset,
\end{equation}
as follows.
\begin{enumerate}
	\item Show that for any set $S$, we have $\yon^{\id_S}\colon\yon^S\to\yon^S$ is the identity.
	\item Show that for any functions $f\colon R\to S$ and $g\colon S\to T$, we have $\yon^g\then\yon^f=\yon^{f\then g}$.
\qedhere
\end{enumerate}

\begin{solution}
\begin{enumerate}
    \item The fact that $\yon^{\id_S}\colon\yon^S\to\yon^S$ is the identity is just a generalization of \cref{exc.representable_nt_components} \cref{exc.representable_nt_components.id}.
    For any set $X$, the $X$-component $X^{\id_S} \colon X^S \to X^S$ of $\yon^{\id_S}$ sends each $h \colon S \to X$ to $\id_S \then h = h$, so $X^{\id_S}$ is the identity on $X^S$.
    Hence $\yon^{\id_S}$ is the identity on $\yon^S$.
    \item Fix $f \colon R \to S$ and $g \colon S \to T$; we wish to show that $\yon^g \then \yon^f = \yon^{f \then g}$.
    It suffices to show component-wise that $X^g \then X^f = X^{f \then g}$ for every set $X$.
    Indeed, $X^g$ sends each $h \colon T \to X$ to $g \then h$; then $X^f$ sends $g \then h$ to $f \then g \then h = X^{f \then g}(h)$.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{lemma}[Yoneda lemma]\label{lemma.yoneda}
Given a functor $F\colon\smset\to\smset$ and a set $S$, there is an isomorphism
\begin{equation}\label{eqn.yoneda}
F(S)\cong\nat(\yon^S,F)
\end{equation}
where $\nat$ denotes the set of natural transformations. Moreover, \eqref{eqn.yoneda} is natural in both $S$ and $F$.
\end{lemma}
\begin{proof}[Sketch of proof]
For any natural transformation $m\colon\yon^S\to F$, consider the component $m_S\colon S^S\to F(S)$. Applying it to the identity on $S$ as an element of $S^S$, we get an element $m_S(\id_S)\in F(S)$.

For any element $a\in F(S)$, there is a natural transformation $m^a\colon\yon^S\to F$ whose $X$-component is the function $X^S\to F(X)$ given by sending $g\colon S\to X$ to $F(g)(a)$. In \cref{exc.finish_proof_yoneda} we ask you to show that this is natural in $X$ and that these two constructions are mutually inverse.
\end{proof}

\begin{exercise}\label{exc.finish_proof_yoneda}
Whoever solves this exercise can say they've proved the Yoneda lemma.
\begin{enumerate}
	\item Show that for any $a\in F(S)$, the maps $X^S\to F(X)$ given as in the proof sketch of \cref{lemma.yoneda} are natural in $X$.
	\item Show that the two mappings from the proof sketch of \cref{lemma.yoneda} are mutually inverse.
	\item Show that \eqref{eqn.yoneda} is natural in $F$.
	\item Show that \eqref{eqn.yoneda} is natural in $S$.
	\item As a corollary of \cref{lemma.yoneda}, show that $\yon^-\colon\smset\op\to\smset^\smset$ is fully faithful, in particular that there is an isomorphism $\nat(\yon^S,\yon^T)\cong S^T$.
\qedhere
\end{enumerate}

\begin{solution}
\begin{enumerate}
    \item Given $a \in F(S)$, naturality of the maps $X^S \to F(X)$ that send $g \colon S \to X$ to $F(g)(a)$ amounts to the commutativity of
    \[
    \begin{tikzcd}[ampersand replacement=\&]
    	X^S\ar[r, "h^S"]\ar[d, "F(-)(a)"']\&
    	Y^S\ar[d, "F(-)(a)"]\\
    	F(X)\ar[r, "F(h)"']\&
    	F(Y)
    \end{tikzcd}
    \]
    for all $h \colon X \to Y$.
    The top map $h^S$ sends any $g \colon X \to S$ to $g \then h$ (\cref{def.representable}), which is then sent to $F(g \then h)(a)$ by the right map.
    Meanwhile, the left map sends $g$ to $F(g)(a)$, which is then sent to $F(h)(F(g)(a))$ by the bottom map.
    So by the functoriality of $F$, the square commutes.
    
    \item We seek to show that the two maps from the proof sketch of \cref{lemma.yoneda} are mutually inverse. First, we show that for any natural transformation $m \colon \yon^S \to F$, we have that $m^{m_S(\id_S)} = m$.
    Given a set $X$, the $X$-component of $m^{m_S(\id_S)}$ sends each $g \colon S \to X$ to $F(g)(m_S(\id_S))$; it suffices to show that this is also where the $X$-component of $m$ sends $g$.
    Indeed, by the naturality of $m$, the square
    \[
    \begin{tikzcd}[ampersand replacement=\&]
    	S^S\ar[r, "g^S"]\ar[d, "m_S"']\&
    	X^S\ar[d, "m_X"]\\
    	F(S)\ar[r, "F(g)"']\&
    	F(X)
    \end{tikzcd}
    \]
    commutes, so in particular
    \begin{equation} \label{eq.finish_proof_yoneda}
        F(g)(m_S(\id_S)) = m_X(g^S(\id_S)) = m_X(\id_S \then g) = m_X(g).
    \end{equation}
    In the other direction, we show that for any $a \in F(S)$, we have $m^a_S(\id_S) = a$: by construction, $m^a_S \colon S^S \to F(S)$ sends $\id_S$ to $F(\id_S)(a) = a$.
    
    \item Given functors $F, G \colon \smset^\smset$ and a natural transformation $\alpha \colon F \to G$, we wish to show that the naturality square
    \[
    \begin{tikzcd}[ampersand replacement=\&]
    	\nat(\yon^S,F)\ar[d, "- \then \alpha"']\ar[r, "\sim"]\&
    	F(S)\ar[d, "\alpha_S"]\\
    	\nat(\yon^S,G)\ar[r, "\sim"]\&
    	G(S)
    \end{tikzcd}
    \]
    commutes.
    The top map sends any $m \colon \yon^S \to F$ to $m_S(\id_S)$, which in turn is sent by the right map to $\alpha_S(m_S(\id_S)) = (m \then \alpha)_S(\id_S)$.
    This is also where the bottom map sends $m \then \alpha$, so the square commutes.
    
    \item Given a function $g \colon S \to X$, we wish to show that the naturality square on the left side of the diagram
    \[
    \begin{tikzcd}[ampersand replacement=\&]
    	\nat(\yon^S,F)\ar[d, "\yon^g \then -"']\ar[r, "\sim"]\&
    	F(S)\ar[d, "F(f)"]\\
    	\nat(\yon^X,F)\ar[r, "\sim"]\&
    	F(X)
    \end{tikzcd}
    \]
    commutes.
    The left map sends any $m \colon \yon^S \to F$ to $\yon^g \then m$, which is sent by the bottom map to $(\yon^g \then m)_X(\id_X) = m_X(X^g(\id_X)) = m_X(f \then \id_X) = m_X(g)$.
    Meanwhile, the top map sends $m$ to $m_S(\id_S)$, which is sent by the right map to $F(g)(m_S(\id_S))$.
    So the square commutes by \eqref{eq.finish_proof_yoneda}.
    
    \item To show that $\nat(\yon^S, \yon^T) \iso S^T$, just take $F = \yon^T$ in \cref{lemma.yoneda}.
\end{enumerate}
\end{solution}
\end{exercise}

%---- Subsection ----%
\subsection{Polynomials: sums of representables}

We've seen that for any set $A$, the symbol $\yon^A$ represents a functor $\smset\to\smset$. We will generalize this by adding representable functors together to form polynomials. In some sense the name ``polynomial'' doesn't quite fit, because in algebra polynomials are often taken to be finite sums, whereas we will use sums that may be infinite. However, we are not the first by far to use the term ``polynomial'' in this way.

So here's the deal. All of our polynomials will be polynomials in one variable, $\yon$; every other letter or number that shows up will represent a set.%
\footnote{For those who clamor for polynomials in many variables, we will see in \cref{**} that the multivariable story falls out of the one-variable story.}
For example, in the following bizarre polynomial
\begin{equation}\label{eqn.biz_poly}
p\coloneqq\rr\yon^\zz+\3\yon^{\3}+A\yon+\sum_{i\in I}Q_i\yon^{R_i+Q_i^2},
\end{equation}
$\rr$ denotes the set of real numbers, $\zz$ denotes the set of integers, $\3$ denotes the set $\{1,2,3\}$, and $A$, $I$, $Q_i$, and $R_i$ denote some arbitrary sets that should have already been defined in order for \eqref{eqn.biz_poly} to make sense.

The polynomials we already understand at this point are the pure power polynomials $\yon^A$ for some set $A$: they are representable functors $\yon^A\colon\smset\to\smset.$
So to understand general polynomials like $p$, we just need to understand what the sums of functors are. It will be useful to discuss products of functors at the same time.

To undertand the sums and products of set-valued functors, we will first need to understand the sums and products of sets.

\paragraph{Dependent sums and products of sets.}

Let $I$ be a set, and let $X_i$ be a set for each $i\in I$. We denote this
\emph{$I$-indexed collection of sets} --- a \emph{dependent set} --- in the form of a functor as $X\colon I\to\smset$ (where we view the set $I$ as a discrete category) or more classically as $(X_i)_{i\in I}$.
Indeed, when a functor $X \colon I \to \smset$ is understood to be a dependent set, we will denote $X(i)$ as $X_i$ for $i \in I$.
Choosing one element from one set in the collection would be denoted $(i,x)$ where $x\in X_i$. Choosing an element from
each set in the collection would give us a function $i \mapsto x_i$ where each
$x_i\in X_i$. This is a sort of function we haven't seen before, at least in
this form --- its codomain \emph{depends} on the element we are applying it to.
Think of a vector field $v$: to each point $p$ it assignes a tangent vector
$v_p$ in the tangent space \emph{at $p$}. We can write the signature of such a
function as
\[f \colon (i \in I) \to X_i.\]
We call this a \emph{dependent function}, since its codomain depends on the
element of its domain we are applying it to.

\begin{definition}[Dependent sums and products of sets]
Let $I$ be a set and $X\colon I\to\smset$ be an $I$-indexed collection of sets. The \emph{sum} $\sum_{i\in I}X_i$ and \emph{product} $\prod_{i\in I}X_i$ of this collection are the sets
\[
\sum_{i\in I}X_i:=\{(i,x)\mid i\in I\text{ and }x\in X_i\}
\qqand
\prod_{i\in I}X_i:=\{f : (i \in I) \to X_i\}.
\]
\end{definition}

\begin{example}\label{ex.two_sums_and_prods}
If $I=\2=\{1,2\}$ then a collection $X\colon I\to \smset$ is just two sets, say $X_1=\{a,b,c\}$ and $X_2=\{c,d\}$. Their sum is the disjoint union
\[\sum_{i\in \2}X_i=X_1+X_2=\{(1,a),(1,b),(1,c),(2,c),(2,d)\}.\]
Its cardinality (i.e.\ the number of elements it contains) will always be the sum of the cardinalities of $X_1$ and $X_2$.

Meanwhile, their product is the usual Cartesian product
\[\prod_{i\in \2}X_i \cong X_1\times X_2=\{(a,c),(a,d),(b,c),(b,d),(c,c),(c,d)\}.\]
Its cardinality will always be the product of the cardinalities of $X_1$ and $X_2$.
\end{example}


\begin{exercise}\label{exc.on_sums_prods_sets}
Let $I$ be a set and let $X_i=\1$ be a one-element set for each $i\in I$. 
\begin{enumerate}
	\item \label{exc.on_sums_prods_sets.sum} Show that there is an isomorphism of sets $I\cong\sum_{i\in I}\1$.
	\item \label{exc.on_sums_prods_sets.prod} Show that there is an isomorphism of sets $\1\cong\prod_{i\in I}\1$.
\end{enumerate}
As a special case, suppose $I\coloneqq\varnothing$ and $X\colon \varnothing\to\smset$ is the unique empty collection of sets.
\begin{enumerate}[resume]
	\item Is it true that $X_i=\1$ for each $i\in I$?
	\item Show that there is an isomorphism of sets $\0\cong\sum_{i\in\varnothing}X_i$.
	\item Show that there is an isomorphism of sets $\1\cong\prod_{i\in\varnothing}X_i$.
\qedhere
\end{enumerate}

\begin{solution}
We are given a set $I$ and a dependent set $(X_i)_{i \in I}$ for which $X_i = \1$ for every $i \in I$.
\begin{enumerate}
    \item \label{sol.on_sums_prods_sets.sum}
    To show that $I \iso \sum_{i \in I} \1$, we note that $x \in \1 = \{1\}$ if and only if $x = 1$, so $\sum_{i \in I} \1 = \{(i, 1) \mid i \in I\}$.
    Then function $I \to \sum_{i \in I} \1$ that sends each $i \in I$ to $(i, 1)$ is clearly an isomorphism.
    
    \item \label{sol.on_sums_prods_sets.prod}
    To show that $\1 \iso \prod_{i \in I} \1$, it suffices to demonstrate that there is a unique dependent function $f \colon (i \in I) \to \1$.
    As $\1 = \{1\}$, such a function $f$ must always send $i \in I$ to $1$.
    This completely characterizes $f$, so there is only one such dependent function.
    
\end{enumerate}
Now $I = \varnothing$ and $X \colon \varnothing \to \smset$ is the unique empty collection of sets.
\begin{enumerate}[resume]
    \item \label{sol.on_sums_prods_sets.vac} Yes: since $I$ is empty, there are no $i \in I$.
    So it is true that $X_i = 1$ holds whenever $i \in I$ holds, because $i \in I$ never holds. 
    We say that this sort of statement is ``vacuously true.''
    
    \item As $I = \varnothing = \0$, we have $\0 = I \iso \sum_{i \in I} \1 = \sum_{i \in \varnothing} X_i$, where the middle isomorphism follows from \cref{sol.on_sums_prods_sets.sum} and the last equation follows from \cref{sol.on_sums_prods_sets.vac}.
    
    \item As $I = \varnothing = \0$, we have $\1 \iso \prod_{i \in I} \1 = \prod_{i \in \varnothing} X_i$, where the isomorphism on the left follows from \cref{sol.on_sums_prods_sets.prod} and the equation on the right follows from \cref{sol.on_sums_prods_sets.vac}.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}\label{exc.dependent_product_as_sections}
  Let $X : I \to \smset$ be a set depending on an $i \in I$. There is a
  projection function
  $\pi_1 : \sum_{i \in I} X_i \to I$
  defined by $\pi_1(i, x) = i$.
  \begin{enumerate}
    \item What is the signature of the second projection $\pi_2(i, x) = x$?
    (Hint: it's a dependent function.)
    \item A \emph{section} of a function $r : A \to B$ is a function $s : B \to A$ such that $s \then r = \id_B$.
    Show that the dependent product is isomorphic to the set of sections of $\pi_1$:
    \[\prod_{i \in I} X_i \cong \left\{s : I \to \sum_{i \in I} X_i \,\middle|\, s \then \pi_1 = \id_I\right\}.\]
    \qedhere
  \end{enumerate}
\begin{solution}
We have a dependent set $X : I \to \smset$ and a projection function $\pi_1 : \sum_{i \in I} X_i \to I$ defined by $\pi_1(i, x) = i$.
\begin{enumerate}
    \item The second projection $\pi_2(i, x) = x$ sends each pair $p = (i, x) \in \sum_{i \in I} X_i$ to $x$, an element of $X_i$.
    Note that we can write $i$ in terms of $p$ as $\pi_1(p)$.
    This allows us to write the signature of $\pi_2$ as $\pi_2 \colon (p \in \sum_{i \in I} X_i) \to X_{\pi_1(p)}$.
    
    \item Let $S := \{s : I \to \sum_{i \in I} X_i \mid s \then \pi_1 = \id_I\}$ be the set of sections of $\pi_1$. To show that $\prod_{i \in I} X_i \cong S$, we will exhibit maps in either direction and show that they are mutually inverse.
    For each $f \colon (i \in I) \to X_i$ in $\prod_{i \in I} X_i$, we have that $f(i) \in X_i$ for all $i \in I$, so we can define a function $s_f \colon I \to \sum_{i \in I} X_i$ that sends each $i \in I$ to $(i, f(i))$.
    Then $\pi_1(s_f(i)) = \pi_1(i, f(i)) = i$, so $s_f$ is indeed a section of $\pi_1$.
    Hence $f \mapsto s_f$ is a map $\prod_{i \in I} X_i \to S$.
    
    In the other direction, for each section $s \colon I \to \sum_{i \in I} X_i$ we have $\pi_1(s(i)) = i$ for all $i \in I$, so we can write $s(i)$ as an ordered pair $(i, \pi_2(s(i)))$ with $\pi_2(s(i)) \in X_i$.
    It follows that we can define a function $f_s \colon (i \in I) \to X_i$ that sends each $i \in I$ to  $\pi_2(s(i))$.
    Then $s \mapsto f_s$ is a map $S \to \prod_{i \in I} X_i$.
    By construction $s_{f_s}(i) = (i, f_s(i)) = (\pi_1(s(i)), \pi_2(s(i))) = s(i)$ and $f_{s_f}(i) = \pi_2(s_f(i)) = \pi_2(i, f(i)) = f(i)$, so these maps are mutually inverse.
\end{enumerate}
\end{solution}
\end{exercise}

A helpful way to think about sum or product sets is by considering what choices must be made to specify an element of such a set.
In the following examples, say that we have a dependent set $X \colon I \to \smset$.

Here we give the instructions for choosing an element of $\sum_{i \in I} X_i$.

\begin{quote}
To choose an element of $\sum_{i \in I} X_i$: 
\begin{enumerate}
    \item choose an element $i \in I$;
    \item choose an element of $X_i$.
\end{enumerate}
\end{quote}

Then the projection $\pi_1$ from \cref{exc.dependent_product_as_sections} sends each element of $\sum_{i \in I} X_i$ to the element of $i \in I$ chosen in step 1, while the projection $\pi_2$ sends each element of $\sum_{i \in I} X_i$ to the element of $X_i$ chosen in step 2.

Now we give the instructions for choosing an element of $\prod_{i \in I} X_i$.

\begin{quote}
To choose an element of $\prod_{i \in I} X_i$: 
\begin{enumerate}
    \item for each element $i \in I$:
    \begin{enumerate}[label=\arabic*.]
        \item choose an element of $X_i$.
    \end{enumerate}
\end{enumerate}
\end{quote}

Armed with these interpretations, we can tackle more complicated expressions, including those with nested $\sum$'s and $\prod$'s like
\begin{equation}\label{eqn.misc98339}
A \coloneqq \sum_{i\in I}\prod_{j\in J(i)}\sum_{k\in K(i,j)}X(i,j,k).
\end{equation}
We can give the instructions for choosing an element of $A$ as a nested list, as follows.

\begin{quote}
To choose an element of $A$:
\begin{enumerate}
    \item choose an element $i \in I$;
    \item for each element $j \in J(i)$:
    \begin{enumerate}[label=\arabic*.]
        \item choose an element $k \in K(i,j)$;
        \item choose an element of $X(i,j,k)$.
    \end{enumerate}
\end{enumerate}
\end{quote}

Note that the choice of $k\in K(i,j)$ can depend on $i$ and $j$; it must be able to, because different values of $i$ and $j$ may lead to different sets $K(i,j)$.

By describing $A$ like this, it is clear that each $a \in A$ can be projected to an element $\pi_1(a) \in I$ from step 1 and a dependent function $\pi_2(a)$ from step 2.
This dependent function in turn sends each $j \in J(i)$ to a pair that can be projected to an element $\pi_1(\pi_2(a)(j)) \in K(i, j)$ from step 2.1 and an element $\pi_2(\pi_2(a)(j)) \in X(i,j,k)$ from step 2.2.

\begin{example}%[Notation for $\sum\prod$ stuff]
\label{ex.notation_sum_prod}
% Here we give notation for the elements of a set involving $\sum$'s and $\prod$'s such as that in \eqref{eqn.misc98339}.

Let $I=\{1,2\}$, let $J(1)=\{j\}$ and $J(2)\coloneqq\{j,j'\}$, let $K(1,j)\coloneqq\{k_1,k_2\}$, $K(2,j)\coloneqq\{k_1\}$, and $K(2,j')\coloneqq\{k'\}$, and let $X(i,j,k)=\{x,y\}$ for all $i,j,k$. Now the formula 
\[\sum_{i\in I}\prod_{j\in J(i)}\sum_{k\in K(i,j)}X(i,j,k)\]
from \eqref{eqn.misc98339} has been given meaning as an actual set. Here is a list of all eight of its elements:
\[
\left\{
\begin{gathered}
	\big(1, j\mapsto(k_1,x)\big),\qquad
	\big(1, j\mapsto(k_1,y)\big),\qquad
	\big(1, j\mapsto(k_2,x)\big),\qquad
	\big(1, j\mapsto(k_2,y)\big),\\
	\big(2, j\mapsto(k_1,x), j'\mapsto(k',x)\big),\qquad
	\big(2, j\mapsto(k_1,x), j'\mapsto(k',y)\big),\\
	\big(2, j\mapsto(k_1,y), j'\mapsto(k',x)\big),\qquad
	\big(2, j\mapsto(k_1,y), j'\mapsto(k',y)\big)
\end{gathered}
\right\}
\]
In each case, we first chose an element $i\in I$, either 1 or 2. Then for each $j\in J(i)$ we chose an element $k\in K(i,j)$; then we concluded by choosing an element of $X(i,j,k)$.
\end{example}

\begin{exercise}
Consider the set
\[B \coloneqq \prod_{i\in I}\sum_{j\in J(i)}\prod_{k\in K(i,j)}X(i,j,k).\]
\begin{enumerate}
	\item Give the instructions for choosing an element of $B$ as a nested list, like we did for $A$ just below \eqref{eqn.misc98339}.
	\item With $I$, $J$, $K$, and $X$ as in \cref{ex.notation_sum_prod}, how many elements are in $B$?
	\item Write out three of these elements in the style of \cref{ex.notation_sum_prod}.
\qedhere
\end{enumerate}
\begin{solution}
We are given the set
\[
    B \coloneqq \prod_{i\in I}\sum_{j\in J(i)}\prod_{k\in K(i,j)}X(i,j,k).
\]
\begin{enumerate}
	\item Here are the instructions for choosing an element of $B$ as a nested list.
	\begin{quote}
	    To choose an element of $B$:
	    \begin{enumerate}[label=\arabic*.]
	        \item for each element $i \in I$:
	        \begin{enumerate}[label=\arabic*.]
	            \item choose an element $j \in J(i)$;
	            \item for each element $k \in K(i, j)$:
	            \begin{enumerate}[label=\arabic*.]
	                \item choose an element of $X(i,j,k)$.
	            \end{enumerate}
	        \end{enumerate}
	    \end{enumerate}
	\end{quote}
	\item Given $I\coloneqq\{1,2\}$, $J(1)\coloneqq\{j\}$, $J(2)\coloneqq\{j,j'\}$, $K(1,j)\coloneqq\{k_1,k_2\}$, $K(2,j)\coloneqq\{k_1\}$, $K(2,j')\coloneqq\{k'\}$, and $X(i,j,k)=\{x,y\}$ for all $i,j,k$, our goal is to count the number of elements in $B$.
	To compute the cardinality of $B$, we can use the fact that the cardinality of a sum (resp. product) is the sum (resp. product) of the cardinalities.
	So
	\begin{align*}
	    |B| &= \prod_{i\in I}\sum_{j\in J(i)}\prod_{k\in K(i,j)}|X(i,j,k)| \\
	    &= \prod_{i\in \{1,2\}}\sum_{j\in J(i)}\prod_{k\in K(i,j)}2 \\
	    &= \left(\sum_{j\in J(1)} 2^{|K(1,j)|}\right)\left(\sum_{j\in J(2)} 2^{|K(2,j)|}\right) \\
	    &= \left(2^2\right)\left(2^1 + 2^1\right) = 16.
	\end{align*}
	\item Here are three of the elements of $B$ (you may have written down others):
	\begin{itemize}
	    \item $(1 \mapsto (j, k_1 \mapsto x, k_2 \mapsto y), 2 \mapsto (j', k' \mapsto x))$
	    \item $(1 \mapsto (j, k_1 \mapsto y, k_2 \mapsto y), 2 \mapsto (j, k_1 \mapsto y))$
	    \item $(1 \mapsto (j, k_1 \mapsto y, k_2 \mapsto x), 2 \mapsto (j', k' \mapsto y))$
	\end{itemize}
\qedhere
\end{enumerate}
\end{solution}
\end{exercise}

\paragraph{Expanding products of sums.}

We will often encounter sums of dependent sets nested within products.
The following proposition helps us work with these; it is sometimes called the \emph{type-theoretic axiom of choice} or the \emph{completely distributive property}, in this case of $\smset$. It is almost trivial, once you understand what it's saying; in particular, once the statement is written in Agda, its proof is one short line of Agda code. 

\begin{proposition}[Pushing $\prod$ past $\sum$]\label{prop.push_prod_sum_set}
For any set $I$, collection of sets $\{J(i)\}_{i\in I}$, and collection of sets $\{X(i,j)\}_{i\in i, j\in J(i)}$, we have a bijection
\begin{equation}\label{eqn.set_completely_distributive}
\prod_{i\in I}\sum_{j\in J(i)}X(i,j)
\cong
\sum_{\bar{j}\in \prod_{i\in I}J(i)}\;\prod_{i\in I}X(i,\bar{j}(i)).
\end{equation}
\end{proposition}
\begin{proof}
We'll do this the old-fashioned way: by giving a map from left to right, a
map from right to left, and a proof that the two maps are mutually inverse. 

First, let's go from left to right. An element of the set on the left is a dependent function $f \colon (i \in I) \to \sum_{j \in J(i)} X(i, j)$, which we can compose with projections from its codomain to yield $\pi_1(f(i)) \in J(i)$ and $\pi_2(f(i)) \in X(i, \pi_1(f(i)))$ for every $i \in I$.
We can then form the following pair in the right hand set:
\[
    (i \mapsto \pi_1(f(i)), i \mapsto \pi_2(f(i))).
\]

Now let's go from right to left. An element of the set on the right is a pair of dependent functions, $\bar{j} \colon (i \in I) \to J(i)$ and $g \colon
(i \in I) \to X(i, \bar{j}(i))$. We then get an element of the set on the left as follows:
\[i \mapsto (\bar{j}(i), g(i)).\]

Now, we just need to check that a round trip takes us back where we were. If we
start on the right from $(\bar{j}, g)$, our round trip gives us the pair
\[(i \mapsto \pi_1(\bar{j}(i), g(i)), i \mapsto \pi_2(\bar{j}(i), g(i))).\]
But $\pi_1(\bar{j}(i), g(i)) = \bar{j}(i)$ and $\pi_2(\bar{j}(i), g(i)) = g(i)$ by definition, so
we're back where we started. On the other hand, starting on the left from $f$ gives us the function
\[i \mapsto (\pi_1(f(i)), \pi_2(f(i))).\]
But again, since $f(i)$ is a pair whose components are $\pi_1(f(i))$ and $\pi_2(f(i))$, we're back where we started.

\erase{
We start with the function from left to right. To give such a function it suffices by the universal property of products and coproducts to fix an arbitrary $j_0\in\prod_{i\in I}J(i)$ and $i_0\in I$, and provide a function $\prod_{i\in I}X(i,j_0(i))\to\sum_{j\in J(i_0)}X(i_0,j)$. We do so by first projecting onto the $i_0$ factor and then including into the $j_0(i_0)$ summand
\[
  \prod_{i\in I}X(i,j_0(i))\to 
  X(i_0,j_0(i_0))\to
  \sum_{j\in J(i_0)}X(i_0,j).
\]
We have now given the function from left to right. To go the other way..
}
\end{proof}

When $J(i)=J$ does not depend on $i\in I$, the formula in \eqref{eqn.set_completely_distributive} becomes much easier.

\begin{corollary} \label{prop.push_prod_sum_set_indep}
For any set $I$, set $J$, and collection of sets $\{X(i, j)\}_{i \in I, j \in J}$, we have a bijection
\begin{equation}
    \prod_{i\in I}\sum_{j\in J}X(i,j)\cong\sum_{\bar{j}\colon I\to J}\prod_{i\in I}X(i,\bar{j}(i)).
\end{equation}
\end{corollary}
\begin{proof}
Just take $J(i) = J$ for all $i \in I$ in \cref{prop.push_prod_sum_set}.
Note that dependent functions $\bar{j}$ in $\prod_{i \in I} J(i)$ then become standard functions $\bar{j} \colon I \to J$.
\end{proof}

Below, e.g.\ in \cref{exc.practice_sum_prod}, you'll often see alternating products and sums; using \eqref{eqn.set_completely_distributive}, you can always write it as a sum of products, in which every $\sum$ appears before every $\prod$ (i.e.\ in ``disjunctive normal form'').
This is analogous to how products of sums in high school algebra can always be expanded into sums of products via the distributive property.

% \begin{exercise} \label{exc.push_prod_sum_set}
% \begin{enumerate}
%     \item Rewrite
%     \[
%         \sum_{i\in I}\prod_{j\in J(i)}\sum_{k\in K(i,j)}X(i,j,k)
%     \]
%     so that every $\sum$ appears before every $\prod$.
%     \item Rewrite
%     \[
%         \prod_{i\in I}\sum_{j\in J(i)}\prod_{k\in K(i,j)}X(i,j,k)
%     \]
%     so that every $\sum$ appears before every $\prod$.\qedhere
% \end{enumerate}
% \begin{solution}
% Our goal is to rewrite each expression so that every $\sum$ appears before every $\prod$.
% \begin{enumerate}
%     \item By applying \cref{prop.push_prod_sum_set}, we can rewrite
%     \[
%         \sum_{i\in I}\prod_{j\in J(i)}\sum_{k\in K(i,j)}X(i,j,k)
%     \]
%     as
%     \[
%         \sum_{i\in I}\sum_{\bar{k}\in \prod_{j\in J}K(i,j)}\prod_{j\in J(i)}X(i,j,\bar{k}(j)).
%     \]
%     \item By applying \cref{prop.push_prod_sum_set}, we can rewrite
%     \[
%         \prod_{i\in I}\sum_{j\in J(i)}\prod_{k\in K(i,j)}X(i,j,k)
%     \]
%     as
%     \[
%         \sum_{\bar{j}\in \prod_{i\in I}J(i)}\;\prod_{i\in I}X(i,\bar{j}(i))\prod_{k\in K(i,\bar{j}(i))}X(i,\bar{j}(i),k).
%     \]
% \end{enumerate}
% \end{solution}
% \end{exercise}

\paragraph{Dependent sums and products of functors $\smset\to\smset$.}

Where are we, and where are we going? We've defined dependent sums and products of sets; that's where we are. Our goal is to define polynomial functors, e.g.\ $\yon^\2+\2\yon+\1$, and the maps between them. Since $\yon^2$, $\yon$, and $\1$ are functors, we just need to define sums of functors $\smset\to\smset$. But we might as well define products of functors at the same time, because they'll very much come in handy.

\begin{definition}[Dependent sums and products of functors $\smset\to\smset$]\label{def.sum_prod}
For any two functors $F,G\colon\smset\to\smset$, let
\[
  (F+G)\colon\smset\to\smset
  \qqand
  (F\times G)\colon\smset\to\smset
\]
denote the functors that respectively assign to each $X\in\smset$ the sets
\[
  (F+G)(X)\coloneqq F(X)+G(X)
  \qqand
	(F\times G)(X)\coloneqq F(X)\times G(X).
\]
We may also denote the product functor $F \times G$ by $FG$.

More generally, for any set $I$ and functors $(F_i)_{i\in I}$, let
\[
\sum_{i\in I}F_i\colon\smset\to\smset
\qqand
\prod_{i\in I}F_i\colon\smset\to\smset
\]
denote the functors that respectively assign to each $X\in\smset$ the sum and product of sets
\[
	\Big(\sum_{i\in I}F_i\Big)(X)\coloneqq\sum_{i\in I} F_i(X)
	\qqand
	\Big(\prod_{i\in I}F_i\Big)(X)\coloneqq\prod_{i\in I} F_i(X).
\]
Given a set $I\in\smset$, we will also use $I$ to denote the constant functor that assigns $I$ to each $X\in\smset$.
In particular, we denote by $\0,\1\colon\smset\to\smset$ the constant functors that respectively assign $\0$ and $\1$ to each $X\in\smset$.
\end{definition}

\begin{exercise} \label{exc.repeated_sum_is_product}
\begin{enumerate}
	\item Show that for a set $I \in \smset$ and a functor $F \colon \smset \to \smset$, the sum of $I$ copies of $F$ is isomorphic to the product of the constant functor $I$ and $F$:
    \[
        \sum_{i \in I} F \iso IF.
    \]
    (Note that this is analogous to the fact from basic arithmetic that adding up $n \in \nn$ copies of number is equal to multiplying that same number by $n$.)
	\item So does $\2\yon$ denote $\2\times\yon$ or $\yon+\yon$, or does it not matter for some reason?
\qedhere
	\end{enumerate}
\begin{solution}
\begin{enumerate}
	\item It suffices to show that for all $X \in \smset$,
    \[
      \sum_{i \in I} F(X) \iso (IF)(X).
    \]
    The left hand side is isomorphic to the set $\{(i,s)\mid i\in I\text{ and }s\in F(X)\} \iso I \times F(X)$, while the right hand side is also isomorphic to the set $I(X) \times F(X) \iso I \times F(X)$. (Alternatively, the result also follows from \cref{prop.push_prod_sum_set}.)
    \item It doesn't matter: $\2\yon$ can denote either one. Indeed, taking $I\coloneqq\2$, the above says that there is an isomorphism $\2\times\yon\cong\yon+\yon$. 
\end{enumerate}
\end{solution}
\end{exercise}

\begin{proposition} \label{prop.prods_coprods_set_endofuncs}
Referring to the notation in \cref{def.sum_prod}, the functors $\0$ and $\1$ are respectively an initial object and a terminal object in $\smset^\smset$, the operations $+$ and $\times$ are respectively a binary coproduct and a binary product in $\smset^\smset$, and the operations $\sum_{i\in I}$ and $\prod_{i\in I}$ are arbitrary coproducts and products in $\smset^\smset$.
\end{proposition}
\begin{proof}
By \cref{ex.two_sums_and_prods,exc.on_sums_prods_sets}, it suffices to show that $\sum_{i\in I}F_i$ and $\prod_{i\in I}F_i$ are a sum and product in $\smset^\smset$. This itself is a special case of a more general fact, where sums and products are replaced by arbitrary colimits and limits, and where $\smset^\smset$ is replaced by an arbitrary functor category $\cat{C}^\cat{D}$, where $\cat{C}$ is a category that (like $\smset$) has limits and colimits; see \cite[page 22 -- 23, displays (24) and (25)]{macLane1992sheaves}.
\end{proof}

We've finally arrived: we can define polynomial functors!

\paragraph{What is a polynomial functor?}

\begin{definition}[Polynomial functors]
A \emph{polynomial functor} (or simply a \emph{polynomial}) is a functor $p\colon\smset\to\smset$ such that there exists a set $I$, sets $(p[i])_{i\in I}$, and an isomorphism
\[p\cong\sum_{i\in I}\yon^{p[i]}\]
to a sum of representables.
\end{definition}

So (up to isomorphism), a polynomial functor is just a sum of representables.

\begin{remark}
Given sets $I, A \in \smset$, it follows from \cref{exc.repeated_sum_is_product} that we have an isomorphism of polynomials
\[
    \sum_{i \in I} \yon^A \iso I\yon^A.
\]
So when we write down a polynomial, we will often combine identical representable summands $\yon^A$ by writing them in the form $I\yon^A$.
In particular, the constant functor $\1$ is a representable functor ($\1 \iso \yon^\0$), so every constant functor $I$ is a polynomial functor: $I \iso \sum_{i \in I} \1$.
\end{remark}

\begin{example}\label{ex.pedantic_poly_eval}
Consider the polynomial $p \coloneqq \yon^\2+\2\yon+\1$. It denotes a functor $\smset\to\smset$; what does this functor do to the set $X\coloneqq\{a,b\}$? 
To be very precise and pedantic, let's say
\[
I\coloneqq\4\qqand
  p[1]\coloneqq\2,\quad
  p[2]\coloneqq\1,\quad
  p[3]\coloneqq\1,\quad
  p[4]\coloneqq\0\
\]
so that $p\cong\sum_{i\in I}\yon^{p[i]}$. Now we have
\[
p(X)\cong
\{(1,a,a),(1,a,b),(1,b,a),(1,b,b),(2,a),(2,b),(3,a),(3,b),(4)\}.
\]
It has $(2^2+2+2+1)$-many, i.e.\ $9$, elements. The representable summand $\yon^A$ throws in all $A$-tuples from $X$, but it's indexed by the name of the summand. In particular if $A=\varnothing$ then it just records the empty tuple at that summand.
\end{example}

\begin{exercise}
In the pedantic style of \cref{ex.pedantic_poly_eval}, write out all the elements of $p(X)$ for $p$ and $X$ as follows:
\begin{enumerate}
	\item $p\coloneqq\yon^\3$ and $X\coloneqq\{4,9\}.$
	\item $p\coloneqq\3\yon^\2+\1$ and $X\coloneqq\{a\}$.
	\item $p\coloneqq\0$ and $X\coloneqq\nn$.
	\item $p\coloneqq\4$ and $X\coloneqq\nn$.
	\item $p\coloneqq\yon$ and $X\coloneqq\nn$.
\qedhere
\end{enumerate}

\begin{solution}
Our goal is to write out the elements of $p(X)$ for each polynomial $p$ and set $X$ that we are given.
\begin{enumerate}
    \item If $p\coloneqq\yon^\3$ and $X\coloneqq\{4,9\}$, then let $I \coloneqq \1$ and $p[1] \coloneqq \3$ so that $p \iso \sum_{i \in I} \yon^{p[i]}$.
    So
    \[
        p(X) \iso \{(1, 4, 4, 4), (1, 4, 4, 9), (1, 4, 9, 4), (1, 4, 9, 9), (1, 9, 4, 4), (1, 9, 4, 9), (1, 9, 9, 4), (1, 9, 9, 9)\}.
    \]
    
    \item If $p\coloneqq\3\yon^\2+\1$ and $X\coloneqq\{a\}$, then let $I \coloneqq \4$, $p[1] \coloneqq p[2] \coloneqq p[3] \coloneqq \2$, and $p[4] \coloneqq \1$ so that $p \iso \sum_{i \in I} \yon^{p[i]}$.
    So $p(X) \iso \{(1, a, a), (2, a, a), (3, a, a), (4)\}$.
	
	\item If $\coloneqq\0$ and $X\coloneqq\nn$, then let $I \coloneqq \0$ so that $p \iso \sum_{i \in I} \yon^{p[i]}$.
	So $p(X) \iso \0$.
	Alternatively, we note that $\0$ is the constant functor that assigns $\0$ to every set. 
	
	\item If $p\coloneqq\4$ and $X\coloneqq\nn$, then let $I \coloneqq \4$ and $p[i] \coloneqq \0$ for every $i \in I$.
	So $p(X) \iso \{(1), (2), (3), (4)\} \iso \4$.
	
	\item If $p\coloneqq\yon$ and $X\coloneqq\nn$, then let $I \coloneqq \1$ and $p[1] \coloneqq \1$ so that $p \iso \sum_{i \in I} \yon^{p[i]}$.
    So $p(X) \iso \{(1, n) \mid n \in \nn\}$.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{example}
Suppose $p\coloneqq\yon^\2+\2\yon+1$. As a functor $\smset\to\smset$ it should be able to act not only on sets but on functions. Let $X\coloneqq\{a_1,a_2,b_1\}$, $Y\coloneqq\{a,b,c\}$, and $f\colon X\to Y$ be the function sending $a_1,a_2\mapsto a$ and $b_1\mapsto b$. The induced function $p(f)\colon p(X)\to p(Y)$ is shown below
\[
\begin{tikzcd}[row sep=2pt, column sep=3pt, shorten <=-5pt, shorten >=-5pt, dashed]
\LMO{(1,a_1,a_1)}\ar[rrrr, blue, bend left=25pt]&\LMO{(1,a_1,a_2)}\ar[rrr, blue, bend left=25pt]&\LMO{(1,a_1,b_1)}\ar[rrr, blue, bend left=25pt]&[30pt]&
\LMO{(1,a,a)}&\LMO{(1,a,b)}&\LMO{(1,a,c)}&&
\\
\LMO{(1,a_2,a_1)}\ar[rrrru, blue, bend left=10pt]&\LMO{(1,a_2,a_2)}\ar[rrru, blue, bend left=10pt]&\LMO{(1,a_2,b_1)}\ar[rrru, blue, bend left=10pt]&&
\LMO{(1,b,a)}&\LMO{(1,b,b)}&\LMO{(1,b,c)}&&
\\
\LMO{(1,b_1,a_1)}\ar[rrrru, blue, bend left=10pt]&\LMO{(1,b_1,a_2)}\ar[rrru, blue, bend left=10pt]&\LMO{(1,b_1,b_1)}\ar[rrru, blue, bend left=10pt]&&
\LMO{(1,c,a)}&\LMO{(1,c,b)}&\LMO{(1,c,c)}&&
\\
\LMO{(2,a_1)}\ar[rrrr, blue, bend left=25pt]&\LMO{(2,a_2)}\ar[rrr, blue, bend left=25pt]&\LMO{(2,b_1)}\ar[rrr, blue, bend left=25pt]&&
\LMO{(2,a)}&\LMO{(2,b)}&\LMO{(2,c)}&&
\\
\LMO{(3,a_1)}\ar[rrrr, blue, bend left=25pt]&\LMO{(3,a_2)}\ar[rrr, blue, bend left=25pt]&\LMO{(3,b_1)}\ar[rrr, blue, bend left=25pt]&&
\LMO{(3,a)}&\LMO{(3,b)}&\LMO{(3,c)}&&
\\&
\LMO{(4)}\ar[rrrr, blue]&&&&\LMO{(4)}
\end{tikzcd}
\]
\end{example}

\begin{exercise}
Let $p\coloneqq\yon^\2+\yon$. Choose a function $f\colon\1\to\2$ and write out the induced function $p(f)\colon p(\1)\to p(\2)$.
\begin{solution}
Given $p\coloneqq\yon^\2+\yon$, we seek the induced function $p(f)\colon p(\1)\to p(\2)$ for a function $f\colon\1\to\2$ of our choice.
We will choose $1 \mapsto 2$.
We can evaluate
\[
    p(\1) \iso \{(1, 1, 1), (2, 1)\} \text{ and } p(\2) \iso \{(1, 1, 1), (1, 1, 2), (1, 2, 1), (1, 2, 2), (2, 1), (2, 2)\}.
\]
So $p(f)$ sends $(1, 1, 1) \mapsto (1, 2, 2)$ and $(2, 1) \mapsto (2, 2)$.
(If we had instead picked $1 \mapsto 1$ as our function $f$, then $p(f)$ would send $(1, 1, 1) \mapsto (1, 1, 1)$ and $(2, 1) \mapsto (2, 1)$.)
\end{solution}
\end{exercise}

\begin{proposition}\label{prop.apply1}
Let $p\coloneqq\sum_{i\in I}\yon^{p[i]}$ be an arbitrary polynomial functor. Then $I\cong p(\1)$, so there is an isomorphism of functors
\begin{equation}\label{eqn.sum_p1}
p\cong\sum_{i\in p(\1)}\yon^{p[i]}.
\end{equation}
\end{proposition}
\begin{proof}
We need to show that $I\iso p(\1)$; the latter claim follows directly. In \cref{exc.on_sums_prods_sets} it was shown that $I\iso\sum_{i\in I}\1$, so we just need to show that $(\yon^{p[i]})(\1)\iso\1$ for every $i \in I$. But $\1^{p[i]}\iso \1$ because there is a unique function $p[i]\to \1$ for any $p[i]$.
\end{proof}
We can draw an analogy between \cref{prop.apply1} and evaluating $p(1)$ for a polynomial $p$ from high school algebra, which yields the sum of the coefficients of $p$.
The notation in \eqref{eqn.sum_p1} will be how we denote arbitrary polynomials from now on.

\begin{exercise}\label{exc.apply0}
We saw in \cref{prop.apply1} that for any polynomial $p$, e.g.\ $p\coloneqq\yon^\3+\3\yon^\2+\4$, the set $p(\1)$ gives back the set of summands, in this case $\8$. 

What does $p(\0)$ give you?
\begin{solution}
We consider $p(\0)$ for arbitrary polynomials $p$.
A representable functor $\yon^S$ for some $S \in \smset$ sends $\0 \mapsto \0$ if $S \neq \0$ (as there are then no functions $S \to \0$), but sends $\0 \mapsto \1$ if $S = \0$ (as there is a unique function $\0 \to \0$).
So
\[
    p(\0) \iso \sum_{i \in p(\1)} (\yon^{p[i]})(\0) \iso \sum_{\substack{i \in p(\1), \\ p[i] \neq \0}} \0 + \sum_{\substack{i \in p(\1), \\ p[i] = \0}} \1 \iso \{i \in p(\1) \mid p[i] = \0\}.
\]
In other words, $p(\0)$ is the set of \emph{constant} representable summands of $p$.
For example, if $p\coloneqq\yon^\3+\3\yon^\2+\4$, then $p(\0) = \4$.
In the language of high school algebra, we might call $p(\0)$ the ``constant term'' of $p$.
\end{solution}
\end{exercise}

%---- Subsection ----%
\subsection{Morphisms between polynomial functors}
\label{subsec.understanding_mor_poly}

Before we define the category $\poly$ of polynomial functors, we notice that polynomial functors already live inside a category, namely the category $\smset^\smset$ of functors $\smset \to \smset$, whose morphisms are natural transformations.
This leads to a very natural (if you will) definition of morphisms between polynomial functors, from which we can derive a category of polynomial functors for free.

\begin{definition}[Polynomial morphisms, $\poly$]
Given polynomial functors $p$ and $q$, a \emph{morphism of polynomial functors} (or a \emph{polynomial morphism}) is a natural transformation $p\to q$.
Then $\poly$ is the category whose objects are polynomial functors and whose morphisms are polynomial morphisms.
\end{definition}

In other words, $\poly$ is the full subcategory of $\smset^\smset$ spanned by the polynomial functors: we take the category $\smset^\smset$, throw out all the objects that are not polynomials, but keep all the same morphisms between any two polynomial functors.

\begin{proposition} \label{prop.poly_coprods}
The category $\poly$ has arbitrary coproducts, given by the operation $\sum_{i \in I}$.
\end{proposition}
\begin{proof}
By \cref{prop.prods_coprods_set_endofuncs}, the category $\smset^\smset$ has arbitrary coproducts given by $\sum_{i \in I}$.
The full subcategory inclusion $\poly \to \smset^\smset$ reflects these coproducts, and by definition $\poly$ is closed under the operation $\sum_{i \in I}$.
\end{proof}

A natural transformation between polynomials $p \to q$ consists of a function $p(X) \to q(X)$ for every set $X \in \smset$ such that the naturality squares commute.
That's a lot of data to keep track of!
Fortunately, there is a much simpler way to think about these polynomial morphisms, which we will discover with some help from our old friend, the Yoneda lemma.

\begin{exercise} \label{exc.poly_morph_yoneda}
Given a set $S$ and a polynomial $q$, show that a polynomial morphism $\yon^S \to q$ can be identified with an element of the set $q(S)$.
That is, there is an isomorphism
\[
    \poly(\yon^S, q) \iso q(S).
\]
Moreover, show that this isomorphism is natural in both $S$ and $q$.
Hint: Use the Yoneda lemma (\cref{lemma.yoneda}).
\begin{solution}
As $\poly(\yon^S, q)$ is defined to be $\nat(\yon^S, q)$\, the natural isomorphism $\poly(\yon^S, q) \iso q(S)$ follows directly from the Yoneda lemma (\cref{lemma.yoneda}) with $F = q$.
\end{solution}
\end{exercise}

Before we present our alternative characterization of polynomial morphisms, recall that every polynomial $p \coloneqq \sum_{i \in p(\1)} \yon^{p[i]}$ is uniquely associated to a dependent set, $(p[i])_{i \in p(\1)}$, which we call its \emph{arena}, as in \eqref{eqn.arena}.
Alternatively, we could write such a dependent set as a functor $p[-] \colon p(\1) \to \smset$, where we view the set $p(\1)$ as a discrete category.
Below, we make use of this functor notation to express the arenas of polynomials.

\begin{proposition}\label{prop.poly_maps_prod_sum}
Let $p\coloneqq\sum_{i\in p(\1)}\yon^{p[i]}$ and $q\coloneqq\sum_{j\in q(\1)}\yon^{q[j]}$ be polynomials.
Then we have an isomorphism
\begin{equation}\label{eqn.main_formula}
\poly(p,q)\cong\prod_{i\in p(\1)}\sum_{j\in q(\1)}{p[i]}^{q[j]}.
\end{equation}
% **Naturality???
In other words, a morphism $p\to q$ can be identified with a pair $(f_1,f^\sharp)$
\begin{equation}\label{eqn.colax_poly_map}
\begin{tikzcd}[column sep=small]
	p(\1)\ar[dr, "p{[-]}"']\ar[rr, "f_1"]&~&
	q(\1)\ar[dl, "q{[-]}"]\\&
	\smset\ar[u, phantom, near end, "\overset{f^\sharp}{\Leftarrow}"]
\end{tikzcd}
\end{equation}
where $f_1 \colon p(\1) \to q(\1)$ is a function (or functor between discrete categories) and $f^\sharp \colon q[f_1(-)] \to p[-]$ is a natural transformation: for each $i\in p(\1)$ with $j\coloneqq f_1(i)$, there is a function $f^\sharp_i\colon q[j]\to p[i]$. % **Maybe write an exercise about viewing dependent functions as natural transformations?
\end{proposition}
\begin{proof}
By the universal property of the coproduct, we have an isomorphism
\[
    \poly\left(\sum_{i \in p(\1)}\yon^{p[i]}, q\right) \iso \prod_{i \in p(\1)} \poly(\yon^{p[i]}, q),
\]
so applying \cref{exc.poly_morph_yoneda} (i.e.\ the Yoneda lemma) and unraveling the definitions of $p$ and $q$ yields \eqref{eqn.main_formula}.

The expression on the right hand side of \eqref{eqn.main_formula} is the set of dependent functions $f \colon (i \in p(\1)) \to \sum_{j \in q(\1)} p[i]^{q[j]}$, each of which is uniquely determined by its components: $\pi_1 \circ f$, which sends $i \in p(\1)$ to $\pi_1(f(i)) \in q(\1)$, and $\pi_2 \circ f$, which sends $i \in p(\1)$ with $j \coloneqq \pi_1(f(i))$ to an element of $p[i]^{q[j]}$, i.e.\ a function $q[j] \to p[i]$.
These can be identified respectively with a (non-dependent) function $f_1 \coloneqq \pi_1 \circ f$ from $p(\1) \to q(\1)$ and a natural transformation $f^\sharp \colon q[f_1(-)] \to p[-]$.
\end{proof}

We have now greatly simplified our characterization of polynomial morphisms $f \colon p \to q$: rather than infinitely many functions satisfying infinitely many naturality conditions, they can be specified simply as a function $f_1 \colon p(\1) \to q(\1)$ and, for each $i \in p(\1)$, a function $f^\sharp_i \colon q[f_1(i)] \to p[i]$, without any additional restrictions.

Here is where we begin to see the advantages of viewing polynomials as arenas.
As a reminder, from the arena perspective, we call the elements of $p(\1)$ the \emph{positions} of $p$, and for each position $i \in p(\1)$, we call the elements of $p[i]$ the \emph{directions} of $p$ at $i$.
We can see that our characterization of a polynomial morphism can be written entirely in the language of positions and directions: when polynomials $p$ and $q$ are viewed as arenas, a morphism $f \colon p \to q$ consists of a ``forwards'' \emph{on-positions} function $f_1$ from the positions of $p$ to the positions of $q$, along with, for every position $i$ of $p$, a ``backwards'' \emph{on-directions} function $f^\sharp_i$ from the directions of $q$ at $f_1(i)$ to the directions of $p$ at $i$.

When we wish to emphasize the arena perspective, we will call the data of $(f_1, f^\sharp)$ a \emph{morphism of arenas} or \emph{arena morphism} between $p$ and $q$; but since \cref{prop.poly_maps_prod_sum} tells us that polynomial morphisms and arena morphisms carry the same data, we may use these terms interchangeably.

Here is how you would implement such a morphism in Agda:
\begin{agda}
record ArenaMorphism (p : Arena) (q : Arena) : Set where
   field
     onPos : (pos p) -> (pos q)
     onDir : (i : pos p) -> dir q (onPos i) -> dir p i
\end{agda}

This forwards on-positions/backwards on-directions formulation may still seem a little complicated, so here is some decision-making intuition.
Recall from \cref{sec.poly.intro.dec} that we may view each position of an arena as a decision and the directions at that position as the options available for that decision.
The morphisms $f\colon p\to q$ are then the ways to \emph{delegate} $p$'s decisions to $q$. Every one of $p$'s decisions, say $i\in p(\1)$, is passed forward to a decision $j\in q(\1)$ for $q$ to make, and every choice $d\in q[j]$ that $q$ could make among its options is passed back as some choice $c\in p[i]$ among $p$'s options.

%In fact, this formula will be so important to us that we will often blur the
%difference between a dependent lens $\lens{f^{\sharp}}{f} : \lens{p[i]}{i \in
%  p(\1)} \fromto \lens{q[j]}{j \in q(\1)}$ with the natural transformation $p \to
%q$ it corresponds to.
%\end{remark}

\begin{example}\label{ex.practice_with_poly_morphisms}
Let $p\coloneqq \yon^\3+\2\yon$ and $q\coloneqq\yon^\4+\yon^\2+\2$. Here they are, depicted as corolla forests:
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, blue!50!black, "$p$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
      child {};
    \node[right=.5 of 2,"\tiny 3" below] (3) {$\bullet$}
      child {};
  \end{tikzpicture}
  };
%
	\node (p2) [draw, red!75!black, right=2 of p1, "$q$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {}
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
      child {}
      child {};
    \node[right=.5 of 2,"\tiny 3" below] (3) {$\bullet$}
    ;
    \node[right=.5 of 3,"\tiny 4" below] (4) {$\bullet$}
    ;
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
To give a map of polynomials $p\to q$, one sends each position $i\in p(\1)$ of $p$ to a position $j\in q(\1)$ of $q$, then sends each direction in $q[j]$ back to one in $p[i]$.

How many ways are there to do this? Before answering this, let's just pick one.
\[
\begin{tikzpicture}
	\node (p1) {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node[blue!50!black, "\tiny 1" below] (1) {$\bullet$} 
      child[blue!50!black] {coordinate (11)}
      child[blue!50!black] {coordinate (12)}
      child[blue!50!black] {coordinate (13)};
    \node[right=1.5 of 1, red!75!black, "\tiny 1" below] (2) {$\bullet$} 
      child[red!75!black] {coordinate (21)}
      child[red!75!black] {coordinate (22)}
      child[red!75!black] {coordinate (23)}
      child[red!75!black] {coordinate (24)};
    \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
    \begin{scope}[densely dotted, bend right, decoration={markings, mark=at position 0.75 with \arrow{stealth}}]
      \draw[postaction={decorate}] (21) to (13);
      \draw[postaction={decorate}] (22) to (11);
      \draw[postaction={decorate}] (23) to (13);
      \draw[postaction={decorate}] (24) to (13);
    \end{scope}
  \end{tikzpicture}	
	};	
%
	\node (p2) [right=1 of p1] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node[blue!50!black, "\tiny 2" below] (1) {$\bullet$} 
      child[blue!50!black] {coordinate (11)};
    \node[right=of 1, red!75!black, "\tiny 1" below] (2) {$\bullet$} 
      child[red!75!black] {coordinate (21)}
      child[red!75!black] {coordinate (22)}
      child[red!75!black] {coordinate (23)}
      child[red!75!black] {coordinate (24)};
    \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
    \begin{scope}[densely dotted, bend right, decoration={markings, mark=at position 0.75 with \arrow{stealth}}]
      \draw[postaction={decorate}] (21) to (11);
      \draw[postaction={decorate}] (22) to (11);
      \draw[postaction={decorate}] (23) to (11);
      \draw[postaction={decorate}] (24) to (11);
    \end{scope}
  \end{tikzpicture}	
	};	
%
	\node (p3) [below right=-1.05cm and 1 of p2] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node[blue!50!black, "\tiny 3" below] (1) {$\bullet$} 
      child[blue!50!black] {};
    \node[right=of 1, red!75!black, "\tiny 4" below] (2) {$\bullet$} 
		;
    \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
  \end{tikzpicture}	
	};	
\end{tikzpicture}
\]
This represents one morphism $p\to q$.

So how many different morphisms are there from $p$ to $q$? The first position of $p$ can be sent to any position of $q$: 1, 2, 3, or 4. Sending it to $1$ requires choosing how each of the four options $(q[1]=\4)$ are to be assigned one of $p[1]=\3$ options; there are $3^4$ ways to do this. Similarly, we can calculate all the ways to handle the first position of $p$: there are $3^4+3^2+3^0+3^0=92$. 

The second position of $p$ can also be sent to 1, 2, 3, or 4, before sending back directions; there are $1^4+1^2+1^0+1^0=4$ ways to do this. 
Similarly there are four ways to send the third position of $p$ to a position of $q$ and send back directions.

In total, there are $92 \cdot 4 \cdot 4=1472$ morphisms $p\to q$.

Unsurprisingly, this is exactly what is given by \eqref{eqn.main_formula}:
\begin{align*}
    |\poly(p, q)| &= \prod_{i \in p(\1)} |q(p[i])| \\
    &= \prod_{i \in p(\1)} |p[i]|^4 + |p[i]|^2 + 2 \\
    &= (3^4 + 3^2 + 2)(1^4 + 1^2 + 2)^2 \\
    &= 92 \cdot 4^2 = 1472.
\end{align*}
\end{example}

\begin{exercise}\label{exc.practice_poly_maps}
\begin{enumerate}
	\item Draw the corolla forests associated to $p\coloneqq\yon^\3+\yon+\1$, $q\coloneqq \yon^\2+\yon^\2+\2$, and $r\coloneqq\yon^\3$.
	\item Give an example of a morphism $p\to q$ and draw it as we did in \cref{ex.practice_with_poly_morphisms}.
	\item Explain your morphism intuitively as a delegation of decisions.
	\item Explain in those terms why there can't be any morphisms $p\to r$.
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item Here are the corolla forests associated to $p\coloneqq\yon^\3+\yon+\1$, $q\coloneqq \yon^\2+\yon^\2+\2$, and $r\coloneqq\yon^\3$ (with each root labeled for convenience).
    \[
    \begin{tikzpicture}[rounded corners]
    	\node (p) [draw, blue!50!black, "$p$" above] {
    	\begin{tikzpicture}[trees, sibling distance=2.5mm]
            \node["\tiny 1" below] (1) {$\bullet$} 
              child {}
              child {}
              child {};
            \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
              child {};
            \node[right=.5 of 2,"\tiny 3" below] (3) {$\bullet$};
        \end{tikzpicture}
        };
    %
    	\node (q) [draw, red!75!black, right=2 of p, "$q$" above] {
    	\begin{tikzpicture}[trees, sibling distance=2.5mm]
            \node["\tiny 1" below] (1) {$\bullet$} 
              child {}
              child {};
            \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
              child {}
              child {};
            \node[right=.5 of 2,"\tiny 3" below] (3) {$\bullet$};
            \node[right=.5 of 3,"\tiny 4" below] (4) {$\bullet$};
        \end{tikzpicture}
        };
    %
    	\node (r) [draw, green!50!black, right=2 of q, "$r$" above] {
    	\begin{tikzpicture}[trees, sibling distance=2.5mm]
        \node["\tiny 1" below] (1) {$\bullet$} 
          child {}
          child {}
          child {};
        \end{tikzpicture}
      };
    \end{tikzpicture}
    \]
	\item Here is one possible morphism $p \to q$ (you may have drawn others).
	\[
    \begin{tikzpicture}
    	\node (p1) {
        	\begin{tikzpicture}[trees, sibling distance=2.5mm]
                \node[blue!50!black, "\tiny 1" below] (1) {$\bullet$} 
                  child[blue!50!black] {coordinate (11)}
                  child[blue!50!black] {coordinate (12)}
                  child[blue!50!black] {coordinate (13)};
                \node[right=1.5 of 1, red!75!black, "\tiny 2" below] (2) {$\bullet$}
                  child[red!75!black] {coordinate (21)}
                  child[red!75!black] {coordinate (22)};
                \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
                \begin{scope}[densely dotted, bend right, decoration={markings, mark=at position 0.75 with \arrow{stealth}}]
                  \draw[postaction={decorate}] (21) to (13);
                  \draw[postaction={decorate}] (22) to (11);
                \end{scope}
            \end{tikzpicture}	
    	};	
        %
    	\node (p2) [right=1 of p1] {
        	\begin{tikzpicture}[trees, sibling distance=2.5mm]
                \node[blue!50!black, "\tiny 2" below] (1) {$\bullet$} 
                  child[blue!50!black] {coordinate (11)};
                \node[right=of 1, red!75!black, "\tiny 4" below] (2) {$\bullet$};
                \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
            \end{tikzpicture}	
    	};	
        %
    	\node (p3) [below right=-1.05cm and 1 of p2] {
        	\begin{tikzpicture}[trees, sibling distance=2.5mm]
                \node[blue!50!black, "\tiny 3" below] (1) {$\bullet$};
                \node[right=of 1, red!75!black, "\tiny 3" below] (2) {$\bullet$};
                \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
            \end{tikzpicture}	
    	};	
    \end{tikzpicture}
    \]
    \item As depicted, our morphism delegates the first decision of $p$ to the second decision of $q$, whose first and second options are passed back to the third and first options, respectively, of the first decision of $p$.
    Then the second decision of $p$ is delegated to the fourth decision of $q$, which has no options; effectively, the second decision of $p$ has been canceled.
    Finally, the third decision of $p$ is delegated to the third decision of $q$, neither of which has any options.
    \item There cannot be a morphism $p \to r$ for the following reason: if we delegate the third decision of $p$, which has no options, to the sole decision of $r$, which has $3$ options, then there is no way to pass a choice of one of the $3$ options back to any of the options associated with the third decision of $p$, as there are no such options.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
For any polynomial $p$ and set $A$, e.g.\ $A=\2$, the Yoneda lemma gives an isomorphism $p(A)\cong \poly(\yon^A,p)$.
\begin{enumerate}
	\item Choose a polynomial $p$ and draw both $\yon^\2$ and $p$ as corolla forests.
	\item Count all the maps $\yon^2\to p$. How many are there?
	\item Is the previous answer equal to $p(\2)$?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item We let $p \coloneqq \yon^3 + 1$ (you could have selected others) and draw both $p$ and $\yon^\2$ as corolla forests, labeling each root for convenience.
    \[
    \begin{tikzpicture}[rounded corners]
    	\node (y2) [draw, blue!50!black, "$\yon^\2$" above] {
    	\begin{tikzpicture}[trees, sibling distance=2.5mm]
            \node["\tiny 1" below] (1) {$\bullet$} 
              child {}
              child {};
        \end{tikzpicture}
        };
    %
    	\node (p) [draw, red!75!black, right=2 of y2, "$p$" above] {
    	\begin{tikzpicture}[trees, sibling distance=2.5mm]
            \node["\tiny 1" below] (1) {$\bullet$} 
              child {}
              child {}
              child {};
            \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$};
        \end{tikzpicture}
        };
    \end{tikzpicture}
    \]
    \item We count all the maps from $\yon^\2$ to $p$.
    The unique position of $\yon^\2$ can be sent to either position of $p$.
    If it is sent to the first position of $p$, then there are $2$ directions of $\yon^\2$ for each of the $3$ directions at the first position of $p$ to be sent to, for a total of $2^3 = 8$ maps.
    Otherwise, the unique position of $\yon^\2$ is sent to the second position of $p$---at which there are no directions, so there is exactly $1$ way to do this.
    So we have $8 + 1 = 9$ maps from $\yon^\2$ to $p$.
    \item Yes, the previous answer is equal to $p(\2) = 2^3 + 1 = 9$.
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}
For each of the following polynomials $p,q$, compute the number of morphisms $p\to q$.
\begin{enumerate}
	\item $p=\yon^\3$,\quad $q=\yon^\4$.
	\item $p=\yon^\3+\1$,\quad $q=\yon^\4$.
	\item $p=\yon^\3+\1$,\quad $q=\yon^\4+\1$.
	\item $p=\4\yon^\3+\3\yon^\2+\yon$,\quad $q=\yon$.
	\item $p=\4\yon^\3$,\quad $q=\3\yon$.
\qedhere
\end{enumerate}
\begin{solution}
Our goal is to compute the number of natural transformations $p\to q$ for each of the following polynomials $p,q$.
By \eqref{eqn.main_formula}, we always have
\[
    |\poly(p, q)| = \prod_{i \in p(\1)} |q(p[i])|.
\]
\begin{enumerate}
	\item If $p=\yon^\3$ and $q=\yon^\4$, then
	\[
	    |\poly(p, q)| = \prod_{i \in \1} |p[i]|^4 = 3^4 = 81.
	\]
	\item If $p=\yon^\3+\1$ and $q=\yon^\4$, then
	\[
	    |\poly(p, q)| = \prod_{i \in \2} |p[i]|^4 = 3^4 \cdot 0^4 = 0.
	\]
	\item If $p=\yon^\3+\1$ and $q=\yon^\4+\1$, then
	\[
	    |\poly(p, q)| = \prod_{i \in \2} |p[i]|^4 + 1 = (3^4 + 1)(0^4 + 1) = 82.
	\]
	\item If $p=\4\yon^\3+\3\yon^2\+\yon$ and $q=\yon$, then
	\[
	    |\poly(p, q)| = \prod_{i \in \8} |p[i]| = 3^4 \cdot 2^3 \cdot 1 = 648.
	\]
	\item If $p=\4\yon^\3$ and $q=\3\yon$, then
	\[
	    |\poly(p, q)| = \prod_{i \in \4} 3|p[i]| = (3 \cdot 3)^4 = 6561.
	\]
\qedhere
\end{enumerate}
\end{solution}
\end{exercise}

\begin{exercise}\label{exc.practice_sum_prod}
\begin{enumerate}
\item Is it true that the following are isomorphic?
\begin{equation}\label{eqn.poly_p_q}
  \poly(p,q)
  \cong^?
  \prod_{i\in p(\1)}\sum_{j\in q(\1)}\prod_{d\in q[j]}\sum_{c\in p[i]}\1
\end{equation}
\item Is it true that the following are isomorphic?
	\begin{equation}\label{eqn.useful_misc472}
	\poly(p,q)\cong^?\sum_{f_1\colon p(\1)\to q(\1)}\prod_{j\in q(\1)}\smset\Bigg(q[j],\prod_{\substack{i \in p(\1), \\ f_1(i) = j}}p[i]\Bigg)
	\end{equation}
\item If the answer to \#2 is ``yes,'' then describe in the language of decision-making how any element of the right-hand side gives a way of delegating decisions from $p$ to $q$. If ``no,'' give intuition for why the two sets are not isomorphic.
\qedhere
\end{enumerate}
\begin{solution}
\begin{longenum}
\item We will show that, yes, the following isomorphism does hold:
\[
  \poly(p,q)
  \cong
  \prod_{i\in p(\1)}\sum_{j\in q(\1)}\prod_{d\in q[j]}\sum_{c\in p[i]}\1.
\]
By \eqref{eqn.main_formula}, it suffices to show that for all $i \in p(\1)$ and $j \in q(\1)$, we have
\[
    p[i]^{q[j]} \iso \prod_{d \in q[j]} \sum_{c \in p[i]} \1.
\]
Indeed, by \cref{prop.push_prod_sum_set_indep} and \cref{exc.on_sums_prods_sets}, we have
\begin{align*}
    \prod_{d \in q[j]} \sum_{c \in p[i]} \1 &\iso \sum_{\bar{c} \colon q[j] \to p[i]} \, \prod_{d \in q[j]} \1 \tag{\cref{prop.push_prod_sum_set_indep}} \\
    &\iso \sum_{\bar{c} \colon q[j] \to p[i]} \1 \tag{\cref{exc.on_sums_prods_sets} \cref{exc.on_sums_prods_sets.prod}} \\
    &\iso \smset(q[j], p[i]) \tag{\cref{exc.on_sums_prods_sets}, \cref{exc.on_sums_prods_sets.sum}} \\
    &\iso p[i]^{q[j]}.
\end{align*}

\item We will show that, yes, the following isomorphism does hold:
\[
	\poly(p,q)\cong\sum_{f_1\colon p(\1)\to q(\1)}\prod_{j\in q(\1)}\smset\Bigg(q[j],\prod_{\substack{i \in p(\1), \\ f_1(i) = j}}p[i]\Bigg).
\]
By \eqref{eqn.main_formula} and \cref{prop.push_prod_sum_set_indep}, we have
\begin{align*}
    \poly(p, q) &\iso \prod_{i \in p(\1)} \sum_{j \in q(\1)} p[i]^{q[j]} \tag*{\eqref{eqn.main_formula}} \\
    &\iso \sum_{f_1 \colon p(\1) \to q(\1)} \prod_{i \in p(\1)} p[i]^{q[f_1(i)]} \tag{\cref{prop.push_prod_sum_set_indep}} \\
    &\iso \sum_{f_1 \colon p(\1) \to q(\1)} \prod_{j \in q(\1)} \prod_{\substack{i \in p(\1) \\ f_1(i) = j}} p[i]^{q[j]} \tag{$\ast$} \\
    &\iso \sum_{f_1\colon p(\1)\to q(\1)}\prod_{j\in q(\1)}\smset\Bigg(q[j],\prod_{\substack{i \in p(\1), \\ f_1(i) = j}}p[i]\Bigg) \tag{Universal property of products}
\end{align*}
where ($\ast$) follows from the fact that for any function $f_1 \colon p(\1) \to q(\1)$, the set $p(\1)$ can be written as the disjoint union of sets of the form $\{i \in p(1) \ | \ f_1(i) = j\}$ for each $j \in q(\1)$.

\item To explain how the set
\[
	D_{p,q} \coloneqq \sum_{f_1\colon p(\1)\to q(\1)}\prod_{j\in q(\1)}\smset\Bigg(q[j],\prod_{\substack{i \in p(\1), \\ f_1(i) = j}}p[i]\Bigg)
\]
specifies a way of delegating decisions from $p$ to $q$, we first give the instructions for choosing an element of $D_{p,q}$ as a nested list:
\begin{quote}
To choose an element of $D_{p,q}$:
\begin{longenum}
    \item choose a function $f_1 \colon p(\1) \to q(\1)$;
    \item for each element $j \in q(\1)$:
    \begin{longenum}
        \item for each element of $q[j]$:
        \begin{longenum}
            \item for each element $i \in p(\1)$ satisfying $f_1(i) = j$:
            \begin{longenum}
                \item choose an element of $p[i]$.
            \end{longenum}
        \end{longenum}
    \end{longenum}
\end{longenum}
\end{quote}
So $f_1$ delegates each of $p$'s decisions to one of $q$'s decisions.
Then for every option of every decision $j$ of $q$, we choose an option of each of $p$'s decisions that has been delegated to $j$ by $f_1$.
\end{longenum}
\end{solution}
\end{exercise}

\begin{example}[Derivatives]\label{ex.derivatives}
We won't have much opportunity to use the following, but it may be interesting. The \emph{derivative} of a polynomial $p$, denoted $\dot{p}$, is defined as follows:
\[
\dot{p}\coloneqq\sum_{i\in p(\1)}\sum_{d\in p[i]}\yon^{p[i]-\{d\}}.
\]
For example, if $p\coloneq\yon^{\{U,V,W\}}+\{A,B\}\yon^{\{X\}}$ then 
\[\dot{p}=\{U\}\yon^{\{V,W\}}+\{V\}\yon^{\{U,W\}}+\{W\}\yon^{\{U,V\}}+\{(A,X),(B,X)\}\yon^\0.\]
Up to isomorphism $p\cong\yon^\3+\2\yon$ and $\dot{p}\cong\3\yon^\2+\2$.
Unsurprisingly, this coincides with the familiar notion of derivatives of polynomials from calculus.

Thus we get a canonical map $\dot{p}\yon\to p$, because we have an isomorphism
\[
\dot{p}\yon\cong\sum_{i\in p(\1)}\sum_{d\in p[i]}\yon^{p[i]}.
\]
This natural transformation comes up in computer science in the context of ``plugging in to one-hole contexts''; we will not explore that here, but see \cite{mcbride} and \cite{abbot2003derivatives} for more info.%The Derivative of a Regular Type is its Type of One-Hole Contexts. http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.22.8611&rep=rep1&type=pdf.
%https://www.cs.nott.ac.uk/~psztxa/publ/tlca03.pdf

A morphism $f\colon p\to \dot{q}$ can be interpreted as something like an arena morphism from $p$ to $q$, except that each position of $p$ explicitly selects a direction of $q$ to remain unassigned. More precisely, for each $i\in p(\1)$ we have $f_1(i)=(j,d)\in \sum_{j\in q(\1)}q[j]$, i.e.\ a choice of position $j$ of $q$, as usual, together with a chosen direction $d\in q[j]$. Then every direction of $q$ at $j$ \emph{other than $d$} is sent back to an direction of $p$ at $i$.
\end{example}

\begin{exercise}
The derivative is not very well-behaved category-theoretically. However, it is intriguing.
\begin{enumerate}
	\item What is the relationship between $\dot{p}(\1)$ and the total number of directions over all the positions of $p$?
	\item Explain the canonical map $\dot{p}\yon\to p$ from \cref{ex.derivatives} in more detail.
	\item Is there always a canonical map $p\to \dot{p}$?
	\item Is there always a canonical map $\dot{p}\to p$?
	\item If given a map $p\to q$, does one get a map $\dot{p}\to\dot{q}$?
% 	\item Read the formula for $\otimes$ and $\ihom{-,-}$ in \eqref{eqn.dirichlet_def} and \eqref{eqn.dir_hom} and find a formula for a map $p\otimes\ihom{p,\yon}\to \dot{p}$ that works for any $p\in\poly$.
	\item When talking to someone who explains maps $p\to\dot{q}$ in terms of ``unassigned directions,'' how might you describe what is modeled by a map $p\yon\to q$?
	\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
    \item We can evaluate $\dot{p}(\1)$ directly from the definition of $\dot{p}$ to obtain
    \[
        \dot{p}(\1) = \sum_{i \in p(\1)} \sum_{d \in p[i]} \1^{p[i]-\{d\}} \iso \sum_{i \in p(\1)} p[i],
    \]
    which is precisely the set of directions over all positions of $p$.
    So there are as many elements of $\dot{p}(\1)$ as there are directions over all positions of $p$.
    
	\item Our goal is to characterize the canonical map $\dot{p}\yon\to p$.
	If we unravel the definitions, this is a map
	\[
	    \sum_{i \in p(\1)} \sum_{d \in p[i]} \yon^{p[i]} \to \sum_{i \in p(\1)} \yon^{p[i]}.
	\]
	We observe that there is always such a map sending every position $(i, d) \in \sum_{i \in p(\1)} p[i]$ of $\dot{p}\yon$ to its first projection $i \in p(\1)$ and is the identity on directions.
	This is the canonical map.

	\item There cannot always be a canonical map $p\to \dot{p}$, for if $p \coloneqq \1$, then $\dot{p} \coloneqq \0$, and there is no map $\1 \to \0$.
	
	\item We show that there cannot always be a canonical map $\dot{p}\to p$.
	Take $p \coloneqq \yon$, so $\dot{p} \coloneqq \1$.
	A map $\1 \to \yon$ must have an on-directions function $\1 \to \0$, but such a function does not exist.
	
	\item We show that even when there is a map $p \to q$, there is not necessarily a map $\dot{p}\to\dot{q}$.
	Take $p \coloneqq \yon$ and $q \coloneqq \1$.
	Then there is a map $p \to q$ that sends the unique position of $\yon$ to the unique position of $\1$ and is the empty function on directions.
	But $\dot{p} = \1$ and $\dot{q} = \0$, and there is no map $\1 \to \0$.
	
% 	\item Read the formula for $\otimes$ and $\ihom{-,-}$ in \eqref{eqn.dirichlet_def} and \eqref{eqn.dir_hom} and find a formula for a map $p\otimes\ihom{p,\yon}\to p'$ that works for any $p\in\poly$.
	
	\item We wish to describe a map $p\yon \to q$ in terms of ``unassigned to directions.''
	Observe that as an arena, $p\yon$ has the same positions as $p$ but has one more direction than $p$ does at each position.
	We denote this extra direction at each position $i \in p(\1)$ of $p\yon$ by $\ast_i$.
	So a map $f \colon p\yon\to q$ sends each position $i$ of $p$ to a position $j$ of $q$, but every direction of $q$ at $j$ could either be sent back to a direction of $p$ at $i$ or the extra direction $\ast_i$.
	We can say that an arena morphism $f \colon p\yon \to q$ is like an arena morphism $p \to q$, except that any of the directions of $q$ may remain un assigned---i.e.\ we may have partial on-directions functions.
\end{enumerate}
\end{solution}
\end{exercise}


%\paragraph{Back to maps of polynomials}
%After that interlude, you are hopefully more comfortable with our main formula
%\cref{eqn.main_formula} describing the set of morphisms between two arbitrary
%polynomial functors as dependent lenses. Let's practice.

% \begin{example}[Constants are sent to constants]\label{ex.const_to_const}
% Any natural transformation $p\to q$ must send constants in $p$ to constants in $q$. So if $p$ has constant terms and $q$ doesn't, e.g.\ if $p=\yon^\2+\1$ and $q=\yon^\3$, then there are no maps $p\to q$. 

% **Finish**
% \end{example}


\paragraph{Translating between natural transformations and arena morphisms.}
We now know that we can specify a morphism of polynomials $p \to q$ in two ways: in the language of functors, by specifying a natural transformation from $p$ to $q$; or in the language of arenas, by specifying a function $f_1 \colon p(\1) \to q(\1)$ and, for each $i \in p(\1)$, a function $f^\sharp_i \colon q[f_1(i)] \to p[i]$.
But what is the relationship between these two formulations?
If you told me an arena morphism, and I told you a natural transformation between polynomial functors, how could we tell if we were talking about the same morphism or not?
We want to be able to translate between these two languages.

Our Rosetta Stone turns out to be the proof of the Yoneda lemma.
The lemma itself forms the crux of the proof of \cref{prop.poly_maps_prod_sum}, that these two formulations of polynomial morphisms are equivalent; so unraveling this proof reveals the translation we seek.

\begin{proposition} \label{prop.morph_arena_to_func}
Let $p$ and $q$ be polynomial functors, and let $(f_1, f^\sharp)$ be a morphism between their associated arenas.
Then the isomorphism in \eqref{eqn.main_formula} sends $(f_1, f^\sharp)$ to the natural transformation $f \colon p \to q$ whose $X$-component $f_X \colon p(X) \to q(X)$ for each $X \in \smset$ sends every
\[
    (i, g) \in \sum_{i \in p(\1)} X^{p[i]} \iso p(X),
\]
with $i \in p(\1)$ and $g \colon p[i] \to X$, to
\[
    (f_1(i), f^\sharp_i \then g) \in \sum_{j \in q(\1)} X^{q[j]} \iso q(X).
\]
\end{proposition}
\begin{proof}
As an element of the product over $I$ on the right hand side of \eqref{eqn.main_formula}, the pair $(f_1, f^\sharp)$ can equivalently be thought of as a set of pairs $\{(f_1(i), f^\sharp_i)\}_{i \in I}$.
Fixing $i \in I$, the pair $(f_1(i), f^\sharp_i)$ is an element of
\[
    \sum_{j \in q(\1)} p[i]^{q[j]} = q(p[i])
\]
(so $f_1(i) \in q(\1)$ and $f^\sharp_i \colon q[f_1(i)] \to p[i]$).
By the Yoneda lemma (\cref{lemma.yoneda}), we have an isomorphism $q(p[i]) \iso \poly(\yon^{p[i]}, q)$, and by the proof of the Yoneda lemma, this isomorphism sends $(f_1(i), f^\sharp_i)$ to the natural transformation $f^i \colon \yon^{p[i]} \to q$ whose $X$-component is the function $f^i_X \colon X^{p[i]} \to q(X)$ given by sending $g \colon p[i] \to X$ to
\[
    q(g)(f_1(i), f^\sharp_i) = \left(\sum_{j \in q(\1)} g^{q[j]}\right)(f_1(i), f^\sharp_i) = \left(f_1(i), g^{q[f_1(i)]}(f^\sharp_i)\right) = (f_1(i), f^\sharp_i \then g).
\]
Taken together, the collection of natural transformations $\{f^i\}_{i \in I}$ is an element of $\prod_{i \in I} \poly(\yon^{p[i]}, q)$.
Applying the universal property of coproducts, as in the proof of \cref{prop.poly_maps_prod_sum}, we find that $\{f^i\}_{i \in I}$ corresponds to the natural transformation $f \colon p \to q$ we desire.
\end{proof}

\begin{example}
Let us return to the polynomials $p \coloneqq \yon^\3 + \2\yon$ and $q \coloneqq \yon^\4 + \yon^\2 + \2$ from \cref{ex.practice_with_poly_morphisms} and the morphism $f \colon p \to q$ depicted below:
\[
\begin{tikzpicture}
	\node (p1) {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node[blue!50!black, "\tiny 1" below] (1) {$\bullet$} 
      child[blue!50!black] {coordinate (11)}
      child[blue!50!black] {coordinate (12)}
      child[blue!50!black] {coordinate (13)};
    \node[right=1.5 of 1, red!75!black, "\tiny 1" below] (2) {$\bullet$} 
      child[red!75!black] {coordinate (21)}
      child[red!75!black] {coordinate (22)}
      child[red!75!black] {coordinate (23)}
      child[red!75!black] {coordinate (24)};
    \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
    \begin{scope}[densely dotted, bend right, decoration={markings, mark=at position 0.75 with \arrow{stealth}}]
      \draw[postaction={decorate}] (21) to (13);
      \draw[postaction={decorate}] (22) to (11);
      \draw[postaction={decorate}] (23) to (13);
      \draw[postaction={decorate}] (24) to (13);
    \end{scope}
  \end{tikzpicture}	
	};	
%
	\node (p2) [right=1 of p1] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node[blue!50!black, "\tiny 2" below] (1) {$\bullet$} 
      child[blue!50!black] {coordinate (11)};
    \node[right=of 1, red!75!black, "\tiny 1" below] (2) {$\bullet$} 
      child[red!75!black] {coordinate (21)}
      child[red!75!black] {coordinate (22)}
      child[red!75!black] {coordinate (23)}
      child[red!75!black] {coordinate (24)};
    \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
    \begin{scope}[densely dotted, bend right, decoration={markings, mark=at position 0.75 with \arrow{stealth}}]
      \draw[postaction={decorate}] (21) to (11);
      \draw[postaction={decorate}] (22) to (11);
      \draw[postaction={decorate}] (23) to (11);
      \draw[postaction={decorate}] (24) to (11);
    \end{scope}
  \end{tikzpicture}	
	};	
%
	\node (p3) [below right=-1.05cm and 1 of p2] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node[blue!50!black, "\tiny 3" below] (1) {$\bullet$} 
      child[blue!50!black] {};
    \node[right=of 1, red!75!black, "\tiny 4" below] (2) {$\bullet$} 
		;
    \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
  \end{tikzpicture}	
	};	
\end{tikzpicture}
\]
Fix a set $X \coloneqq \{a,b,c,d,e\}$.
When viewed as a natural transformation, the morphism $f$ has as its $X$-component a function $f_X \colon p(X) \to q(X)$.
In other words, for any element of $p(X)$, the morphism $f$ should be able to give us an element of $q(X)$.

What does an element of $p(X)$ look like?
Well, to specify such an element, we would need to choose a position $i$ of $p$ and a function $p[i] \to X$.
We can depict this by selecting one of the corollas in the forest of $p$ and labeling each leaf of that corolla with an element of $X$.
For example, here we depict an element $(1, g)$ of $p(X)$, where $g \colon p[1] \to X$ is given by $1 \mapsto c, 2 \mapsto e,$ and $3 \mapsto a$:
\[
\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node[blue!50!black, "\tiny 1" below] (1) {$\bullet$} 
      child[blue!50!black] {node {$c$}}
      child[blue!50!black] {node {$e$}}
      child[blue!50!black] {node {$a$}};
\end{tikzpicture}
\]
Similarly, an element of $q(X)$ can be drawn as a corolla in the forest of $q$, with each leaf labeled by an element of $X$.
So what element of $q(X)$ is $f_X(1, g)$?

\cref{prop.morph_arena_to_func} tells us that $f_X(1, g)$ can be read off of the forest depiction of $f$ at position $1$:
\[
\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node[blue!50!black, "\tiny 1" below] (1) {$\bullet$} 
      child[blue!50!black] {coordinate (11)}
      child[blue!50!black] {coordinate (12)}
      child[blue!50!black] {coordinate (13)};
    \node[right=1.5 of 1, red!75!black, "\tiny 1" below] (2) {$\bullet$} 
      child[red!75!black] {coordinate (21)}
      child[red!75!black] {coordinate (22)}
      child[red!75!black] {coordinate (23)}
      child[red!75!black] {coordinate (24)};
    \draw[|->, shorten <= 3pt, shorten >= 3pt] (1) -- (2);
    \begin{scope}[densely dotted, bend right, decoration={markings, mark=at position 0.75 with \arrow{stealth}}]
      \draw[postaction={decorate}] (21) to (13);
      \draw[postaction={decorate}] (22) to (11);
      \draw[postaction={decorate}] (23) to (13);
      \draw[postaction={decorate}] (24) to (13);
    \end{scope}
\end{tikzpicture}	
\]
To draw $f_X(1, g)$, we first draw the corolla in the forest of $q$ corresponding to $f_1(1)$: the corolla on the right hand side above.
Then we label each leaf of that corolla by following the arrow from that leaf (as given by $f^\sharp_i$) to a leaf of $p$ at $1$, and use the label there that is given by $(1, g)$.
So $f_X(1, g)$ looks like
\[
\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node[red!75!black, "\tiny 1" below] (1) {$\bullet$} 
      child[red!75!black] {node {$a$}}
      child[red!75!black] {node {$c$}}
      child[red!75!black] {node {$a$}}
      child[red!75!black] {node {$a$}};
\end{tikzpicture}
\]
\end{example}

% ** Add an exercise—labeled trees?

\cref{prop.morph_arena_to_func} lets us translate from arena morphisms to natural transformations.
The following corollary tells us how to go in the other direction.
In particular, it justifies the notation $f_1$ for the on-positions function of $f$.

\begin{corollary} \label{prop.morph_func_to_arena}
Let $p$ and $q$ be polynomial functors, and let $f \colon p \to q$ be a natural transformation between them.
Then the isomorphism in \eqref{eqn.main_formula} sends $f$ to the arena morphism $(f_1, f^\sharp)$ such that $f_1 \colon p(\1) \to q(\1)$ is the $\1$-component of $f$ and, for each $i \in p(\1)$, we have
\[
    (f_1(i), f^\sharp_i) = f_{p[i]}(i, \id_{p[i]}).
\]
\end{corollary}
\begin{proof}
By \cref{prop.morph_arena_to_func}, the $\1$-component $f_\1 \colon p(\1) \to q(\1)$ sends every $i \in p(\1)$ to $f_1(i) \in q(\1)$, so the on-positions function $f_1$ is equal to the $\1$-component $f_\1$.
Also, the $p[i]$-component $f_{p[i]} \colon p(p[i]) \to q(p[i])$ sends every $(i, \id_{p[i]}) \in p(p[i])$, with $i \in p(\1)$, to $(f_1(i), f^\sharp_i \then \id_{p[i]}) = (f_1(i), f^\sharp_i)$.
\end{proof}

% ** More exercises??

\paragraph{Identity and composition of arena morphisms.}

Thus far, we have seen how the category $\poly$ of polynomial functors and natural transformations can just as easily be thought of as the category of arenas and arena morphisms.
But in order to actually discuss the latter category, we need to be able to give identity arena morphisms and describe how these arena morphisms compose.
To do so, we can leverage our ability to translate back and forth between arena morphisms and natural transformations.

For instance, given a polynomial $p$, the identity morphism of its associated arena should correspond to the identity natural transformation of $p$ as a functor.

\begin{exercise}[Identity arena morphisms] \label{exc.arena_morph_id}
Let $p$ be a polynomial and let $\id_p \colon p \to p$ be its identity natural transformation, whose $X$-component $(\id_p)_X \colon p(X) \to p(X)$ for each $X \in \smset$ is the identity function on $p(X)$; that is, $(\id_p)_X = \id_{p(X)}$.

Use \cref{prop.morph_func_to_arena} to show that the arena morphism $((\id_p)_1, (\id_p)^\sharp)$ associated to $\id_p$ is such that $(\id_p)_1 \colon p(\1) \to p(\1)$ and $(\id_p)^\sharp_i \colon p[(\id_p)_1(i)] \to p[i]$ for $i \in p(\1)$ are all identity functions.
\begin{solution}
We wish to show that the arena morphism $((\id_p)_1, (\id_p)^\sharp)$ associated to the identity natural transformation $\id_p$ of a polynomial $p$ is such that $(\id_p)_1$ and every $(\id_p)^\sharp_i$ are all identity functions.
Indeed, by \cref{prop.morph_func_to_arena}, for each $i \in p(\1)$, we have
\[
    ((\id_p)_1(i), (\id_p)^\sharp_i) = (\id_p)_{p[i]}(i, \id_{p[i]}) = (i, \id_{p[i]}),
\]
as $(\id_p)_{p[i]}$ is the identity function on $p(p[i])$.
\end{solution}
\end{exercise}

Similarly, we should be able to deduce how two arena morphisms compose by translating them to natural transformations, composing those, then translating back to arena morphisms.

\begin{exercise}[Composing arena morphisms] \label{exc.arena_morph_comp}
Let $p,q,$ and $r$ be polynomials, let $f \colon p \to q$ and $g \colon q \to r$ be natural transformations, and let $h \coloneqq f \then g$ be their composite, whose $X$-component $h_X \colon p(X) \to r(X)$ for each $X \in \smset$ is the composite of the $X$-components of $f$ and $g$; that is, $h_X = f_X \then g_X$.

Use \cref{prop.morph_func_to_arena} to show that the arena morphism $(h_1, h^\sharp)$ associated to $h$ satisfies $h_1 = f_1 \then g_1$ and $h^\sharp_i = g^\sharp_{f_1(i)} \then f^\sharp_i$ for all $i \in p(\1)$.
\begin{solution}
Given polynomial morphisms $f \colon p \to q, g \colon q \to r,$ and their composite $h \coloneqq f \then g$, we wish to show that the arena morphism $(h_1, h^\sharp)$ associated to $h$ satisfies $h_1 = f_1 \then g_1$ and $h^\sharp_i = g^\sharp_{f_1(i)} \then f^\sharp_i$ for all $i \in p(\1)$.
Indeed, by \cref{prop.morph_func_to_arena} and \cref{prop.morph_arena_to_func}, for each $i \in p(\1)$, we have
\begin{align*}
    (h_1(i), h^\sharp_i) &= h_{p[i]}(i, \id_{p[i]}) \\
    &= g_{p[i]}(f_{p[i]}(i, \id_{p[i]})) \tag{$h = f \then g$} \\
    &= g_{p[i]}(f_1(i), f^\sharp_i) \tag{\cref{prop.morph_func_to_arena}} \\
    &= (g_1(f_1(i)), g^\sharp_{f_1(i)} \then f^\sharp_i). \tag{\cref{prop.morph_arena_to_func}}
\end{align*}
\end{solution}
\end{exercise}

%% **Examples/exercises of composing two polynomial morphisms?

\begin{exercise}[A functor $\Cat{Top}\to\poly$] \label{exc.top_poly_func}
This exercise is for those who know what topological spaces and continuous maps are. It will not be used again in this book.
\begin{enumerate}
	\item Suppose that $X$ is a topological space. Organize its points and their neighborhoods into a polynomial $p_X$.
	\item Give a formula by which any continuous map $X\to Y$ induces a map of polynomials $p_X\to p_Y$.
	\item Show that your formula defines a functor.
	\item Is it full? Faithful?
\qedhere
\end{enumerate}
\begin{solution}
\begin{enumerate}
	\item Given a topological space $X$, we can define a polynomial $p_X$ whose positions are the points in $X$ and whose directions at $x \in X$ are the open neighborhoods of $x$.
	In other words,
	\[
	    p_X \coloneqq \sum_{x \in X} \yon^{\{ U \subseteq X \ | \ x \in U, \, U \text{ open} \}}.
	\]
	\item \label{exc.top_poly_func.morphs} For every continuous map $f \colon X \to Y$, we give a polynomial morphism $p_f \colon p_X \to p_Y$.
	The on-positions function is just $f$, while for each position $x \in X$ of $p_X$, the on-directions function $(p_f)^\sharp_x \colon p_Y[f(x)] \to p_X[x]$ sends each open neighborhood $U$ of $f(x)$ to the open neighborhood $f^{-1}(U)$ of $x$.
	
	\item To show that $p_X$ is functorial in $X$, it suffices to show that sending continuous maps $f \colon X \to Y$ to their induced polynomial morphisms $p_f \colon p_X \to p_Y$ preserves identities and composition.
	First, we show that for any topological space $X$, the polynomial morphism $p_{\id_X}$, where $\id_X$ is the identity map on $X$, is an identity morphism.
	By \cref{exc.top_poly_func.morphs}, the on-positions function of $p_{\id_X}$ is $\id_X$, and for each $x \in X$ the on-directions function $(p_f)^\sharp_x \colon p_X[x] \to p_X[x]$ sends $U \in p_X[x]$ to $(\id_X)^{-1}(U) = U$.
	Hence $p_{\id_X}$ is the identity on both positions and directions; it follows from \cref{exc.arena_morph_id} that $p_{\id_X}$ is an identity morphism.
	
	We now show that for topological spaces $X,Y,$ and $Z$ and continuous maps $f \colon X \to Y$ and $g \colon Y \to Z$, we have $p_f \then p_g = p_{f \then g}$.
	By \cref{exc.top_poly_func.morphs} and \cref{exc.arena_morph_comp}, the on-positions function of either side is equal to $f \then g$, so it suffices to show that for all $x \in X$,
	\[
	    (p_{f \then g})^\sharp_x = (p_g)^\sharp_{f(x)} \then (p_f)^\sharp_x.
	\]
	Again by \cref{exc.top_poly_func.morphs}, the left hand side sends each $U \in p_Z[g(f(x))]$ to $(f \then g)^{-1}(U)$, while the right hand side sends $U$ to $f^{-1}(g^{-1}(U))$, but by elementary set theory, these sets are equal.
	
	\item The functor is not full.
	Consider the spaces $X = \2$ with the indiscrete topology (i.e. the only open sets are the empty set and $X$) and $Y = \2$ with the discrete topology (i.e. all subsets are open).
	Then $p_X \iso \2\yon$ and $p_Y \iso \2\yon^\2$, so our functor induces a function from the set of continuous functions $X \to Y$ to the set of polynomial morphisms $\2\yon \to \2\yon^\2$.
	We claim that this function is not surjective: in particular, consider the polynomial morphism $h \colon \2\yon \to \2\yon^\2$ that is the identity on positions (and uniquely defined on directions).
	Then a continuous function $f \colon X \to Y$ that our functor sends to $h$ must also be the identity on the underlying sets of $X$ and $Y$.
	But such a function cannot be continuous, as the preimage under $f$ of a singleton set of $Y$, which is open, would be a singleton set of $X$, which would not be open. 
	So our functor sends no continuous function $X \to Y$ to $h$, and therefore is not full.
	
	The functor is, however, faithful: for any spaces $X$ and $Y$ and continuous function $f \colon X \to Y$, we can uniquely recover $f$ from $p_f$ by taking the on-positions function $(p_f)_1$.
\end{enumerate}
\end{solution}
\end{exercise}


% %---- Subsection ----%
\subsection{Prepare for dynamics}\label{subsec_prepare_dyn}

As beautiful as the category $\poly$ is---and to be clear we have not really begun to say what is so special about it---discussing its virtues is not our goal. We want to use it!

Polynomial functors are a setting in which to speak about dynamics, decisions, and data. We want the reader to understand this deeply as they go through the mathematics. So in order to make the story a bit more seamless, we discuss a few relevant aspects of $\poly$ that we can use immediately.


\paragraph{Products in $\poly$}
The category $\poly$ has limits and colimits, is Cartesian closed, has epi-mono factorizations, is completely distributive, etc., etc. However, in order to tell a good story of dynamics, we only need products right now. These will be useful for letting many different interfaces control the same internal dynamics.

\begin{proposition}\label{prop.poly_times}
The category $\poly$ has arbitrary products. 
\end{proposition}
\begin{proof}
The proof is very similar to that of \cref{prop.poly_coprods}.

By \cref{prop.prods_coprods_set_endofuncs}, the category $\smset^\smset$ has arbitrary products given by $\prod_{i \in I}$.
The full subcategory inclusion $\poly \to \smset^\smset$ reflects these products.
It remains to show that $\poly$ is closed under the operation $\prod_{i \in I}$.

Indeed, given polynomials $\{p_i\}_{i \in I}$, by \cref{prop.push_prod_sum_set}, their product is
\begin{equation} \label{eqn.poly_prod}
    \prod_{i \in I} \sum_{j \in p_i(\1)} \yon^{p_i[j]} \iso \sum_{\bar{j} \in \prod_{i \in I} p_i(\1)} \prod_{i \in I} \yon^{p_i[\bar{j}(i)]} \iso \sum_{\bar{j} \in \prod_{i \in I} p_i(\1)} \yon^{\sum_{i \in I} p_i[\bar{j}(i)]},
\end{equation}
which, as a coproduct of representables, is in $\poly$.
% We will see that $\1$ is a terminal object and that the product of $p$ and $q$ in $\poly$ is the usual product of $p$ and $q$ as polynomials. That is, if $p\coloneqq\sum_{i\in p(\1)}\yon^{p[i]}$ and $q\coloneqq\sum_{j\in q(\1)}\yon^{q[j]}$ are in standard notation, then
% \begin{equation}\label{eqn.poly_times}
% p\times q\cong\sum_{i\in p(\1)}\sum_{j\in q(\1)}\yon^{p[i]+q[j]}.
% \end{equation}
% We leave the proof as an exercise; see \cref{exc.poly_times}.
\end{proof}

It follows from \cref{eqn.poly_prod} that the terminal object of $\poly$ is $\1$, and that binary products are given by
\begin{equation}\label{eqn.poly_times}
    p \times q \iso \sum_{i \in p(\1)} \sum_{j \in q(\1)} \yon^{p[i] + q[j]}.
\end{equation}

\begin{exercise}\label{exc.poly_times}
Use \cref{eqn.main_formula} to prove \cref{prop.poly_times}. In particular:
\begin{enumerate}
	\item Prove that $\1$ is terminal in $\poly$.
	\item Prove that for polynomials $p,q$, their product is given by the formula in \eqref{eqn.poly_times}.
\qedhere
\end{enumerate}
\end{exercise}

We will begin writing $pq$ rather than $p\times q$:
\begin{equation} \tag{Notation}
pq\coloneqq p\times q
\end{equation}

\begin{example}
We can draw the product of two polynomials in terms of their associated polys. Let $p\coloneqq\yon^\3+\yon$ and $q\coloneqq\yon^\4+\yon^\2+\1$.
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, blue!50!black, "$p$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
      child {};
  \end{tikzpicture}
  };
%
	\node (p2) [draw, red!50!black, right=2 of p1, "$q$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {}
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
      child {}
      child {};
    \node[right=.5 of 2,"\tiny 3" below] (3) {$\bullet$}
    ;
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Then $pq\cong\yon^\7+\2\yon^\5+\2\yon^\3+\yon$. In pictures, we take all pairs of decisions, and for each pair we take the union the options.
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "$pq$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny {(1,1)}" below] (11) {$\bullet$} 
      child[blue!50!black] {}
      child[blue!50!black] {}
      child[blue!50!black] {}
      child[red!50!black] {}
      child[red!50!black] {}
      child[red!50!black] {}
      child[red!50!black] {};
    \node[right=1.5 of 11, "\tiny {(1,2)}" below] (12) {$\bullet$} 
      child[blue!50!black] {}
      child[blue!50!black] {}
      child[blue!50!black] {}
      child[red!50!black] {}
      child[red!50!black] {};
    \node[right=1.5 of 12, "\tiny {(1,3)}" below] (13) {$\bullet$} 
      child[blue!50!black] {}
      child[blue!50!black] {}
      child[blue!50!black] {};
    \node[right=1.5 of 13, "\tiny {(2,1)}" below] (21) {$\bullet$} 
      child[blue!50!black] {}
      child[red!50!black] {}
      child[red!50!black] {}
      child[red!50!black] {}
      child[red!50!black] {};
    \node[right=1.5 of 21, "\tiny {(2,2)}" below] (22) {$\bullet$} 
      child[blue!50!black] {}
      child[red!50!black] {}
      child[red!50!black] {};
    \node[right=1.5 of 22, "\tiny {(2,3)}" below] (23) {$\bullet$} 
      child[blue!50!black] {};
	\end{tikzpicture}
	};
\end{tikzpicture}
\]
\end{example}


\paragraph{Parallel product}
There is a closely related monoidal structure on $\poly$ that will be useful for putting dynamical systems in parallel and then wiring them together.

\begin{definition}\label{def.dirichlet}
Let $p$ and $q$ be polynomials. When they are expressed in standard notation, their \emph{parallel product}, denoted $p\otimes q$ is given by the formula:
\begin{equation}\label{eqn.dirichlet_def}
p\otimes q\cong\sum_{i\in p(\1)}\sum_{j\in q(\1)}\yon^{p[i]\times q[j]}.
\end{equation}
On arenas, this is defined by
\begin{equation}\label{eqn.parallel_product_dependent}
\sum_{i \in p(\1)}\yon^{p[i]} \otimes \sum_{j \in q(\1)}\yon^{q[j]} := \sum_{(i,j) \in p(\1) \times q(\1)}\yon^{p[i]\times q[j]}.
\end{equation}
\end{definition}

One should compare this with the formula for product of polynomials shown in \eqref{eqn.poly_times}. The difference is that parallel product multiplies exponents where regular product adds them.

\begin{remark}
  The reason we call this the parallel product is because it generalizes the
  parallel product for lenses in \cref{sec.lens_discrete}.
\end{remark}

\begin{example}
We can draw the product of two polynomials in terms of their associated polys. Let $p\coloneqq\yon^\3+\yon$ and $q\coloneqq\yon^\4+\yon^\2+\1$.
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, blue!50!black, "$p$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
      child {};
  \end{tikzpicture}
  };
%
	\node (p2) [draw, red!50!black, right=2 of p1, "$q$" above] {
	\begin{tikzpicture}[trees, sibling distance=2.5mm]
    \node["\tiny 1" below] (1) {$\bullet$} 
      child {}
      child {}
      child {}
      child {};
    \node[right=.5 of 1,"\tiny 2" below] (2) {$\bullet$} 
      child {}
      child {};
    \node[right=.5 of 2,"\tiny 3" below] (3) {$\bullet$}
    ;
  \end{tikzpicture}
  };
\end{tikzpicture}
\]
Then $p\otimes q\cong\yon^{\1\2}+\yon^\6+\yon^\4+\yon^\2+\2$. In pictures, we take all pairs of decisions, and for each pair we take the product of the options.
\[
\begin{tikzpicture}[rounded corners]
	\node (p1) [draw, "$pq$" above] {
	\begin{tikzpicture}[trees, sibling distance=1mm]
    \node["\tiny {(1,1)}" below] (11) {$\bullet$} 
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
    ;
    \node[right=1.5 of 11, "\tiny {(1,2)}" below] (12) {$\bullet$} 
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
    ;
    \node[right=1.5 of 12, "\tiny {(1,3)}" below] (13) {$\bullet$} 
    ;
   \node[right=1.5 of 13, "\tiny {(2,1)}" below] (21) {$\bullet$} 
      child {}
      child {}
      child {}
      child {}
 		;    
		\node[right=1.5 of 21, "\tiny {(2,2)}" below] (22) {$\bullet$} 
      child {}
      child {}
 		;    
    \node[right=1.5 of 22, "\tiny {(2,3)}" below] (23) {$\bullet$} 
 		;    
	\end{tikzpicture}
	};
\end{tikzpicture}
\]
\end{example}

\begin{exercise}
What is the parallel product of monomials
\[
A_1\yon^{B_1}\otimes A_2\yon^{B_2}?
\]
\end{exercise}

\begin{exercise}
Let $p\coloneqq\yon^\3+\yon$ and $q\coloneqq\2\yon^\4$. Draw the following
arenas using corollas:
\begin{enumerate}
	\item Draw $p$ and $q$ as arenas.
	\item Draw $pq=p\times q$ as an arena.
	\item Draw $p\otimes q$ as an arena.
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}
Consider the polynomials $p\coloneqq \2\yon^\2+3\yon$ and $q\coloneqq\yon^\4+\3\yon^\3$.
\begin{enumerate}
	\item What is $p\times q$?
	\item What is $p\otimes q$?
	\item What is the product of the following purely formal expression we'll see \emph{only this once!}:
	\[
	(2\mdot2^\yon+3\mdot 1^\yon+\1) \cdot 
	(1\mdot4^\yon+3\mdot 3^\yon+\2)
	\]
These are called Dirichlet series.
	\item Do you see a connection between what the last two parts? If so, would
    you say that it justifies the name ``Dirichlet product'' as another name for
    the parallel product $\otimes$?
\end{enumerate}
\end{exercise}

\begin{exercise}
What is $(\3\yon^\5+\6\yon^\2)\otimes\4$? Hint: $\4=\4\yon^\0$.
\end{exercise}

\begin{exercise}\label{exc.prepare_poly_smc}
Let $p,q,r\in\poly$ be any polynomials.
\begin{enumerate}
  \item Show that there is an isomorphism $p\otimes\yon\cong p$.
  \item Show that there is an isomorphism $(p\otimes q)\otimes r\cong p\otimes (q\otimes r)$.
  \item Show that there is an isomorphism $(p\otimes q)\cong(q\otimes p)$.
 \qedhere
\end{enumerate}
\end{exercise}

In \cref{exc.prepare_poly_smc} we have gone most of the way to proving that $(\poly,\otimes,\yon)$ is a symmetric monoidal category. 

\begin{proposition}\label{prop.dirichlet_monoidal}
The category $\poly$ has a symmetric monoidal structure $(\yon,\otimes)$ where $\otimes$ is the parallel product from \cref{def.dirichlet}.
\end{proposition}
\begin{proof}[Sketch of proof]
Given maps of polynomials $f\colon p\to p'$ and $g\colon q\to q'$ we need to give a
map $(f\otimes g)\colon (p\otimes q)\to (p'\otimes q')$. On positions, define
\[
(f\otimes g)_1(i,j)\coloneqq \big(f_1(i),g_1(j)\big)
\]
On directions at $(i,j)\in p(\1)\times q(\1)$, define
\[
  (f\otimes g)^\sharp_{(i,j)}(d,e)\coloneqq
  \big(f^\sharp_i(d),g^\sharp_j(e)\big).
\]
We have not proven all the coherences between the various isomorphisms, but we ask the reader to take it on trust or to check it for themselves. 
\end{proof}

\begin{exercise}
\begin{enumerate}
	\item If $p=A$ and $q=B$ are constant polynomials, what is $p\otimes q$?
	\item If $p=A$ is constant and $q$ is arbitrary, what can you say about $p\otimes q$?
	\item If $p=A\yon$ and $q=B\yon$ are linear polynomials, what is $p\otimes q$?
	\item For arbitrary $p,q\in\poly$, what is the relationship between the sets $(p\otimes q)(\1)$ and $p(\1)\times q(\1)$?
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}\label{exc.dir_closed_classes}
Which of the following classes of polynomials are closed under $\otimes$? Note also whether they contain $\yon$.
\begin{enumerate}
	\item The set $\{A\yon^\0\mid A\in\smset\}$ of constant polynomials.
	\item The set $\{A\yon\mid A\in\smset\}$ of linear polynomials.
	\item The set $\{A\yon+B\mid A,B\in\smset\}$ of affine polynomials.
	\item The set $\{A\yon^\2+B\yon+C\mid A,B,C\in\smset\}$ of quadradic polynomials.
	\item The set $\{A\yon^B\mid A,B\in\smset\}$ of monomials.
	\item The set $\{S\yon^S\mid S\in\smset\}$ of systematic polynomials.
	\item The set $\{p\in\poly\mid p(\1)\text{ is finite}\}$.
\end{enumerate}
What is the smallest class of polynomials that's closed under $\otimes$ and contains $\yon$?
\end{exercise}

\begin{exercise}
Show that for any $p_1,p_2,q\in\poly$ there is an isomorphism
\[
(p_1+p_2)\otimes q\cong (p_1\otimes q)+(p_2\otimes q)
\qedhere
\]
\end{exercise}

\begin{proposition}
For any monoidal structure $(I,\odot)$ on $\smset$, there is a corresponding monoidal structure on $\poly$ with unit $\yon^I$. It is given by Day convolution, and it distributes over $+$. 

In the case of $(0,+)$ and $(1,\times)$, this procedure returns the $(1,\times)$ and $(\yon,\otimes)$ monoidal structures respectively.
\end{proposition}
\begin{proof}
Day convolution always takes a monoidal structure on $\smset$ and returns one on functors $\smset\to\smset$; the issue is whether $\poly$ is closed under the resulting monoidal product. We will show that it is, roughly because every polynomial is a coproduct of representables.

**
\end{proof}

\begin{exercise}
\begin{enumerate}
	\item Show that the operation $(A, B)\mapsto A+AB+B$ on $\smset$ is associative.
	\item Show that $0$ is unital for the above operation.
	\item Let $(1,\odot)$ denote the corresponding monoidal product on $\poly$. What is $(\yon^\3+\yon)\odot(\2\yon^\2+\2)$?
\qedhere
\end{enumerate}
\end{exercise}

\paragraph{$\otimes$-monoids in $\poly$}

\begin{definition}
A \emph{$\otimes$-monoid in $\poly$} consists of a polynomial $m$, a map $(*)\colon m\otimes m\to m$, and a position $e\colon\yon\to m$ that form a monoid in $(\poly,\yon,\otimes)$.
\end{definition}

These have a kind of swarm-like semantics, making individuals able to summarize the positions of a group of subordinates, as well as distribute instructions to those subordinates in a coherent way. 

\begin{exercise}
Explain how $\odot$ has the ``swarm-like'' semantics described above.
\end{exercise}

\begin{example}[Monoids in $\smset$ give linear $\otimes$-monoids]
If $(M,e,(*))$ is a monoid in $(\smset,1,\times)$ then the linear polynomial $M\yon$ carries a corresponding $\otimes$-monoid, roughly because $A\yon\otimes B\yon\cong (A\times B)\yon$. This construction is functorial and fully faithful: a map between monoids in $\smset$ can be identified with a map between $\otimes$-monoids.
\end{example}

\begin{example}[Comonoids in $\smset$ give representable $\otimes$-monoids]
Every comonoid $(S,\epsilon,\delta)$ in $(\smset,1,\times)$ gives rise to a $\otimes$-monoid structure on $\yon^S$. This construction is again (contravariantly) functorial and fully faithful.
\end{example}

\begin{example}
Let $m\coloneqq\rr_{\geq0}\yon^{\rr_{\geq0}}$. Take $e=0$ and $(a,b)\mapsto(a+b, t\mapsto (\frac{at}{a+b},\frac{bt}{a+b}))$. This forms a $\otimes$-monoid.
\end{example}

\begin{proposition}
If $m,n$ are the carriers of $\otimes$-monoids, then $m\otimes n$ naturally also carries a $\otimes$-monoid structure.
\end{proposition}

\begin{proposition}[Free $\otimes$-monoid]
The forgetful functor from $\otimes$-monoids to $\poly$ has a left adjoint.
\end{proposition}
\begin{proof}
The carrier $p'$ of the free $\otimes$-monoid on $p$ has positions $p'(\1)\cong\Set{List}(p(\1))$, i.e.\ lists of positions in $p$. Given a position $\ell=(i_1,\ldots,i_n)$, the direction-set there is given by $\prod_{j\in\ord{n}} p[j]$.
**
\end{proof}

\paragraph{Bimorphic lenses}\label{page.bimorphic_lens}

Monomials are special polynomials: those of the form $A\yon^B$ for sets $A,B$. Here's a picture of $\5\yon^{\1\2}$:
\[
\begin{tikzpicture}[trees, sibling distance=1mm]
	\foreach \i in {1,...,5}
	{
    \node["\tiny \i" below] at (1.8*\i,0) {$\bullet$} 
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
      child {}
    ;
	};
\end{tikzpicture}
\]


The formula for morphisms between these is particularly simple:
\[
  \poly\left(A_1\yon^{B_1},\,A_2\yon^{B_2}\right)
  \cong
  \smset(A_1,A_2)\times\smset(A_1\times B_2,B_1)
\]

It says that to give a morphism from one monomial to another, you just need to give two functions. Let's rewrite it to make those two functions explicit:
\[
  \poly\left(A_1\yon^{B_1},\,A_2\yon^{B_2}\right)
  \cong
  \left\{
    (f_1,f^\sharp)
  \;\middle|\;
  	\parbox{1.2in}{
    $
    \begin{aligned}
  	  f_1&\colon A_1\to A_2\\
  	  f^\sharp&\colon A_1\times B_2\to B_1
    \end{aligned}
    $
  }
  \right\}
\]
Ordinarily, the $f^\sharp$ is more involved in that its type depends on $f_1$, but for monomials every decision has the same number of options, so to speak.

The monomials in $\poly$ and the morphisms between them forms a full subcategory of $\poly$, and it has been called the \emph{the category of bimorphic lenses} \cite{hedges2018limits}. It comes up in functional programming. The morphisms $A_1\yon^{B_1}\to A_2\yon^{B_2}$ break up into two functions which people give special names:
\begin{equation}\label{eqn.bimorphic_lens}
\begin{aligned}
	\text{get}&\colon A_1\to A_2\\
	\text{set}&\colon A_1\times B_2\to B_1
\end{aligned}
\end{equation}
The idea is that each $A$-decision ``gets'' a $B$-decision, and every option there in $B$ ``sets'' an option back in $A$

We will use the term \emph{lens} when we want to remind the reader that morphisms between monomials are much simpler than those between arbitrary polynomials.

\begin{remark}
Consider lenses between polynomials of the form $S\yon^S$. In terms of arenas, the set of options for each decision $s\in S$ is again just the set $S$ of decisions. So decisions are all about ``which $s\in S$ you're at, and which one you want to be at next".

A lens, i.e.\ a polynomial map $(\text{get, set})\colon S\yon^S\to T\yon^T$ is as usual a way to delegate $S$-decisions to $T$-decisions. Among them, some lenses are considered to be ``very well behaved'' because they give $T$ a more sensible form of control. Namely, they are the ones that satisfy the following for all $s\in S$ and $t,t'\in T$:
\[
	\text{get}(\text{set}(s,t))=t
	\qquad
  \text{set}(s,\text{get}(s))=s
  \qquad
  \text{set}(\text{set}(s,t),t')=\text{set}(s,t')
\]
We will see these emerge from more general theory in \cref{??}.
\end{remark}


%-------- Section --------%
\section{Dynamical systems using $\poly$}\label{sec.dynam_in_poly}

Let's start putting all this $\poly$ stuff to use. 

%---- Subsection ----%
\subsection{Moore machines}

Remember Moore machines from \cref{def.deterministic_system}? 

\begin{definition}\label{def.moore_machine_again}
If $A$, $B$, and $A$ are sets, an $(A,B)$-Moore machine with states $S$ consists of two functions
\begin{align*}
	\text{expose}&\colon S\to B\\
	\text{update}&\colon S\times A\to S 
\end{align*}
\end{definition}

Look familiar?  It's easy to see that an $(A,B)$ Moore machine with states $S$ is just a map of polynomials
\[
S\yon^S\to B\yon^A
\]
or to say it another way, a lens from $(S,S)\to(A,B)$ in the sense of \cref{eqn.bimorphic_lens}.

\begin{example}\label{ex.counting_trajectory}
There is a dynamical system that takes unchanging input and produces as output the sequence of natural numbers $0,1,2,3,...$. It is a Moore machine of type $(\1,\nn)$ with states $\nn$. The polynomial map $\nn\yon^\nn\to\nn\yon$ is given by identity on positions and $n\mapsto n+1$ on directions
\[
\begin{tikzpicture}[polybox, mapstos]
	\node[poly, dom] (s) {$n+1$\nodepart{two}$n$};
	\node[poly, cod, linear, right=of s] (p) {$\vphantom{1}$\nodepart{two}$n$};
	\draw (s_pos) to[first] (p_pos);
	\draw (p_dir) to[last] (s_dir);
\end{tikzpicture}
\]
\end{example}

We can generalize both $S\yon^S$ and $B\yon^A$ in \cref{def.moore_machine_again}, though the latter is much simpler and we'll spend much of the section on it. After some examples, we'll briefly preview something we're going to spend a lot of time later, namely what's special about $S\yon^S$; then we'll discuss how to model regular languages using Moore machines and how products of polynomials allow multiple interfaces to act on the same system.

\begin{example}\label{ex.Moore_three}
Here's a picture of a Moore machine with $S\coloneqq\3$ states:
\[
\begin{tikzpicture}
	\node[draw] {
  \begin{tikzcd}[column sep=small]
  	\LMO{b_1}\ar[rr, dgreen, thick, bend left]\ar[loop left, thick, orange]&&
  	\LMO{b_2}\ar[ll, thick, orange, bend left]\ar[dl, bend left, thick, dgreen]\\&
  	\LMO{b_2} \ar[ul, thick, orange, bend left] \ar[loop left, thick, dgreen]
  \end{tikzcd}
  };
\end{tikzpicture}
\]
Each state is labeled by its exposed value, i.e.\ element of $B\coloneqq\{b_1,b_2\}$. Each state has two outgoing arrows, one orange and one green, so $A\coloneqq\{{\color{orange}\text{orange}},{\color{dgreen}\text{green}}\}$.

You can imagine barking ``orange! orange! green! orange!'' etc. at this machine, and it running through states.
\end{example}

\begin{example}\label{ex.R2_moore}
Here's a(n infinite) Moore machine with states $\rr^2$:
\[
\rr^2\yon^{\rr^2}\to\rr^2\yon^{[0,1]\times[0,2\pi)}%]
\]
Its output type is $\rr^2$, which we might think of as a position in 2-d space, and its input type is $[0,1]\times[0,2\pi]$, which we might think of a command to move a certain distance in a certain direction. The map itself is given by the lens:
\begin{align}
  \rr^2&\To{\text{get}}\rr^2&
  \rr^2\times[0,1]\times[0,2\pi]&\To{\text{put}}\rr^2
  	\nonumber\\\label{eqn.r2moore}
  (a,b)&\mapsto(a,b)&
  (a,b,r,\theta)&\mapsto(a+r\cos\theta, b+r\sin\theta)
\end{align}
\end{example}

\begin{exercise}
Explain in words what is going on in \eqref{eqn.r2moore}.
\end{exercise}

\begin{example}[From functions to Moore machines]\label{ex.funs_to_moore}
For any function $f\colon A\to B$ there is a corresponding $(A,B)$-Moore machine with states $B$ that takes in a stream of $A$'s and outputs the stream of $B$'s obtained by applying $f$. 

It is given by the map $(\id_B,\texttt{const} f)\colon B\yon^B\to B\yon^A$. That is, it is identity on positions (outputs the state directly), and on inputs is the function $B\times A\To{\pi}A\To{f} B$ that drops the current position and then applies $f$ to the input.

If the machine begins in state $b_0$ and is given a stream $(a_1,a_2,\ldots)$, the machine's output will be $(b_0,f(a_1),f(a_2),\ldots)$. We could say this machine is \emph{memoriless} because the current output does not depend on any internal memory.
\end{example}

\begin{exercise}\label{exc.funs_to_moore}
Suppose given a function $f\colon A\times B\to B$.
\begin{enumerate}
	\item Find a corresponding $(A,B)$-Moore machine $B\yon^B\to B\yon^A$.
	\item Would you say the machine is memoriless?
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}
Find $A,B\in\smset$ such that the following can be identified with a morphism $S\yon^S\to B\yon^A$:
\begin{enumerate}
	\item a \emph{discrete dynamical system}, i.e.\ a set $S$ and a function $S\to S$.
	\item a \emph{magma}, i.e.\ a set $S$ and a function $S\times S\to S$.
	\item a set $S$ and a subset $S'\ss S$.
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}
Consider the Moore machine in \cref{ex.R2_moore}, and think of it as a robot. Using the terminology from that example, modify the robot as follows.

Add to its state a ``health meter,'' which has a value between 0 and 10. Make the robot lose health whenever the $x$-coordinate of its position is negative. Use its health $h$ as a multiplier, allowing it to move a distance of $hr$ given an input of $r$.
\end{exercise}

\begin{exercise}\label{exc.file_reader}
Let's say a file of length $n$ is a function $f\colon\ord{n}\to\Set{ascii}$, where $\Set{ascii}\coloneqq\2\5\6$. Suppose given such a file and refer to elements of $\ord{n}=\{1,\ldots,n\}$ as positions. Make a robot (Moore machine) whose output type is $\Set{ascii}$ and whose input type is
\[
\{(s,t)\mid 1\leq s\leq t\leq n\}+\{\text{continue}\}
\]
Given an input, if it is of the form $(s,t)$ then the robot goes to position $s$ in the file and begins reading (assuming it receives the ``continue'' signal) one character at a time, until it reaches position $t$. Then it continually outputs ``done'' until it receives another $(s,t)$ pair.
\end{exercise}

When we get to generalized Moore machines, we will be able to let the robot ``close its port,'' so that while it can't receive signals while it's busy reading; see \cref{ex.generalized_file_reader}.

\begin{exercise}[Tape of a Turing machine]
A Turing machine has a tape. The tape has a position for each integer, and each position holds a value $v\in V=\{0,1,-\}$ of 0,1, or blank. At any given time the tape not only holds this function $f\colon\zz\to V$ from positions to values, but also a distinguished choice $c\in\zz$ of ``current'' position. Thus the set of states of the tape is $T\coloneqq V^\zz\times\zz$.

The Turing machine interacts with the tape by asking for the value at the current position, an element of $V$, and by telling it to change the value there as well as whether to move left or right. Thus the output of the tape is $V$ and the input is $V\times\{L,R\}$.

\begin{enumerate}
	\item Give the form of the tape as a Moore machine, i.e.\ map of polynomials $t\colon S\yon^S\to p$ for appropriate $S\in S$ and $p\in\poly$.
	\item Write down the specific $t$ that makes it act like a tape as specified above.
\qedhere
\end{enumerate}
\end{exercise}

\begin{example}[Paddling]\label{ex.paddler}
Consider an entity with interface $\nn\yon$; its behavior will be a stream of natural numbers, any stream. What if we don't want to enable our entity to just jump around wildly. Instead, suppose we want to be very strict about what how far the entity can move and what makes it move.

To accomplish this, we in fact use two entities, which we call \emph{paddler} and \emph{tracker}:%
\footnote{Perhaps one could refer to the tracker as the \emph{demiurge}; it is responsible for maintaining the material universe.}
\[
  \textit{paddler}\coloneqq\2\yon
  \qqand
  \textit{tracker}\coloneqq\nn\yon^\2
\]
The paddler has interface $\2\yon$ because it is blind and can only move its paddle left or right, $\2\cong\{\text{left, right}\}$. The tracker has interface $\nn\yon^\2$ because it will announce the location of the paddler (as an element $n\in\nn$) and it watch what the paddler does (as an element of $\2$). Their enclosure together
\[
\textit{tracker}\otimes\textit{paddler}\to\nn\yon
\]
is the obvious rearrangement of the identity function $\nn\times\2\to\nn\times\2$, so that we can see the tracker's announcement and the tracker can see the paddler's paddle position.

Let's leave the paddler's dynamics alone---how you make that paddler behave is totally up to you---and instead focus on the dynamics of the tracker. We want it to watch for when the paddle switches from left to right or from right to left; at that moment it should push the paddler forward one unit. Thus the states of the tracker are given by $S\coloneqq\2\nn$, and its dynamics
\[\varphi\colon S\yon^S\to\nn\yon^\2\]
are given by the map given on elements $p,p'\in\2$ and $i\in\nn$ by the formula:
\[
  (p,i)\mapsto i,p'\mapsto
	\begin{cases}
		i&\tn{ if }p=p'\\
		i+1&\tn{ if }p\neq p'
	\end{cases}
\]
As advertised, when the paddle swishes, the tracker announces that the paddler has moved forward one unit; when the paddle stays still, the tracker announces that the paddler itself also stays still.
\end{example}

\begin{exercise}
Change the dynamics and state-set of the tracker in \cref{ex.paddler} so that it exhibits the following behavior.

When the paddle swishes once and stops, the tracker increases its position by one unit and stops, as before in \cref{ex.paddler}. But when the paddle swishes twice in a row, the tracker increases its position by two units on the second swish! So if it is quiet for a while and then swishes three times in a row, the tracker will increase its position by one then two then two.
\end{exercise}

\begin{example}[Picking up the chalk]\label{ex.pickup_chalk}
Imagine you are at a table; you see some chalk and you pinch it between your thumb and forefinger. An amazing thing about reality is that you will then have the chalk, in the sense that you can move it around. How might we model this situation in $\poly$?

Let's say that your hand can be at one of two heights, down or up, and that you can either press (apply pressure between your thumb and forefinger) or not press. Let's also say that you take in information about the chalk's height. Here are the two sets we'll be using:
\[
	H\coloneqq\{\text{down, up}\}
	\qqand
	P\coloneqq\{\text{press, no press}\}.
\]
Your interface is $HP\yon^H$: producing a height and a pressure, receiving a height.

As for the chalk, it is in one of two modes: in your possession or not. Either way it reveals its height, which is either down on the table or up in the air. The chalk always takes in information about whether pressure is being applied or not. When it's not in your possession (mode 1), that's the whole story, but when it is in your possession (mode 2) it also receives your hand's height. All together, here are the two interfaces:
\[
	\textit{you}\coloneqq HP\yon^H
	\qqand
	\textit{chalk}\coloneqq \{1\}H\yon^P + \{2\}H\yon^{PH}.
\]

Now we want to give the interaction between you and the chalk. As we said before, you see the chalk's height. If your hand is at the height of the chalk, it receives your pressure. If it's in your possession, it also receives your hand's height. 

To provide a map $\textit{you}\otimes\textit{chalk}\To{\varphi}\yon$, we use the fact that $\textit{chalk}$ is a sum and that $\otimes$ distributes over $+$. Thus we need to give two maps
\[
	HP\yon^H\otimes H\yon^P\To{\psi}\yon
	\qqand
	HP\yon^H\otimes H\yon^{HP}\To{\psi'}\yon
\]
The map $\psi'$, corresponding to when the chalk is in your possession, is quite easy to describe; it can be unfolded to a function
$HPH\to HHP$, and we take it to be the obvious map sending your height and pressure to the chalk and the chalk's height to you; see \cref{exc.pickup_chalk}. But $\psi$ is more semantically interesting; it is given by the following map
\[
  ((p,h),h')\mapsto
  \begin{cases}
  	(h',\text{no press})&\tn{ if }h\neq h'\\
  	(h',p)&\tn{ if }h= h'
  \end{cases}
\]
We'll use primes, e.g.\ $h'$ to denote variables associated to the chalk, and no primes, e.g.\ $h$ and $p$ to denote variables associated to you.

So now we've got you and the chalk in a closed system together, given by $\varphi=\psi+\psi'$, so we are ready to add some dynamics. As for your dynamics, it can be whatever you want, so let's just add some dynamics to the chalk and call it a day. The chalk  has only four states $C\coloneqq \2H\cong\4$: the $H$ coordinate is its current height and the other coordinate is its mode (1 or 2) corresponding to whether or not it is ``in your possession''. We will give a dynamical system $C\yon^C\to\textit{chalk}$ with states $C$ and chalk-interface, i.e.\ a map
\begin{equation}\label{eqn.chalk_dynamics}
	\2H\yon^{\2H}\to \{1\}H\yon^P + \{2\}H\yon^{PH}.
\end{equation}
As you might guess, the chalk reveals its mode and height directly. If it's not in your possession it falls down unless you catch (apply pressure to) it; if it is in your possession, it takes whatever height you give it. This is all expressed by the following dynamics, defining \eqref{eqn.chalk_dynamics}:
\begin{align*}
  (1,h')&\mapsto
  	\left(1,h',p\mapsto
		\begin{cases}
			(\text{down, no press})&\tn{ if }p=\text{no press}\\
			(h',\text{press})&\tn{ if }p=\text{press}
		\end{cases}\right)\\
	(2, h')&\mapsto
		\left(2,h',(h,p)\mapsto
		\begin{cases}
			(h,1)&\tn{ if }p=\text{no press}\\
			(h,2)&\tn{ if }p=\text{press}
		\end{cases}\right)
\end{align*}
Obviously, this is all quite complicated, intricate, and contrived. Our goal here is only to show that you can define interactions in which one system can engage with or disengage from another, and that when the two systems are engaged, the first controls the behavior of the second.
\end{example}

\begin{exercise}\label{exc.pickup_chalk}
\begin{enumerate}
	\item In \cref{ex.pickup_chalk}, we said that $\psi'\colon HP\yon^H\otimes H\yon^{HP}\To{\psi'}\yon$ was easy to describe and given by a function $HPH\to HHP$. Explain what's being said, and provide the function.
	\item Provide dynamics to the \textit{you} character. For example, you repeatedly reach down and pick up the chalk, lift your hand, and drop it. 
\qedhere
\end{enumerate}
\end{exercise}

\paragraph{Situations.}

Let $p$ be a polynomial. We will refer to a map $p\to\yon$ as a \emph{situation} for $p$, and denote the set of them by
\[
\Gamma(p)\coloneqq\poly(p,\yon)
\]
as we did in \cref{prop.adjoint_quadruple}. The idea for the name is that a situation (perhaps a better word would be ``condition'', but that term is already used for rule or requirement) is what dictates what you'll see, given anything you might do. If the situation is that you're at a party, then that dictates what you'll receive, given your position. So a situation $\gamma\in\Gamma(p)$ takes every position $i\in p(\1)$ and returns a direction $\gamma(i)\in p[i]$.

A map $p_1\otimes p_n\to\yon$ puts these $n$ interfaces in a situation together. The following proposition helps explain why situation is a useful concept.

\begin{proposition}\label{prop.situations2}
Given polynomials $p,q\in\poly$, there is a bijection
\[
\Gamma(p\otimes q)\cong\smset(q(\1),\Gamma(p))\times\smset(p(\1),\Gamma(q)).
\]
\end{proposition}
The idea is that for $p$ and $q$ to be enclosed together in a system simply means that the positions of each one become a situation for the other. 
\begin{proof}
This is a direct calculation.
\begin{align*}
	\Gamma(p\otimes q)&\coloneqq
	\prod_{i\in p(\1)}\prod_{j\in q(\1)}(p[i]\times q[j]\\&\cong
	\left(\prod_{i\in p(\1)}\prod_{j\in q(\1)}p[i]\right)\times
		 \left(\prod_{i\in p(\1)}\prod_{j\in q(\1)}q[j]\right)\\&\cong
	\smset(q(\1),\Gamma(p))\times\smset(p(\1),\Gamma(q))
\end{align*}
\end{proof}

\begin{exercise}
\begin{enumerate}
	\item State a generalization of \cref{prop.situations2} for $n$-many polynomials $p_1,\ldots,p_n\in\poly$.
	\item Prove it.
	\item Generalize the ``idea'' statement between \cref{prop.situations2} and its proof.
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}
We will use \cref{prop.situations2} to consider the interaction $\varphi$ between \textit{you} and \textit{chalk} from \cref{ex.pickup_chalk} as a pair of functions $\textit{you}\to\Gamma(\textit{chalk})$ and $\textit{chalk}\to\Gamma(\textit{you})$.
\begin{enumerate}
	\item How is the chalk's position a situation for you? That is, write the map $\textit{chalk}\to\Gamma(\textit{you})$.
	\item How is your position a situation for the chalk? That is, write the map $\textit{you}\to\Gamma(\textit{chalk})$.
\qedhere
\end{enumerate}
\end{exercise}

\paragraph{The polynomial $S\yon^S$ as a comonad on $\smset$.}\label{page.poly_comonad}

A \emph{comonad} on $\smset$ is a functor $F\colon\smset\to\smset$, equipped with two natural transformations $\epsilon\colon F\to\id$ and $\delta\colon F\to F\circ F$, satisfying three equations. We don't need this now, so we won't get into it here. But we will note that every comonad comes from an adjunction, and the adjunction corresponding to $S\yon^S$ is
\[
\adj{\smset}{-\times S}{-^S}{\smset}
\]
the ``curry/uncurry'' adjunction. In functional programming, the comonad $S\yon^S$ is called the \emph{state comonad},%
\footnote{The comonad $S\yon^S$ is sometimes called the \emph{store} comonad.} 
and the elements of $S$ are called states. It is no coincidence that we also refer to elements of $S$ as states. 

Again, we will be \emph{very} interested in polynomial comonads later---as mentioned in \cref{prop.ahman_uustalu1} they are exactly categories!!---but for now we move on to things we can use right away in our story about dynamical systems.%
\footnote{If you're curious what category the comonad $S\yon^S$ corresponds to, it's the one with object set $S$ and a unique morphism $s_1\to s_2$ for every pair of objects $s_1,s_2\in S$.}

\paragraph{Regular languages}

Regular languages are very important in computer science. One way to express what they are is to say that they are exactly the languages recognizable by a deterministic finite state automaton. What is that?

\begin{definition}\label{def.dfa}
A \emph{deterministic finite state automaton} consists of
\begin{enumerate}
	\item a finite set $S$, elements of which are called \emph{states}
	\item a finite set $A$, elements of which are called \emph{input symbols},
	\item a function $u\colon S\times A\to S$, called the \emph{update function},
	\item an element $s_0\in S$, called the \emph{initial state},
	\item a subset $F\ss S$, called the \emph{accept states}.
\end{enumerate}
\end{definition}

\begin{proposition}
A deterministic finite state automaton can be identified with a pair of maps
\[
\yon\to S\yon^S\to \2\yon^A.
\]
\end{proposition}
\begin{proof}
A map $\yon\to S\yon^S$ can be identified with an element $s_0\in S$. A map $S\yon^S\to\2\yon^A$ consists of a function $S\to\2$---which can be identified with a subset of $S$---together with a function $S\times A\to S$, which is the rest of the required structure.
\end{proof}


\paragraph{Products: two interfaces operating on the same system.}

One thing we can use right away in our thinking about dynamical systems is products of polynomials. The universal property of products says that for any polynomials $s,p_1,p_2$ and maps $s\to p_1$ and $s\to p_2$ there is a unique map $s\to p_1p_2$. In the context of Moore machines, we have the following.

\begin{proposition}
Suppose given an $(A_1,B_1)$-Moore machine and an $(A_2,B_2)$-Moore machine, each with state set $S$. Then there is an induced $(A_1+A_2,B_1B_2)$-Moore machine, again with state set $S$.
\end{proposition}
\begin{proof}
We are given maps of polynomials $S\yon^S\to B_1\yon^{A_1}$ and $S\yon^S\to B_2\yon^{A_2}$. Hence by the universal property of products we have a map
\[
  S\yon^S\to
  (B_1\yon^{A_1})\times(B_2\yon^{A_2})
  \cong(B_1B_2)\yon^{A_1+A_2},
\] 
as desired.
\end{proof}

\begin{example} \label{ex.labeled_transition}
Consider two four-state dynamical systems $4\yon^4\to \rr\yon^{\{r,b\}}$ and $4\yon^4\to \rr\yon^{\{g\}}$, each of which gives outputs in $\rr$; we think of $r,b,g$ as red, blue, and green, respectively. We can draw such morphisms as labeled transition systems, e.g.
\[
\begin{tikzpicture}
	\node[draw] (1) {
  \begin{tikzcd}[row sep=15pt]
  	\LMO{3.14}\ar[r, bend left=15pt, red]\ar[loop left=15pt, blue]&
  	\LMO{0}\ar[l, bend left=15pt, red]\ar[d, bend left=15pt, blue]\\
  	\LMO[under]{1.41}\ar[u,bend left=15pt, red]\ar[r, bend right=15pt, blue]&
  	\LMO[under]{2.72}\ar[l, bend right=15pt, red]\ar[loop right=15pt, blue]
  \end{tikzcd}
	};
	\node[draw, right=of 1] {
  \begin{tikzcd}[row sep=15pt]
  	\LMO{2}\ar[d, green!50!black]&
  	\LMO{4}\ar[l, green!50!black]\\
  	\LMO[under]{8}\ar[loop left, green!50!black]&
  	\LMO[under]{16}\ar[ul, green!50!black]
  \end{tikzcd}
  };
 \end{tikzpicture}
\]

The universal property of products provides a unique way to put these systems together to obtain a morphism $4\yon^4\to(\rr\yon^{\{r,b\}}\times \rr\yon^{\{g\}})=(\rr^2)\yon^{\{r,b,g\}}$. With the examples above, it looks like this:
\[
\begin{tikzpicture}
	\node[draw] (1) {
  \begin{tikzcd}
  	\LMO{(3.14,2)}\ar[r, bend left=15pt, red]\ar[loop left, blue]\ar[d, bend left=15pt, green!50!black]&
  	\LMO{(0,4)}\ar[l, bend left=15pt, red]\ar[d, bend left=15pt, blue]\ar[l, green!50!black]\\
  	\LMO[under]{(1.41,8)}\ar[u,bend left=15pt, red]\ar[r, bend right=15pt, blue]\ar[loop left, green!50!black]&
  	\LMO[under]{(2.72,16)}\ar[l, bend right=15pt, red]\ar[loop right=15pt, blue]\ar[ul, green!50!black]
  \end{tikzcd}
  };
\end{tikzpicture}
\]
\end{example}

In other words, if there are two or more interfaces that drive a single set of states, we can combine them.



\begin{exercise}[Toward event-based systems]
Let $f\colon S\yon^S\to B\yon^A$ be a Moore machine. It is constantly needing input at each time step. An event-based system is one that doesn't always get input, and only reacts when it does.

So suppose we want to allow our machine not to do anything. That is, rather than needing to press a button in $A$ at each time step, we want to be able to \emph{not} press any button, in which case the machine just stays where it is. We want a new machine $f'\colon S\yon^S\to p$ that has this behavior; what is $p$ and what is $f'$?
\end{exercise}



%---- Subsection ----%
\subsection{Dependent Systems}

Everything we've done above was for interfaces of the form $B\yon^A$, i.e.\ for monomials. But the theory works just as well for an arbitrary $p$, a sum of monomials.

\begin{definition}[Dependent systems]\label{def.gen_moore}
A \emph{dependent system} is a map of polynomials
\[S\yon^S\to p\]
for some $S\in\smset$ and $p\in\poly$. The set $S$ is called the set of \emph{states} and the polynomial $p$ is called the \emph{(poly-) interface}.
\end{definition}

We could also call these \emph{generalized Moore machines}, since Moore machines were seen to be given by the special case $p=B\yon^A$ for sets $A,B$. A polynomial might be $p=B_1\yon^{A_1}+\cdots+B_k\yon^{A_k}$ (though it doesn't have to be finite), so the output is an element of the coproduct $B_1+\cdots+B_k$, and the choice of output determines what sort of input you get. What kind of output is that?

We now begin to think of outputs not only as outward expressions, but as positions that one takes within ones arena, terminology we've been using all along. If the arena is your body, this would be positions of your body. This includes where you go, as well as the direction you're looking with your head and eyes, whether your lips are pursed or not, etc. In fact, all talking and gesturing is performed by changing your position. And your position determines what inputs you'll notice: if your eyes are closed, your input type is different than if your eyes are open.

\slogan{The position you're in is a sensory organ, a hand outstretched, an eye open or closed f.}

If we squint, we could even see an output more as a sensing apparatus than anything else. This is pretty philosophical, but imagine your outputs---what you say and do---are more there as a question to the world, a way of sensing what the world is like.

But however you think of dependent systems, we need to get a feel for how they work. Let's start with something familiar.

\begin{example}\label{ex.regular_lang_stop}
Recall regular languages from \cref{def.dfa}. Often one does not want to ``keep going'' after recognizing a word in ones language. For that, rather than use a map $S\yon^S\to 2\yon^A$, we could use a map
\[
(f_1,f^\sharp)\colon S\yon^S\to \yon^A+\1
\]
To give such a map, one in particular provides a function $f_1\colon S\to\2$; here we are thinking of $\2$ as the set of positions in $\yon^A+\1$. A function $f_1$ sends some elements of $S$ to $1$ and sends others to $2$; those that are sent to $2$ are said to be ``accepted.'' This is captured by the fact that there are no options in the term $\1$, no inputs available there. In other words, the function $f^\sharp$ is trivial there.

On the other hand, $f^\sharp_s$ is not trivial on those elements $s\in S$ for which $f_1(s)=1$. They must come equipped with a function $f^\sharp_s\colon A\to S$, saying how the machine updates on each element of $A$, starting at state $s$. Again, this is in line with the way state machines encode regular languages.
\end{example}

\begin{exercise}\label{exc.det_fsa_misc_398}
Consider the deterministic finite state automaton shown below
\[
\begin{tikzcd}[column sep=small]
	\LMO{}\ar[rr, bend left, orange]\ar[loop left, dgreen]&&
	\LMO{}\ar[dl, bend left, orange]\ar[ll, dgreen, bend left]\\&
	\LMO{}
\end{tikzcd}
\]
The state without any outgoing arrows is the ``accept'' state for a regular language, and the left-most state is the start state. Answer the following questions, in keeping with the notation from \cref{ex.regular_lang_stop}.

\begin{enumerate}
	\item What is $S$?
	\item What is $A$?
	\item In terms of regular languages, what is the alphabet here?
	\item Specify the morphism of polynomials $S\yon^S\to\yon^A+1$.
	\item Name a word that is accepted by this machine.
	\item Name a word that is not accepted by this machine.
\qedhere
\end{enumerate}
\end{exercise}

\begin{example}[Graphs] \label{ex.graph_dyn}
Given a graph $G = (E \tto V)$ with source map $s \colon E \to V$ and target map $t \colon E \to V$, there is an associated polynomial
\[
    g := \sum_{v \in V} \yon^{s\inv(v)}.
\]
We call this the \emph{emanation polynomial of $G$}.

The graph itself can be seen as a dynamical system $f \colon V\yon^V \to g$, where $f_1 = \id_V$ and $f^\sharp(v, e) = t(e)$.
\end{example}

\begin{exercise}
Pick your favorite graph $G$, and consider the associated dynamical system as in \cref{ex.graph_dyn}.
Draw the associated labeled transition system as in \cref{ex.labeled_transition}.
\end{exercise}

\begin{example}[Adding a pause button]\label{ex.pause}
Given any dependent dynamical system $f\colon S\yon^S\to p$, we can ``add a pause button,'' meaning that for any state (and any position), we add an input that keeps the state where it is.

To do this, note that we have a map $\epsilon\colon S\yon^S\to\yon$ given by identity (see \cref{**}). By the universal property of products, we can pair $f$ and $\epsilon$ to get a map $(f,\epsilon)\colon S\yon^S\to p\yon\cong p\times \yon$. This process is actually universal in a way we'll find important later. Indeed, it's called \emph{copointing}; see \cref{prop.copointing}.
\end{example}

\begin{example}[Repeater]
Suppose given a dependent dynamical system $\varphi$ that sometimes outputs an element of $A$ and sometimes outputs only silence. That is, its interface is $A\yon+\yon$. But what if some other system inputs only $A$'s; we will combine $\varphi$ with another system---a repeater---to get an $A$-emitter, i.e.\ a system with interface $A\yon$. How do we construct the repeater, and how do the two systems fit together?

For the repeater, we will dispense with any interesting interface and just use $A\yon^A$: it listens for an $A$ and outputs an $A$. We enclose the two systems in an $A$-emitter using a map
\[\psi\colon (A\yon+\yon)\otimes A\yon^A\to A\yon\]
which we now describe. Since $\otimes$ distributes over $+$, it suffices to give maps $A\yon\otimes A\yon^A\to A\yon$ and $\yon\otimes A\yon^A\to A\yon$. The former corresponds to the case that the system is currently outputting, and the second corresponds to when the system is silent. For the former we use the map
\[
A\yon\otimes A\yon^A\cong (A\yon\otimes\yon^A)\otimes A\yon\To{\epsilon\otimes\id}\yon\otimes A\yon
\]
In other words, we output the repeater's position as the current $A$, and we update the repeater's position to the system's current state.

For the latter it suffices---by the universal property of products---to give $A\yon^A\to\yon$ and $A\yon^A\to A$. For the first we use $\epsilon$, which means that during silence, the repeater holds the $A$ constant; for the second we use the product projection, which means that we output the current value of the repeater.
\end{example}

\begin{example}[Inputting a start state]
Suppose you have a closed system $f^\sharp\colon S\yon^S\to\yon$. The modeler can choose a start state $\yon\to S\yon^S$, but what if we want some other system to choose the start state? We haven't gotten to wiring diagrams yet, but the idea is to create a system that starts as not-closed---accepting as input a state $s\in S$---and then dives into its closed loop with that start state.

Let $S'\coloneqq S+\1$, so that the start state $\yon\to S'\yon^{S'}$ now is canonical: it's the new $\1$. We also have a canonical inclusion $S\To{i}S'$. We will give a morphism
\[
S'\yon^{S'}\to\yon+\yon^S
\]
that starts out with its outer box in the mode $\yon^S$ of accepting an $S$-input, and then moves to the mode $\yon$ so that it is a closed system forever after.

To give a morphism $S'\yon^{S'}\to\yon+\yon^S$, it is sufficient to give two morphisms: $S\yon^{S'}\to\yon$ and $\yon^{S'}\to\yon^S$. The first is equivalent to a function $S\to S'$ and we take the map $S\To{f^\sharp}S\To{i}S'$; this means that whenever we want to update the state from a state in $S$ we'll just do whatever our original closed system did. The second is also equivalent to a function $S\to S'$ and we use $i$; this means that whatever state is input at the beginning will be what we take as our first noncanonical state.
\end{example}

\begin{exercise}
Find what you think is an interesting generalization of deterministic finite state automata that you can model using generalized Moore machines.
\end{exercise}

\begin{example}\label{ex.movement_options}
Choose $n\in\nn$, a \emph{grid size}, and for each $i\in\ord{n}=\{1,\ldots,n\}$ let $d(i)$ be the set
\[
	d(i)\coloneqq
	\begin{cases}
		\{0,1\}&\tn{ if }i=1\\
		\{-1,0\}&\tn{ if }i=n\\
		\{-1,0,1\}&\tn{ if } 1<i<n
	\end{cases}
\]
So $d(i)$ is the set of directions someone could move (or not move) if at position $i$.
\[
\begin{tikzpicture}[scale=.5]
  \draw[step=1cm,gray,very thin] (-3,-3) grid (4,4);
	\draw[->, red ] (-2.5,3.5) -- (-1.5, 3.5);
	\draw[->, red ] (-2.5,3.5) -- (-1.5, 2.5);
	\draw[->, red ] (-2.5,3.5) -- (-2.5, 2.5);
	\draw[->, blue] (1.5, 0.5) -- (0.5, 0.5);
	\draw[->, blue] (1.5, 0.5) -- (2.5, 0.5);
	\draw[->, blue] (1.5, 0.5) -- (1.5, 1.5);
	\draw[->, blue] (1.5, 0.5) -- (1.5,-0.5);
	\draw[->, blue] (1.5, 0.5) -- (0.5, 1.5);
	\draw[->, blue] (1.5, 0.5) -- (0.5,-0.5);
	\draw[->, blue] (1.5, 0.5) -- (2.5, 1.5);
	\draw[->, blue] (1.5, 0.5) -- (2.5,-0.5);
\end{tikzpicture}
\]
Then a generalized Moore machine of the form $S\yon^S\to p$, where
\[
p= \sum_{(i,j)\in\ord{n}\times\ord{n}}\yon^{d(i)\times d(j)},
\]
is one that has more movement options when it is in the center of the grid than when it is on the sides or corners.
\end{example}

\begin{exercise}
Add to \cref{ex.movement_options} as follows.
\begin{enumerate}
	\item Redefine $p$ so that at each grid value, the robot can receive not only the set of directions it can move in but also a ``reward value'' $r\in\rr$. 
	\item Define the set $S$ of robot states so that an element $s\in S$ includes both the robot's position and a list of all reward values so far.
	\item Define a morphism of polynomials $S\yon^S\to p$ in a way that respects positions and properly updates the robots list of rewards, but otherwise does anything you want.
\qedhere
\end{enumerate}
\end{exercise}

\begin{example}\label{ex.generalized_file_reader}
In \cref{exc.file_reader} one is tasked with making a file reader $\Sys{FileReader}$, where a file is a function $f\colon\ord{n}\to\Set{ascii}$. Now we take that same idea but make the robot have a different interface when it is in read-mode: namely, one where it cannot take in signals.

Let $\State{FileReader} \coloneqq \{(s,t)\mid 1\leq s\leq t\leq n\}$ consist of a
current position $s$ and a terminal position $t$. For our interface, we'll have
two modes, each of which exposes an ascii character:
\[\Out{FileReader} = \present{ \fun{Accepting}(c),\, \fun{Busy}(c) \mid c \in \Set{ascii} }
\]
%%
%% Jaz: In Haskell, this would read
%%      data \Out{FileReader} = Accepting ascii | Busy ascii
%%
For our input, we need a family $\In{FileReader} : \Out{FileReader} \to \smset$.
We'll define this by cases:
\begin{align*}
  \In{FileReader}(\fun{Accepting}(c)) &= \State{FileReader}, \\
  \In{FileReader}(\fun{Busy}(c)) &= \ord{1}.
\end{align*}

Our file reader will be $\fun{Accepting}$ if its current position is the
terminal position; otherwise, it will be $\fun{Busy}$. In either case, it will
expose the ascii character at the current position.
\begin{align*}
  \expose{FileReader}(s, t) = \begin{cases} \fun{Accepting}(f(s)) &\mbox{if $s = t$}\\ \fun{Busy}((f(s)))  \end{cases}
\end{align*}

While the file reader is $\fun{Busy}$, it will step forward through the file.
When it is $\fun{Accepting}$, it will set its new current and terminal position
to be the input. 
\begin{align*}
  \update{FileReader}(s, t) = \begin{cases} \_ \mapsto (s + 1, t) &\mbox{if $\expose{FileReader}(s, t)$ is $\fun{Busy}$} \\ (s', t') \mapsto (s', t') &\mbox{if $\expose{FileReader}(s, t)$ is $\fun{Accepting}$}  \end{cases}
\end{align*}

Let $A\coloneqq\{(s,t)\mid 1\leq s\leq t\leq n\}$, and let $p\coloneqq \Set{ascii}\mdot\yon^A+\Set{ascii}\mdot\yon^\1$; we construct a morphism in $\poly$
\[
(r_1,r^\sharp)\colon A\yon^A\to \Set{ascii}\mdot\yon^A+\Set{ascii}\mdot\yon^\1
\]
as follows.

\[A + B = \langle \fun{inl}(a), \fun{inr}(b) \mid a \in A, b \in B \rangle\]

\[A +_C B = \langle \fun{inl}(a), \fun{inr}(b) \mid a \in A, b \in B, \forall c
\in C.
\fun{inl}(f(c)) = \fun{inr}(g(c)) \rangle\]


On positions define
\[
	r_1(s,t)\coloneqq
	\begin{cases}
		\const{inl}\ f(s)&\tn{ if } s=t\\
		\const{inr}\ f(s)&\tn{ if } s<t
	\end{cases}
\]

\[
	r^\sharp_{(t,t)}(s',t')\coloneqq (s',t')
	\qquad
	r^\sharp_{(s,t)}(1)\coloneqq (s+1,t)
\]
\end{example}

\begin{exercise}
Make a file reader that acts like that in \cref{ex.generalized_file_reader}, except that it only emits output $o\in\Set{ascii}$ when $o=100$.
\end{exercise}

%---- Subsection ----%
\subsection{Wiring diagrams}

We want our dynamical systems to interact with each other.
\begin{equation}\label{eqn.control_diag}
\begin{tikzpicture}[oriented WD, baseline=(B)]
	\node[bb={2}{1}, fill=blue!10] (plant) {\texttt{Plant}};
	\node[bb={1}{1}, below left=-1 and 1 of plant, fill=blue!10]  (cont) {\texttt{Controller}};
	\node[circle, inner sep=1.5pt, fill=black, right=.1] at (plant_out1) (pdot) {};
	\node[bb={0}{0}, inner ysep=25pt, inner xsep=1cm, fit=(plant) (pdot) (cont)] (outer) {};
	\coordinate (outer_out1) at (outer.east|-plant_out1);
	\coordinate (outer_in1) at (outer.west|-plant_in1);
	\begin{scope}[above, font=\footnotesize]
  	\draw (outer_in1) -- node {$A$} (plant_in1);
  	\draw (cont_out1) to node (B) {$B$} (plant_in2);
  	\draw (plant_out1) to node {$C$} (outer_out1);
  	\draw
  		let 
  			\p1 = (cont.south west-| pdot),
  			\p2 = (cont.south west),
  			\n1 = \bby,
  			\n2 = \bbportlen
  		in
  			(pdot) to[out=0, in=0]
  			(\x1+\n2, \y1-\n1) --
  			(\x2-\n2, \y2-\n1) to[out=180, in=180]
  			(cont_in1);
		\end{scope}
	\node[below=0of outer.north] {\texttt{System}};
\end{tikzpicture}
\end{equation}
In this picture the plant is receiving information from the world outside the system, as well as from the controller. It's also producing information for the outside world which is being monitored by the controller.

There are three boxes shown in \eqref{eqn.control_diag}: the controller, the plant, and the system. Each has inputs and outputs, and so we can consider the interface as a monomial.
\begin{equation}\label{eqn.basic_diagram}
	\const{Plant}=C\yon^{AB}
	\qquad\quad
	\const{Controller} = B\yon^C
	\qquad\quad
	\const{System} = C\yon^A.
\end{equation}

The wiring diagram itself is a morphism in $\poly$ of the form
\[
	w\colon\const{Plant}\otimes\const{Controller}\to\const{System}
\]
Since everything involved is a monomial---the parallel product of monomials is a monomial---the whole wiring diagram $w$ is a lens $CB\yon^{ABC}\to C\yon^A$. This morphism says how wires are feeding from outputs to inputs. Like all lenses, it consists of two functions
\[
  \text{get}\colon CB\to C
  \qqand
  \text{put}\colon CBA\to ABC
\]
The first says ``inside the system you have boxes outputting values of type $C$ and $B$. The system needs to produce an output of type $C$; how shall I obtain it?'' The second says ``the system is providing an input value of type $A$, and inside the system you have boxes outputting values of type $C$ and $B$. These boxes need input values of type $A$, $B$, and $C$; how shall I obtain them?'' The answer of course is that \emph{get} is given by projection $(c,b)\mapsto c$ and \emph{put} is given by a permutation $(c,b,a)\mapsto (a,b,c)$. The wiring diagram is a picture that tells us which maps to use.

\begin{exercise}
\begin{enumerate}
	\item Make a new wiring diagram like \eqref{eqn.control_diag} except where the controller also receives information of type $A'$ from the outside world.
	\item What are the monomials in your diagram (replacing \eqref{eqn.basic_diagram})?
	\item What is the morphism of polynomials corresponding to this diagram?
\qedhere
\end{enumerate}
\end{exercise}

Now suppose given a dynamical system in each inner box:
\[
S\yon^S\To{f}\const{Plant}
\qqand
T\yon^T\To{g}\const{Controller}
\]
Then since $\otimes$ is a monoidal product on $\poly$ (see \cref{prop.dirichlet_monoidal}), we get a map
\[
S\yon^S\otimes T\yon^T\To{f\otimes g}\const{Plant}\otimes\const{Controller}
\]
In other words we have a morphism of polynomials $ST\yon^{ST}\to \const{Plant}\otimes\const{Controller}$; that's a new dynamical system with state space $ST=(S\times T)$; a state in it is just a pair of states, one in $S$ and one in $T$. Furthermore our wiring diagram already gave us a map $\const{Plant}\otimes\const{Controller}\to\const{System}$, so combining, we have a new system
\[
ST\yon^{ST}\to\const{System}.
\]

\begin{exercise}
Consider the following wiring diagram.
\[
\begin{tikzpicture}[oriented WD, font=\footnotesize, bb port sep=1, bb port length=2.5pt, bb min width=.4cm, bby=.2cm, inner xsep=.2cm, x=.5cm, y=.3cm, text height=1.5ex, text depth=.5ex]
   	\node[bb={2}{1}, fill=blue!10] (Trf) {$\const{Alice}$};
  	\node[bb={1}{2}, fill=blue!10, below=1 of Trf] (Trg) {$\const{Bob}$};
		\node[bb={2}{2}, fill=blue!10] at ($(Trf)!.5!(Trg)+(1.5,0)$) (Trh) {$\const{Carl}$}; 
  	\node[bb={0}{0}, fit={($(Trf.north west)+(-.25,4)$) (Trg) ($(Trh.north east)+(.25,0)$)}] (Tr) {};
		\node[below] at (Tr.north) {$\const{Team}$};
  	\node[coordinate] at (Tr.west|-Trf_in2) (Tr_in1) {};
  	\node[coordinate] at (Tr.west|-Trg_in1) (Tr_in2) {};
  	\node[coordinate] at (Tr.east|-Trh_out2) (Tr_out1) {};
  	\node at ($(Trg_out2)+(5pt,0)$) (dot) {$\bullet$};
\begin{scope}[font=\tiny]
  	\draw[shorten <=-2pt] (Tr_in1) -- node[below=-3pt] {$A$} (Trf_in2);
  	\draw[shorten <=-2pt] (Tr_in2) -- node[below=-3pt] {$B$} (Trg_in1);
		\draw (Trf_out1) to node[above=-3pt] {$D$} (Trh_in1);
		\draw (Trg_out1) to node[above=-3pt] {$E$} (Trh_in2);
  	\draw (Trg_out2) -- node[below=-3pt] {$F$} (dot.center);
  	\draw[shorten >=-2pt] (Trh_out2) -- node[below=-3pt] {$G$} (Tr_out1);
  	\draw let \p1=(Trh.east), \p2=(Trf.north west), \n1=\bbportlen, \n2=\bby in
  		(Trh_out1) to[in=0] (\x1+\n1,\y2+\n2) -- node[pos=.3, below=-3pt] {$H$} (\x2-\n1,\y2+\n2) to[out=180] (Trf_in1);
	\end{scope}
\end{tikzpicture}
\]
\begin{enumerate}
	\item Write out the polynomials for each of Alice, Bob, and Carl.
	\item Write out the polynomial for the outer box, Team.
	\item The wiring diagram constitutes a morphism $f$ in $\poly$; what is its type $f\colon ?\to ?$
	\item What morphism is it?
	\item Suppose we are given dynamical systems $A\yon^A\to\const{Alice}$, $B\yon^B\to\const{Bob}$, and $C\yon^C\to\const{Carl}$. What is the induced dynamical system on $\const{Team}$?
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}[Long division]
\begin{enumerate}
	\item Come up with a function ``divmod'' of type $\nn\times\nn_{\geq1}\to\nn\times\nn$ and which, for example, sends $(10,7)$ to $(1,3)$ and $(30,7)$ to $(4,2)$.
	\item Use \cref{exc.funs_to_moore} to turn it into a dynamical system.
	\item Interpret the following wiring diagram:
\[
\begin{tikzpicture}[oriented WD, bb small]
	\node[bb port sep=3, fill=blue!10, bb={2}{2}] (divmod) {divmod};
	\node[bb={0}{1}, fill=blue!10, left=of divmod_in2] (7) {$7$};
	\node[bb port sep=2, bb={2}{1}, fill=blue!10, below right=-1 and 3 of divmod_out2] (times) {$*$};
	\node[bb={0}{1}, fill=blue!10, below left=-1 and 1 of times_in2] (10) {$10$};
	\node[bb={0}{0}, inner xsep=\bbx, fit=(divmod) (times)(7) (10)] (outer) {};
	\coordinate (outer_in1) at (outer.west|-divmod_in1);
	\coordinate (outer_out1) at (outer.east|-divmod_out1);
	\coordinate (outer_out2) at (outer.east|-times_out1);
	\draw (outer_in1) -- (divmod_in1);
	\draw (7_out1) -- (divmod_in2);
	\draw (10_out1) -- (times_in2);
	\draw (divmod_out1) -- (outer_out1);
	\draw (divmod_out2) to (times_in1);
	\draw (times_out1) -- (outer_out2);
\end{tikzpicture}
\]
	\item Use the above and a diagram of the following form to create a function that spits out the base-10 digits of $1/7$.
\[
\begin{tikzpicture}[oriented WD]
	\node[bb={1}{2}, fill=blue!10] (inner) {};
	\node[bb={0}{0}, inner xsep=1cm, inner ysep=1cm] (outer) {};
	\coordinate (outer_out1) at (outer.east|-inner_out1);
	\draw[shorten >=-3pt] (inner_out1) -- (outer_out1);
	\draw 
		let \p1=(inner.south east), \p2=(inner.south west), \n1=\bbportlen, \n2=\bby in
		(inner_out2) to[in=0] (\x1+\n1,\y1-\n2) -- (\x2-\n1,\y1-\n2) to[out=180] (inner_in1);
		\node[right, font=\footnotesize] at (outer_out1) {$0.142857142857142857\cdots$};
\end{tikzpicture}
\]
\end{enumerate}
\end{exercise}

\begin{example}[Graphs as interaction diagrams]\label{ex.graph_interaction}
Suppose given a graph $G$ and a set $\tau(v)$ for every vertex
\[
\begin{tikzcd}
	A\ar[r, shift left=3pt, "\src"]\ar[r, shift right=3pt, "\tgt"']&
	V\ar[r, "\tau"]&
	\smset
\end{tikzcd}
\]
For each vertex $v\in V$, let $A_v\coloneqq\src\inv(v)\ss A$ denote the arrows emanating from $v$, and define the monomial
\[
	p_v\coloneqq\tau(v)\yon^{\prod_{a\in A_v}\tau(\tgt\ a)}
\]
From this data we can give a morphism
\[
\bigotimes_{v\in V}p_v\Too{\varphi}\yon.
\]
To do so, we just need a function of the form
\[
\prod_{v\in V}\tau(v)\too\prod_{v\in V}\prod_{a\in A_v}\tau(\tgt\ a)
\]
We use $f\mapsto v\mapsto a\mapsto f(\tgt\ a)$.

The map $\varphi$ wires together the interfaces $p_v$, over all vertices $v\in V$, inside a closed outer box. That way, once we instantiate each $p_v$ with a dynamical system $S\yon^S\to p_v$---one that outputs $\tau(v)$ and inputs $\prod_{a\in A_v}\tau(\tgt\ a)$---they will all interact together as specified by the graph.

For example, a common graph found in cellular automata is a 2-dimensional integer lattice, with vertices $V\coloneqq\zz\times\zz$. The \emph{stencil} indicates which vertices ``hear'' which other vertices. One might use
\[A\coloneqq\{-1,0,1\}\times\{-1,0,1\}\times V\]
with $\src(i,j,m,n)=(m,n)$ and $\tgt(i,j,m,n)=(m+i, n+j)$.
\end{example}

\begin{exercise}[Conway's Game of Life]\label{exc.conway}
This exercise is for those who are familiar with Conway's Game of Life. We will use \cref{ex.graph_interaction}.
\begin{enumerate}
	\item What is the appropriate graph $A\tto V$?
	\item What is the appropriate function $\tau\colon V\to\smset$?
	\item What are the polynomials $p_v$ from \cref{ex.graph_interaction}?
	\item What is the appropriate state set $S_v$ for each interface $p_v$?
	\item What is the appropriate dynamical system map $S_v\yon^{S_v}\to p_v$?
\qedhere
\end{enumerate}
\end{exercise}

%\begin{exercise}[Cellular automata]\label{exc.cellular_automata}
%Let $G=(V,E)$ be a simple graph, i.e.\ $V,E\in\smset$ and $E\ss V\times V$. You can imagine it as a grid 
%\[
%\begin{tikzcd}[shift left=2pt]
%	\LMO{(1,1)}\ar[r]      \ar[d]&
%	\LMO{(1,2)}\ar[r]\ar[l]\ar[d]&
%	\LMO{(1,3)}\ar[r]\ar[l]\ar[d]&
%	\LMO{(1,4)}\ar[r]\ar[l]\ar[d]&
%	\LMO{(1,5)}      \ar[l]\ar[d]\\
%	\LMO{(2,1)}\ar[r]      \ar[d]\ar[u]&
%	\LMO{(2,2)}\ar[r]\ar[l]\ar[d]\ar[u]&
%	\LMO{(2,3)}\ar[r]\ar[l]\ar[d]\ar[u]&
%	\LMO{(2,4)}\ar[r]\ar[l]\ar[d]\ar[u]&
%	\LMO{(2,5)}      \ar[l]\ar[d]\ar[u]\\
%	\LMO{(3,1)}\ar[r]      \ar[d]\ar[u]&
%	\LMO{(3,2)}\ar[r]\ar[l]\ar[d]\ar[u]&
%	\LMO{(3,3)}\ar[r]\ar[l]\ar[d]\ar[u]&
%	\LMO{(3,4)}\ar[r]\ar[l]\ar[d]\ar[u]&
%	\LMO{(3,5)}      \ar[l]\ar[d]\ar[u]\\
%	\LMO{(4,1)}\ar[r]      \ar[d]\ar[u]&
%	\LMO{(4,2)}\ar[r]\ar[l]\ar[d]\ar[u]&
%	\LMO{(4,3)}\ar[r]\ar[l]\ar[d]\ar[u]&
%	\LMO{(4,4)}\ar[r]\ar[l]\ar[d]\ar[u]&
%	\LMO{(4,5)}      \ar[l]\ar[d]\ar[u]\\
%	\LMO{(5,1)}\ar[r]            \ar[u]&
%	\LMO{(5,2)}\ar[r]\ar[l]      \ar[u]&
%	\LMO{(5,3)}\ar[r]\ar[l]      \ar[u]&
%	\LMO{(5,4)}\ar[r]\ar[l]      \ar[u]&
%	\LMO{(5,5)}      \ar[l]      \ar[u]
%\end{tikzcd}
%\]
%finite or infinite, or just an arbitrary graph. For every vertex $v$, the set of vertices $v'$ for which $(v',v)\in E$, i.e.\ for which there is an edge $v'\to v$, is denoted
%\[I(v)\coloneq\{v'\mid (v',v)\in E\}.\]
%For each $v\in V$, let $p_v\coloneqq \2\yon^{\2^{I(v)}}$; it ``outputs'' a color $\2\cong\{\const{black},\const{white}\}$ and inputs a function $I(v)\to\2$, specifying what all the neighbors are outputting.
%\begin{enumerate}
%	\item In the drawn grid, what is $I(1,1)$? What is $I(2,2)$?
%	\item Specify a morphism $g\colon \bigotimes_{v\in V}p_v\to\yon$ that passes to each vertex $v$ the colors of its neighbors in $I(v)$.
%	\item Suppose that for each vertex $v\in V$ you are given a function $f_v\colon 2^{I(v)}\to\2$. Use it to construct a dynamical system $f'_v\colon\2\yon^\2\to p_v$ that updates its state in keeping with $f_v$ and outputs its state directly.
%	\item Briefly look up cellular automata in a reference of your choice. Would you say that the dynamical system $\bigotimes_{v\in V}\2\yon^\2\To{\bigotimes f'_v}\bigotimes_{v\in V}p_v\To{g}\yon$ we obtain by wiring together the dynamical systems in the specified way does the same thing as the cellular automata in your reference?
%\qedhere
%\end{enumerate}
%\end{exercise}

%---- Subsection ----%
\subsection{General interaction}

In general, we want systems that can change their interface---remove a port, add a port, change the type of a port, etc.---based on their internal states. But when such systems interact with others, the interaction pattern must be able to accommodate all of the various combinations of interfaces.

\begin{example}
Suppose given two interfaces $p$ and $p'$, having mode sets $M$ and $M'$ respectively
\[
	p\coloneqq \sum_{m\in M} B_m\yon^{A_m}
	\qqand
	p'\coloneqq \sum_{m'\in M'} B'_m\yon^{A'_m}
\]
The parallel product of these is:
\[
p\otimes p'\cong \sum_{(m,m')\in MM'}B_mB'_m\yon^{A_mA'_m}
\]
so the interface $B_mB'_{m'}\yon^{A_mA'_{m'}}$ at each of these $(M\times M')$-many modes $(m,m')$ must be accommodated in any morphism $w\colon p\otimes p'\to q$. For example if $M=\2$ and $M'=\3$ then $w$ can be specified by six maps.
\end{example}

But in fact the possibilities for interaction are much more general than we have led the reader to believe. They may not be broken down into modes at all.

\begin{example}
Let $p\coloneqq B\yon^A$ and $p'=B'\yon^{A'}$. To give a morphism $f\colon p\otimes p'\to \yon$, one specifies a map $B\times B'\to \1$, which is no data, as well as a map $BB'\to AA'$. In other words, for every pair of outputs $(b,b')$ one specifies a pair of inputs $(a,a')$. 

Let's think of elements of $B$ and $B'$ not as outputs, but as positions. 
\[
\begin{tikzpicture}[oriented WD, bb port length=0]
	\node[bb={1}{0}, fill=blue!10, dotted] (p) {$b$};
	\node[bb={1}{0}, fill=blue!10, dotted, below right=-0.5 and 0.5 of p] (q) {$b'$};
	\node[bb={0}{0}, inner sep=10pt, fit=(p) (q)] {};
	\node at (p_in1) {\faEye};
	\node at (q_in1) {\faEye};
\end{tikzpicture}
\hspace{.5in}
\begin{tikzpicture}[oriented WD, bb port length=0]
	\node[bb={1}{0}, fill=blue!10, dotted] (p) {$b$};
	\node[bb={1}{0}, fill=blue!10, dotted, below left=-0.5 and 0.5 of p] (q) {$b'$};
	\node[bb={0}{0}, inner sep=10pt, fit=(p) (q)] {};
	\node at (p_in1) {\faEye};
	\node at (q_in1) {\faEye};
\end{tikzpicture}
\]
Then given both positions $(b,b')$, the interaction pattern $f$ tells us what the two eyes see, i.e. what values of $(a,a')$ we get.
\end{example}

\begin{example}
Suppose you have two systems $p,q$, both having the same type $p=q\coloneqq\rr^2\yon^{\rr^2-(0,0)}$. 
\[
\begin{tikzpicture}
	\node (m1) {\faMotorcycle};
	\node[above=-.15 of m1] (e1) {\faEye};
	\node[draw, thick, blue!10, fit = (m1) (e1)] {};
	\node[below right=0 and 1 of m1] (m2) {\scalebox{-1}[1]{\faMotorcycle}};
	\node[above=-.15 of m2] (e2) {\faEye};
	\node[draw, thick, blue!10, fit = (m2) (e2)] {};
\end{tikzpicture}
\]
Taking all pairs of reals except $(0,0)$ corresponds to the fact that the eye cannot see that which is at the same position as the eye.

Let's have the two systems constantly approaching each other with a force equal to the reciprocal of the squared distance between them. If they finally collide, let's have the whole thing come to a halt.

To do this, we want the outer system to be of type $\{\const{go}\}\yon+\{\const{stop}\}$. The morphism $\rr^2\yon^{\rr^2-(0,0)}\otimes\rr^2\yon^{\rr^2-(0,0)}\to\{\const{go}\}\yon+\{\const{stop}\}$ is given on positions by
\[
  \big((x_1,y_1),(x_2,y_2)\big)\mapsto
	\begin{cases}
		\const{stop}&\mbox{ if $x_1=x_2$ and $y_1=y_2$}\\
		\const{go}&\mbox{ otherwise}.
	\end{cases}
\]
On directions, we use the function
\[
  \big((x_1,y_1),(x_2,y_2)\big)\mapsto \big((x_2-x_1,y_2-y_1),(x_1-x_2,y_1-y_2)\big),
\]
so that each system is able to see the vector pointing from it to the other system (unless that vector is zero, in which case the whole thing has halted). 

Let's use these vectors to define the internal dynamics of each system. Each system will hold as its internal state its current position and velocity, i.e.\ $S=\rr^2\times\rr^2$. To define a map of polynomials $S\yon^S\to\rr^2\yon^{\rr^2-(0,0)}$ we simply output the current position and update the current velocity by adding a vector pointing to the other system and having appropriate magnitude:
\begin{align*}
	\rr^2\times\rr^2&\To{\text{get}}\rr^2\\
	\big((x,y),(x',y')\big)&\Mapsto{\text{get}}(x,y)
\end{align*}
\begin{align*}
	\rr^2\times\rr^2\times(\rr^2-(0,0))&\To{\text{put}}\rr^2\times\rr^2\\
	\big((x,y),(x',y'),(a,b)\big)&\Mapsto{\text{put}}\left(x+x',y+y',x'+\frac{a}{(a^2+b^2)^{3/2}},y'+\frac{b}{(a^2+b^2)^{3/2}}\right)
\end{align*}
\end{example}

\begin{exercise}
Let $p,q\coloneqq\nn\yon^\nn$.
\begin{enumerate}
	\item Write a polynomial morphism $p\otimes q\to\yon$ that corresponds to the function $(a,b)\mapsto (b,a+b)$.
	\item Write dynamical systems $\nn\yon^\nn\to p$ and $\nn\yon^\nn\to q$, each of which simply outputs the previous input.
	\item Suppose each system starts in state $1\in\nn$. What is the trajectory of the $p$-system?
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}
Suppose $(X,d)$ is a metric space, i.e.\ $X$ is a set and $d\colon X\times X\to\rr$ is a function satisfying the usual laws. Let's have robots interact in this space.

Let $A,A'$ be sets, each thought of as a set of signals, and let $a_0\in A$ and $a_0'\in A'$ be elements, each thought of as a default value. Let $p\coloneqq AX\yon^{A'X}$ and $p'\coloneqq A'X\yon^{AX}$, and imagine there are two robots, one with interface $p$ and one with interface $p'$.
\begin{enumerate}
	\item Write down a morphism $p\otimes p'\to\yon$ such that each robot receives the other's location, but that it only receives the other's signal when the locations $x,x'$ are sufficiently close, $d(x,x')<1$. Otherwise it receives the default signal.
	\item Write down a morphism $p\otimes p'\to\yon^{[0,5]}$ where the value $s\in [0,5]$ is a scalar, allowing the signal to travel $s$ times further.
	\item Suppose that each robot has a set $S,S'$ of private states. What functions are involved in providing a dynamical system $f\colon SX\yon^{SX}\to AX\yon^{A'X}$?
	\item Change the setup in any way so that the robots only extend a port to hear the other's signal when the distance between them is less than 1. Otherwise, they can only detect the position (element of $X$) that the other currently inhabits.
\qedhere
\end{enumerate}
\end{exercise}

So what is a map $p_1\otimes\cdots\otimes p_k\to q$ in general? It's a protocol by which he $k$-many participants $p_i$ together decide what decision $q$ must make, as well as how $q$'s choice among its options (the decision once made) is passed back and distributed as an option at each $p_i$.

\begin{example}[Cellular automata who vote on their interaction pattern]\label{ex.cell_auto_vote_interaction}
Recall from \cref{exc.cellular_automata} how we constructed cellular automata on a graph $G=(V,E)$. Here $E\ss V\times V$, or equivalently what we might call an \emph{interaction pattern} $I\colon V\to \2^V$, specifies the incoming neighbors $I(v)$ of each $v\in V$.

Suppose now that we are given a function $i\colon V\to\nn$ that we think of as specifying the number $i(v)$ of neighbors each $v\in V$ accepts. Let $\ord{i}(v)=\{1,2,\ldots, i(v)\}$. We will be interested in the polynomial $p_v\coloneqq\2\yon^{\2^{\ord{i}(v)}}$ for each $v$; it represents an interface that outputs a color $\2\cong\{\const{black},\const{white}\}$ and that inputs a function $\ord{i}(v)\to\2$, meant to give the colors of the neighboring vertices.

Say that an interaction pattern $I\colon V\to\2^V$ \emph{respects} $i$ if we have an isomorphism $I(v)\cong\ord{i}(v)$ for each $v\in V$. Suppose given a function $I\colon \2^V\to (\2^V)^V$ such that for each element $s\in\2^V$, the interaction pattern $I_s\colon V\to \2^V$ respects $i$. In the case of \cref{exc.cellular_automata}, $I$ was a constant function. Now we can think of it like all the vertices are voting, via $I$, on the connection pattern. 

We can put this all together by giving a morphism in $\poly$ of the form
\begin{equation}\label{eqn.polymap_misc9237}
\bigotimes_{v\in V}p_v\cong\2^V\yon^{\2^{\sum_{v\in V}\ord{i}(v)}}\too\yon.
\end{equation}
We can such a morphism with a function $g\colon \2^V\to\2^{\sum_{v\in V}\ord{i}(v)}$. Suppose given $s\in\2^V$, so that we have an isomorphism $I_s(v)\cong\ord{i}(v)$ for each $v\in V$; we want a function $g(s)\colon\sum_{v\in V}I_s(v)\to\2$. That is, for each $v$ we want a function
\[
g(s)_v\colon I_s(v)\to\2.
\]
But $I_s(v)\ss V$, so our function $s\colon V\to\2$ induces the desired function $I_s(v)\to\2$.

We have accomplished our goal: the automata vote on their connection pattern. Of course, we don't mean to imply that this vote needs to be democratic or fair in any way: it is an arbitrary function $I\colon \2^V\to(\2^V)^V$. It could be dictated by a given vertex $v_0\in V$ in the sense that its on/off state completely determines the connection pattern $V\times V\to \2$; this would be expressed by saying that $I$ factors as $\2^V\to\2^{v_0}\cong\2\To{I_0}(\2^V)^V$ for some $I_0$.
\end{example}

\begin{exercise}
Change \cref{ex.cell_auto_vote_interaction} slightly by changing the outer box.
\begin{enumerate}
	\item First change it to $A\yon$ for some set $A$ of your choice, and update \eqref{eqn.polymap_misc9237} so that the system outputs some aspect of the current state $\2^V$.
	\item What would it mean to change \eqref{eqn.polymap_misc9237} to a map $\bigotimes_{v\in V}p_v\to\yon^A$ for some $A$?
\qedhere
\end{enumerate}
\end{exercise}

\begin{example}\label{ex.bonds_break}
Recall the picture from \cref{ex.intro_examples_bonds_supplier_assemble}. We said that when too much force is applied to a material, bonds can break. Let's simplify the picture a bit.
\[
\begin{tikzpicture}[oriented WD, bb small, bb port length=0]
	\node[bb={1}{1}, fill=blue!10] (x1) {$\Phi_1$};
	\node[bb={1}{1}, fill=blue!10, right=of x1] (x2) {$\Phi_2$};
	\node[bb={1}{1}, fit= (x1) (x2)] (outer) {};
	\draw[->, shorten >= -4mm] (x1_in1) -- (outer_in1) node[left=4.5mm, font=\tiny] {Force};
	\draw (x1_out1) -- (x2_in1);
	\draw[->, shorten >= -4mm] (x2_out1) -- (outer_out1) node[right=4.5mm, font=\tiny] (L) {Force};
%
	\node[bb={1}{1}, fill=blue!10, right=2in of L] (y1) {$\Phi_1$};
	\node[bb={1}{1}, fill=blue!10, right=of y1] (y2) {$\Phi_2$};
	\node[bb={1}{1}, fit= (y1) (y2)] (outer) {};
	\draw[->, shorten >= -4mm] (y1_in1) -- (outer_in1) node[left=4.5mm, font=\tiny] (R){Force};
	\draw[->, shorten >= -4mm] (y2_out1) -- (outer_out1) node[right=4.5mm, font=\tiny] {Force};
	\node[starburst, draw, minimum width=2cm, minimum height=1.5cm,red,fill=orange,line width=1.5pt] at ($(L)!.5!(R)$)
{Snap!};
\end{tikzpicture}
\]
We will imagine systems $\Phi_1$ and $\Phi_2$ as initially connected in space, that they experience forces from the outside world, and that---for as long as they are connected---they experience forces from each other. More precisely, each internal arena is defined by
\[
	p_1=p_2\coloneqq F\yon^{FF}+\yon^F.
\]
Elements of $F$ will be called \emph{forces}. We need to be able to add and compare forces, i.e.\ we need $F$ to be an ordered monoid; let's say $F=\nn$ for simplicity. The idea is that the arena has two modes: the monomial $F\yon^{FF}$ consisting of two input forces (one from its left and one from its right) and an output force $f_i$, and the monomial $\yon^F$ consisting of one input force (just from the outside). Similarly, in the first mode the system $\Phi_i$ is outputting a force for the other---whether the other uses it or not---but in the second mode the system produces no force for the other.

The external arena is defined to be
\[
p\coloneqq\yon^{FF};
\]
it takes as input two forces $(f_L, f_R)$ and produces unchanging output.

Though the systems $\Phi_1$ and $\Phi_2$ may be initially connected, if the forces on either one surpass a threshold, that system stops sending and receiving forces from the other. The connection is broken and neither system ever receives forces from the other again. This is what we will implement explicitly below.

To do so, we need to create a contract $p_1\otimes p_2\to p$ of the external arena $p$ around (the arenas of) the internal systems. That is, we need to give a morphism of polynomials
\[
\kappa\colon (F\yon^{FF}+\yon^F)\otimes (F\yon^{FF}+\yon^F)\to\yon^{FF}.
\]
By distributivity and the universal property of coproducts, it suffices to give four maps:
\[\arraycolsep=1.4pt
\begin{array}{lll}
	\kappa_{11}\colon&~ FF\yon^{(FF)(FF)}&\to\yon^{FF}\\
	\kappa_{12}\colon&~ F\yon^{(FF)F}&\to\yon^{FF}\\
	\kappa_{21}\colon&~ F\yon^{F(FF)}&\to\yon^{FF}\\
	\kappa_{22}\colon&~ \yon^{FF}&\to\yon^{FF}
\end{array}
\]
The middle two maps $\kappa_{12}$ and $\kappa_{21}$ won't actually occur in our dynamics, so we take them to be arbitrary. We take the last map $\kappa_{22}$ to be an identity (the forces from outside are passed to the two internal boxes). The first map $\kappa_{11}$ is equivalent to a function $(FF)(FF)\to (FF)(FF)$ which we take to be $((f_1,f_2),(f_L,f_R))\mapsto((f_L, f_2),(f_1,f_R))$.

Now that we have the arenas wired together, it remains to give the dynamics on the internal boxes. The states in the two cases will be identical, namely $S\coloneqq F+1$, meaning that at any point the system will either be in the state of holding a force or not. The dynamics will be identical as well, up to a symmetry swapping left and right; let's work with the first. Its interface is $p_1=F\yon^{FF}+\yon^F$ and its dynamics are given by
\[\Phi_1\colon (F+1)\yon^{F+1}\to F\yon^{FF}+\yon^F\]
which splits up as the coproduct of $F\yon^{F+1}\to F\yon^{FF}$ and $\yon^{F+1}\to\yon^F$. The second map corresponds to when the connection is broken; it is given by projection, meaning it just updates the state to be the received force. The first map  $F\yon^{F+1}\to F\yon^{FF}$ corresponds to the case where the system is holding some force, is receiving two input forces and must update its state and produce one output force. For the passforward $F\to F$, let's use identity meaning it outputs the force it's holding. For the passback $F(FF)\to \{\const{Just}\}F+\{\const{Nothing}\}$, let's use the map $(f,(f_L,f_2))\mapsto t(f_L,f_2)$ defined here:
\[
t(f_L,f_2)\coloneqq
\begin{cases}
	\const{Just}~f_L&\tn{ if }f_1+f_2<100\\
	\const{Nothing}&\tn{ otherwise}
\end{cases}
\]
Thus when the sum of forces is high enough, the internal state is updated to the broken state; otherwise it is sent to the force it receives from outside.
\end{example}


\begin{example}\label{ex.supplier_change}
We want to consider the case of a company $C$ that may change its supplier based on its internal state. The company has no output wires, but has two modes of operation---two positions---corresponding to who it wants to receive widgets $W$ from:
\[
\begin{tikzpicture}[oriented WD, every node/.style={fill=blue!10}]
	\node[bb={0}{1}] (s1) {Supplier 1};
	\node[bb={0}{1}, below=of s1] (s2) {Supplier 2};
	\node[bb={1}{0}, right=0.5 of s1] (c) {Company};
	\draw (s1_out1) to node[above, fill=none, font=\tiny] {$W$} (c_in1);
	\draw (s2_out1) to +(5pt,0) node[fill=none] {$\bullet$};
\begin{scope}[xshift=3.5in]
	\node[bb={0}{1}] (s1') {Supplier 1};
	\node[bb={0}{1}, below=of s1'] (s2') {Supplier 2};
	\node[bb={1}{0}, right=0.5 of s2'] (c') {Company};
	\draw (s2'_out1) to node[above, fill=none, font=\tiny] {$W$} (c'_in1);
	\draw (s1'_out1) to +(5pt,0) node[fill=none] {$\bullet$};
\end{scope}
	\node[starburst, draw, minimum width=2cm, minimum height=2cm,align=center,fill=white, font=\small,line width=1.5pt] at ($(c.east)!.5!(s2'.west)$)
{Change\\supplier!};
\end{tikzpicture}
\]
The company has interface $2\yon^W$, and the each supplier has interface $W\yon$; let's take the total system interface (undrawn) to be the closed system $\yon$. Then this mode-dependent wiring diagram is just a map $2\yon^W\otimes W\yon\otimes W\yon\to\yon$. Its on-positions function $2W^2\to1$ is uniquely determined, and its on-directions function $2W^2\to W$ is the evaluation. In other words, the company's position determines which supplier from which it receives widgets.
\end{example}

\begin{example}\label{ex.assemble_machine}
When someone assembles a machine, their own outputs dictate the connection pattern of the machine's components.
\begin{equation}\label{eqn.someone2}
\begin{tikzpicture}[oriented WD, font=\ttfamily, bb port length=0, every node/.style={fill=blue!10}, baseline=(someone.north)]
	\node[bb port sep=.5, bb={0}{1}] (A) {unit A};
	\node[bb port sep=.5, bb={1}{0}, right=of A] (B) {unit B};
	\coordinate (helper) at ($(A)!.5!(B)$);
	\node[bb={1}{1}, below=2 of helper] (someone) {\tikzsymStrichmaxerl[3]};
	\draw[->, dashed, blue] (someone_in1) to[out=180, in=270] (A.270);
	\draw[->, dashed, blue] (someone_out1) to[out=0, in=270] (B.270);
	\draw[->] (A_out1) -- +(10pt,0);
	\draw (B_in1) -- +(-10pt,0);
%
\begin{scope}[xshift=3.5in]
	\node[bb port sep=.5, bb={0}{1}] (A') {unit A};
	\node[bb port sep=.5, bb={1}{0}, right=.5of A'] (B') {unit B};
	\coordinate (helper') at ($(A')!.5!(B')$);
	\node[bb={1}{1}, below=2 of helper'] (someone') {\tikzsymStrichmaxerl[3]};
	\draw[->, dashed, blue] (someone'_in1) to[out=180, in=270] (A'.270);
	\draw[->, dashed, blue] (someone'_out1) to[out=0, in=270] (B'.270);
	\draw[->] (A'_out1) -- (B'_in1);
\end{scope}
%
	\node[starburst, draw, minimum width=2cm, minimum height=2cm,fill=blue!50,line width=1.5pt, align=center, font=\upshape] at ($(B)!.5!(A')-(0,.6cm)$)
{Attach!};
\end{tikzpicture}
\end{equation}
In order for the above picture to make sense, $A$ has the same output that $B$ has as input, say $X$, and we need a default value $x_0\in X$ for $B$ to input when not connected to $A$.

We could say that the person in \eqref{eqn.someone2} has interface $2\yon$, the units have interfaces $X\yon$ and $\yon^X$ respectively, and the whole system is closed; that is, the diagram represents a morphism $2\yon\otimes X\yon\otimes \yon^X\to\yon$. The morphism $2X\yon^X\to\yon$ is uniquely determined on positions, and on directions it is given by cases $(1,x)\mapsto x_0$ and $(2,x)\mapsto x$.
\end{example}

We can easily generalize \cref{ex.assemble_machine}. Indeed, we will see in the next section that there is a polynomial $\ihom(q_1\otimes\cdots\otimes q_k\,,\,r)$ of all ways  $q_1,\ldots,q_k$ can interact in $r$, and that a map from some $p$ to it is just a bigger interaction pattern:
\[
\poly(p,[q_1\otimes\cdots\otimes q_k\,,\,r])\cong\poly(p\otimes q_1\otimes\cdots\otimes q_k\,,\,r).
\]
In other words, if $p$ thinks its deciding how $q_1,\ldots,q_k$ are wired up in $r$, and gets feedback from that wiring pattern itself, then in actuality $p$ is just part of a wiring diagram with $q_1,\ldots,q_k$ inside of $r$.\

What it also means is that if you want, you can put a little dynamical system inside of $[q_1\otimes\cdots\otimes q_k,r]$ and have it constantly choosing interaction patterns. Let's see how it works.


%---- Subsection ----%
\subsection{Closure of $\otimes$}%[-,-]


The parallel monoidal product is closed---we have a monoidal closed structure on $\poly$---meaning that there is an operation, which we denote $\ihom{-,-}\colon\poly\op\times\poly\to\poly$ and an isomorphism
\[
  \poly(p\otimes q,r)\cong\poly(p,\ihom{q,r})
\]
natural in $p,q,r$. The closure operation is defined on $q,r$ as follows:
\begin{equation}\label{eqn.dir_hom}
	\ihom{q,r}\coloneqq\prod_{j\in q(\1)}r\circ(q[j]\yon)
\end{equation}

\begin{exercise}
Show that there is an isomorphism
\[
\scalebox{1.3}{$\displaystyle
[q,r]\cong\sum_{f\colon p\to q}\yon^{\sum_{i\in q(\1)}r[f(i)]}
$}
\]
where the sum is indexed by $f\in\poly(p,q)$.
\end{exercise}

\begin{example}\label{ex.double_dual}
For any $A\in\smset$ we have
\[
  \ihom{\yon^A,\yon}\cong A\yon
  \qqand
  \ihom{A\yon,\yon}\cong\yon^A.
\]
These both follow directly from \eqref{eqn.dir_hom}.
\end{example}

\begin{exercise}
Calculate $\ihom{q,r}$ for $q,r\in\poly$ given as follows.
\begin{enumerate}
	\item $q\coloneqq 0$ and $r$ arbitrary.
	\item $q\coloneqq 1$ and $r$ arbitrary.
	\item $q\coloneqq\yon$ and $r$ arbitrary.
	\item $q\coloneqq A$ and $r\coloneqq B$ for $A,B\in\smset$ (constants).
	\item $q\coloneqq A\yon$ and $r\coloneqq B\yon$ for $A,B\in\smset$ (linears).
	\item $q\coloneqq\2\yon^\3+\yon^\2$ and $r\coloneqq\4\yon^\2+\7$.
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}
Show that for any $p\in\poly$, if there is an isomorphism $\ihom{\ihom{p,\yon},\yon}\cong p$, then $p$ is either linear $A\yon$ or representable $\yon^A$ for some $A$. Hint: first show that $p$ must be a monomial.
\end{exercise}

\begin{proposition}\label{prop.dirichlet_closure}
With $\ihom{-,-}$ as defined in \eqref{eqn.dir_hom}, there is a natural isomorphism
\begin{equation}\label{eqn.poly_closure_brackets}
	\poly(p\otimes q,r)\cong\poly(p,\ihom{q,r}).
\end{equation}
\end{proposition}
\begin{proof}
We have the following chain of natural isomorphisms:
\begin{align*}
	\poly(p\otimes q,r)&\cong
	\poly\Big(\sum_{i\in p(\1)}\sum_{j\in q(\1)}\yon^{p[i]q[j]},r\Big)\\&\cong
	\prod_{i\in p(\1)}\prod_{j\in q(\1)}\poly(\yon^{p[i]q[j]},r)\\&\cong
	\prod_{i\in p(\1)}\prod_{j\in q(\1)}r(p[i]q[j])\\&\cong
	\prod_{i\in p(\1)}\prod_{j\in q(\1)}\poly(\yon^{p[i]},r\circ(q[j]\yon))\\&\cong
	\prod_{i\in p(\1)}\poly\Big(\yon^{p[i]},\prod_{j\in q(\1)}r\circ(q[j]\yon)\Big)\\&\cong
	\poly(p,\ihom{q,r}).&
	\qedhere
\end{align*}
\end{proof}

\begin{exercise}\label{exc.poly_plug_1}
Show that for any $p,q$ we have an isomorphism of sets
\[
\poly(p,q)\cong\ihom{p,q}(\1).
\]
Hint: you can either use the formula \eqref{eqn.dir_hom}, or just use 
\eqref{eqn.poly_closure_brackets} with the Yoneda lemma and the fact that $\yon\otimes p\cong p$.
\end{exercise}


For any $p,q\in\poly$ there is a canonical \emph{evaluation} map
\begin{equation}\label{eqn.eval_dirichlet}
  \fun{eval}\colon \ihom{p,q}\otimes p\too q.
\end{equation}

\begin{exercise}
\begin{enumerate}
	\item Obtain the evaluation map $\fun{eval}\colon \ihom{p,q}\otimes p\too q$ from \eqref{eqn.poly_closure_brackets}.
	\item Show that for any $p,q,r$ and map $f\colon p\otimes q\to r$, there is a unique morphism $f'\colon p\to\ihom{q,r}$ such that the following diagram commutes
	\[
	\begin{tikzcd}
		p\otimes q\ar[r, "f'\otimes q"]\ar[rr, bend right, "f"']&
		{\ihom{q,r}}\otimes q\ar[r, "\fun{eval}"]&
		r
	\end{tikzcd}
	\]
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}
\begin{enumerate}
	\item For any $S$, obtain the map $S\yon^S\to\yon$ whose on-directions map is identity, using eval and \cref{ex.double_dual}.
	\item Show that maps of the four types $\kappa_{11}$, $\kappa_{12}$, $\kappa_{21}$, $\kappa_{22}$ shown in \cref{ex.bonds_break} can be obtained by tensoring together identity maps and eval maps.
\qedhere
\end{enumerate}
\end{exercise}

\begin{example}[Modeling your environment without knowing what it is]
Let's imagine a robot whose interface is an arbitrary polynomial $p$. Let's imagine it is living together in a closed system
\[
	f\colon (q_1\otimes\cdots\otimes q_n)\otimes p\to \yon
\]
with some other robots whose interfaces are $q_1,\ldots,q_n$; let $q\coloneqq(q_1\otimes\cdots\otimes q_n)$. The interaction pattern induces a morphism $f'\colon q\to \ihom{p,\yon}$ such that the original system $f$ factors through the evaluation $\ihom{p,\yon}\otimes p\to \yon$.

In other words $\ihom{p,\yon}$ holds within it all of the possible ways $p$ can interact with other systems in a closed box.%
\footnote{And if you want the generic way $p$ to interact with other systems in a box $r$, just use $\ihom{p,r}$.}
To investigate this just a bit, note that $\ihom{p,\yon}\cong\prod_{i\in p(\1)}p[i]\yon$. That is, for each position in $p$ it produces a direction there, which is just what $p$ needs as input.

Now suppose we were to populate the interface $p$ with dynamics, a map $S\yon^S\to p$. One could aim to choose a set $S$ along with an interesting map $g\colon S\to\poly(p,\yon)$. Then each state $s$ would include a guess $g(s)$ about what the state of the environment is in. This is not the real environment $q$, but just the environment as it affects $p$, namely $\ihom{p,\yon}$. The robot's states model environmental conditions.
\end{example}


\begin{exercise}\label{exc.sum_times_closure}
Show that for any polynomials $p_1,p_2,q$, we have an isomorphism
\[
[p_1+p_2,q]\cong[p_1,q]\times[p_2,q].
\]
\end{exercise}

\begin{example}[Chu $\&$]
Suppose given polynomials $p_1,p_2,q_1,q_2,r\in\poly$ and morphisms
\[
	\varphi_1\colon p_1\otimes q_1\to r
	\qqand
	\varphi_2\colon p_2\otimes q_2\to r
\]
One might call these ``$r$-Chu spaces.'' One operation you can do with these as Chu spaces is to return something denoted $\varphi_1\&\varphi_2$, or ``$\varphi_1$ \emph{with} $\varphi_2$'' of the following type:
\[
\varphi_1\&\varphi_2\colon (p_1\times p_2)\otimes (q_1+q_2)\to r
\]
Suppose given a position in $p_1$ and a position in $p_2$. Then given a position in either $q_1$ or $q_2$, one evaluates either $\varphi_1$ or $\varphi_2$ respectively to get a position in $r$; given a direction there, one returns the corresponding direction in $q_1$ or $q_2$ respectively, as well as a direction in $p_1\times p_2$ which is either a direction in $p_1$ or in $p_2$.

This sounds complicated, but it can be done formally, once we have monoidal closure. We first rearrange both $\varphi_1,\varphi_2$ to be $p$-centric, using monoidal currying:
\[
\psi_1\colon p_1\to [q_1,r]
\qqand
\psi_2\colon p_2\to [q_2,r]
\]
Now we multiply to get $\psi_1\times\psi_2\colon p_1\times p_2\to[q_1,r]\times[q_2,r]$. Now we use \cref{exc.sum_times_closure} to see that $[q_1,r]\times[q_2,r]\cong[q_1+q_2,r]$, and then finally monoidal-uncurry to obtain $p_1\times p_2)\otimes(q_1+q_2)\to r$ as desired.
\end{example}


%-------- Section --------%
\section{Bonus math about the category $\poly$}\label{sec.bonus_poly}

The category $\poly$ has very useful formal properties, including completion under colimits and limits, various adjunctions with $\smset$, factorization systems, and so on. Most of the following material is not necessary for the development of our main story, but we collect it here for reference. The reader can skip directly to \cref{chapter.comon} if so inclined. Better yet might be to just gently leaf through \cref{sec.bonus_poly}, to see how well-behaved and versatile the category $\poly$ really is.

%---- Subsection ----%
\subsection{Special polynomials and adjunctions}

There are a few special classes of polynomials that are worth discussing: 
\begin{enumerate}
	\item constant polynomials $\0,\1,\2,A$; 
	\item linear polynomials $\0,\yon, \2\yon, A\yon$;
	\item pure-powers polynomials, $\1, \yon, \yon^\2, \yon^A$; and 
	\item monomials $\0, A, \yon, \2\yon^\3, A\yon^B$.
\end{enumerate}
The first two classes, constant and linear polynomials, are interesting because they both put a copy of $\smset$ inside $\poly$, as we'll see in \cref{prop.ff_const_set_to_poly,prop.ff_lin_set_to_poly}. The third puts a copy of $\smset\op$ inside $\poly$, and the fourth puts a copy of bimorphic lenses inside $\poly$, as we saw in \cref{subsec_prepare_dyn} (page~\pageref{page.bimorphic_lens}).

\begin{exercise}
Which of the four classes above are closed under
\begin{enumerate}
	\item the cocartesian monoidal structure $(\0,+)$?
	\item the cartesian monoidal structure $(\1,\times)$?
	\item the parallel monoidal structure $(\yon,\otimes)$?
	\item composition of polynomials $p\circ q$?%
	\footnote{Composition, together with the unit $\yon$, is in fact yet another monoidal structure, as we will see in \cref{chapter.comon}.}
\qedhere
\end{enumerate}
\end{exercise}

\begin{proposition}\label{prop.ff_const_set_to_poly}
There is a fully faithful functor $\smset\to\poly$ sending $A\mapsto A\yon^\0=A$.
\end{proposition}
\begin{proof}
By \cref{eqn.colax_poly_map}, a map $f\colon A\yon^\0\to B\yon^\0$ consists of a function $f\colon A\to B$ and for each $a\in A$ a function $\0\to\0$. There is only one such function, so $f$ can be identified with just a map of sets $A\to B$.
\end{proof}

\begin{proposition}\label{prop.ff_lin_set_to_poly}
There is a fully faithful functor $\smset\to\poly$ sending $A\mapsto A\yon$.
\end{proposition}
\begin{proof}
By \cref{eqn.colax_poly_map}, a map $f\colon A\yon^\1\to B\yon^\1$ consists of a function $f\colon A\to B$ and for each $a\in A$ a function $\1\to\1$. There is only one such function, so $f$ can be identified with just a map of sets $A\to B$.
\end{proof}

\begin{theorem}\label{thm.adjoint_quadruple}
$\poly$ has an adjoint quadruple with $\smset$:
\begin{equation}\label{eqn.adjoints_galore}
\begin{tikzcd}[column sep=60pt, background color=theoremcolor]
  \smset
  	\ar[r, shift left=7pt, "A" description]
		\ar[r, shift left=-21pt, "A\yon"']&
  \poly
  	\ar[l, shift right=21pt, "p(\0)"']
  	\ar[l, shift right=-7pt, "p(\1)" description]
	\ar[l, phantom, "\scriptstyle\Leftarrow"]
	\ar[l, phantom, shift left=14pt, "\scriptstyle\Rightarrow"]
	\ar[l, phantom, shift right=14pt, "\scriptstyle\Rightarrow"]
\end{tikzcd}
\end{equation}
where the functors have been labeled by where they send $A\in\smset$ and $p\in \poly$. 

Both rightward functors are fully faithful.
\end{theorem}
\begin{proof}
For any set $A$, there is a functor $\poly\to\smset$ given by sending $p$ to $p(A)$; it is $\poly(A,-)$. This, together with \cref{prop.ff_const_set_to_poly,prop.ff_lin_set_to_poly} give us the four functors and the fact that the two rightward functors are fully faithful. It remains to provide the following three natural isomorphisms:
\[
\smset(A,p(\0))\cong\poly(A,p)\qquad
\smset(p(\1),A)\cong\poly(p,A)\qquad
\smset(A,p(\1))\cong\poly(A\yon,p).
\]
All three come from our main formula, \cref{eqn.main_formula}; we leave the details to the reader in \cref{exc.adjoint_quadruple}.
\end{proof}

\begin{exercise}\label{exc.adjoint_quadruple}
Here we prove the remainder of \cref{thm.adjoint_quadruple} using \cref{eqn.main_formula}:
\begin{enumerate}
	\item Provide a natural isomorphism $\smset(A,p(\0))\cong\poly(A,p)$.
	\item Provide a natural isomorphism $\smset(p(\1),A)\cong\poly(p,A)$.
	\item Provide a natural isomorphism $\smset(A,p(\1))\cong\poly(A\yon,p)$.
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}\label{exc.positions_maps_yon}
Show that for any polynomial $p$, its set $p(\1)$ of positions is in bijection with the set of functions $\yon\to p$.
\end{exercise}

In \cref{thm.adjoint_quadruple} we see that $p\mapsto p(\0)$ and $p\mapsto p(\1)$ have left adjoints. This is true more generally for any set $A$ in place of $\0$ and $\1$, as we show in \cref{cor.substituting_adj}. However, the fact that $p\mapsto p(\1)$ is also a right adjoint---and hence that we have the \emph{quadruple} of adjunctions in \eqref{eqn.adjoints_galore}---is special to $A=\0,\1$.

Next we note that the set of polynomial morphisms $p\to q$ 

\begin{proposition}\label{prop.two_var_adj}
There is a two-variable adjunction between $\smset$, $\poly$, and $\poly$:%
\footnote{The first set $\poly(Ap,q)$ involves the $A$-fold coproduct of $p$ and the middle set $\poly(p,q^A)$ involves the $A$-fold product of $q$, neither of which we have proven exists. For organizational purposes, we put that off until \cref{prop.coprod_prod_poly}.
}
\begin{align}\label{eqn.two_var_adj}
\poly(Ap,q)\cong\poly(p,q^A)\cong\smset(A,\poly(p,q)).
\end{align}
\end{proposition}
\begin{proof}
Since $Ap$ is the $A$-fold coproduct of $p$ and $q^A$ is the $A$-fold product of $q$, the universal properties of coproduct and product give isomorphisms
\[\poly(Ap,q)\cong\prod_{a\in A}\poly(p,q)\cong\poly(p,q^A).\]
The middle set is in bijection with $\smset(A,\poly(p,q))$, completing the proof.
\end{proof}

Replacing $q$ with $p$ and replacing $p$ with $\yon^B$ in \cref{prop.two_var_adj}, we obtain the following using the Yoneda lemma.

\begin{corollary}\label{cor.substituting_adj}
For any set $B$ there is an adjunction
\[
\adj{\smset}{A\yon^B}{p(B)}{\poly}
\]
where the functors are labeled by where they send $p\in\poly$ and $A\in\smset$.
\end{corollary}

\begin{exercise}
Prove \cref{cor.substituting_adj} from \cref{prop.two_var_adj}.
\end{exercise}

\begin{proposition}\label{prop.yoneda_left_adjoint}
The Yoneda embedding $A\mapsto \yon^A$ has a left adjoint
\[
\adjr{\smset\op}{\yon^-}{\Gamma}{\poly}
\]
where $\Gamma(p)\coloneqq\prod_{i\in p(\1)}p[i]$.
\end{proposition}
\begin{proof}
We have the following chain of natural isomorphisms:
\begin{align*}
  \smset(A,\Gamma(p))&\cong
  \Big(\prod_{i\in p(\1)}p[i]\Big)^A
  	&\text{Definition of function}\\&\cong
  \prod_{i\in p(\1)}{p[i]}^A
  	&\text{Definition of product}\\&\cong
  \prod_{i\in p(\1)}\sum_{j\in\1}{p[i]}^A
  	&\text{Trivial sum}\\&\cong
  \poly(p,\yon^A).&\cref{eqn.main_formula}
\end{align*}

\end{proof}

\begin{exercise}
Show that $\Gamma(p)\cong\ihom{p,\yon}(\1)$ where $\ihom{-,-}$ is as in \cref{prop.dirichlet_closure}.
\end{exercise}

\paragraph{Epi-mono factorization.}

\begin{proposition}\label{prop.monics_in_poly}
Let $(f_1,f^\sharp)\colon p\to q$ be a morphism in $\poly$. It is a monomorphism iff the function $f_1\colon p(\1)\to q(\1)$ is a monomorphism in $\smset$ and, for each $i\in p(\1)$ the function $f_i^\sharp\colon q[f_1(i)]\to p[i]$ is an epimorphism in $\smset$.
\end{proposition}
\begin{proof}
\noindent$\Rightarrow$: Suppose that $f$ is a monomorphism. Since $p\mapsto p(\1)$ is a right adjoint (\cref{thm.adjoint_quadruple}), it preserves monomorphisms. We need to show that for any $i\in p(\1)$ the function $f_i^\sharp\colon q[f_1(i)]\to p[i]$ is an epimorphism in $\smset$. Suppose given a set $A$ and a pair of functions $g^\sharp,h^\sharp\colon p[i]\tto A$ with $g^\sharp f_i^\sharp=h^\sharp f_i^\sharp$. They can be identified with morphisms $\yon^A\tto p$ whose compositions with $f$ are equal, hence $g=h$ by assumption, and hence $g^\sharp=h^\sharp$ as desired.

\noindent$\Leftarrow$: Suppose that $f_1$ is a monomorphism and that for each $i\in p(\1)$ the function $f_i^\sharp$ is an epimorphism. Let $r$ be a polynomial, $g,h\colon r\tto p$ two morphisms, and suppose $fg=fh$. Then $f_1g_1=f_1h_1$, which implies $g_1=h_1$; we'll consider $g_1$ the default representation. We also have that $g^\sharp_kf^\sharp_{g_1k}=h^\sharp_kf^\sharp_{g_1k}$ for any $k\in r(\1)$. But $f^\sharp_{g_1k}$ is an epimorphism, so in fact $g^\sharp_k=h^\sharp_k$, as desired.
\end{proof}

\begin{example}\label{ex.clock_in_N}
Choose a finite nonempty set $\ord{k}$ for $1\leq k\in\nn$, e.g.\ $\ord{k}=\1\2$. There is a monomorphism
\[
(f,f^\sharp)\colon\ord{k}\yon^{\ord{k}}\to\nn\yon^\nn
\]
such that the trajectory ``going around and around the $k$-clock'' comes from the usual counting trajectory \cref{ex.counting_trajectory} $\nn\yon^\nn\to\yon$.

On positions we have $f(i)=i$, for all natural numbers $1\leq i\leq k$. On directions we have $f^\sharp(n)=n\mod k$.
\end{example}

\begin{exercise}
In \cref{ex.clock_in_N} we gave a map $\1\2\yon^{\1\2}\to\nn\yon^\nn$. This allows us to turn any dynamical system with $\nn$-many states into a dynamical system with 12 states, while keeping the same interface, say $p$. 

Explain how the behavior of the new system $\1\2\yon^{\1\2}\to p$ would be seen to relate to the behavior of the old system $\nn\yon^\nn\to p$.
\end{exercise}

\begin{proposition}\label{prop.epis_in_poly}
Let $(f_1,f^\sharp)\colon p\to q$ be a morphism in $\poly$. It is an epimorphism iff the function $f_1\colon p(\1)\to q(\1)$ is an epimorphism in $\smset$ and, for each $j\in q(\1)$ the induced function 
\[
f^\flat_j\colon q[j]\to\prod_{\{i\in p(\1)\,\mid\, f_1(i)=j\}}p[i]
\]
from \eqref{eqn.useful_misc472} is a monomorphism.
\end{proposition}
\begin{proof}
\noindent$\Rightarrow$: Suppose that $f$ is an epimorphism. Since $p\mapsto p(\1)$ is a left adjoint (\cref{thm.adjoint_quadruple}), it preserves epimorphisms. We need to show that for any $j\in q(\1)$ the  function $f^\flat_j$ is a monomorphism in $\smset$. Suppose given a set $A$ and a pair of functions $g^\sharp,h^\sharp\colon A\tto q[j]$ with $f^\flat_jg^\sharp=f^\flat_jh^\sharp$. They can be identified with morphisms $g,h\colon q\tto \yon^A+\1$, which send the $j$-component to the first component, $\yon^A$, and send all other component to the second component, $\1$. It is easy to check that $fg=fh$, hence $g=h$, and hence $g^\sharp=h^\sharp$ as desired.

\noindent$\Leftarrow$: Suppose that $f_1$ is an epimorphism and that for each $j\in q(\1)$ the function $f^\flat_j$ is a monomorphism. Let $r$ be a polynomial, $g,h\colon q\tto r$ two morphisms, and suppose $gf=hf$. Then $g_1f_1=h_1f_1$, which implies $g_1=h_1$; we'll consider $g_1$ the default representation. We also have that $f^\sharp_ig^\sharp_{fi}=f^\sharp_ih^\sharp_{fi}$ for any $i\in p(\1)$. Then, in particular, for any $j\in q(\1)$ the two composites
\[
\begin{tikzcd}
	r[g_1j]\ar[r, shift left, "g^\sharp_j"]\ar[r, shift right, "h^\sharp_j"']&q[j]\ar[r, "f^\flat_j"]&\displaystyle\prod_{\{i\in p(\1)\,\mid\,f_1(i)=j\}}p[i]
\end{tikzcd}
\]
are equal, which implies that $g^\sharp_j=h^\sharp_j$ as desired.
\end{proof}

\begin{exercise}
Show that the only way for a map $p\to\yon$ to \emph{not} be an epimorphism is when $p=0$.
\end{exercise}

\begin{proposition}
Let $A$ and $B$ be sets and $AB$ their product. Find an epimorphism $\yon^A+\yon^B\surj\yon^{AB}$.
\end{proposition}

\begin{exercise}
Suppose $f$ is both a mono and an epi; it is an iso? (That is, is $\poly$ \emph{balanced}?)
\end{exercise}

\begin{exercise}[Epi-mono factorization]\label{exc.mono_epi_poly}
Suppose $p,q\in\poly$ are polynomials and $f=(f_1,f^\sharp)\colon p\to q$ is a morphism with notation as in \cref{eqn.colax_poly_map}.
\begin{enumerate}
	\item Can every morphism in $\poly$ be factored as an epic followed by a monic?
	\item Is your factorization unique up to isomorphism?
\qedhere
\end{enumerate}
\end{exercise}



%---- Subsection ----%
\subsection{Limits, colimits, and cartesian closure}

We will now see that $\poly$ has all limits and colimits, and moreover it is cartesian closed.

Let's begin with something fairly simple: that $+$ gives a coproduct in $\poly$. We could have said this elementary fact much earlier, but we were in a rush to get to the applications in \cref{sec.dynam_in_poly}.

\begin{exercise}
Show that the category $\poly$ has finite coproducts as follows.
\begin{enumerate}
	\item Show that $\0$ is an initial object in $\poly$, i.e.\ that for any polynomial $p$ there is a unique morphism $\0\to p$.
	\item Show that the standard sum of polynomials $p_1+p_2$ is a coproduct of $p_1$ and $p_2$. That is, provide morphisms $p_1\to p_1+p_2\from p_2$ and show that for any other $q$ with morphisms $p_1\To{f_1} q\From{f_2} p_2$, there exists a unique morphism $p_1+p_2\to q$---shown dashed---making the following diagram commute 
	\[
	\begin{tikzcd}
		p_1\ar[r]\ar[dr, "f_1"']&
		p_1+p_2\ar[d, dashed]&
		p_2\ar[l]\ar[dl, "f_2"]\\&
		q
	\end{tikzcd}
	\qedhere
	\]
\end{enumerate}
\end{exercise}

The general case of coproducts and products is not much more difficult.

\begin{proposition}\label{prop.coprod_prod_poly}
The category $\poly$ has coproducts and products.
\end{proposition}
\begin{proof}
Let $A$ be a set and $p\colon A\to\poly$ a collection of polynomials $(p_a)_{a\in A}$.%
Their coproduct is
\begin{equation}\label{eqn.sum_polys}
\sum_{a\in A}p_a=\sum_{a\in A}\sum_{i\in p_a(\1)}\yon^{p_a[i]}\cong\sum_{(a,i)\in\sum_{a\in A}p_a(\1)}\yon^{p_a[i]}
\end{equation}
which is manifestly a sum of representables, i.e.\ a polynomial, and which one can check satisfies the universal property of coproduct; see \cref{exc.check_coprod_prod}.

We claim that the product of this collection is
\begin{equation}\label{eqn.prod_polys}
\prod_{a\in A}p_a=
\prod_{a\in A}\sum_{i\in p_a(\1)}\yon^{p_a[i]}\cong
\sum_{i\colon \prod_{a\in A}p_a(\1)}\yon^{\sum_{a\in A}p_a[i(a)]}.
\end{equation}
Again, it is a sum of representables, so a polynomial, and one can check that it satisfies the universal property of product; see \cref{exc.check_coprod_prod}.
\end{proof}

\begin{exercise}\label{exc.check_coprod_prod}
Finish the proof of \cref{prop.coprod_prod_poly} as follows.
\begin{enumerate}
	\item Show that \eqref{eqn.sum_polys} satisfies the universal property for coproduct of polynomials.
	\item Show that \eqref{eqn.prod_polys} satisfies the universal property for product of polynomials.
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}
Let $A=\2$ and $p\colon A\to\poly$ be given by $p_1\coloneqq\yon+\1$ and $p_2\coloneqq\yon+\2$. What is $\prod_{i\in\2}p[i]$ according to \cref{eqn.prod_polys}? Does it check out?
\end{exercise}

\begin{proposition}\label{prop.completely_distributive}
The category $\poly$ is completely distributive, i.e.\ for any set $A$, sets $(B_a)_{a\in A}$, and polynomials $(p_{(a,b),})_{a\in A, b\in B_a}$, there is an isomorphism
\[
  \sum_{b\colon\prod_{a\in A}B(a)}\;\prod_{a\in A}\;p_{(a,b(a)),}
  \cong
	\prod_{a\in A}\;\sum_{b\in B(a)}\;p_{(a,b),}
\]
\end{proposition}
\begin{proof}
By the universal property of coproducts and products, to provide a morphism $\sum_{b\colon\prod_{a\in A}B(a)}\prod_{a\in A}p_{(a,b),}
  \to	\prod_{a\in A}\sum_{b\in B(a)}p_{(a,b),}$, it suffices to fix an arbitrary $b_0\in\prod_{a\in A}B(a)$ and $a_0\in A$ and provide a morphism $\prod_{a\in A}p_{(a,b_0(a)),}\to\sum_{b\in B(a_0)}p_{(a_0,b),}$. We do so by first projecting onto the $a_0$-factor $\prod_{a\in A}p_{(a,b_0(a)),}\to p_{(a_0, b_0(a_0)),}$ and then including into the $b_0(a_0)$-summand $p_{(a_0,b_0(a_0)),}\to\sum_{b\in B(a_0)}p_{(a_0,b),}$. This establishes the morphism.
  
  To see that it is an isomorphism in $\poly$, i.e.\ a natural isomorphism of functors, it suffices to check it on components. So fix $X\in\smset$. The induced map
  \[
  \sum_{b\colon\prod_{a\in A}B(a)}\;\prod_{a\in A}\;p_{(a,b(a)),}
  \cong
	\prod_{a\in A}\;\sum_{b\in B(a)}\;p_{(a,b),}
  \]
  is exactly as in \cref{prop.push_prod_sum_set}, which we proved is an isomorphism. This completes the proof.
\end{proof}

\begin{exercise}
How is the usual distributive law,
\[
p(q+r)\cong pq+pr
\]
for $p,q,r\in\poly$, a special case of \cref{prop.completely_distributive}?
\end{exercise}

\paragraph{Cartesian closure}
For any two polynomials $q,r$, define $r^q\in\poly$ by the following formula
\begin{equation}\label{eqn.exponential}
  r^q\coloneqq\prod_{i\in q(\1)}r\circ(\yon+q[j])
\end{equation}
where $\circ$ denotes composition.

Before proving that this really is an exponential in $\poly$, which we do in \cref{thm.poly_cart_closed}, we first get some practice with it.

\begin{example}
Let $A$ be a set. We've been writing the polynomial $A\yon^\0$ simply as $A$ and the polynomial $\yon^\1$ simply as $\yon$, so it better be true that the there is an isomorphism 
\[\yon^A\cong (\yon^\1)^{(A\yon^\0)}\]
in order for the notation to be consistent. Luckily, this is true. Checking \eqref{eqn.exponential}, we have
\[(\yon^\1)^{A\yon^\0}=\prod_{a\in A}\yon\circ(\0+\yon)\cong\yon^A\]
\end{example}

\begin{exercise}
Compute the following exponentials in $\poly$ using \eqref{eqn.exponential}:
\begin{enumerate}
	\item $p^\0$ for an arbitrary $p\in\poly$.
	\item $p^\1$ for an arbitrary $p\in\poly$.
	\item $\1^p$ for an arbitrary $p\in\poly$.
	\item $A^p$ for an arbitrary $p\in\poly$ and $A\in\smset$.
	\item $\yon^\yon$.
	\item $\yon^{\4\yon}$.
	\item $(\yon^A)^{\yon^B}$ for arbitrary sets $A,B\in\smset$.
\qedhere
\end{enumerate}
\end{exercise}


\begin{theorem}\label{thm.poly_cart_closed}
The category $\poly$ is Cartesian closed. That is, we have a natural isomorphism
\[
  \poly(p,r^q)\cong\poly(p\times q,r),
\]
where $r^q$ is the polynomial defined in \eqref{eqn.exponential}.
\end{theorem}
\begin{proof}
We have the following chain of natural isomorphisms
\begin{align*}
	\poly(p,r^q)&\cong
	\poly\Big(p,\prod_{j\in q(\1)}r\circ (\yon+q[j])\Big)\\&\cong
	\prod_{j\in q(\1)}\poly(p,r\circ(\yon+q[j]))\\&\cong
	\prod_{j\in q(\1)}\prod_{i\in p(\1)}\poly(\yon^{p[i]},r\circ(\yon+q[j]))\\&\cong
	\prod_{i\in p(\1)}\prod_{j\in q(\1)}r\circ(p[i]+q[j])\\&\cong
	\prod_{i\in p(\1)}\prod_{j\in q(\1)}\sum_{k\in r(\1)}(p[i]+q[j])^{r[k]}\\&\cong
	\poly(p\times q,r).
\end{align*}
The last step uses \cref{eqn.main_formula,prop.poly_times}.
\end{proof}

\begin{exercise}
Use \cref{thm.poly_cart_closed} to show that for any polynomials $p,q$, there is a canonical evaluation map
\begin{equation}\label{eqn.eval_times}
	\text{eval}\colon q\times p^q\to p.
\end{equation}
\end{exercise}


\begin{exercise}
Using \cref{eqn.exponential}, show that the functor $\smset\to\poly$ sends exponentials to exponentials.
\end{exercise}

\begin{theorem}\label{thm.poly_limits}
The category $\poly$ has all limits.
\end{theorem}
\begin{proof}
Recall that a category has all limits iff it has equalizers and products, so by \cref{prop.coprod_prod_poly} it suffices to show that $\poly$ has equalizers. 

Let $f_1,f_2\colon p\tto q$ be two maps of polynomials. Let $E\to p(\1)\tto q(\1)$ be an equalizer of the functions $f_1(\1),$ and $f_2(\1)$ in $\smset$. For each $e\in E$, write $f(e)\coloneqq f_1(e)=f_2(e)$; we have two polynomial morphisms $\yon^{p_e}\tto\yon_{q[f(e)]}$, i.e.\ two functions $q[f(e)]\tto p_e$. Defining $p'[e]\in\smset$ to be their coequalizer, we can define a polynomial $p'$ as follows:
\[
  p'\coloneqq\sum_{e\in E}\yon^{p'[e]}
\]
which comes equipped with a morphism $g\colon p'\to p$. One can check that it is an equalizer of $f_1,f_2$; see \cref{exc.poly_limits}.
\end{proof}

\begin{exercise}\label{exc.poly_limits}
Complete the proof of \cref{thm.poly_limits} as follows:
\begin{enumerate}
	\item We said that $p'$ comes equipped with a morphism $g\colon p'\to p$; what is it?
	\item Show that $g\then f_1=g\then f_2$.
	\item Show that $g$ is an equalizer of the pair $f_1,f_2$.
\qedhere
\end{enumerate}
\end{exercise}

\begin{exercise}
Let $p$ be any polynomial.
\begin{enumerate}
	\item There is a canonical choice of morphism $\eta\colon p\to p(\1)$; what is it?
	\item Suppose given an element $i\in p(\1)$, i.e.\ a function $\1\to p(\1)$.
	\item What is the pullback
	\[
	\begin{tikzcd}
	?\ar[r]\ar[d]&
	p\ar[d, "\eta"]\\
	\1\ar[r, "i"']&
	p(\1)\ar[ul, phantom, very near end, "\lrcorner"]
	\end{tikzcd}
	\qedhere
	\]
\end{enumerate}
\end{exercise}

\begin{example}[Pullbacks in $\poly$]\label{ex.pullbacks_in_poly}
Given polynomials $q,q',r$ and morphism $q\To{f} r\From{f'} q'$, the pullback 
\[
\begin{tikzcd}
	p\ar[r]\ar[d]&
	q'\ar[d, "f'"]\\
	q\ar[r, "f"']&
	r\ar[ul, phantom, very near end, "\lrcorner"]
\end{tikzcd}
\]
 is given as follows. The set of positions in $p$ is the pullback of the positions of $q$ and $q'$ over those of $r$. On each $p$-position, say $(i, i')$ with $f_1(i)=f'_1(i')$, we take the directions set of $p$ in that position to be the  pushout of the directions $q[i]$ and $q'[i']$ over $r[f_1(i)]=r[f_1'(i')]$:
\begin{equation}\label{eqn.pullback_poly}
\begin{tikzcd}
	p(\1)\ar[r]\ar[d]&
	q'(\1)\ar[d, "f_1'"]\\
	q(\1)\ar[r, "f_1"']&
	r(\1)\ar[ul, phantom, very near end, "\lrcorner"]
\end{tikzcd}
\qqand
\begin{tikzcd}
	p[(i,i')]\ar[from=r]\ar[from=d]&
	q'[i']\ar[from=d, "(f')_{i'}^\sharp"']\\
	q[i]\ar[from=r, "f^\sharp_i"]&
	r[f_1(i)]\ar[ul, phantom, very near end, "\ulcorner"]
\end{tikzcd}
\end{equation}
\end{example}

\begin{exercise}
Let $q\coloneqq \yon^\2+\yon$, $q'\coloneqq\2\yon^\3+\yon^\2$, and $r\coloneq\yon+\1$.
\begin{enumerate}
	\item Choose morphisms $f\colon q\to r$ and $f'\colon q'\to r$ and write them down.
	\item Find the pullback of your diagram.
\qedhere
\end{enumerate}
\end{exercise}

\begin{theorem}\label{thm.poly_colimits}
The category $\poly$ has all colimits.
\end{theorem}
\begin{proof}
Recall that a category has all colimits iff it has coequalizers and coproducts, so by \cref{prop.coprod_prod_poly} it suffices to show that $\poly$ has coequalizers.

Let $f_1,f_2\colon p\tto q$ be two maps of polynomials. The pair of functions
\[f_1(\1),f_2(\1)\colon p(\1)\tto q(\1)\] 
define a graph $G\colon\fbox{$\bullet\tto\bullet$}\to\smset$ whose set $C$ of connected components is given by the coequalizer $g\colon q(\1)\to C$ of $f_1(\1)$ and $f_2(\1)$. The coequalizer of $f_1$ and $f_2$ will turn out to be a $C$-indexed sum of representables, each of which is given by a limit of a diagram of representables from $p$ and $q$, but expressing this limit, as we proceed to do, is a bit involved.

For each connected component $c\in C$, we have a connected subgraph $G_c\ss G$ with vertices $V_c\coloneqq g\inv(c)$ and edges $E_c\coloneqq f_1\inv(g\inv(c))=f_2\inv(g\inv(c))$. Note that $E_c\ss p(\1)$ and $V_c\ss q(\1)$, so to each $e\in E_c$ (resp.\ to each $v\in V_c$) we have an associated representable $\yon^{p[e]}$ (resp.\ $\yon^{q[v]}$).

The category of elements $\int G_c$ is a bipartite graph with objects $V+E$ and with two sorts of morphisms, $e\to f_1(e)$ and $e\to f_2(e)$, associated to each $e\in E_c$; all non-identity arrows point from an object in $E$ to an object in $V$. There is a functor $F\colon(\int G_c)\op\to\smset$ sending every $v\mapsto q[v]$, every $e\mapsto p[e]$, and every morphism to a function between them, namely either $(f_1^\sharp)_e\colon q[f_1(e)]\to p[e]$ or $(f_2^\sharp)_e\colon q[f_2(e)]\to p[e]$. Define $q'[c]\in\smset$ to be the limit $q'[c]\coloneqq\lim F\in\smset$ of $F$.

We claim that $q'\coloneqq\sum_{c\in C}\yon^{q'[c]}$ is the coequalizer of $f_1$ and $f_2$. We leave the completion proof to the interested reader in \cref{exc.poly_colimits}.
\end{proof}

\begin{exercise}\label{exc.poly_colimits}
Complete the proof of \cref{thm.poly_colimits} as follows:
\begin{enumerate}
	\item Provide a map $g\colon q\to q'$ and show that $f_1\then g=f_2\then g$.
	\item Show that $g$ is a coequalizer of the pair $f_1,f_2$.
\qedhere
\end{enumerate}
\end{exercise}

\begin{example}
Given a diagram in $\poly$, one could either take its colimit as \emph{polynomial} functors (its colimit in $\poly)$ or its colimit simply as a diagram of functors. These can yield different results.

For example, consider the two projections $\yon^\2\to\yon$, i.e.\ the diagram
\[
\yon^\2\tto\yon.
\]
In $\poly$, the colimit is $\1$. But as functors, the colimit is the functor
\[
  X\mapsto
  \begin{cases}
  	\0&\tn{ if }X=\0\\
  	\1&\tn{ if }X\neq\0
  \end{cases}
\]
\end{example}

\begin{exercise}
Recall (\cref{prop.adjoint_quadruple}) that for any polynomial $p$, there are canonical maps
\[
	p(\1)\yon\to p
	\qqand
	p\to \yon^{\Gamma p}.
\]
\begin{enumerate}
	\item What is the canonical map $\5\yon\to\3\yon^\2+\2\yon$?
	\item What is the canonical map $\3\yon^\2+\2\yon\to\yon^\8$?
	\item Show that the following are pushouts in $\poly$:
\[
\begin{tikzcd}
	p(\1)\yon\ar[r, "!"]\ar[d]&
	\yon\ar[d, "!"]\\
	p\ar[r]&
	\yon^{\Gamma p}\ar[ul, phantom, very near start, "\ulcorner"]
\end{tikzcd}
\qqand
\begin{tikzcd}
	\5\yon\ar[r, "!"]\ar[d]&
	\yon\ar[d, "!"]\\
	\3\yon^{\2}+\2\yon\ar[r]&
	\yon^\8\ar[ul, phantom, very near start, "\ulcorner"]
\end{tikzcd}
\]
	\item Is the pushout of a Cartesian map always Cartesian?
\end{enumerate}
\end{exercise}

\begin{proposition}\label{prop.tensor_as_pushout}
For polynomials $p,q$, the following is a pushout:
\[
\begin{tikzcd}
	p(\1)\yon\otimes q(\1)\yon\ar[r]\ar[d]&
	p(\1)\yon\otimes q\ar[d]\\
	p\otimes q(\1)\yon\ar[r]&
	p\otimes q\ar[ul, phantom,very near start, "\ulcorner"]
\end{tikzcd}
\]
\end{proposition}
\begin{proof}
All the maps shown are identity on positions, so the displayed diagram is the coproduct over all $(i,j)\in p(\1)\times q(\1)$ of the diagram shown left
\[
\begin{tikzcd}
	\yon\ar[r]\ar[d]&
	\yon^{q[j]}\ar[d]\\
	\yon^{p[i]}\ar[r]&
	\yon^{p[i]\times q[j]}\ar[ul, phantom,very near start, "\ulcorner"]
\end{tikzcd}
\begin{tikzcd}
	\1\ar[dr, phantom, "\lrcorner"]&
	q[j]\ar[l]\\
	p[i]\ar[u]&
	p[i]\times q[j]\ar[l]\ar[u]
\end{tikzcd}
\]
where we used $(p\otimes q)[(i,j)]\cong p[i]\times q[j]$. This is the image under the Yoneda embedding of the diagram of sets shown right, which is clearly a limit. The result follows by \cref{prop.yoneda_left_adjoint}.
\end{proof}

This means that to give a map $\varphi\colon p\otimes q\to r$, it suffices to give two maps $\varphi_p\colon p\otimes q(\1)\yon\to r$ and $\varphi_q\colon p(\1)\yon\otimes q\to r$ that agree on positions. The map $\varphi_p$ says how information about $q$'s position is transferred to $p$, and the map $\varphi_q$ says how information about $p$'s position is transferred to $q$.

\begin{corollary}\label{cor.tensor_as_pushout}
Suppose given polynomials $p_1,\ldots,p_n\in\poly$. Then $p_1\otimes\cdots\otimes p_n$ is isomorphic to the wide pushout
\[
  \colim
  \left(
  \begin{tikzcd}[column sep=-10pt]
  	&
		p_1(\1)\yon\otimes\cdots\otimes  p_n(\1)\yon\ar[dl]\ar[dr]\\
		p_1\otimes p_2(\1)\yon\otimes\cdots\otimes p_n(\1)\yon&
		\cdots&
		p_1(\1)\yon\otimes\cdots\otimes p_{n-1}(\1)\yon \otimes p_n
  \end{tikzcd}
  \right)
\]
\end{corollary}
\begin{proof}
By induction on $n\in\nn$. When $n=0$ the wide pushout has no legs and the empty tensor product is $\yon$, so the result holds. If the result holds for $n$ then it holds for $n+1$ by \cref{prop.tensor_as_pushout}.
\end{proof}

We can use \cref{cor.tensor_as_pushout} to characterize interaction patterns. Given polynomials $p_1,\ldots, p_n,$ and $q$, and a map
\[\varphi\colon p_1\otimes\cdots\otimes p_n\to q\]
we may want to know which $p_i$'s can ``hear'' which $p_j$'s. To make this precise, we will associate to $\varphi$ a simple directed graph that describes the information flow. Given a set $V$, define
\[
\Cat{SimpleGraph}(V)\coloneqq\{A\ss V\times V\mid \forall(v\in V). (v,v)\not\in A\}.
\]
In fact, we will start with a more general result that explains how maps such as $\varphi$ can be \emph{mode-dependent}. But before we do, let's explain the idea in an example.

\begin{example}[Introducing random process]\label{ex.random_process}
What is it about flipping a coin or rolling a die that is random? This is a different question than whether the coin or die is fair or even consistent. What's important is that we don't have any influence over the result of the outcome.

Suppose that we have a system $\varphi\colon p\otimes c\to r$, where we think of $p$ as a player and $c$ as a coin. By \cref{prop.tensor_as_pushout} we know that $\varphi$ can be identified with a commuting diagram
\[
\begin{tikzcd}
	p(\1)\yon\otimes c(\1)\yon\ar[r]\ar[d]&
	p(\1)\yon\otimes c\ar[d]\\
	p\otimes c(\1)\yon\ar[r]&
	r
\end{tikzcd}
\]
Assuming for simplicity that the player and coin form a closed system, i.e.\ that$r=\yon$, the map $\varphi$ can be identified with two maps: $\varphi_c\colon p(\1)\yon\otimes c\to\yon$ and $\varphi_p\colon p\otimes c(\1)\yon\to\yon$. To say that $p$'s position does not influence $c$ is to say that the former map factors through the projection $\pi\colon p(\1)\yon\otimes c\to c$
\[
	p(\1)\yon\otimes c\To{\pi} c\to \yon.
\]
In general, we will be interested in the interaction pattern between a number of systems, in terms of who influences who.
\end{example}

\begin{example}
Carrying on from \cref{ex.random_process}, suppose given polynomials $p_1,\ldots,p_n,r$ and a map
\[\varphi\colon p_1\otimes\cdots\otimes p_n\to r.\]
By \cref{cor.tensor_as_pushout}, $\varphi$ can be identified with a tuple of maps 
\[\varphi_i\colon p_i\otimes\bigotimes_{j\neq i}p_j(\1)\yon\too r\]
that agree on positions $\varphi(\1)\colon p(\1)\otimes\cdots\otimes p_n(\1)\to r(\1)$.

Now for each $1\leq i\leq n$, we can ask for the smallest subset $A_i\ss\{j\mid 1\leq j\leq n, j\neq i\}$ such that $\varphi_i$ factors through the projection
\[
	p_i\otimes\bigotimes_{j\neq i}p_j(\1)\yon\To{\pi_A}
	p_i\otimes\bigotimes_{j\in A_i}p_j(\1)\yon\to
	r.
\]
The result is a simple directed graph: its vertices are the numbers $V\coloneqq\{i\mid 1\leq i\leq n\}$ and for each vertex we have a subset $A_i\ss V\setminus \{i\}$, which we consider as the arrows with target $i$. The set of all arrows in this graph is $A\coloneqq\sum_{i}A_i$.

The simple directed graph associated to the player-and-coin model in \cref{ex.random_process} would be
\[
\LMO{c}\to\LMO{p}
\]
indicating that the coin's position can be noticed by the player but the player's position cannot be noticed by the coin. In general, we may have something like the following:
\[
\begin{tikzcd}
	&
	\LMO{p_1}\ar[dl]\ar[dr]\ar[r, shift left]&
	\LMO{p_2}\ar[l, shift left]\ar[dr]\\
	\LMO{p_3}&&
	\LMO{p_4}&
	\LMO{p_5}\ar[l]
\end{tikzcd}
\]
which says that $p_1$ is heard by $p_2,p_3,p_4$ but not by $p_5$, etc.
\end{example}

For any $p\in\poly$, let $p/\poly$ denote the coslice category, i.e.\ the category whose objects are maps $p\to q$ emanating from $p$, and whose morphisms are commutative triangles.

\begin{proposition}[Interaction graphs]
For any polynomials $p_1,\ldots,p_n\in\poly$ there is an adjunction
\[
	\adj
		{\Cat{SimpleGraph}(\ord{n})\op}
		{}{}
		{p_1\otimes\cdots\otimes p_n/\poly}
\]
Moreover, the left adjoint is fully faithful iff $n\leq 1$ or $|p_i(\1)|\geq 2$ for each $1\leq i\leq n$, i.e.\ iff each polynomial has at least two positions.
\end{proposition}
\begin{proof}

\end{proof}



%---- Subsection ----%
\subsection{Monoidal $*$-bifibration over $\smset$}

We will see that the functor $p\mapsto p(\1)$ has special properties making it what
\cite{shulman2008framed} refers to as a \emph{monoidal $*$-bifibration}. This means that $\smset$ acts as a sort of remote controller on the category $\poly$, grabbing every polynomial by its positions and pushing or pulling it this way and that. 

For example, suppose one has a set $A$ and a function $f\colon A\to p(\1)$. Then we get a new polynomial $f^*p$ with positions $A$. The notation here agrees with that in \cref{thm.poly_lcc}: it is given by a pullback
\begin{equation}\label{eqn.f^*_defined}
\begin{tikzcd}
	f^*p\ar[r, "\fun{cart}"]\ar[d]&
	p\ar[d, "\eta_p"]\\
	A\ar[r, "f"']&
	p(\1)\ar[ul, phantom, very near end, "\lrcorner"]
\end{tikzcd}
\end{equation}
Here $\eta_p$ is the unit of the adjunction $\adjr{\smset}{A}{p(\1)}{\poly}$. Since it is an isomorphismon positions and $p\mapsto p(\1)$ is a right adjoint, the map $f^*p\to A$ is also an isomorphism on positions. Since on each position $a\in A$, the function $f^\sharp_a$ is an isomorphism on directions (both domain and codomain are the empty set), and since the $a$-position of $f^*p$ is constructed by a pushout (see \cref{ex.pullbacks_in_poly}), each function $\fun{cart}_a^\sharp\colon p[f(a)]\to(f^*p)[a]$ is an isomorphism too. We'll see this as part of a bigger picture in \cref{prop.basechange,thm.triple_adjoint_basechange}.


\begin{definition}[Vertical, cartesian]
Let $f\colon p\to q$ be a morphism of polynomials. It is called \emph{vertical} if $f_1\colon p(\1)\to q(\1)$ is an isomorphism. It is called \emph{cartesian} if, for each $i\in p(\1)$ the function $f^\sharp_i\colon q[f(i)]\to p[i]$ is an isomorphism.
\end{definition}

\begin{proposition}\label{prop.vert_cart_factorization}
Every morphism in $\poly$ can be uniquely factored as a vertical morphism followed by a cartesian morphism.
\end{proposition}
\begin{proof}
Recall from \cref{eqn.colax_poly_map} that a morphism in $\poly$ can be written as to the left; we can thus rewrite it as to the right:
\[
\begin{tikzcd}[column sep=small]
	p(\1)\ar[dr, bend right, "{p[-]}"']\ar[rr, "f_1"]&~&
	q(\1)\ar[dl, bend left, "{q[-]}"]\\&
	\smset\ar[u, phantom, near end, "\overset{f^\sharp}{\Leftarrow}"]
\end{tikzcd}
\hspace{1in}
\begin{tikzcd}
	p(\1)\ar[dr, bend right, "p_-"']\ar[r, equal, ""' name=equal]&
	p(\1)\ar[d, "{q[f_1(-)]}" description]\ar[r, "f_1"]&
	q(\1)\ar[dl, bend left, "{q[-]}"]\\&
	|[alias=set]|\smset\ar[from=equal, to=set, pos=.3, phantom, "\overset{f^\sharp}{\Leftarrow}"]
\end{tikzcd}
\]
The object $\sum{i\in p(\1)}\yon^{q[f_1i]}$ is clearly unique up to isomorphism.
\end{proof}

\begin{proposition}
Vertical morphisms satisfy 2/3: given $p\To{f}q\To{g}r$ with $h=g\circ f$, if any two of $f,g,h$ are vertical, then so is the third.

If $g$ is Cartesian then $h$ is cartesian iff $f$ is cartesian.
\end{proposition}

\begin{exercise}
Give an example of polynomials $p,q,r$ and maps $p\To{f}q\To{g}r$ such that $f$ and $g\circ f$ are cartesian but $g$ is not.
\end{exercise}

\begin{proposition}\label{prop.cart_as_nt}
A morphism $f\colon p\to q$ is cartesian iff it is cartesian as a natural transformation, i.e.\ for any sets $A,B$ and function $g\colon A\to B$, the naturality square
\[
\begin{tikzcd}
	p(A)\ar[r, "f_A"]\ar[d, "p(g)"']&
	q(A)\ar[d, "q(g)"]\\
	p(B)\ar[r, "g_A"']&
	q(B)\ar[ul, phantom, very near end, "\lrcorner"]
\end{tikzcd}
\]
is a pullback.
\end{proposition}

\begin{exercise}
Prove \cref{prop.cart_as_nt}.
\end{exercise}

\begin{proposition}\label{prop.monoidal_pres_carts}
The monoidal structures $+$, $\times$, and $\otimes$ preserve cartesian morphisms.
\end{proposition}
\begin{proof}
Suppose that  $f\colon p\to p'$ and $g\colon q\to q'$ are cartesian. 

A position of $p+q$ is a position $i\in p(\1)$ or a position $j\in q(\1)$, and the map $(f+g)^\sharp$ at that position is either $f^\sharp_i$ or $g^\sharp_j$; either way it is an isomorphism, so $f+g$ is cartesian.

A position of $p\times q$ (resp.\ of $p\otimes q$) is a pair $(i,j)\in p(\1)\times q(\1)$. The morphism $(f\times g)^\sharp_{i,j}$ is $f^\sharp_i+g^\sharp_j$ (resp.\ $f^\sharp_i\times g^\sharp_j$) which is again an isomorphism if $f^\sharp_i$ and $g^\sharp_j$ are. Hence $f\times g$ (resp.\ $f\otimes g$) is cartesian, completing the proof.
\end{proof}

\begin{proposition}\label{prop.pullback_cartesian}
Let $f\colon p\to q$ be a morphism and $g\colon q'\to q$ a cartesian morphism. Then the pullback $g'$ of $g$ along $p$
\[
\begin{tikzcd}
	p\times_qq'\ar[r]\ar[d]&
	q'\ar[d, "g"]\\
	p\ar[r, "f"']&
	q\ar[ul, phantom, very near end, "\lrcorner"]
\end{tikzcd}
\]
is cartesian.
\end{proposition}
\begin{proof}
This follows from \cref{ex.pullbacks_in_poly} since the pushout of an isomorphism is an isomorphism.
\end{proof}

\begin{theorem}[Cartesian morphisms in $\poly$ are exponentiable]\label{thm.cart_exponentiable}
If $f\colon p\to q$ is cartesian then the functor $f^*\colon\poly/q\to\poly/p$ given by pulling back $q'\to q$ along $f$ is a left adjoint:
\[
\begin{tikzcd}[column sep=50pt, background color=theoremcolor]
	\poly/p\ar[r, shift right=7pt, "f_*"']&
	\poly/q\ar[l, shift right=7pt, "f^*"']\ar[l, phantom, "\Rightarrow"]
\end{tikzcd}
\]
\end{theorem}
\begin{proof}
Fix $e\colon p'\to p$ and $g\colon q'\to q$.
\[
\begin{tikzcd}
	p'\ar[d, "e"']&q'\ar[d, "g"]\\
	p\ar[r, "f"']&q.
\end{tikzcd}
\]
We need to define a functor $f_*\colon\poly/p\to\poly/q$ and prove the analogous isomorphism establishing it as right adjoint to $f^*$. We first establish some notation. Given a set $Q$ and sets $(P'_i)_{i\in I}$, each equipped with a map $Q\to P'_i$, let $Q/\sum_{i\in I}P'_i$ denote the coproduct in $Q/\smset$, or equivalently the wide pushout of sets $P'_i$ with apex $Q$. Then we have the following formula for $f_*p'$, which we write in larger font for clarity:
\begin{equation}\label{eqn.cart_exp}
f_*p'\coloneqq
\scalebox{1.3}{$\displaystyle
\sum_{j\in q(\1)}\;\sum_{i'\in\prod\limits_{i\in f_1\inv(j)}e_1\inv(i)}\;\yon^{q[j]/\sum_{i\in f_1\inv(j)}p'[i'(i)]}.
$}
\end{equation}
Again, $q[j]/\sum_{i\in f_1\inv(j)}p'[i'(i)]$ is the coproduct of the $p'[i'(i)]$, taken in $q[j]/\smset$. Since $p[i]\cong q[f(i)]$ for any $i\in p(\1)$ by the cartesian assumption on $f$, we have the following chain of natural isomorphisms
\begin{align*}
	(\poly/p)(f^*q', p')&\cong
	\prod_{i\in p(\1)}\;\prod_{\{j'\in q'(\1)\,\mid\,g_1(j')=f_1(i)\}}\;\sum_{\{i'\in p'(\1)\,\mid\,e_1(i')=i\}}\;(p[i]/\smset)(p'[i'],p[i]+_{q[f(i)]}q'[j'])\\&\cong
	\prod_{i\in p(\1)}\;\prod_{\{j'\in q'(\1)\,\mid\,g_1(j')=f_1(i)\}}\;\sum_{\{i'\in p'(\1)\,\mid\,e_1(i')=i\}}\;(q[f(i)]/\smset)(p'[i'],q'[j'])\\&\cong
	\prod_{j\in q(\1)}\;\prod_{\{j'\in q'(\1)\,\mid\, g_1(j')=j\}}\;\prod_{\{i\in p(\1)\,\mid\,f_1(i)=j\}}\;\sum_{\{i'\in p'(\1)\,\mid\,e_1(i')=i\}}\;(q[j]/\smset)(p'[i'],q'[j'])\\&\cong
	\prod_{j\in q(\1)}\;\prod_{\{j'\in q'(\1)\,\mid\, g_1(j')=j\}}\;\sum_{i'\in\prod_{i\in f_1\inv(j)}e_1\inv(i)}\;\prod_{i\in f_1\inv(j)}\;(q[j]/\smset)(p'[i'(i)],q'[j'])\\&\cong
	\prod_{j\in q(\1)}\;\prod_{\{j'\in q'(\1)\,\mid\, g_1(j')=j\}}\;\sum_{i'\in\prod_{i\in f_1\inv(j)}e_1\inv(i)}\;(q[j]/\smset)\Big(\sum_{i\in f_1\inv(j)}p'[i'(i)],q'[j']\Big)\\&\cong
	(\poly/q)(q',f_*p')
	&\qedhere
\end{align*}
\end{proof}

\begin{example}
Let $p\coloneqq\2\yon^\2$, $q\coloneqq\yon^\2+\yon^\0$, and $f\colon p\to q$ the unique cartesian morphism between them. Then for any $e\colon p'\to p$ over $p$, \eqref{eqn.cart_exp} provides the following description for the pushforward $f_*p'$. We use the isomorphisms $p(\1)\cong\2$ and $q(\1)\cong\2$ to talk about the positions of $p$ and $q$.

Over the $j=2$ position (which has $q[2]=\0$), we have $\prod_{i\in f_1\inv(2)e_1\inv(i)}\cong\1$ is an empty product, and $q[2]/\sum_{i\in f_1\inv(2)}p'[i'(i)]$ is an empty sum (in $q_2/\smset$), so we get $\yon^\0\cong\1$.

Over the $j=1$ position (which has $q[1]=\2$), we have $\prod_{i'\in f_1\inv(1)e_1\inv(i)}\cong e_1\inv(1)\times e_1\inv(2)$. For each element $i'\in e_1\inv(1)\times e_1\inv(2)$, the sets $p'[i'(1)]$ and $p'[i'(2)]$ are each the codomain of a map from $q[1]=p[1]=p[2]=\2$ coming from $e^\sharp$, and $q[1]/\sum_{i\in\{1,2\}}p'[i'(i)]$ is the pushout $p'[i'(1)]\from\2\to p'[i'(2)]$. Let's call that pushout set $X_{i'}$. Then in sum we have
\[
f_*p'\cong\Big(\sum_{i'\in e_1\inv(1)\times e_2\inv(2)}\yon^{X_{i'}}\Big)+\1.
\]
\end{example}

\begin{exercise}
Prove that the unique map $f\colon\yon\to\1$ is exponentiable.
\begin{solution}
Choose $p\in\poly$ and $q'\in\poly/\yon$. Then there is $q\in\poly$ such that $q'\cong q\yon$, equipped with the projection $q\yon\to\yon$. The pushforward is given by the exponential
\[f_*(q\yon)\coloneqq q^\yon\]
from the cartesian closure; see \cref{eqn.exponential}. Indeed, we have
\begin{align*}
	\poly/\yon(f^*p,q\yon)&\cong
	\poly/\yon(p\yon,q\yon)\\&\cong
	\poly(p\yon,q)\\&\cong
	\poly(p,q^\yon).
\end{align*}
\end{solution}
\end{exercise}

In fact, it is shown in \cite[Theorem 6.3]{Moss-VonGlehn} that $\poly$ is locally cartesian closed.


For any set $A$, let $\poly[A.]$ denote the category whose objects are polynomials $p$ equipped with an isomorphism $A\cong p(\1)$, and whose morphisms are polynomial maps respecting the isomorphisms with $A$.

\begin{proposition}[Base change]\label{prop.basechange}
For any function $f\colon A\to B$, pullback $f^*$ along $f$ induces a functor $\poly[B.]\to\poly[A.]$, which we also denote $f^*$.
\end{proposition}
\begin{proof}
This follows from \eqref{eqn.pullback_poly} with $q\coloneqq A$ and $r\coloneqq B$, since pullback of an iso is an iso.
\end{proof}

\begin{theorem}\label{thm.triple_adjoint_basechange}
For any function $f\colon A\to B$, the pullback functor $f^*$ has both a left and a right adjoint
\begin{equation}\label{eqn.adjoint_triple_monoidal_fib}
\begin{tikzcd}[column sep=large, background color=theoremcolor]
	\poly[A.]\ar[r, shift left=16pt, "f_!"]\ar[r, shift right=16pt, "f_*"']
	\ar[r, phantom, shift left=9pt, "\Rightarrow"]\ar[r, phantom, shift right=9pt, "\Leftarrow"]
&
	\poly[B.]\ar[l, "f^*" description]
\end{tikzcd}
\end{equation}
Moreover $\otimes$ preserves the op-Cartesian arrows, making this a monoidal $*$-bifibration in the sense of \cite[Definition 12.1]{shulman2008framed}.
\end{theorem}
\begin{proof}
Let $p$ be a polynomial with $p(\1)\cong A$. Then the formula for $f_!p$ and $f_*p$ are given as follows:
\begin{equation}\label{eqn.f_!andf_*}
f_!p\cong\scalebox{1.3}{$\displaystyle\sum_{b\in B}\yon^{\big(\prod\limits_{a\mapsto b}p[a]\big)}$}
\qqand
f_*p\cong\scalebox{1.3}{$\displaystyle\sum_{b\in B}\yon^{\big(\sum\limits_{a\mapsto b}p[a]\big)}$}
\end{equation}
It may at first be counterintuitive that the left adjoint $f_!$ involves a product and the right adjoint $f_*$ involves a sum. The reason for this comes from \cref{prop.dlens_self_indexing}, namely that $\poly$ is equivalent to the Grothendieck construction applied to the functor $\smset\op\to\smcat$ sending each set $A$ to the category $(\smset/A)\op$. The fact that functions $f\colon A\to B$ induces an adjoint triple between $\smset/A$ and $\smset/B$, and hence between $(\smset/A)\op$ and $(\smset/B)\op$ explains the variance in \eqref{eqn.f_!andf_*} and simultaneously establishes the adjoint triple \eqref{eqn.adjoint_triple_monoidal_fib}.

The functor $p\mapsto p(\1)$ is strong monoidal with respect to $\otimes$ and strict monoidal if we choose the lens construction as our model of $\poly$. By \cref{prop.monoidal_pres_carts}, the monoidal product $\otimes$ preserves cartesian morphisms; thus we will have established the desired monoidal $*$-bifibration in the sense of \cite[Definition 12.1]{shulman2008framed} as soon as we know that $\otimes$ preserves op-cartesian morphisms.

Given $f$ and $p$ as above, the op-cartesian morphism is the morphism $p\to f_!p$ obtained as the composite $p\to f^*f_!p\to f_!p$ where the first map is the unit of the $(f_!,f^*)$ adjunction and the second is the cartesian morphism for $f_!p$. On positions $p\to f_!p$ acts as $f$, and on directions it is given by projection. 

If $f\colon p(\1)\to B$ and $f'\colon p'(\1)\to B'$ are functions then we have
\begin{align*}
	f_!(p)\otimes f'_!(p')&\cong
	\sum_{b\in B}\sum_{b'\in B'}\yon^{\big(\prod_{a\mapsto b}p[a]\big)\times\big(\prod_{a'\mapsto b'}p'[a']\big)}\\&\cong
	\sum_{(b,b')\in B\times B'}\yon^{\big(\prod_{(a,a')\mapsto(b,b')}p[a]\times p[b]\big)}\\&
	\cong (f_!\otimes f'_!)(p\otimes p')
\end{align*}
and the op-cartesian morphisms are clearly preserved since projections in the second line match with projections in the first.
\end{proof}

%-------- Section --------%
\section{Summary and further reading}

...

Thanks to Joachim Kock for telling me about the derivative $\dot{p}$ of a polynomial and the relationship between $\dot{p}(\1)$ and the total number of leaves of $p$.


See work by Gambino and Kock, Joyal, Paul Taylor, Michael Abbott and Neil Ghani (containers), ....

\Closesolutionfile{solutions}

\section{Exercise solutions}
\footnotesize
\input{solution-file1}

\end{document}
